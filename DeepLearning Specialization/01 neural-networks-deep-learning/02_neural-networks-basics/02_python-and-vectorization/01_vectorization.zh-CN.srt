1
00:00:00,000 --> 00:00:03,195
欢迎回来.向量化基本上就是

2
00:00:03,195 --> 00:00:07,315
一项让你的代码变得更高效的艺术

3
00:00:07,315 --> 00:00:11,835
在深度学习的实际应用中

4
00:00:11,835 --> 00:00:15,210
你可能会遇到大量的训练数据

5
00:00:15,210 --> 00:00:18,475
因为深度学习算法在这个情况下表现更好

6
00:00:18,475 --> 00:00:22,790
所以你的代码运行的运行速度非常重要，否则

7
00:00:22,790 --> 00:00:24,525
如果它运行在一个大的数据集上面

8
00:00:24,525 --> 00:00:27,000
你的代码可能花费很长时间去运行，你会发现

9
00:00:27,000 --> 00:00:30,255
你将要等待非常长的时间去得到结果

10
00:00:30,255 --> 00:00:32,035
所以在深度学习领域

11
00:00:32,035 --> 00:00:37,490
我认为实现向量化的能力已经变成一个关键的技巧

12
00:00:37,490 --> 00:00:40,010
让我们从一个例子开始

13
00:00:40,010 --> 00:00:42,225
让我们用一个例子开始

14
00:00:42,225 --> 00:00:48,780
什么是向量化？

15
00:00:48,780 --> 00:00:55,405
在逻辑回归中，你需要去计算Z=WTX+B

16
00:00:55,405 --> 00:00:58,000
W是列向量，X也是列向量

17
00:00:58,000 --> 00:01:07,080
如果你有很多的特征，那么就会有一个非常大的向量，所以W和X是R内的nx维向量

18
00:01:07,080 --> 00:01:10,170
所以去计算WTX

19
00:01:10,170 --> 00:01:15,660
如果你有一个非向量化的实现

20
00:01:15,660 --> 00:01:18,725
你将会做一些事情，例如Z=0

21
00:01:18,725 --> 00:01:24,860
*pythn代码   i in range(n-x)

22
00:01:24,860 --> 00:01:27,330
*python代码  所以i=1,2....nx

23
00:01:27,330 --> 00:01:34,040
Z plus equals W I times XI. Z+=W[i]*X[i]

24
00:01:34,040 --> 00:01:37,100
所以你在最后z+=b

25
00:01:37,100 --> 00:01:39,855
所以，这是一个非向量化的实现

26
00:01:39,855 --> 00:01:43,090
你会发现这是真的很慢

27
00:01:43,090 --> 00:01:48,560
作为对比，一个向量化的实现将会非常直接计算WTX

28
00:01:48,560 --> 00:01:52,085
在Python 或者numpy

29
00:01:52,085 --> 00:02:01,428
你实现的命令是Z=np.dot(W,X)

30
00:02:01,428 --> 00:02:06,270
这是在计算WTX

31
00:02:06,270 --> 00:02:09,075
你也可以直接加上B

32
00:02:09,075 --> 00:02:12,400
你将会发现这个非常快

33
00:02:12,400 --> 00:02:17,075
让我们用一个小例子说明一下

34
00:02:17,075 --> 00:02:21,960
在我的Jupyter notebook 我将会写一些Python代码

35
00:02:21,960 --> 00:02:28,041
首先，让我们导入numpy库

36
00:02:28,041 --> 00:02:30,000
作为 np，例如

37
00:02:30,000 --> 00:02:36,570
像下面这样我将要创建一个数据A

38
00:02:36,570 --> 00:02:39,560
让我们看下打印A

39
00:02:39,560 --> 00:02:41,160
现在，写下这些代码块

40
00:02:41,160 --> 00:02:43,170
如果我在键盘敲击shift 和 enter 两个键

41
00:02:43,170 --> 00:02:44,847
它将会执行这个代码

42
00:02:44,847 --> 00:02:47,970
所以，它创建了数组A以及打印它

43
00:02:47,970 --> 00:02:50,580
现在，让我们完成向量化的例子

44
00:02:50,580 --> 00:02:51,990
我将要导入time库

45
00:02:51,990 --> 00:02:53,580
因为我要使用那个

46
00:02:53,580 --> 00:02:56,565
为了去计算两次不同的操作花费了多长时间

47
00:02:56,565 --> 00:02:59,139
他们能创建一个数组A吗

48
00:02:59,139 --> 00:03:02,905
通过random.rand函数随机得到

49
00:03:02,905 --> 00:03:10,065
用随机数值创建了一个百万维度的数组

50
00:03:10,065 --> 00:03:13,300
b = np.random.rand.(1000000)

51
00:03:13,300 --> 00:03:16,120
另外一个百万维度的数组

52
00:03:16,120 --> 00:03:20,810
现在 tic=time.time() 测量一下当前时间

53
00:03:20,810 --> 00:03:26,395
c = np.dot (a, b).

54
00:03:26,395 --> 00:03:28,649
toc = time.time.

55
00:03:28,649 --> 00:03:31,950
打印一下

56
00:03:31,950 --> 00:03:34,857
向量化的版本

57
00:03:34,857 --> 00:03:37,685
这是一个向量化的版本

58
00:03:37,685 --> 00:03:41,985
现在让我们打印一下

59
00:03:41,985 --> 00:03:45,060
让我们看一下持续时间

60
00:03:45,060 --> 00:03:48,330
python代码*  toc - tic x 1000

61
00:03:48,330 --> 00:03:52,075
所以我们表达这个在毫秒级上

62
00:03:52,075 --> 00:03:54,075
ms代表毫秒

63
00:03:54,075 --> 00:03:56,435
我将要同时敲击Shift和 Enter

64
00:03:56,435 --> 00:04:01,890
所以这个代码花费3毫秒或者这个时间的1.5倍

65
00:04:01,890 --> 00:04:06,170
或许大概 1.5 或者3.5毫秒 

66
00:04:06,170 --> 00:04:08,370
它有点变化当我再次运行它的时候

67
00:04:08,370 --> 00:04:12,085
但是好像，平均她要花费1.5毫秒

68
00:04:12,085 --> 00:04:15,665
或许我这次运行是2毫秒

69
00:04:15,665 --> 00:04:16,967
好吧那就这样吧！

70
00:04:16,967 --> 00:04:19,005
让我们继续增加这个代码

71
00:04:19,005 --> 00:04:22,270
这是非向量化的版本

72
00:04:22,270 --> 00:04:24,151
让我们看看，c=0

73
00:04:24,151 --> 00:04:27,750
 tic = time.time.

74
00:04:27,750 --> 00:04:29,335
现在它实现了一个loop

75
00:04:29,335 --> 00:04:35,348
python 代码:for i in range 1:1000000

76
00:04:35,348 --> 00:04:38,676
我将要取出0右边的数字

77
00:04:38,676 --> 00:04:43,936
C += (a,i) x (b,i)

78
00:04:43,936 --> 00:04:50,775
以及 toc = time.time.

79
00:04:50,775 --> 00:04:57,725
最后，打印for loop

80
00:04:57,725 --> 00:05:15,225
它花费的时间是1000*toc-tic ms

81
00:05:15,225 --> 00:05:17,505
目的是为了知道我们正在做这个在毫秒级别

82
00:05:17,505 --> 00:05:19,735
让我们再做点其他的事情

83
00:05:19,735 --> 00:05:22,802
我们打印出C的值

84
00:05:22,802 --> 00:05:27,960
计算一下它，确认在两个案例中他们是相同的

85
00:05:27,960 --> 00:05:35,770
我打算去敲击shift和enter去运行这个，检查一下结果

86
00:05:35,770 --> 00:05:38,305
在两个案例中，向量化版本

87
00:05:38,305 --> 00:05:41,125
和非向量化版本计算了相同的值

88
00:05:41,125 --> 00:05:45,355
正如你知道的，250286左右

89
00:05:45,355 --> 00:05:48,670
向量化版本花费了1.5毫秒

90
00:05:48,670 --> 00:05:57,555
很明确，for loop和非向量化版本花费了大约400，几乎500毫秒

91
00:05:57,555 --> 00:06:01,285
非向量化版本多花费了

92
00:06:01,285 --> 00:06:05,660
300倍向量化版本的时间

93
00:06:05,660 --> 00:06:11,230
用这个例子你将会看见如果你仅仅记住去向量化你的代码

94
00:06:11,230 --> 00:06:15,120
你的代码完全运行300倍快

95
00:06:15,120 --> 00:06:16,540
让我们再次运行一下它

96
00:06:16,540 --> 00:06:18,930
再次运行一下它

97
00:06:18,930 --> 00:06:22,235
向量化版本1.5毫秒，循环使用了

98
00:06:22,235 --> 00:06:25,960
481毫秒

99
00:06:25,960 --> 00:06:29,535
大约慢300倍用循环做这个

100
00:06:29,535 --> 00:06:30,980
如果时间变慢

101
00:06:30,980 --> 00:06:33,880
这个有很大的不同在你的代码花费一分钟去运行和

102
00:06:33,880 --> 00:06:37,615
花费5个小时去运行

103
00:06:37,615 --> 00:06:41,410
当你正在实现深度学习算法

104
00:06:41,410 --> 00:06:43,300
你能真正的快速得到一个返回的结果

105
00:06:43,300 --> 00:06:46,590
它将会更快，如果你向量化你的代码

106
00:06:46,590 --> 00:06:49,300
你可能听过很多这样的话

107
00:06:49,300 --> 00:06:54,260
大规模的深度学习使用了GPU或者图像处理单元实现

108
00:06:54,260 --> 00:06:59,515
但是我做的所有的案例都是在Jupiter notebook上面实现，这里只有CPU

109
00:06:59,515 --> 00:07:04,530
CPU和GPU都有并行化的指令

110
00:07:04,530 --> 00:07:07,530
他们有时候会叫做SIMD指令

111
00:07:07,530 --> 00:07:11,190
这个代表了一个单独指令多维数据

112
00:07:11,190 --> 00:07:13,045
这个的基础意义是什么？

113
00:07:13,045 --> 00:07:16,835
如果你使用了built-in函数，像这样

114
00:07:16,835 --> 00:07:23,495
np.function 或者 并不要求你实现循环的函数

115
00:07:23,495 --> 00:07:28,150
这使得python中的numpy充分

116
00:07:28,150 --> 00:07:33,640
利用并行化去更快的计算

117
00:07:33,640 --> 00:07:38,610
这是事实在GPU和CPU上面计算

118
00:07:38,610 --> 00:07:41,070
GPU被标记更加擅长

119
00:07:41,070 --> 00:07:44,980
SIMD计算但是CPU事实上也不是太差

120
00:07:44,980 --> 00:07:47,510
可能没有GPU那么擅长吧

121
00:07:47,510 --> 00:07:51,660
你看下，怎么向量化能够加速你的代码

122
00:07:51,660 --> 00:07:54,685
经验规律是无论什么时候

123
00:07:54,685 --> 00:07:57,425
都避免使用明确的for循环

124
00:07:57,425 --> 00:07:59,980
让我们进入到下一个视频去看下更多的向量化的案例

125
00:07:59,980 --> 00:08:04,000
和开始学习向量化逻辑回归