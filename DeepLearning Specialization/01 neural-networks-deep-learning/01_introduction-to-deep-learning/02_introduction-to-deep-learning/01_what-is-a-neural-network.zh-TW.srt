1
00:00:01,050 --> 00:00:03,840
深度學習這個專有名詞
指的是訓練神經網路

2
00:00:03,840 --> 00:00:06,050
有時候很大的神經網路

3
00:00:06,050 --> 00:00:08,400
到底什麼是神經網路?

4
00:00:08,400 --> 00:00:11,340
在這段影片中, 讓我給您
一些基本的直觀

5
00:00:12,850 --> 00:00:16,540
讓我們從
房價預測例子開始

6
00:00:16,540 --> 00:00:20,599
假設您有一個資料集有
六個房子, 您知道這些房子的大小是

7
00:00:20,599 --> 00:00:24,478
多少平方呎或者多少平方米
您也知道房價，您想要

8
00:00:24,478 --> 00:00:28,501
用一個函數來預測
房價, 房子大小的函數

9
00:00:28,501 --> 00:00:33,509
如果您熟悉線性
迴歸分析, 您也許會說，讓我們

10
00:00:33,509 --> 00:00:38,450
用一條直線來配這些資料
所以我們得到一條直線像這樣

11
00:00:38,450 --> 00:00:41,850
但加一點點花樣, 您會說
我們知道價格

12
00:00:41,850 --> 00:00:43,770
永遠不會是負數

13
00:00:43,770 --> 00:00:48,050
所以與其使用直線來配
最終會變負數

14
00:00:48,050 --> 00:00:49,960
讓我們扳一下這個曲線

15
00:00:49,960 --> 00:00:51,530
在這裡它會變成 0 

16
00:00:51,530 --> 00:00:56,770
這個厚的藍色線最終
會是您的函數來

17
00:00:56,770 --> 00:00:59,760
預測房價
以房子的大小的函數

18
00:00:59,760 --> 00:01:03,310
而0在這裡然後有
這一條線配到右邊

19
00:01:04,408 --> 00:01:08,735
您可以想像這個函數
您用來配這些房價

20
00:01:08,735 --> 00:01:11,880
是很簡單的神經網路

21
00:01:11,880 --> 00:01:14,230
這幾乎是最簡單的神經網路

22
00:01:14,230 --> 00:01:15,000
讓我畫在這裡

23
00:01:17,220 --> 00:01:22,170
我們有一個輸入到這個神經網路
房子大小我們稱為 x

24
00:01:22,170 --> 00:01:26,791
它進入這個節點
這個小圓圈

25
00:01:26,791 --> 00:01:30,940
然後輸出價格我們稱為 y

26
00:01:30,940 --> 00:01:37,183
所以這個小圓圈, 是一個
單一神經元在神經網路中

27
00:01:37,183 --> 00:01:41,830
建立這個函數
我們畫在左邊

28
00:01:43,350 --> 00:01:48,940
這個神經元做的是輸入
大小, 計算這個線性函數

29
00:01:48,940 --> 00:01:51,960
取最大值 0, 
然後輸出預測價格

30
00:01:53,190 --> 00:01:58,230
順便說一下在神經網路
論文中, 您會常看到這個函數

31
00:01:58,230 --> 00:02:00,992
這個函數先從
0一段時間然後

32
00:02:00,992 --> 00:02:03,550
它會起飛成一條直線

33
00:02:03,550 --> 00:02:09,108
這個函數稱為 ReLU
函數是

34
00:02:09,108 --> 00:02:17,620
線性整流函數 (Rectified Linear Unit)

35
00:02:17,620 --> 00:02:18,252
所以 R-E-L-U 
而

36
00:02:18,252 --> 00:02:22,520
整流的意思是取極大值 0
是為什麼您得到的函數形狀像這樣

37
00:02:23,640 --> 00:02:25,550
您現在不需要擔心
有關 ReLU

38
00:02:25,550 --> 00:02:30,200
但只是
您會在以後的課程中再見到它

39
00:02:30,200 --> 00:02:33,790
所以如果這是一個單一神經元
神經網路

40
00:02:33,790 --> 00:02:38,870
實在是極小神經網路
而一個大型的神經網路

41
00:02:38,870 --> 00:02:44,520
是由很多的
單一神經元堆疊在一起

42
00:02:44,520 --> 00:02:50,700
如果您想像這個神經元
像是樂高積木一樣, 您可以

43
00:02:50,700 --> 00:02:55,270
得到一個大的神經網路用
很多的這些樂高積木疊在一起

44
00:02:55,270 --> 00:02:56,110
我們來看個例子

45
00:02:57,260 --> 00:03:02,220
假設與其只使用
房子大小來預測房價

46
00:03:02,220 --> 00:03:04,330
您現在有其他的特徵

47
00:03:04,330 --> 00:03:08,164
您知道房子其他東西
像是臥房數目

48
00:03:08,164 --> 00:03:13,630
我把它寫成 #bedrooms, 
您也許想一件事

49
00:03:13,630 --> 00:03:18,820
真得會影響房價
是家庭的大小

50
00:03:18,820 --> 00:03:21,882
這間房子
適合您三個, 四個或是

51
00:03:21,882 --> 00:03:22,687
五個家庭成員?

52
00:03:22,687 --> 00:03:26,351
而這實際上基於房子大小
幾平方呎或幾平方米而

53
00:03:26,351 --> 00:03:28,960
房間臥房數目
決定了是否

54
00:03:28,960 --> 00:03:31,462
一個房子可以配合
您家庭成員多寡

55
00:03:31,462 --> 00:03:34,909
然後也許您知道
郵遞區號 (zip code)

56
00:03:34,909 --> 00:03:40,520
不同國家稱之為郵遞區號 (postal code)

57
00:03:40,520 --> 00:03:48,820
而這郵遞區號也許
代表您的可行走性

58
00:03:48,820 --> 00:03:51,434
所以這個區域是高可步行性?

59
00:03:51,434 --> 00:03:53,635
像是走路到雜貨店

60
00:03:53,635 --> 00:03:54,194
走路到學校

61
00:03:54,194 --> 00:03:55,250
需要開車嗎?

62
00:03:55,250 --> 00:03:57,870
有些人喜歡高度可步行性區域

63
00:03:57,870 --> 00:04:06,145
郵遞區號
或許跟富有程度會告訴您

64
00:04:06,145 --> 00:04:09,200
在美國確是如此但
一些國家也是

65
00:04:09,200 --> 00:04:13,590
告訴您學校的品質

66
00:04:13,590 --> 00:04:17,820
所以每個這種小圈圈
畫在這裡一些可能是 ReLU

67
00:04:17,820 --> 00:04:22,670
線性整流函數, 或者一些是稍微非線性函數

68
00:04:22,670 --> 00:04:24,936
基於房子大小跟
跟臥房數目

69
00:04:24,936 --> 00:04:28,420
你可以估計家庭的規模，
他們的郵遞區號，預估可步行性，

70
00:04:28,420 --> 00:04:32,050
基於郵遞區號跟
富有狀況來預估學校品質

71
00:04:32,050 --> 00:04:35,660
最後您也許想
人們用來決定花多少錢

72
00:04:35,660 --> 00:04:38,880
買一間房子是基於
一些真的對他們重要的事情

73
00:04:38,880 --> 00:04:43,060
在這裡是家族成員
可步行性跟學校品質而

74
00:04:43,060 --> 00:04:45,210
這些幫助您預估房價

75
00:04:46,330 --> 00:04:51,740
所以在這個例子中，x 是所有這些四個輸入

76
00:04:53,470 --> 00:04:56,460
y 是你想要
預測的價格

77
00:04:57,960 --> 00:05:03,350
所以將這些
單獨的神經元或簡單的預測堆疊在一起

78
00:05:03,350 --> 00:05:07,360
就像之前的這些投影片一樣, 我們現在
有一稍微大的神經網路

79
00:05:07,360 --> 00:05:10,850
您要如何管理神經網路
也就是當您建置它時

80
00:05:10,850 --> 00:05:15,860
您需要給一個輸入 x

81
00:05:15,860 --> 00:05:20,740
輸出 y 一些
您訓練集的例子

82
00:05:20,740 --> 00:05:23,580
所有中間的這些
它們會自己搞定

83
00:05:25,435 --> 00:05:29,225
您真正建立的會是

84
00:05:29,225 --> 00:05:32,055
您有一個神經
網路有四個輸入

85
00:05:32,055 --> 00:05:35,455
輸入的特徵會是房子大小
臥房數目

86
00:05:35,455 --> 00:05:40,365
郵遞區號跟
鄰居的財富情況

87
00:05:40,365 --> 00:05:44,805
所以給予這些輸入特徵

88
00:05:44,805 --> 00:05:50,200
這個神經網路的工作
就是預估房價

89
00:05:50,200 --> 00:05:55,942
請注意到這些
圓圈, 這些是稱為隱藏單元

90
00:05:55,942 --> 00:06:02,310
在神經網路裡這些每一個
拿進這四個輸入的特徵

91
00:06:02,310 --> 00:06:08,139
所以在這個例子, 與其說這
第一個單元代表家族大小而

92
00:06:08,139 --> 00:06:12,056
家族大小只依據於特徵
 x1 跟 x2, 

93
00:06:12,056 --> 00:06:15,302
我們這麼說
神經網路

94
00:06:15,302 --> 00:06:18,200
在神經網路, 您決定
這些節點是什麼

95
00:06:18,200 --> 00:06:21,070
我們會給您所有四個輸入特徵
來計算您想要的

96
00:06:21,070 --> 00:06:26,170
所以我們說這些層
是這個輸入層跟

97
00:06:26,170 --> 00:06:28,960
這些中間層
在神經網路中是緊密連接

98
00:06:28,960 --> 00:06:31,740
因為每一個輸入特徵連接了
每一個

99
00:06:31,740 --> 00:06:33,980
在中間層的圓圈

100
00:06:33,980 --> 00:06:38,630
而值得注意的是神經
網路只要給予足夠的資料 x

101
00:06:38,630 --> 00:06:43,290
跟 y, 給予足夠的訓練例子
 x 跟 y, 神經網路

102
00:06:43,290 --> 00:06:47,450
會非常好的找出
函數來對應從 x 到 y

103
00:06:48,990 --> 00:06:51,680
所以這是基本的神經網路

104
00:06:51,680 --> 00:06:54,290
實際上當您建立您的
神經網路

105
00:06:54,290 --> 00:06:57,130
您或許會發現他們是最有用
最強大

106
00:06:57,130 --> 00:07:01,620
在監督式學習裡, 意思是
您試著拿輸入 x

107
00:07:01,620 --> 00:07:06,980
對應一些輸出 y, 像我們剛剛看到的
房價預測的例子

108
00:07:06,980 --> 00:07:11,490
在下一段影片中，讓我們試著
一些更多的監督式學習的例子

109
00:07:11,490 --> 00:07:15,670
一些例子, 您也許會發現
神經網路會無比的有用

110
00:07:15,670 --> 00:07:16,670
在一些應用上