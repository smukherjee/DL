다시 환영합니다. vectorization은 기본적으로 코딩에서 명백한 for loop들을 제거하는 기술인데요 딥러닝 세대에서, 특히 딥러닝 실행부분에서는 여러분은 비교적 큰 데이터세트에서 트레이닝 하는 것을 보실 텐데요, 그 이유는 그 분야에서 딥러닝 알고리즘이 특출 나기 때문입니다. 그렇기 때문에 코딩을 빨리 진행하는 것이 매우 중요합니다. 딥러닝이 빅 데이터세트에서 실행되기 때문에, 여러분의 코드가 실행하는데 오래 걸릴 수도 있는데요, 그렇게 되면 결과값을 기다리는데 오래 걸릴 수도 있게 됩니다. 그러면 딥러닝 세대에서는, 제 생각에는 vectorization을 진행 할 수 있는 것이 핵심 기술인 것 같습니다. 예제를 보겠습니다. 우선 예제를 봅시다. vectorization은 무엇일까요? 로지스틱 회귀분석에서는 z = w transpose x 더하기 b를 계산해야 됩니다. w는 세로줄 벡터이고 x도 이런 벡터였죠. 여러 가지 특성이 있으면 벡터도 큰 것으로 이루어질 수 있겠죠 그러면 w 와 x는 모두 여기 R 의 n이거나 R의 nx dimension의 벡터겠죠. 그러면 w transpose x를 계산하자면, 여러분이 만약 non-vectorized 도입을 했다면, z 가 0인 것으로 했을 것입니다. 그리고 i는 n-x의 범위를 갖도록 하구요 즉, i 가 1에서 nx까지 인 것이죠, z 플러스는 wi 곱하기 xi입니다. 그리고 z 플러스 b를 끝에 할 수도 있겠죠. 이것이 non-vectorized 도입 방식인데요, 이렇게 하면 매우 느릴 것입니다. 반대로, vectorized 된 도입은, w transpose x를 직접 계산합니다. 파이썬이나 넘피에서 말이죠, 쓰는 명령은 z = np 점 (w, x)인데요 이 값은 w tanspose x입니다. 그리고 직접 b를 여기다 더할 수도 있습니다. 이것이 더 빠른 것을 느끼실 텐데요, 데모를 통해 한번 묘사해보겠습니다. 이것은 Jupiter notebook인데요, 여기다가 파이썬 코드를 적어보겠습니다. 처음으로는, 넘피 library를 불러오겠습니다. as np로 말이죠, 예를 들어, A를 작성해서, array로 말이죠, 그리고 print a를 타입 해보겠습니다. 그럼 여기 코드를 적었으니, 이제 shit + enter를 누르면, 코드를 실행합니다. 이제 array A를 생성했고 print out 합니다. 이제 vectorization 데모도 한번 해보겠습니다. 이제 time library를 불러올 텐데요, 이것을 이용하기 때문이죠, 다른 운영작업이 얼마나 걸리는지 시간을 재기 위해서 말이죠. array A를 생성할 것입니다. 이것은 random 점 rand 이고... 이제 백만 다이멘션을 만들어보겠습니다. b = np.random.rand.입니다. 그리고 또 하나의 백만 개 array이고요, 이제 tic=time.time인데요, 이것은 현재시간을 측정합니다. c = np.dot (a, b)이고요, toc은 time.time입니다. 이제 프린트 해볼까요? 이것은 vectorized 버전인데요, vectorized version을 타이핑하겠습니다. 그러면 이제 이전 것을 print out 할 텐데요, 이것은 toc 빼기 tic 곱하기 100인데요 이렇게 해서 밀리세컨즈로 표현하겠습니다. ms가 밀리세컨즈입니다. 이제 shift+enter를 칠 것입니다. 그러면 이 코드를 만드는 세 3 milliseconds가 걸렸거나 이번 경우 1.5인데요, 한번에 1.5 또는 3.5 밀리세컨즈 소요됩니다. 제가 실행하면서 조금씩 다르긴 한데요, 평균적으로는 1.5 밀리세컨즈가 소요되는 것 같습니다. 이것을 실행하면 2 밀리세컨즈 소요될 수 있죠. 자 그럼, 좋아요. 이런 코드 블럭을 계속 더해보겠습니다. 이제는 non-vectorize 버전을 도입해보겠습니다. c=0이고요, 그리고 tic = time.time 이제 공식을 도입해보겠습니다. I의 범위가 백만이고 0의 개수를 잘 썼길 바랍니다. C += (a, i) x (b, i)이고요, 그리고 toc는 time.time입니다. 마지막으로, print "for loop"을 칩니다. 소요되는 시간은 여기 1000 곱하기 tox - tic + "ms" 입니다. 밀리세컨즈로 표기하기 위해 말이죠. 한가지만 더 하겠습니다. 여기 C의 값을 print out 하겠습니다. 저희가 계산한 값을 print out해서 2가지의 경우 모두 동일한 값임을 확인하겠습니다. 저는 이제 shift + enter를 눌러서 실행하고 확인해보겠습니다. 두 가지 경우 모두, vectorized 버전과 non-vectorized version모두 동일한 값을 산출했습니다. 여러분도 알다시피 2.5에서 6.99 등등 말이죠 vectorized 버전은 1.5 밀리세컨즈가 소요됐고 explicit for loop non-vectorized 버전은 400, 거의 500밀리세컨즈 소요됐습니다. 이렇게 non-vectorize 버전이 거의 300배 가까이 더 오래 걸렸습니다. 이번 예제를 통해서 여러분이 코드만 vectorize 할 줄 알더라도 300배는 더 빨리 실행된다는 것을 보았습니다. 다시 한번 실행해보겠습니다. 다시 한번이요. 예, 맞죠, vectorized 버전은 1.5 밀리세컨즈, 그리고 for loop 의 경우 481 밀리세컨즈 입니다. 거의 300배는 느리죠. for loop의 경우가요. 300배 느린 점의 차이는 여러분의 코드가 1분이 걸리거나 5시간이 걸리는 차이이기도 합니다. 그리고 여러분이 딥러닝 알고리즘을 도입하는 경우에 결과값을 훨씬 더 빨리 알아낼 수 있습니다. code를 vectorize하는 경우 훨씬 더 빠를 것입니다. ‘Scalable Deep Learning’ 도입이 GPU 또는 Graphic Processing Unit에서 이루어진다는 것을 들으셨을 것입니다. 하지만 제가 the Jupiter notebook에서 방금 한 데모들은 모두 CPU에서 한 것입니다. 알고 보면 CPU와 GPU 모두 parallelization instruction이 있습니다. 가끔씩 이런 것을SIMD instructions이라 합니다. 이것은 single instruction multiple data의 약자입니다. 기본적으로 무슨 뜻이냐면, 이런 빌트인 기능을 이용하면, np. function 이나 다른 for loop의 도입이 필요 없는 기능을요, 그런 경우, 파이썬 Pi 가 parallelism을 활용할 수 있게 계산을 빨리 처리하도록 해줍니다. 이러한 산출에 관련한 내용은 CPU와 GPU에서 모두 적용되고요. 하지만 GPU가 특별히 SIMD calculations 에 뛰어나기 때문에 그렇습니다. 하지만 CPU도 나쁘지 않습니다. GPU보단 조금 못하더라도 말이죠. 여러분은 어떻게 vectorizarion이 여러분의 코드의 속도를 현저하게 높일 수 있는지 보실 수 있습니다 기억하실 경험 의거 규칙은 가능하면, explicit for loop을 사용하는 것을 피하라는 것입니다. 다음 비디오로 넘어가서 더 많은 vectorization 예제를 살펴보고 로지스틱 회귀분석을 vectorization하는 방법을 배우겠습니다.