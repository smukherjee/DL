1
00:00:00,000 --> 00:00:03,224
तो डीप लर्निंग का क्या सम्बंध है मस्तिष्क से?

2
00:00:03,224 --> 00:00:06,918
पंचलाइन बता देने का ख़तरा मोल लेते हुए, मैं कहूँगा, बहुत ज़्यादा नहीं.

3
00:00:06,918 --> 00:00:11,539
लेकिन चलो देखते हैं एक झलक में कि 
क्यों लोग समानता बनाते हैं डीप

4
00:00:11,539 --> 00:00:13,400
लर्निंग और मानव मस्तिष्क में.

5
00:00:13,400 --> 00:00:17,624
जब आप इम्प्लमेंट करते हैं एक न्यूरल नेटवर्क, 
यह है जो आप करते हैं, फ़ॉर्वर्ड प्रोप और

6
00:00:17,624 --> 00:00:18,302
बैक प्रॉप.

7
00:00:18,302 --> 00:00:22,774
और मैं सोचता हूँ क्योंकि यह कठिन है 
दे पाना अनुभव कि क्या ये

8
00:00:22,774 --> 00:00:27,122
इक्वेज़न्स कर रहीं हैं वास्तव में ग्रेडीयंट डिसेंट, 
एक तरह से एक बहुत जटिल फ़ंक्शन.

9
00:00:27,122 --> 00:00:30,857
समानता कि यह है मस्तिष्क जैसे बन गया है, वास्तव में,

10
00:00:30,857 --> 00:00:34,380
एक अत्यधिक सरलीकृत विवरण कि यह क्या कर रहा है.

11
00:00:34,380 --> 00:00:37,707
लेकिन इसकी सरलता बनाती है इसे एक तरह से आकर्षक

12
00:00:37,707 --> 00:00:41,898
लोगों के लिए जो सिर्फ़ कहते हैं इसे सार्वजनिक रूप से 
तथा मीडिया को इसे बताने के लिए, और

13
00:00:41,898 --> 00:00:44,808
इसने निश्चित रूप से लोकप्रिय कल्पना बनाया है.

14
00:00:44,808 --> 00:00:49,214
और वहाँ थोड़ी बहुत समानता है दोनो में, मान लो,

15
00:00:49,214 --> 00:00:54,468
एक लॉजिस्टिक रेग्रेशन यूनिट जिसमें 
एक सिग्मोईड ऐक्टिवेशन फ़ंक्शन है और

16
00:00:54,468 --> 00:00:58,427
यहाँ है एक चित्र एक अकेले न्यूरॉन का मस्तिक में.

17
00:00:58,427 --> 00:01:02,326
इस चित्र में एक जैविक न्यूरॉन की, यह न्यूरॉन,

18
00:01:02,326 --> 00:01:07,941
जो है एक सेल आपके मस्तिष्क में,
 प्राप्त करती है संकेत अन्य न्यूरॉन्स से.

19
00:01:07,941 --> 00:01:12,056
हो सकता है कि x1, x2, x3, या अन्य न्यूरॉन्स से,
 हो सकता है, a1, a2, a3.

20
00:01:12,056 --> 00:01:17,419
करती है एक सरल थ्रेशोल्ड कॉम्प्यूटेशन, और फिर
 यदि यह न्यूरॉन फायर होता है, यह भेजता है

21
00:01:17,419 --> 00:01:23,366
बिजली का एक पल्स ऐक्सॉन से, 
इस लम्बी तार से, शायद अन्य न्यूरॉन्स को.

22
00:01:23,366 --> 00:01:28,181
तो वहाँ एक बहुत सरल समानता है एक लॉजिस्टिक यूनिट में,

23
00:01:28,181 --> 00:01:31,365
एक न्यूरॉन में जो एक न्यूरल नेटवर्क में है और

24
00:01:31,365 --> 00:01:34,809
एक जैविक न्यूरॉन में जो यहाँ पर दिखाया गया है.

25
00:01:34,809 --> 00:01:39,356
लेकिन मुझे लगता है कि आज भी न्यूरो साययंटिस्ट्स को
 लगभग पता नहीं क्या

26
00:01:39,356 --> 00:01:41,441
एक अकेला न्यूरॉन करता है.

27
00:01:41,441 --> 00:01:45,532
एक सिंगल न्यूरॉन प्रतीत होता है अधिक जटिल
 तुलना में जितना हम कर पाए हैं

28
00:01:45,532 --> 00:01:48,141
चिन्हित तंत्रिका विज्ञान में.

29
00:01:48,141 --> 00:01:52,719
और जबकि कुछ जो यह कर रहा है वह है थोड़ा 
बहुत लॉजिस्टिक रेग्रेशन जैसे,

30
00:01:52,719 --> 00:01:56,866
फिर भी बहुत कुछ है जो कि एक अकेला न्यूरॉन 
कर रहा है वह कोई भी नहीं,

31
00:01:56,866 --> 00:01:59,101
नहीं कोई मनुष्य, आज समझता है.

32
00:01:59,101 --> 00:02:00,091
उदाहरण के लिए,

33
00:02:00,091 --> 00:02:05,713
वास्तव में कैसे न्यूरॉन्स मानवीय मस्तिष्क में 
सीखते हैं अभी भी एक बहुत रहस्यमय प्रक्रिया है.

34
00:02:05,713 --> 00:02:09,897
और यह पूरी तरह से आज स्पष्ट नहीं है कि क्या 
मानव मस्तिष्क एक अल्गोरिद्म का उपयोग करता है

35
00:02:09,897 --> 00:02:14,269
जो है कुछ बैक प्रॉपगेशन जैसा, या ग्रेडीयंट डिसेंट, 
या क्या वहाँ है कुछ

36
00:02:14,269 --> 00:02:18,277
मौलिक रूप से अलग सीखने के सिद्धांत है 
जो मानव मस्तिष्क उपयोग करता है.

37
00:02:18,277 --> 00:02:23,515
तो जब मैं सोचता हूँ डीप लर्निंग के बारे में, मैं सोचता हूँ
 इसका सीखने में बहुत अच्छा होने के बारे में सीखने के लिए

38
00:02:23,515 --> 00:02:28,679
बहुत नम्य फ़ंक्शन्स, बहुत जटिल फ़ंक्शन्स, 
सीखना x-से-y मैपिंग़्स,

39
00:02:28,679 --> 00:02:32,614
सीखना इनपुट-आउट्पुट मैपिंग़्स सूपर्वायज़्ड लर्निंग में.

40
00:02:32,614 --> 00:02:37,205
और जबकि यह है जैसे मस्तिष्क के साथ समानता, 
शायद वह उपयोगी थी कभी,

41
00:02:37,205 --> 00:02:41,960
मैं सोचता हूँ क्षेत्र अब पहुँच गया है उस पोईंट 
जहाँ वह समानता नहीं बची है.

42
00:02:41,960 --> 00:02:45,633
और मैं कोशिश करता हूँ वह समानता 
इस्तेमाल नहीं करने की आजकल.

43
00:02:45,633 --> 00:02:48,809
तो इतना है न्यूरल नेटवर्क और मस्तिष्क पर.

44
00:02:48,809 --> 00:02:52,554
मैं अवश्य सोचता हूँ शायद कम्प्यूटर विज़न के क्षेत्र ने
 ली है थोड़ी अधिक

45
00:02:52,554 --> 00:02:56,684
प्रेरणा मानव मस्तिष्क से बजाय अन्य विषयों 
जिनमें भी अप्लाई होता है डीप

46
00:02:56,684 --> 00:02:57,333
लर्निंग.

47
00:02:57,333 --> 00:03:02,835
लेकिन मैं व्यक्तिगत रूप से मानव मस्तिष्क से 
समानता कम इस्तेमाल करता हूँ पहले की अपेक्षा.

48
00:03:02,835 --> 00:03:05,216
तो बस इतना ही इस वीडियो में.

49
00:03:05,216 --> 00:03:08,423
अब आप जानते है कि कैसे इम्प्लमेंट करना है 
फ़ॉर्वर्ड प्रॉप और बैक प्रॉप और

50
00:03:08,423 --> 00:03:11,182
ग्रेडीयंट डिसेंट डीप न्यूरल नेटवर्क्स के लिए भी.

51
00:03:11,182 --> 00:03:13,408
अभ्यास के लिए शुभ कामनाएँ, और

52
00:03:13,408 --> 00:03:17,109
मैं तत्पर हूँ साँझा करने के लिए और अधिक ये 
आइडियाज़ आपके साथ अगले कोर्स में.