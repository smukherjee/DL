1
00:00:00,000 --> 00:00:03,195
戻ってきましたね
ベクトル化は

2
00:00:03,195 --> 00:00:07,315
for loop をコードに
書かないようにする技術です

3
00:00:07,315 --> 00:00:11,835
深層学習時代や
深層学習の実践では

4
00:00:11,835 --> 00:00:15,210
比較的巨大なデータセットを
学習に使うことがあります

5
00:00:15,210 --> 00:00:18,475
このような状況でこそ
深層学習のアルゴリズムが輝くからです

6
00:00:18,475 --> 00:00:22,790
コードの実行速度が
速いことが重要です

7
00:00:22,790 --> 00:00:24,525
さもないと
巨大なデータの時には

8
00:00:24,525 --> 00:00:27,000
学習時に
コードの実行に長時間かかり

9
00:00:27,000 --> 00:00:30,255
結果がでるまでに
非常に長い時間待つことになります

10
00:00:30,255 --> 00:00:32,035
このため深層学習時代には

11
00:00:32,035 --> 00:00:37,490
ベクトル化するスキルが
鍵のひとつになりました

12
00:00:37,490 --> 00:00:40,010
例を見る事から始めよう。

13
00:00:40,010 --> 00:00:42,225
ではベクトル化とは
何でしょうか

14
00:00:42,225 --> 00:00:48,780
ロジステック回帰では
Z=Wの転置かけるX+bを計算する必要があります

15
00:00:48,780 --> 00:00:55,405
Wは列のベクトルで
Xもまたベクトルです

16
00:00:55,405 --> 00:00:58,000
多くの特徴量があるときは
非常に大きなベクトルになるでしょう

17
00:00:58,000 --> 00:01:07,080
WもXも
RのnX次元のベクトルです

18
00:01:07,080 --> 00:01:10,170
Wの転置かけるXの計算には

19
00:01:10,170 --> 00:01:15,660
万がいち
ベクトル化せずに実装する場合には

20
00:01:15,660 --> 00:01:18,725
こんな風にするでしょう
まずZ=0 と書き

21
00:01:18,725 --> 00:01:24,860
for i in range(nX) と書き

22
00:01:24,860 --> 00:01:27,330
i は１からnXになり

23
00:01:27,330 --> 00:01:34,040
Z+=W[i]*X[i]と書き

24
00:01:34,040 --> 00:01:37,100
Z+=b を最後に書くでしょう

25
00:01:37,100 --> 00:01:39,855
これがベクトル化しない場合の
実装です

26
00:01:39,855 --> 00:01:43,090
これだと本当に遅いことが
分かるでしょう

27
00:01:43,090 --> 00:01:48,560
対照的にベクトル化した実装だと
Wの転置かけるXを直接計算します

28
00:01:48,560 --> 00:01:52,085
Python やnumpy では

29
00:01:52,085 --> 00:02:01,428
Z=np.dot(W,X)のコマンドを使います

30
00:02:01,428 --> 00:02:06,270
これでWの転置かけるXが
計算できます

31
00:02:06,270 --> 00:02:09,075
これにb を
足せばよいだけです

32
00:02:09,075 --> 00:02:12,400
この方法のほうが
かなり速いことが分かります

33
00:02:12,400 --> 00:02:17,075
実際の例をデモで
例示します

34
00:02:17,075 --> 00:02:21,960
この私のJupyter Notebook に
Python のコードを書きます

35
00:02:21,960 --> 00:02:28,041
まずnumpy のライブラリを
np としてインポートします

36
00:02:28,041 --> 00:02:30,000
例えば

37
00:02:30,000 --> 00:02:36,570
a をこのように
array として作ります

38
00:02:36,570 --> 00:02:39,560
print(a)
してみましょう

39
00:02:39,560 --> 00:02:41,160
こんな風にコードを書いて

40
00:02:41,160 --> 00:02:43,170
shift+enter を押すと

41
00:02:43,170 --> 00:02:44,847
コードが実行されます

42
00:02:44,847 --> 00:02:47,970
array a を作り
結果を出力します

43
00:02:47,970 --> 00:02:50,580
ベクトル化のデモをしましょう

44
00:02:50,580 --> 00:02:51,990
time ライブラリを
インポートします

45
00:02:51,990 --> 00:02:53,580
これを使い

46
00:02:53,580 --> 00:02:56,565
異なる演算の実行時間を
測ります

47
00:02:56,565 --> 00:02:59,139
array a を作ります

48
00:02:59,139 --> 00:03:02,905
random.rand で

49
00:03:02,905 --> 00:03:10,065
乱数値の格納された
百万の長さのarray を作ります

50
00:03:10,065 --> 00:03:13,300
b = np.random.rand で

51
00:03:13,300 --> 00:03:16,120
もう１つarrayを作ります

52
00:03:16,120 --> 00:03:20,810
tic = time.time() として
今の時刻を取得します

53
00:03:20,810 --> 00:03:26,395
c = np.dot(a,b) と書き

54
00:03:26,395 --> 00:03:28,649
toc = time.time() と書き

55
00:03:28,649 --> 00:03:31,950
print を使用して

56
00:03:31,950 --> 00:03:34,857
ベクトル化版を表すように

57
00:03:34,857 --> 00:03:37,685
vectorize version: と書きます

58
00:03:37,685 --> 00:03:41,985
実行最終時刻のtoc から

59
00:03:41,985 --> 00:03:45,060
tic を引いた

60
00:03:45,060 --> 00:03:48,330
(toc-tic)かける1,000を行い

61
00:03:48,330 --> 00:03:52,075
ミリ秒単位で
表現するようにします

62
00:03:52,075 --> 00:03:54,075
ms がミリ秒です

63
00:03:54,075 --> 00:03:56,435
shift+enter を押します

64
00:03:56,435 --> 00:04:01,890
コードの実行時間は
約３ミリ秒か1.5ミリ秒でした

65
00:04:01,890 --> 00:04:06,170
時により1.5ミリ秒か
3.5ミリ秒くらいかかります

66
00:04:06,170 --> 00:04:08,370
少し実行時間に差が出ますが

67
00:04:08,370 --> 00:04:12,085
平均で1.5ミリ秒か２ミリ秒くらいが

68
00:04:12,085 --> 00:04:15,665
実行時間です

69
00:04:15,665 --> 00:04:16,967
こんにちは

70
00:04:16,967 --> 00:04:19,005
ここにコードを追加していきます

71
00:04:19,005 --> 00:04:22,270
ベクトル化していないコードを
実装しましょう

72
00:04:22,270 --> 00:04:24,151
c = 0 と書き

73
00:04:24,151 --> 00:04:27,750
tic = time.time()と書き

74
00:04:27,750 --> 00:04:29,335
for loop を実装します

75
00:04:29,335 --> 00:04:35,348
for i in range(1000000)と書き

76
00:04:35,348 --> 00:04:38,676
私は０を正しく書けましたかね

77
00:04:38,676 --> 00:04:43,936
C += a[i] * b[i]と書き

78
00:04:43,936 --> 00:04:50,775
toc = time.time()と書き

79
00:04:50,775 --> 00:04:57,725
最後にfor loop を
print します

80
00:04:57,725 --> 00:05:15,225
経過時間は1,000*(toc -tic ) + msで

81
00:05:15,225 --> 00:05:17,505
ミリ秒なのを
表します

82
00:05:17,505 --> 00:05:19,735
もう１つ追加しましょう

83
00:05:19,735 --> 00:05:22,802
計算したc の値を表示して

84
00:05:22,802 --> 00:05:27,960
両方の方法で同じ値か
確認できるようにします

85
00:05:27,960 --> 00:05:35,770
shift+enter を押して実行します
確認しましょう

86
00:05:35,770 --> 00:05:38,305
ベクトル化版でも

87
00:05:38,305 --> 00:05:41,125
非ベクトル化版でも
同じ値が計算されました

88
00:05:41,125 --> 00:05:45,355
250286.99...と続く値です

89
00:05:45,355 --> 00:05:48,670
ベクトル化版は
1.5ミリ秒で

90
00:05:48,670 --> 00:05:57,555
for loop を使った非ベクトル版では
約400から500ミリ秒を超えそうな時間です

91
00:05:57,555 --> 00:06:01,285
非ベクトル版は約300倍ほど

92
00:06:01,285 --> 00:06:05,660
ベクトル版よりも
長い時間がかかりました

93
00:06:05,660 --> 00:06:11,230
この例でみるように
ベクトル化することさえ忘れなければ

94
00:06:11,230 --> 00:06:15,120
コードは300倍以上も速く
動作します

95
00:06:15,120 --> 00:06:16,540
もう１度実行しましょう

96
00:06:16,540 --> 00:06:18,930
実行しました

97
00:06:18,930 --> 00:06:22,235
ベクトル化版は1.5ミリ秒で
for loop 版は

98
00:06:22,235 --> 00:06:25,960
481ミリ秒かかりました

99
00:06:25,960 --> 00:06:29,535
ここでもfor loop は
300分の１の速度でした

100
00:06:29,535 --> 00:06:30,980
300倍遅い場合には

101
00:06:30,980 --> 00:06:33,880
実行が１分で完了するか

102
00:06:33,880 --> 00:06:37,615
５時間かかるかの違いが
コードに出てきます

103
00:06:37,615 --> 00:06:41,410
深層学習のアルゴリズムを
実装する場合には

104
00:06:41,410 --> 00:06:43,300
結果がより速く
返ってきます

105
00:06:43,300 --> 00:06:46,590
ベクトル化すると
かなり速く実行されます

106
00:06:46,590 --> 00:06:49,300
多くの拡張可能な深層学習の実装が

107
00:06:49,300 --> 00:06:54,260
GPU(画像処理ユニット)で行われてると
聞いたことがあるかもしれません

108
00:06:54,260 --> 00:06:59,515
ここで今実行したJupyter Notebook でのデモは
CPU で実行しました

109
00:06:59,515 --> 00:07:04,530
実はGPU もCPU も両方とも
並行処理命令があります

110
00:07:04,530 --> 00:07:07,530
SIMD 命令と呼ばれます

111
00:07:07,530 --> 00:07:11,190
Single Instruction Multiple Data の
頭文字です

112
00:07:11,190 --> 00:07:13,045
これが意味するのは

113
00:07:13,045 --> 00:07:16,835
np.dot 関数や
他の関数のような

114
00:07:16,835 --> 00:07:23,495
for loop を
使わなくて済む組み込み関数を使うと

115
00:07:23,495 --> 00:07:28,150
Python のnumpy が

116
00:07:28,150 --> 00:07:33,640
計算処理を迅速に行うための
並行処理をかなり有効に利用することができます

117
00:07:33,640 --> 00:07:38,610
これはCPU での計算処理でも
GPU での計算処理でも当てはまります

118
00:07:38,610 --> 00:07:41,070
ただGPU は驚くほどSIMD 計算を

119
00:07:41,070 --> 00:07:44,980
効率的に行えるだけで
CPU の計算も実はそれほど悪くありません

120
00:07:44,980 --> 00:07:47,510
GPU ほどは
良くないだけです

121
00:07:47,510 --> 00:07:51,660
ベクトル化すると
コードの速度をかなり上げられるのを見てきました

122
00:07:51,660 --> 00:07:54,685
覚えておくべき経験則からの教訓は

123
00:07:54,685 --> 00:07:57,425
for loop を
使わないようにすることです

124
00:07:57,425 --> 00:07:59,980
次のビデオに進んで
さらにベクトル化の例を見て

125
00:07:59,980 --> 00:08:04,000
ロジステック回帰を
ベクトル化しましょう