1
00:00:00,060 --> 00:00:04,380
Senin derin geliştirmede etkili olman

2
00:00:02,669 --> 00:00:06,870
derin sinir ağları geliştirmek şunları gerektirir:

3
00:00:04,380 --> 00:00:09,269
parametreleri organize etmeki aynı zamanda

4
00:00:06,870 --> 00:00:11,759
hiper parametreleri de organize etmek, 
öyleyse hiper parametreler nedir?

5
00:00:09,269 --> 00:00:15,170
O zaman bir göz atalım,

6
00:00:11,759 --> 00:00:17,820
modelinizin parametreleri W ve B ve

7
00:00:15,170 --> 00:00:21,720
söylemeniz gereken diğer şeyler de var

8
00:00:17,820 --> 00:00:26,220
öğrenme algoritmanız için özellikle

9
00:00:21,720 --> 00:00:28,920
öğrenme hızı alfa çünkü bizim

10
00:00:26,220 --> 00:00:32,329
alfayı ayarlamaya ihtiyacımız var ve sonunda bu da

11
00:00:28,920 --> 00:00:34,890
parametrelerin nasıl değişeceğini belirleyecek veya

12
00:00:32,329 --> 00:00:38,190
belki iterasyon sayısını 

13
00:00:34,890 --> 00:00:40,170
gradyan inişi için gerekli olan ve

14
00:00:38,190 --> 00:00:42,629
öğrenme algoritma algoritmasının 

15
00:00:40,170 --> 00:00:47,340
sayıları varıdır ayarlanması gereken,

16
00:00:42,629 --> 00:00:50,629
saklı katmanlar gibi ve bunlar

17
00:00:47,340 --> 00:00:56,039
büyük harf L ile gösterilir, saklı üniteler

18
00:00:50,629 --> 00:00:59,670
gibi, sofor, bir ve iki ve üç ve

19
00:00:56,039 --> 00:01:03,329
böyle devameden, sonra seçme şansınız var

20
00:00:59,670 --> 00:01:05,610
aktivasyon fonksiyonunu, hangisini

21
00:01:03,329 --> 00:01:06,869
ReLU mu, tanh mi sigma mı 

22
00:01:05,610 --> 00:01:11,760
özellikle 

23
00:01:06,869 --> 00:01:13,590
saklı katmanlarda kullanacağınız ve tüm bu şeyler

24
00:01:11,760 --> 00:01:15,990
söylemeniz gereken şeylerdir

25
00:01:13,590 --> 00:01:19,640
öğrenme algoritmanız için ve böylece bunlar

26
00:01:15,990 --> 00:01:22,200
nihai kontrol parametreleridir ve

27
00:01:19,640 --> 00:01:25,640
W ve B'yi kontrol eder, yani bunlara

28
00:01:22,200 --> 00:01:29,340
hiper parametre adı verilir.

29
00:01:25,640 --> 00:01:30,750
Çünkü alfa gibi şeyler,

30
00:01:29,340 --> 00:01:32,369
öğrenme hızı, iterasyon sayısı,

31
00:01:30,750 --> 00:01:36,000
saklı katman sayısı ve bunun gibi

32
00:01:32,369 --> 00:01:39,290
parametreler W ve B'yi kontrol eder, 

33
00:01:36,000 --> 00:01:41,970
sonuçta bunlara hiper parametre denir.

34
00:01:39,290 --> 00:01:44,250
Çünkü hiper parametreler 

35
00:01:41,970 --> 00:01:46,950
bildiğiniz gibi, son çıktıyı 

36
00:01:44,250 --> 00:01:50,100
W ve B parametrelerinin değerlerini bir şekilde belirlemek gerekir.

37
00:01:46,950 --> 00:01:53,520
Sonunda derin öğrenme içinde 

38
00:01:50,100 --> 00:01:55,470
pek çok farklı hiper parametre vardır, sonra

39
00:01:53,520 --> 00:01:57,899
sonraki kursta göreceğiz

40
00:01:55,470 --> 00:02:02,990
diğer hiper parametreleri de 

41
00:01:57,899 --> 00:02:02,990
momentum değeri, mini yığın boyutu

42
00:02:05,150 --> 00:02:13,020
düzenleme parametreleri çeşitleri 

43
00:02:07,220 --> 00:02:14,700
ve bunun gibi, eğer bunlardan hiçbiri

44
00:02:13,020 --> 00:02:16,020
size anlamlı görünmüyorsa 

45
00:02:14,700 --> 00:02:18,810
hiç düşünmeyin, bununla ilgili

46
00:02:16,020 --> 00:02:21,870
ikinci kursta konuşacağız, çünkü derin

47
00:02:18,810 --> 00:02:24,120
öğrenmede çok fazla hiper parametre var,

48
00:02:21,870 --> 00:02:26,370
önceki hatalarına rağmen makine

49
00:02:24,120 --> 00:02:28,890
öğrenmesinin. Burada ben 

50
00:02:26,370 --> 00:02:31,050
öğrenme hızını anlatırken tutarlı olmayı deneyeceğim.

51
00:02:28,890 --> 00:02:33,480
Öğrenme hızı alfa hiper parametredir,

52
00:02:31,050 --> 00:02:35,250
parametre değildir. Bence

53
00:02:33,480 --> 00:02:37,920
makine öğrenmesindeki erken hatalar

54
00:02:35,250 --> 00:02:39,600
o zamanlar çok fazla hiper parametre yoktu,

55
00:02:37,920 --> 00:02:42,120
ve işler biraz yavaştı ve kısaca

56
00:02:39,600 --> 00:02:44,610
alfaya parametre demek kolaydı, teknik olarak

57
00:02:42,120 --> 00:02:47,580
alfa parametredir, ama gerçek parametreleri

58
00:02:44,610 --> 00:02:50,280
belirleyen bir parametredir.

59
00:02:47,580 --> 00:02:51,570
Bu yüzden tutarlı isimlendirme yapacağım, özellikle

60
00:02:50,280 --> 00:02:54,180
Alfa sayısı kadar

61
00:02:51,570 --> 00:02:55,769
iterasyon ve benzeri hiper parametler için.

62
00:02:54,180 --> 00:02:57,810
Derin ağı çalıştırırken 

63
00:02:55,769 --> 00:02:59,940
kendi uygulamalarında, bulabilirsiniz ki

64
00:02:57,810 --> 00:03:01,560
pek çok olası ayarlama vardır,

65
00:02:59,940 --> 00:03:04,440
hiper parametreler için 

66
00:03:01,560 --> 00:03:07,230
denemeler yapmak gerekebilir. 
Bugün derin öğrenme uygulamaları

67
00:03:04,440 --> 00:03:09,840
Çok kırılgandır, genellikle

68
00:03:07,230 --> 00:03:12,150
örneklenebilecek bir fikrin olabilir

69
00:03:09,840 --> 00:03:13,549
en iyi değer için

70
00:03:12,150 --> 00:03:16,739
öğrenme hızı için, mesela

71
00:03:13,549 --> 00:03:20,670
alfa için 0.01 gibi. Ve bunu denediğinde

72
00:03:16,739 --> 00:03:22,530
kodlamanın içinde nasıl

73
00:03:20,670 --> 00:03:23,910
çalıştığına bakıp ve sonra temel aldığı

74
00:03:22,530 --> 00:03:25,890
çıktıya göre, diyebilirsiniz ki

75
00:03:23,910 --> 00:03:28,620
bunu değiştirmek istiyorum, ve artırmak istiyorum

76
00:03:25,890 --> 00:03:30,930
öğrenme hızı 0.05 olsun, eğer 

77
00:03:28,620 --> 00:03:32,970
en iyi değerden emin değilseniz

78
00:03:30,930 --> 00:03:35,010
öğrenme hızı için, belki

79
00:03:32,970 --> 00:03:37,680
bir alfa öğrenme değeri değerini deneyerek

80
00:03:35,010 --> 00:03:39,690
ilgili maliyet fonksiyonu j azalıyorsa

81
00:03:37,680 --> 00:03:41,820
daha büyük değeri deneyebilirsiniz

82
00:03:39,690 --> 00:03:43,650
öğrenme hızı alfa için ve

83
00:03:41,820 --> 00:03:45,060
maliyet fonksiyonunun büyümesini görebilirsiniz ve

84
00:03:43,650 --> 00:03:47,250
bu değer sapabilir, deneyebilirsiniz diğer 

85
00:03:45,060 --> 00:03:49,709
versiyonları ve bunun hızla azaldığını görebilirsiniz,

86
00:03:47,250 --> 00:03:51,780
yüksek bir değerden kendisinin tersine kadar ayrıca

87
00:03:49,709 --> 00:03:53,670
yine farklı bir versiyon denediğinizde de

88
00:03:51,780 --> 00:03:55,530
maliyet fonksiyonunun çeşitli davranışlarını görürsünüz.

89
00:03:53,670 --> 00:03:57,840
sonuçta söyleyebileceğiniz değerler

90
00:03:55,530 --> 00:04:00,870
değeri gibi görünür

91
00:03:57,840 --> 00:04:02,790
alfanın bu hızlı bir öğrenme verir

92
00:04:00,870 --> 00:04:04,290
ve düşük bir yakınsama için olanak sağlar

93
00:04:02,790 --> 00:04:06,720
düşük bir maliyet fonksiyonuna, j fonksiyonu, 
ben bu değeri kullanacağım

94
00:04:04,290 --> 00:04:08,040
bu değer alfa değeri gördüğünüz

95
00:04:06,720 --> 00:04:10,170
bir önceki sunumda, pek çok 

96
00:04:08,040 --> 00:04:11,489
farklı hiper parametre içerir. Sonuçta

97
00:04:10,170 --> 00:04:13,830
yeni yeni başlarken

98
00:04:11,489 --> 00:04:15,450
uygulamamaya bence 

99
00:04:13,830 --> 00:04:17,940
önceden tam olarak bilmek çok zor

100
00:04:15,450 --> 00:04:20,580
hiper parametrelerin en iyi değerlerini

101
00:04:17,940 --> 00:04:22,169
hiper parametrelerin, sonuçta sıkıkla olması gereken

102
00:04:20,580 --> 00:04:24,570
Sadece çok farklı(değerleri) denemek zorundasınız, 

103
00:04:22,169 --> 00:04:26,970
ve bu döngüyü tekrarlamak. 

104
00:04:24,570 --> 00:04:28,440
deneme bazı değeri gerçekten deneyin beş gizli

105
00:04:26,970 --> 00:04:31,140
bu kadar saklı ünite içeren

106
00:04:28,440 --> 00:04:34,140
bunu uygulayın ve çalışıp çalışmadığını görün ve

107
00:04:31,140 --> 00:04:36,180
iterasyonu yapın. Sonuçta bu sunumun başlığı

108
00:04:34,140 --> 00:04:38,340
derin öğrenme uygulamaları çok

109
00:04:36,180 --> 00:04:40,740
deneysel bir süreçtir ve deneysel süreç

110
00:04:38,340 --> 00:04:42,419
şöyle söylemenin havalı bir yolu olabilir

111
00:04:40,740 --> 00:04:45,330
 görmek için denemek zorundayım

112
00:04:42,419 --> 00:04:47,190
bir sürü şeyi çalışıp çalışmadığını 
 Bir diğer etki de  

113
00:04:45,330 --> 00:04:48,810
bugün derin öğrenme uygulanmaktadır, 

114
00:04:47,190 --> 00:04:51,990
pek çok probleme, bilgisayarlı

115
00:04:48,810 --> 00:04:53,789
görmeden, konuşma tanımaya, doğal 

116
00:04:51,990 --> 00:04:55,500
dil işlemeye ve pek çok farklı

117
00:04:53,789 --> 00:04:59,250
yapılandırılmış veri uygulamalarına örneğin

118
00:04:55,500 --> 00:05:02,430
Belki de çevrimiçi bir reklam veya web arama

119
00:04:59,250 --> 00:05:05,640
veya ürün önerileri ve benzeri ve

120
00:05:02,430 --> 00:05:08,190
gördüğüm o ilk gördüğüm

121
00:05:05,640 --> 00:05:10,080
herhangi bir disiplinden araştırmacılar, bu yöntemlerin

122
00:05:08,190 --> 00:05:12,060
herhangi birini veya diğerini deneyerek çalışabilirler

123
00:05:10,080 --> 00:05:14,400
ve bazen sezgilerinin hiper 

124
00:05:12,060 --> 00:05:16,590
 parametreleri şekillendirdiği olur ve bazen

125
00:05:14,400 --> 00:05:17,849
olmaz, sonuçta ben sıklıkla tavsiye veririm ki

126
00:05:16,590 --> 00:05:20,970
özellikle yeni probleme başlarken

127
00:05:17,849 --> 00:05:23,550
ilgili değerlerin bir aralığını deneyip

128
00:05:20,970 --> 00:05:25,500
değerleri ve ne çalışıyor ve sonra karıştırın 

129
00:05:23,550 --> 00:05:27,930
bunun sistematik bir yolu, 

130
00:05:25,500 --> 00:05:30,780
bazı sistematik yollar deneyeceğiz,

131
00:05:27,930 --> 00:05:32,070
bir  değer aralığında, tamam ikinci olarak

132
00:05:30,780 --> 00:05:33,570
çalışıyor olsanız da

133
00:05:32,070 --> 00:05:35,220
bir uygulamada uzun zamandır

134
00:05:33,570 --> 00:05:37,979
belki İnternetten reklam için çalışıyorsunuzdur,

135
00:05:35,220 --> 00:05:39,930
ilerleme kaydettikçe

136
00:05:37,979 --> 00:05:41,580
bu problemde, o kadar mümkündür ki en iyi

137
00:05:39,930 --> 00:05:43,830
öğrenme hızı değerleri sayısı

138
00:05:41,580 --> 00:05:46,440
saklı katmanlara göre değişebilir, 

139
00:05:43,830 --> 00:05:49,229
sisteminiz için en iyi şekilde ayarlasanız bile

140
00:05:46,440 --> 00:05:51,750
hiperparametre değerleri 

141
00:05:49,229 --> 00:05:53,430
mümkündür ki en iyi değer

142
00:05:51,750 --> 00:05:55,650
bir sene öncesine göre farklı olabilir, belki

143
00:05:53,430 --> 00:05:57,840
Çünkü bilgisayar altyapısı

144
00:05:55,650 --> 00:05:59,789
Bu CPU veya GPU tiplerindeki

145
00:05:57,840 --> 00:06:01,560
falan çalışan yapılar değişebilir ama

146
00:05:59,789 --> 00:06:03,659
kural olarak bildiğiniz gibi

147
00:06:01,560 --> 00:06:05,070
eskiden beri belki bir kaç aydır, 

148
00:06:03,659 --> 00:06:06,659
eğer bir problem üzerinde çalışıyorsanız

149
00:06:05,070 --> 00:06:09,030
veya uzunca bir süredir, pek çok

150
00:06:06,659 --> 00:06:10,800
yıllarca, sadece bazı değerleri

151
00:06:09,030 --> 00:06:12,570
Hiper parametreleri ve iki kez kontrol edin 

152
00:06:10,800 --> 00:06:15,150
daha iyi bir değer var mı yok mu diye kontrol edin

153
00:06:12,570 --> 00:06:17,280
hiper parametreler için, böyle yaptıkça yavaşça

154
00:06:15,150 --> 00:06:18,779
hiper parametreler için sezgi kazanacaksınız

155
00:06:17,280 --> 00:06:19,870
en iyi şekilde çalışan sizin

156
00:06:18,779 --> 00:06:21,820
problemlerinizde

157
00:06:19,870 --> 00:06:24,010
ve biliyorum ki bu görünebilir

158
00:06:21,820 --> 00:06:25,510
derin öğrenmenin tatmin edici
 olmayan bir parçası gibi

159
00:06:24,010 --> 00:06:27,940
tüm değerleri tek tek denemek

160
00:06:25,510 --> 00:06:30,160
bu hiper parametreler için ama belki

161
00:06:27,940 --> 00:06:32,200
bu bir alandır derin öğrenme

162
00:06:30,160 --> 00:06:33,850
araştırmalarının gelişmekte olduğu ve belki

163
00:06:32,200 --> 00:06:36,190
zamanla biz verebiliyor olacağız daha iyi

164
00:06:33,850 --> 00:06:38,350
en iyi hiper parametreler için rehberlik

165
00:06:36,190 --> 00:06:41,260
ama şu da mümkün ki, 

166
00:06:38,350 --> 00:06:43,630
çünkü CPU ve GPUlar ve ağlar ve

167
00:06:41,260 --> 00:06:45,910
verisetleri değişiyor, ve bu

168
00:06:43,630 --> 00:06:47,680
mümkündür ki rehber 

169
00:06:45,910 --> 00:06:49,360
oluşması zaman alacaktır, ve siz

170
00:06:47,680 --> 00:06:50,860
sürekli farklı değerleri deniyor ve

171
00:06:49,360 --> 00:06:52,479
onları bir beklemeye alıp değerlendiriyor

172
00:06:50,860 --> 00:06:54,100
çapraz doğrulama kümesi ya da bir şey ve

173
00:06:52,479 --> 00:06:56,350
sizin için çalışan değeri seçiyor olabilirsiniz

174
00:06:54,100 --> 00:06:58,870
problemleriniz için. Bu kısa bir tartışmaydı

175
00:06:56,350 --> 00:07:01,030
hiper parametreleri için, ikinci kursta

176
00:06:58,870 --> 00:07:03,280
bizim önerilerimiz olacak, nasıl 

177
00:07:01,030 --> 00:07:06,040
sistematik olarak alanı keşfetmek için

178
00:07:03,280 --> 00:07:07,570
hiper parametreler (alanını) ama şimdilik gerçekten

179
00:07:06,040 --> 00:07:09,430
ihtiyaç duyabileeğiniz tüm araçlara sahipsiniz

180
00:07:07,570 --> 00:07:11,470
programlama egzersizini yapmak için, ama önce

181
00:07:09,430 --> 00:07:14,050
birkaç bakış açısı daha paylaşmak isterim

182
00:07:11,470 --> 00:07:16,150
genellikle sorduğum bir kaç fikir

183
00:07:14,050 --> 00:07:18,660
derin öğrenmenin ne işi olur

184
00:07:16,150 --> 00:07:18,660
insan beyniyle