1
00:00:00,000 --> 00:00:01,530
في الفيديو السابق،

2
00:00:01,530 --> 00:00:04,227
تعرفت على نموذج الانحدار اللوجستي.

3
00:00:04,227 --> 00:00:07,526
لتدريب المعلمتين W وB
لنموذج الانحدار اللوجيستي،

4
00:00:07,526 --> 00:00:10,570
يجب أن تحدد دالة تكلفة.

5
00:00:10,570 --> 00:00:14,430
لنلق نظرة على دالة التكلفة التي
يمكنك استخدامها لتدريب الانحدار اللوجيستي.

6
00:00:14,430 --> 00:00:18,195
لتلخيص ذلك، هذا ما تعرفنا
عليه في الشريحة السابقة.

7
00:00:18,195 --> 00:00:20,792
لذا يكون الإخراج ŷ هو سينية منقولة مصفوفة w

8
00:00:20,792 --> 00:00:24,690
لـ x مضافًا إليها b حيث تتحدد سينية Z هنا.

9
00:00:24,690 --> 00:00:27,600
لذا للتعرف على المعلمات
الخاصة بالنموذج لديك، فتتوفر لك

10
00:00:27,600 --> 00:00:31,200
مجموعة تدريبية من أمثلة تدريب m

11
00:00:31,200 --> 00:00:34,060
ومن الطبيعي أنك تريد البحث عن المعلمتين W

12
00:00:34,060 --> 00:00:37,781
وB بحيث تتضمن على الأقل
المجموعة التدريبية المخرجات المتوفرة لديك.

13
00:00:37,781 --> 00:00:40,225
والتنبؤات المتوفرة لديك في المجموعة التدريبية

14
00:00:40,225 --> 00:00:43,260
والتي نكتبها كالآتي ŷ (i)‎ التي سيتم تقريبها إلى

15
00:00:43,260 --> 00:00:47,720
التسميات الملموسة y_i التي حصلت
عليها في المجموعة التدريبية.

16
00:00:47,720 --> 00:00:52,110
ولمزيد من التفاصيل حول المعادلة في الأعلى،

17
00:00:52,110 --> 00:00:56,205
قلنا إن ŷ كما هو محدد أعلاه

18
00:00:56,205 --> 00:01:00,930
لمثال التدريب x وبالطبع لكل أمثلة التدريب،

19
00:01:00,930 --> 00:01:03,240
إننا نستخدم هذه الأحرف المرتفعة

20
00:01:03,240 --> 00:01:07,710
المحاطة بأقواس داخل قوسين
لفهرسة الأمثلة وتمييزها.

21
00:01:07,710 --> 00:01:12,870
سيتم الحصول على التنبؤ المتعلق
بعينة التدريب (i) التي تمثل كالآتي ŷ (i)‎

22
00:01:12,870 --> 00:01:18,835
من خلال الحصول على الدالة السينية
وتطبيقها على منقولة مصفوفة W لـ X،

23
00:01:18,835 --> 00:01:25,905
(i) وهو إدخال مثال التدريب مضافًا إليه
V ويمكنك أيضًا تحديد Z (i)‎ كالآتي.

24
00:01:25,905 --> 00:01:30,110
Z (i)‎ يساوي منقولة مصفوفة
W لـ x (i)‎ مضافًا إليها b.

25
00:01:30,110 --> 00:01:31,350
لذا خلال هذه الدورة،

26
00:01:31,350 --> 00:01:33,966
سنستخدم هذا الاصطلاح الترميزي

27
00:01:33,966 --> 00:01:41,605
حيث تشير الأقواس المرتفعة i إلى البيانات.

28
00:01:41,605 --> 00:01:47,615
الحرف X أو Y أو Z أو أي
حرف آخر مرتبط بمثال التدريب i،

29
00:01:47,615 --> 00:01:50,885
يكون مرتبطًا بمثال i.

30
00:01:50,885 --> 00:01:54,840
وهذا ما يعنيه الحرف المرتفع i في الأقواس.

31
00:01:54,840 --> 00:01:57,630
والآن لنتعرف على دالة الخسارة أو

32
00:01:57,630 --> 00:02:01,315
دالة الخطأ التي يمكننا استخدامها
لقياس مدى عمل الخوارزمية جيدًا.

33
00:02:01,315 --> 00:02:06,015
أمر واحد قد تفعله هو تحديد الخسارة
عندما تقوم الخوارزمية بإخراج

34
00:02:06,015 --> 00:02:12,320
ŷ والتسمية الحقيقية Y لتكون الخطأ
التربيعي أو نصف خطأ تربيعي.

35
00:02:12,320 --> 00:02:14,975
يتضح أنه يمكنك إجراء ذلك،

36
00:02:14,975 --> 00:02:17,670
ولكن في الانحدار اللوجيستي، لا
يقوم الأشخاص عادةً بذلك

37
00:02:17,670 --> 00:02:21,000
لأنه عندما تتعرف على المعلمات،

38
00:02:21,000 --> 00:02:25,682
تجد أن مشكلة الاستمثال التي
سنتحدث عنها لاحقًا تصبح غير محدبة.

39
00:02:25,682 --> 00:02:30,105
لذا ينتهي بك الأمر بمشكلة الاستمثال
بمشكلة محلية متعددة.

40
00:02:30,105 --> 00:02:33,285
لذا قد لا يجد الهبوط التدريجي الأمثلية العالمية.

41
00:02:33,285 --> 00:02:35,580
إذا كنت لا تفهم آخر تعليقين،

42
00:02:35,580 --> 00:02:38,320
فلا تقلق سنتناول ذلك في فيديو لاحق.

43
00:02:38,320 --> 00:02:40,990
ولكن المعلومة البديهية التي نستخلصها هي أن

44
00:02:40,990 --> 00:02:44,620
هذا الدالة L المعروفة باسم دالة الخسارة هي دالة

45
00:02:44,620 --> 00:02:51,265
ستحتاج إليها لتحديد وقياس مدى جودة
إخراج ŷ عندما تكون التسمية الحقيقية هي y.

46
00:02:51,265 --> 00:02:54,345
كما يبدو أن الخطأ التربيعي قد يكون خيارًا معقولاً،

47
00:02:54,345 --> 00:02:58,160
باستثناء أنه يجعل الهبوط التدريجي لا يعمل جيدًا.

48
00:02:58,160 --> 00:03:00,500
لذا في الانحدار اللوجيستي، سنحدد بالفعل

49
00:03:00,500 --> 00:03:05,695
دالة خسارة أخرى تلعب دورًا
مشابهًا مثل الخطأ التربيعي

50
00:03:05,695 --> 00:03:08,910
بحيث سينتج عنها مشكلة الاستمثال

51
00:03:08,910 --> 00:03:13,530
والتي تكون محدبة وسنجد في الفيديو
اللاحق أن إجراء التحسين يصبح سهلاً جدًا.

52
00:03:13,530 --> 00:03:17,310
لذا ما نستخدمه في الانحدار اللوجيستي

53
00:03:17,310 --> 00:03:21,795
هي في الواقع دالة الخسارة
التالية الموضحة بالأعلى هنا،

54
00:03:21,795 --> 00:03:31,740
وهي سالب y log ŷ مضافًا
إليه سطر واحد به y log

55
00:03:31,740 --> 00:03:34,600
وسطر واحد به ŷ.

56
00:03:34,600 --> 00:03:38,785
إليك بعض الأسباب التي تجعل
دالة الخسارة هذه منطقية.

57
00:03:38,785 --> 00:03:41,285
تذكّر أنه إذا استخدمنا

58
00:03:41,285 --> 00:03:45,820
الخطأ التربيعي، فمن ثمّ تريد أن
يكون الخطأ التربيعي صغيرًا قدر الإمكان.

59
00:03:45,820 --> 00:03:48,680
وباستخدام دالة خسارة الانحدار اللوجيستي هذه،

60
00:03:48,680 --> 00:03:51,495
سنريد أيضًا أن يكون هذا الخطأ صغيرًا قدر الإمكان.

61
00:03:51,495 --> 00:03:53,508
لفهم السبب الذي يجعل ذلك منطقيًا،

62
00:03:53,508 --> 00:03:55,260
لنلق نظرة على الحالتين.

63
00:03:55,260 --> 00:03:56,570
في الحالة الأولى،

64
00:03:56,570 --> 00:03:59,430
لنفترض أن Y تساوي 1، فمن ثمّ يكون

65
00:03:59,430 --> 00:04:05,415
من الطبيعي كتابة دالة الخسارة
ŷ فاصلة y مسبقة بعلامة السالب هذه.

66
00:04:05,415 --> 00:04:08,735
لذا تكون سالب log ŷ.

67
00:04:08,735 --> 00:04:10,770
إذا كانت y تساوي 1 لأنه إذا كانت y تساوي

68
00:04:10,770 --> 00:04:14,070
1، فمن ثمّ تكون العبارة الثانية
هي 1 مطروحًا منه Y يساوي صفر.

69
00:04:14,070 --> 00:04:19,880
لذا يعني ذلك أنه إذا كانت y تساوي 1، فإنك
تريد أن تكون سالب log ŷ كبيرة قدر الإمكان.

70
00:04:19,880 --> 00:04:26,040
لذا يعني ذلك أنك تريد أن تكون log ŷ كبيرة

71
00:04:26,040 --> 00:04:32,935
قدر الإمكان مما يعني أنك تريد أن تكون ŷ كبيرة.

72
00:04:32,935 --> 00:04:35,170
ولكن لأن ŷ كما تعرف هي

73
00:04:35,170 --> 00:04:38,440
دالة سينية، فلا يمكن أن تزيد قيمتها عن 1.

74
00:04:38,440 --> 00:04:41,850
لذا يعني ذلك أنه إذا كانت y تساوي 1، فإنك

75
00:04:41,850 --> 00:04:44,050
تريد أن تكون ŷ كبيرة قدر الإمكان.

76
00:04:44,050 --> 00:04:48,220
ولكن لا يمكن أن تزيد قيمتها عن 1
لذا فإنك تريد أيضًا أن تكون ŷ قريبة من 1.

77
00:04:48,220 --> 00:04:50,740
أما الحالة الثانية، فهي إذا كانت y تساوي صفرًا.

78
00:04:50,740 --> 00:04:55,375
إذا كانت y تساوي صفر، فمن ثمّ العبارة
الأولى في دالة الخسارة تساوي صفر لأن

79
00:04:55,375 --> 00:05:01,290
y تساوي صفر والعبارة الثانية تحدد دالة الخسارة.

80
00:05:01,290 --> 00:05:07,210
لذا تكون دالة الخسارة سالب log يليها
1 مطروحًا منه ŷ.

81
00:05:07,210 --> 00:05:11,480
لذا إذا كنت تحاول في طريقة التعلم
أن تجعل دالة الخسارة صغيرة،

82
00:05:11,480 --> 00:05:19,450
فيعني ذلك أنك تريد log يليها 1
مطروحًا منه ŷ أن تكون كبيرة.

83
00:05:19,450 --> 00:05:22,050
ونظرًا لوجود علامة سالب

84
00:05:22,050 --> 00:05:24,660
ومن خلال سبب مشابه، يمكنك أن تستنتج

85
00:05:24,660 --> 00:05:30,870
أن دالة الخسارة هذه تحاول أن
تجعل ŷ صغيرة قدر الإمكان.

86
00:05:30,870 --> 00:05:34,320
ومرة أخرى لأن ŷ يجب أن تتراوح بين صفر و1.

87
00:05:34,320 --> 00:05:38,155
يعني ذلك أنه إذا كانت y تساوي صفر،

88
00:05:38,155 --> 00:05:43,790
فمن ثمّ ستدفع دالة الخسارة بالمعلمات
لتجعل ŷ قريبة من صفر قدر الإمكان.

89
00:05:43,790 --> 00:05:48,305
والآن، توجد دوال متعددة بتأثير
رفيدة بحيث إذا كانت y تساوي

90
00:05:48,305 --> 00:05:52,950
1، فنحاول أن نجعل ŷ كبيرة، وإذا كانت
Y تساوي صفر، فنحاول أن نجعل ŷ صغيرة.

91
00:05:52,950 --> 00:05:55,150
أوضحنا هنا باللون الأخضر

92
00:05:55,150 --> 00:05:59,920
تبريرًا عشوائيًا إلى حد ما لدالة الخسارة هذه وسنوضح

93
00:05:59,920 --> 00:06:03,970
في فيديو اختياري لاحق تقديم تبرير عشوائي

94
00:06:03,970 --> 00:06:08,500
يوضح سبب أننا نفضل في الانحدار
اللوجيستي استخدام دالة الخسارة بهذا الشكل تحديدًا.

95
00:06:08,500 --> 00:06:13,630
وفي النهاية، تم تحديد دالة الخسارة
على فيما يتعلق بمثال تدريب واحد.

96
00:06:13,630 --> 00:06:16,760
فهي تقيس مدى جودة استخدامك لمثال تدريب واحد.

97
00:06:16,760 --> 00:06:21,148
سأوضح الآن شيئًا يُعرف باسم دالة التكلفة

98
00:06:21,148 --> 00:06:24,690
والتي تقيس مدى جودة استخدامك
لمجموعة تدريبية بالكامل.

99
00:06:24,690 --> 00:06:28,660
لذا تكون دالة التكلفة J التي تنطبق على

100
00:06:28,660 --> 00:06:33,130
المعلمتين W وB ستكون متوسط 1

101
00:06:33,130 --> 00:06:43,270
على m من ∑ لدالة الخسارة المنطبقة
على كل أمثلة التدريب والعكس.

102
00:06:43,270 --> 00:06:45,435
بينما تكون ŷ هنا بالطبع

103
00:06:45,435 --> 00:06:49,570
إخراج التنبؤ على خوارزمية
الانحدار اللوجيستي باستخدام

104
00:06:49,570 --> 00:06:52,430
مجموعة محددة من المعلمتين W وB.

105
00:06:52,430 --> 00:06:54,480
ولتوضيح ذلك هنا،

106
00:06:54,480 --> 00:06:58,010
هذا يساوي سالب 1 على

107
00:06:58,010 --> 00:07:03,550
m من ∑ من i تساوي 1 حتى
m لتعريف دالة الخسارة.

108
00:07:03,550 --> 00:07:07,530
لذا تكون y (i) Log ŷ

109
00:07:07,530 --> 00:07:14,530
(i) مضافًا إليها سطر واحد وهو
y (i) log، وسطر واحد وهو ŷ (i)‎.

110
00:07:14,530 --> 00:07:17,880
أعتقد أنه يمكنني استخدام أقواس مربعة هنا.

111
00:07:17,880 --> 00:07:20,945
لذا تكون علامة الطرح خارج كل الأسطر الأخرى.

112
00:07:20,945 --> 00:07:23,665
لذا فالمصطلح الذي سأستخدمه هو أن

113
00:07:23,665 --> 00:07:29,120
دالة الخسارة تنطبق فقط على
مثال تدريب واحد مثل ذلك.

114
00:07:29,120 --> 00:07:33,010
بينما دالة التكلفة، فهي تكلفة المعلمات.

115
00:07:33,010 --> 00:07:36,115
لذا عند استخدام نموذج
تدريب الانحدار اللوجستي،

116
00:07:36,115 --> 00:07:38,980
سنحاول البحث عن المعلمتين W وB

117
00:07:38,980 --> 00:07:43,475
اللاتي يقللان من التكاليف
الإجمالية لدالة J المكتوبة في الأسفل.

118
00:07:43,475 --> 00:07:48,040
لقد تعرفت للتو على إعداد
خوارزمية الانحدار اللوجيستي

119
00:07:48,040 --> 00:07:50,770
ودالة الخسارة لمثال التدريب

120
00:07:50,770 --> 00:07:54,190
ودالة التكلفة الإجمالية لمعلمات الخوارزمية لديك.

121
00:07:54,190 --> 00:07:59,485
يتضح من ذلك أنه يمكن عرض الانحدار
اللوجيستي كشبكة عصبية صغيرة جدًا جدًا.

122
00:07:59,485 --> 00:08:01,905
في الفيديو التالي، سنتناول ذلك بحيث يمكنك بدء

123
00:08:01,905 --> 00:08:04,965
تخمين وظيفة الشبكات العصبية.

124
00:08:04,965 --> 00:08:08,230
لذا لننتقل إلى الفيديو التالي حول كيفية

125
00:08:08,230 --> 00:08:11,630
عرض الانحدار اللوجيستي
كشبكة عصبية صغيرة جدًا.