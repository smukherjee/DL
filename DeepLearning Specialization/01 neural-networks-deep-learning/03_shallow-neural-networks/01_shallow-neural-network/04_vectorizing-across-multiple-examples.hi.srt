1
00:00:00,360 --> 00:00:04,530
पिछले वीडियो में, आपने देखा कैसे कम्प्यूट करना है 
प्रिडिक्शन एक न्यूरल नेटवर्क पर,

2
00:00:04,530 --> 00:00:06,610
दिया होने पर एक ट्रेनिंग इग्ज़ाम्पल.

3
00:00:06,610 --> 00:00:11,520
इस वीडियो में, आप देखेंगे कैसे वेक्टराइज़ करना है 
बहुत से ट्रेनिंग इग्ज़ाम्पल्ज़ पर.

4
00:00:11,520 --> 00:00:15,350
और परिणाम काफ़ी समान होगा जो 
आपने देखा लॉजिस्टिक रेग्रेशन के लिए.

5
00:00:15,350 --> 00:00:19,050
जहाँ स्टैक करके विभिन्न ट्रेनिंग इग्ज़ाम्पल्ज़ को भिन्न कॉलम्स में

6
00:00:19,050 --> 00:00:23,630
मेट्रिक्स के, आप ले पाएँगे इक्वेज़न्स जो 
आपके पास थी पिछले वीडियो में.

7
00:00:23,630 --> 00:00:27,860
और बहुत थोड़े बदलाव से, बदलने से ताकि 
न्यूरल नेटवर्क कम्प्यूट करे

8
00:00:27,860 --> 00:00:32,340
आउट्पुट सभी ट्रेनिंग इग्ज़ाम्पल्ज़ पर सब एक साथ.

9
00:00:32,340 --> 00:00:35,080
चलो देखते हैं विस्तार से कि कैसे वह करना है.

10
00:00:35,080 --> 00:00:40,192
हमारे पास चार इक्वेज़न्स थी पिछले वीडियो से कि 
कैसे कम्प्यूट करना है z1,

11
00:00:40,192 --> 00:00:41,348
a1, z2 और a2.

12
00:00:41,348 --> 00:00:46,867
और वे बताते हैं आपको कैसे, 
दिया होने पर एक इनपुट फ़ीचर वेक्टर x,

13
00:00:46,867 --> 00:00:53,810
आप इस्तेमाल कर सकते हैं उनका बनाने के लिए
 a2 = y हैट एक अकेले ट्रेनिंग इग्ज़ाम्पल के लिए.

14
00:00:54,920 --> 00:01:00,050
अब यदि आपके पास हैं m ट्रेनिंग इग्ज़ाम्पल्ज़, 
आपको इस प्रक्रिया को दोहराने की ज़रूरत है

15
00:01:00,050 --> 00:01:01,870
मान लो पहले ट्रेनिंग इग्ज़ाम्पल के लिए.

16
00:01:01,870 --> 00:01:06,600
x सुपरस्क्रिप्ट (1) कम्प्यूट करने के लिए

17
00:01:06,600 --> 00:01:11,062
y हैट 1 जो है प्रिडिक्शन आपके पहले ट्रेनिंग इग्ज़ाम्पल पर.

18
00:01:11,062 --> 00:01:16,537
तब x (2) का उपयोग करें प्रिडिक्ट करने के लिए y hat (2).

19
00:01:16,537 --> 00:01:23,050
और इसी प्रकार आगे x(m) तक बनाने के लिए y हैट (m).

20
00:01:23,050 --> 00:01:28,349
तो लिखने के लिए ये सभी ऐक्टिवेशन फ़ंक्शन्स नोटेशन में,

21
00:01:28,349 --> 00:01:31,669
मैं लिखूँगा इसे a[2](1) की तरह.

22
00:01:31,669 --> 00:01:36,676
और इसे a[2](2) की तरह.

23
00:01:36,676 --> 00:01:40,640
और इसे a[2](m), तो

24
00:01:40,640 --> 00:01:46,830
यह नोटेशन a[2](i).

25
00:01:46,830 --> 00:01:52,520
यह गोल कोष्ठक i संदर्भित करता हैं ट्रेनिंग इग्ज़ाम्पल i को,

26
00:01:52,520 --> 00:01:57,220
और वर्ग कोष्ठक 2 संदर्भित करता हैं लेयर 2 को, ठीक है.

27
00:01:58,530 --> 00:02:02,460
तो ऐसे वर्ग कोष्ठक और गोल कोष्ठक सूचकांक काम करते हैं.

28
00:02:04,170 --> 00:02:07,920
तो वे कहते हैं कि यदि आपके पास है 
एक अनवेक्टराइज्ड इम्प्लमेंटेशन और

29
00:02:07,920 --> 00:02:11,000
चाहते हैं कम्प्यूट करना प्रिडिक्शन आपके 
सारे ट्रेनिंग इग्ज़ाम्पल्ज़ पर,

30
00:02:11,000 --> 00:02:15,630
आपको करना पड़ेगा वह i के लिए 1 से m तक.

31
00:02:15,630 --> 00:02:18,260
तब मूलत: इम्प्लमेंट ये चार इक्वेज़न्स, ठीक है?

32
00:02:18,260 --> 00:02:24,162
आपको बनाना पड़ेगा एक z[1](i)

33
00:02:24,162 --> 00:02:30,064
= W(1) x(i) + b[1],

34
00:02:30,064 --> 00:02:38,253
a[1](i) = सिग्मोईड ऑफ़ z[1](1).

35
00:02:38,253 --> 00:02:43,683
z[2](i) = w[2]a[1](i)

36
00:02:43,683 --> 00:02:50,099
+ b[2] और z[2](i) बराबर है w[2]a[1](i) प्लस b[2] और

37
00:02:50,099 --> 00:02:56,686
a[2](i) = सिग्मोईड ऑफ़ of z[2](i).

38
00:02:56,686 --> 00:03:03,172
तो यह है मूलत: ये चार इक्वेज़न्स ऊपर जोड़ कर सूपरस्क्रिप्ट गोल

39
00:03:03,172 --> 00:03:08,788
कोष्ठक i सभी वेरिएबल्स को जो निर्भर करते हैं ट्रेनिंग इग्ज़ाम्पल पर.

40
00:03:08,788 --> 00:03:12,612
तो जोड़ने से यह सूपरस्क्रिप्ट गोल कोष्ठक i x को है z और a,

41
00:03:12,612 --> 00:03:18,570
यदि आप कम्प्यूट करना चाहते हैं सभी 
आउट्पुट्स आपके m ट्रेनिंग इग्ज़ाम्पल्ज़ पर,

42
00:03:18,570 --> 00:03:23,930
हम क्या करना चाहेंगे कि वेक्टराइज़ करे ये सारी कॉम्प्यूटेशन, 
ताकि हटा सके यह फ़ोर लूप.

43
00:03:23,930 --> 00:03:27,680
और वैसे, यदि ऐसा लग रहा है कि मैं 
बहुत विस्तार में जा रहा हूँ

44
00:03:27,680 --> 00:03:31,170
लिनीअर ऐल्जेब्रा में, ऐसा होता है कि इसे इम्प्लमेंट कर पाना

45
00:03:31,170 --> 00:03:34,580
सही ढंग से महत्वपूर्ण है डीप लर्निंग के युग में.

46
00:03:34,580 --> 00:03:38,160
और हमने वास्तव में चुनी है नोटेशन बहुत ध्यान से 
इस कोर्स के लिए और

47
00:03:38,160 --> 00:03:41,460
बनाया है यह वेक्टराइज़ेशन स्टेप सरल जितना हो सके.

48
00:03:41,460 --> 00:03:46,140
तो मैं उम्मीद करता हूँ कि जानना ये बारीकियाँ 
वास्तव में मदद करेंगी आपको

49
00:03:46,140 --> 00:03:49,750
अधिक जल्दी पाने के लिए सही इम्प्लमेंटेशन 
इन अल्गोरिद्म को चलाने के लिए.

50
00:03:51,060 --> 00:03:56,210
ठीक है, तो चलो मैं कॉपी करता हूँ यह पूरा ब्लॉक कोड का 
अगली स्लाइड में और

51
00:03:56,210 --> 00:03:57,880
तब हम देखते हैं कैसे इसे वेक्टराइज़ करते हैं.

52
00:03:59,130 --> 00:04:02,154
तो यहाँ है जो हमारे पास था पिछली स्लाइड से जिसमें फ़ॉर

53
00:04:02,154 --> 00:04:04,324
लूप चल रहा है हमारे m ट्रेनिंग इग्ज़ाम्पल्ज़ पर.

54
00:04:04,324 --> 00:04:09,769
तो याद करो कि हमने परिभाषित की थी मेट्रिक्स x जो बराबर है

55
00:04:09,769 --> 00:04:16,860
हमारे ट्रेनिंग इग्ज़ाम्पल्ज़ के जिन्हें स्टैक किया है 
इन कॉलम्स में इस प्रकार.

56
00:04:16,860 --> 00:04:20,180
तो लेते हैं ट्रेनिंग इग्ज़ाम्पल्ज़ और स्टैक करते हैं उन्हें इन कॉलम्स में.

57
00:04:20,180 --> 00:04:23,220
तो यह बन जाती है एक n, या

58
00:04:23,220 --> 00:04:27,860
शायद n बाई m डिमेन्शन का मेट्रिक्स.

59
00:04:29,198 --> 00:04:32,630
मैं आपको सिर्फ़ दूँगा पंच लाइन और बताऊँगा कि 
क्या आपको इम्प्लमेंट करने की आवश्यकता है

60
00:04:32,630 --> 00:04:35,760
पाने के लिए एक वेक्टराइज्ड इम्प्लमेंटेशन इस फ़ॉर लूप की.

61
00:04:35,760 --> 00:04:41,394
ऐसा होता है कि आपको क्या करना है कि कम्प्यूट करना है

62
00:04:41,394 --> 00:04:46,035
Z[1] = W[1] X + b[1],

63
00:04:46,035 --> 00:04:50,692
A[1]= सिग्मोईड ऑफ़ z[1].

64
00:04:50,692 --> 00:04:56,157
फिर Z[2] = w[2]

65
00:04:56,157 --> 00:05:01,348
A[1] + b[2] और

66
00:05:01,348 --> 00:05:10,100
फिर A[2]= सिग्मोईड ऑफ़ z[2].

67
00:05:10,100 --> 00:05:16,440
तो यदि आप चाहते हैं समानता वह है कि हम गए वेक्टर x से

68
00:05:16,440 --> 00:05:23,480
वेक्टर X पर स्टैक करते हुए x को विभिन्न कॉलम्स में.

69
00:05:23,480 --> 00:05:28,494
यदि आप करते हैं वही चीज़ z के लिए, तो उदाहरण के लिए,

70
00:05:28,494 --> 00:05:33,509
यदि आप लेते हैं z[1](1), z[1](2), और इसी प्रकार

71
00:05:33,509 --> 00:05:40,290
आगे, और ये सारे हैं कॉलम वेक्टर्स, आगे z[1](m) तक, ठीक है.

72
00:05:40,290 --> 00:05:46,270
तो वह है पहली चीज़ कि सभी वे m, 
और स्टैक करते हैं उन्हें कॉलम्स में.

73
00:05:46,270 --> 00:05:50,045
वह तब देता है आपको मेट्रिक्स z[1].

74
00:05:50,045 --> 00:05:55,299
और इसी प्रकार आप देखते हैं मान लो इस चीज़ को और

75
00:05:55,299 --> 00:06:00,957
आप लेते हैं a[1](1), a[1](2), और इसी प्रकार और

76
00:06:00,957 --> 00:06:06,980
a[1](m) तक, और स्टैक करते हैं उन्हें कॉलम्स में.

77
00:06:06,980 --> 00:06:11,610
तब यह, जैसे हम गए x से केपिटल X तक, और

78
00:06:11,610 --> 00:06:13,280
z से केपिटल Z तक,

79
00:06:13,280 --> 00:06:20,920
यह जाता है a से, जो हैं वेक्टर्स इस A[1] के,

80
00:06:20,920 --> 00:06:26,685
वह है वहाँ और इसी प्रकार Z[2] और A[2] के लिए.

81
00:06:26,685 --> 00:06:30,141
तो वे भी मिलते हैं लेने से ये वेक्टर्स और

82
00:06:30,141 --> 00:06:32,016
स्टैक करने से उन्हें क्षैतिज रूप से.

83
00:06:32,016 --> 00:06:37,326
और लेने से ये वेक्टर्स और स्टैक करने से उन्हें क्षैतिज रूप से,

84
00:06:37,326 --> 00:06:40,840
पाने के लिए Z[2] और A[2].

85
00:06:40,840 --> 00:06:44,042
एक गुण इस नोटेशन के जो शायद मदद करे

86
00:06:44,042 --> 00:06:47,391
आपको सोचने में इस बारे में है कि यह मेट्रिक्स मान लो Z और A,

87
00:06:47,391 --> 00:06:51,420
क्षैतिज रूप से हम इंडेक्स करेंगे पूरे ट्रेनिंग इग्ज़ाम्पल्ज़ पर.

88
00:06:51,420 --> 00:06:55,631
तो इसलिए क्षैतिज इंडेक्स दर्शाता है विभिन्न ट्रेनिंग इग्ज़ाम्पल्ज़,

89
00:06:55,631 --> 00:06:59,730
जब आप जाते हैं बाएँ से दाएँ आप जा रहें हैं ट्रेनिंग सेट से.

90
00:06:59,730 --> 00:07:04,617
और अनुलम्ब रूप से, यह अनुलम्ब इंडेक्स दर्शाता है विभिन्न नोड्ज़

91
00:07:04,617 --> 00:07:06,130
न्यूरल नेटवर्क में.

92
00:07:06,130 --> 00:07:11,077
तो उदाहरण के लिए, यह नोड, यह वैल्यू सबसे ऊपर,

93
00:07:11,077 --> 00:07:16,554
सबसे ऊपर बाएँ कोने में मेट्रिक्स के दर्शाता है ऐक्टिवेशन को

94
00:07:16,554 --> 00:07:21,633
पहली हिडन यूनिट के पहले ट्रेनिंग इग्ज़ाम्पल पर.

95
00:07:21,633 --> 00:07:25,812
एक वैल्यू नीचे दर्शाता है ऐक्टिवेशन दूसरी हिडन यूनिट का

96
00:07:25,812 --> 00:07:27,525
पहले ट्रेनिंग इग्ज़ाम्पल पर,

97
00:07:27,525 --> 00:07:31,505
फिर तीसरी हिडन यूनिट पहले ट्रेनिंग इग्ज़ाम्पल पर 
और इसी प्रकार आगे.

98
00:07:31,505 --> 00:07:37,540
तो आप जा सकते हैं नीचे यह है आपका 
इंडेक्स हिडन यूनिट नम्बर्स का.

99
00:07:39,670 --> 00:07:42,564
जबकि यदि आप जाते हैं क्षैतिज रूप से, 
आप जा रहे हैं पहली हिडन यूनिट से

100
00:07:42,564 --> 00:07:45,450
और पहले ट्रेनिंग इग्ज़ाम्पल से सब पहली हिडन यूनिट पर और

101
00:07:45,450 --> 00:07:48,240
और दूसरे ट्रेनिंग इग्ज़ाम्पल पर, 
तीसरे ट्रेनिंग इग्ज़ाम्पल पर.

102
00:07:48,240 --> 00:07:53,718
और इसी प्रकार आगे जब तक यह
 नोड यहाँ दर्शाता है ऐक्टिवेशन पहली

103
00:07:53,718 --> 00:07:59,030
हिडन यूनिट का अंतिम ट्रेनिंग इग्ज़ाम्पल पर और 
mth ट्रेनिंग इग्ज़ाम्पल पर.

104
00:08:00,760 --> 00:08:07,663
ठीक है तो क्षैतिज रूप से मेट्रिक्स A जाता है 
विभिन्न ट्रेनिंग इग्ज़ाम्पल्ज़ पर.

105
00:08:10,150 --> 00:08:14,195
और अनुलम्ब रूप से विभिन्न इंडेक्स मेट्रिक्स

106
00:08:14,195 --> 00:08:17,589
A में दर्शाते हैं विभिन्न हिडन यूनिट्स.

107
00:08:22,342 --> 00:08:26,870
और एक यही समान चीज़ सत्य है 
मेट्रिक्स Z और X के लिए भी

108
00:08:26,870 --> 00:08:31,840
जहाँ क्षैतिज इंडेक्स दर्शाता है 
विभिन्न ट्रेनिंग इग्ज़ाम्पल्ज़,

109
00:08:31,840 --> 00:08:36,227
और अनुलम्ब रूप से, यह दर्शाता है 
विभिन्न इनपुट फ़ीचर्ज़ जो है

110
00:08:36,227 --> 00:08:41,180
बिल्कुल भिन्न इनपुट लेयर के 
नोड्ज़ से न्यूरल नेटवर्क में.

111
00:08:42,750 --> 00:08:46,600
तो इन इक्वेज़न्स को, आप जानते हैं 
कैसे इम्प्लमेंट करना है न्यूरल नेटवर्क में

112
00:08:46,600 --> 00:08:51,320
वेक्टराइज़ करके, 
मतलब वेक्टराइज़ करना बहुत से इग्ज़ाम्पल्ज़ पर.

113
00:08:51,320 --> 00:08:55,130
अगले वीडियो में मैं दिखाना चाहता हूँ 
आपको थोड़ा अधिक औचित्य कि क्यों

114
00:08:55,130 --> 00:08:59,070
यह है एक सही इम्प्लमेंटेशन इस तरह के 
वेक्टराइज़ेशन की.

115
00:08:59,070 --> 00:09:03,468
ऐसा है कि औचित्य होगा समान जो 
आपने पहले देखा है [सुनाई नहीं दिया].

116
00:09:03,468 --> 00:09:05,300
तो चलिए चलते हैं अगले वीडियो में.