كجزء من هذه الدورة التدريبية من
خلال deeplearning.ai، أتمنى ألا أكتفي بتعليمكم الأفكار
الفنية في التعلم العميق، ولكن أتمنى أن أقدم لكم بعض الناس،
بعض الأبطال في التعلم العميق. الذين ابتكروا العديد من هذه الأفكار التي سنتعلمها
في هذه الدورة التدريبية أو في هذا التخصص. وفي هذه الفيديوهات، أتمنى أيضًا أن أطلب من
هؤلاء القادة في مجال التعلم العميق أن يقدموا لكم نصيحة مهنية تتعلق
بكيفية خوض مجال التعلم العميق، وبكيفية إجراء البحث أو
إيجاد وظيفة في التعلم العميق. وكأول سلسلة المقابلات هذه، أنا سعيد لأقدم لكم
مقابلة مع جيوفري هينتون. مرحبًا جيوفري، وشكرًا لك
على إجراء هذه المقابلة مع deeplearning.ai. >> شكرًا لدعوتك لي. >> أعتقد أنك في هذه المرحلة
قد ابتكرت الكثير من الأفكار المتعلقة بالتعلم العميق أكثر من أي شخص
آخر في هذا العالم. والكثير من الناس يدعونك
بالأب الروحي للتعلم العميق. على الرغم من أنني لم أدرك
حتى قيامنا بالدردشة منذ بضع دقائق، أنك تعتقد أنني أول شخص يطلق عليك
هذا اللقب، وهو شيء يسعدني للغاية. ولكن ما أريد أن أسأله هو،
الكثير من الناس يعرفونك كأسطورة، ولكنني أريد أن أسألك عن
قصتك الشخصية خلف تلك الأسطورة. إذًا كيف اشتركت في، من خلال العودة للوراء،
كيف اشتركت في الذكاء الاصطناعي التعلم الآلي والشبكات العصبية؟ >> عندما كنت في المدرسة الثانوية،
كان لدي زميل في الفصل أفضل مني في كل شيء دومًا،
فقد كان رائعًا في الرياضيات. وجاء إلى المدرسة ذات يوم وقال، هل تعلم
أن العقل يستخدم الصور ثلاثية الأبعاد؟ وأعتقد أن ذلك كان حوالي عام 1966،
وقلت له، ما المقصود بالصورة ثلاثية الأبعاد؟ وأوضح لي أنه في الصورة ثلاثية الأبعاد،
يمكنك قطع نصف الصورة مع استمرار الحصول على الصورة بأكملها. وأن الذكريات في العقل
قد تكون موزعة على العقل كله. وبالتالي كنت أعتقد أنه
قرأ حول تجارب ﻻشلي، حيث يمكنك قطع أجزاء
من عقل الفأر واكتشاف أنه من الصعب جدًا
العثور على جزء معيّن يخزّن ذكرى معيّنة. وقد كان هذا أول شيء يجعلني
مهتمًا بكيفية تخزين العقل للذكريات. وبعد ذلك عندما ذهبت إلى الجامعة، بدأت دراسة علم
وظائف الأعضاء والفيزياء. أعتقد عندما كنت في كامبريدج، وكنت الطالب الجامعي الوحيد
الذي يدرس علم وظائف الأعضاء والفيزياء. ثم توقفت عن ذلك وحاولت دراسة الفلسفة، لأنني
اعتقدت أن ذلك قد يجعلني أتمتع برؤية أكبر. ولكن بدا لي هذا الأمر في الواقع غير مكتمل فيما يتعلق بسبل التمييز
عند قولهم لشيء خاطئ. ولذلك فقد تحولت إلى علم النفس. وفي علم النفس، كانت لديهم
نظريات بسيطة جدًا، وبدت لي غير كافية بصورة واضحة
لشرح ما يقوم به العقل. وحينها قررت أخذ راحة
لبعض الوقت وأصبحت نجارًا. وبعد ذلك قررت أن أجرّب دراسة
الذكاء الاصطناعي، وذهبت إلى إدنبرة، لدراسة الذكاء الاصطناعي مع لانجر هيغينز. وقد قام بعمل رائع جدًا
في الشبكات العصبية وكان قد توقف عن الشبكات العصبية،
وأُعجب جدًا بأطروحة وينوغراد. فعندما وصلت كان يعتقد
أنني أقوم بهذه الأشياء القديمة وكان يجب علي البدء من خلال
رمزية الذكاء الاصطناعي. وكان يحدث بيننا الكثير من الخلافات، ولكنني
واصلت القيام بما أؤمن به. >> ثم ماذا؟ >> في نهاية المطاف حصلت على شهادة الدكتوراه في الذكاء
الاصطناعي وبعدها لم أستطع الحصول على وظيفة في بريطانيا. ولكنني رأيت هذا الإعلان الرائع جدًا عن زمالات سلوان في كاليفورنيا،
وتمكنت من الحصول على واحدة منها. وذهبت إلى ولاية كاليفورنيا،
وكان كل شيء مختلفًا هناك. ففي بريطانيا، كانت الشبكات العصبية
تعتبر شيئًا سخيفًا، وفي كاليفورنيا، كان كل من دونالد نورمان وديفيد روملهارت منفتحين جدًا
للأفكار حول الشبكات العصبية. كانت المرة الأولى التي أذهب فيها إلى مكان
يُنظر خلاله إلى التفكير في كيفية عمل العقل، والتفكير في أن ذلك قد
يكون مرتبطًا بعلم النفس، كشيء إيجابي جدًا. وكان هناك الكثير من المرح، خاصة التعاون مع
ديفيد روملهارت كان رائعًا. >> أراه أمرًا عظيمًا. كان هذا عندما
كنت في جامعة كاليفورنيا، سان دييغو (UCSD) فقد كنت أنت وروملهارت حوالي، عام 1982، تختتمون كتابة بحث
الانتشار الخلفي المؤثر، أليس كذلك؟ >> في الواقع، كان الأمر
أكثر تعقيدًا من ذلك. >> ماذا حدث؟ >> أعتقد، أوائل عام 1982، تمكّن ديفيد روملهارت وأنا، ورون ويليامز، بيننا من تطوير
خوارزمية الانتشار الخلفي، لقد كانت بالأساس فكرة ديفيد روملهارت. واكتشفنا لاحقًا أن الكثير
من الآخرين قد ابتكروها. فقد ابتكرها ديفيد باركر،
ربما بعدنا، ولكن قبل أن ننشرها. وكان بول ويربوس قد نشرها بالفعل
قبل بضع سنوات، ولكن لم ينتبه إليها أحد. وكان هناك أشخاص آخرون نجحوا
في تطوير خوارزميات مشابهة جدًا، فإنه ليس من الواضح ما المقصود بالانتشار الخلفي. ولكن استخدام قاعدة التسلسل
للحصول على المشتقات لم تكن فكرة جديدة. >> فهمت ذلك، لماذا تظن أن
البحث الخاص بكم هو من ساعد المجتمع كثيرًا في فهم الانتشار الخلفي؟ فقد كان الأمر يبدو وأن بحثكم قد أبرز
انتشار عدوى فيما يتعلق بقبول هذه الخوارزمية، أيًا كان من وافق عليها. >> تمكّنا من نشر البحث في
مجلة Nature في عام 1986. وفعلت الكثير من العمل السياسي
لجعل البحث مقبولاً. واكتشفت أن أحد المُحكمين
ربما سيكون ستيوارت سوثيرلاند، والذي كان طبيب نفسي
معروف جدًا في بريطانيا. وذهبت للتحدث معه
لفترة طويلة وشرح له بالضبط
ما يجري. وكان معجبًا جدًا بحقيقة إظهارنا أن الانتشار الخلفي
يمكنه تعلم تمثيلات للكلمات. ويمكنكم النظر إلى هذه التمثيلات،
والتي تكون عبارة عن متجهات صغيرة، ويمكنكم فهم معنى
الميزات الفردية. وقد قمنا بتدريبها على الكلمات الثلاثية
حول الأشجار العائلية، مثل ماري والدتها فيكتوريا. ويمكنكم أن تذكروا لها أول كلمتين،
وسيتعين عليها التنبؤ بالكلمة الأخيرة. وبعد تدريبكم لها، يمكنكم أن تروا جميع أنواع الميزات
في تمثيلات الكلمات الفردية. مثل جنسية الشخص هناك، في أي جيل كان، وإلى أي فرع
من شجرة العائلة كان ينتمي، وهلم جرا. وهذا ما جعل ستيوارت
سوثيرلاند مذهولاً تمامًا وأعتقد أن ذلك كان السبب وراء قبول البحث. >> تضمينات كلمات مبكرة
وتشاهد بالفعل سمات مستخلصة للمعاني الدلالية التي
تظهر من خوارزمية التدريب. >> نعم، من وجهة نظر عالم نفسي،
ما كان مثيرًا هو نجاح الفكرة في توحيد عنصري أفكار مختلفين تمامًا
حول كيف كانت المعرفة. فقد كانت هناك وجهة نظر العالم النفسي القديمة
أن المفهوم هو مجرد مجموعة كبيرة من السمات وأن هناك
الكثير من الأدلة على ذلك. وبعد ذلك كانت هناك وجهة نظر الذكاء الاصطناعي،
والتي تعد وجهة نظر رسمية للأشخاص ذوي العلاقة بالبنيوية. والتي كانت تفيد بأن المفهوم هو
كيف يكون متصلاً بالمفاهيم الأخرى. ولتجسيد مفهوم، يتعين عليك القيام بشيء
مثل هيكل الرسم البياني أو ربما شبكة دلالية. وما أظهره مثال الانتشار الخلفي هذا
هو أنه يمكنك تزويده بالمعلومات التي يمكن أن تندرج في هيكل
الرسم البياني أو في هذه الحالة شجرة عائلة. وسيقوم بتحويل هذه المعلومات إلى
سمات بطريقة يمكنها استخدام السمات لاشتقاق
معلومات متسقة جديدة، أي تعميمها. ولكن الشيء المهم للغاية هو هذا التنقل بين
التمثيل الرسومي أو التمثيل الهيكلي
لشجرة العائلة وتمثيل الأشخاص
كمتجهات سمات كبيرة. وفي الواقع من خلال التمثيل الرسومي
يمكنك الحصول على متجهات السمات. ومن متجهات السمات، يمكنك
الحصول على المزيد حول التمثيل الرسومي. >> إذًا كان هذا في 1986؟ كان ذلك في بداية التسعينات، أظهر بينغيو أنه
يمكنك أخذ بيانات حقيقية، يمكنك أخذ نص إنجليزي وتطبيق
نفس التقنيات عليه، والحصول على تضمينات للكلمات الحقيقية من
النص الإنجليزي، ونال هذا إعجاب الناس كثيرًا. >> أعتقد أننا كنّا نتحدث مؤخرًا كثيرًا حول كيف تقود
أجهزة الكمبيوتر السريعة مثل وحدات معالجة الرسومات وأجهزة الكمبيوتر الفائقة
التعلم العميق. لم أكن ألاحظ ذلك مسبقًا بين 1986
وبداية التسعينات، يبدو أن بدايات هذا الاتجاه
كانت بينك أنت وبينغيو. >> نعم، فقد كان تطورًا كبيرًا. في 1986، كنت أستخدم آلة القائمة
والذي كان أقل من عُشر ميجافلوب. وبحلول عام 1993 تقريبًا،
كان الأشخاص يمكنهم رؤية عشرة ميجافلوب. >> أفهم ذلك.
>> إذًا، كان هناك عامل قدره 100، وهذه المرحلة التي كان
الاستخدام خلالها سهلاً، لأن أجهزة الكمبيوتر
قد بدأت حينها تصبح أسرع. >> خلال العقود العديدة الماضية،
تمكّنت من ابتكار العديد من الأجزاء المتعلقة
بالشبكات العصبية والتعلم العميق. وأنا أشعر بالفضول بالفعل،
لكل هذه الأشياء التي ابتكرتها، أي من هذه الأشياء ما زلت
متحمسًا بشدة له؟ >> أعتقد أن الشيء الأفضل
كان العمل مع تيري سيجنوسكي وآلات بولتزمان. فقد اكتشفنا أن هناك، خوارزمية التعلم البسيطة هذه
التي تم تطبيقها على الشبكات الكبيرة المتصلة بكثافة حيث
يمكنك فقط رؤية بعض العقد. وبالتالي ستتعلم التمثيلات المخفية
وكانت خوارزمية بسيطة للغاية. وكانت تبدو كالشيء الذي
يجب عليك التمكّن من استيعابه في العقل لأن كل تشابك لا يحتاج إلا إلى معرفة
سلوك الخليتين العصبيتين اللتين كان مرتبطًا بهما مباشرة. والمعلومات التي تم
نشرها كانت مماثلة. كانت هناك مرحلتان مختلفتان،
وقد أطلقنا عليهما الاستيقاظ والنوم. ولكن في المرحلتين المختلفتين، تقوم بنشر المعلومات
بنفس الطريقة تمامًا. بينما في شيء مثل الانتشار الخلفي،
هناك مسار أمامي ومسار خلفي
ويعملان بصورة مختلفة. فهما يرسلان أنواعًا
مختلفة من الإشارات. لذلك أنا أعتقد أن هذا
هو الشيء الأفضل. ولسنوات عديدة، بدا الأمر
وكأنه فضول، لأنه بدا وكأنه
بطيء للغاية. ولكن بعد ذلك، تخلصت من
القليل من هذه الميزة، وبدأت تجعلني أشعر بالاستقرار وأكتفي باستخدام تكرار واحد
في شبكة أبسط إلى حد ما. وهذا منحني
آلات بولتزمان المقيدة، والتي نجحت في العمل
بفعالية خلال الممارسة. وفي مسابقة Netflix،
على سبيل المثال، كانت آلات بولتزمان المقيدة واحدة
من العناصر الخاصة بالعمل الفائز. >> وفي الواقع، كان جزء كبير من النهضة
الحديثة في الشبكة العصبية والتعلم العميق، والذي بدأ منذ 2007 تقريبًا،
يرجع إلى عمل آلة بولتزمان المقيدة، وآلة بولتزمان غير المقيدة
الذي أنجزه المعمل لديكم. >> نعم، وهذا جزء آخر من العمل
الذي أشعر بسعادة كبيرة بشأنه، وفكرة ذلك هو أنه يمكنك تدريب
آلة بولتزمان المقيدة لديك، والتي تحتوي على طبقة واحدة فحسب من
السمات المخفية ويمكنك تعلّم طبقة واحدة من السمات. وبعد ذلك يمكنك التعامل مع هذه
السمات كبيانات وفعل نفس الأمر مرة أخرى وحينها يمكنك التعامل مع السمات الجديدة
التي تعلمتها كبيانات وتكرار نفس الأمر مرة أخرى، بأكبر قدر تريده. فقد كان هذا الأمر لطيفًا، ونجح عند تطبيقه عمليًا. وأدركت UY Tay أنه يمكن التعامل مع
الأمر برمته كنموذج واحد، ولكنه كان نوعًا غريبًا من النموذج. فقد كان نموذجًا لديك بالأعلى
آلة بولتزمان المقيدة، ولكن بالأسفل لديك شبكة
الاعتقاد السينية والتي كانت شيئًا تم اختراعه منذ سنوات كثيرة. لذلك فقد كان نموذجًا موجهًا وما تمكّنا من التوصل إليه من خلال
تدريب آلات بولتزمان المقيدة هذه كان طريقة فعالة للقيام
بالاستنتاجات في شبكات الاعتقاد السينية. لذا، في ذلك الوقت، كان هناك أشخاص يدرسون الشبكات العصبية،
وقد كانوا يستخدمون الشبكات المتصلة بكثافة، ولكن لم تكن لديهم أي وسائل جيدة لترك
بصمات احتمالية بشأنها. ولديكم أشخاص يقومون بنماذج رسومية،
بخلاف أطفالي، الذين يمكنهم القيام بالاستنتاج بصورة صحيحة، ولكن
فقط في الشبكات المتصلة بصورة متناثرة. وما تمكّنا من إظهاره هو
طريقة تعلم شبكات الاعتقاد العميقة هذه لذلك فهناك نموذج تقريبي
للاستنتاج يتميز بسرعة كبيرة، فهم يعمل على تسليم مسار أمامي واحد فحسب
وكانت هذه نتيجة رائعة جدًا. ويمكنك ضمان أنه في كل مرة
تتعلم خلالها هذه الطبقة الإضافية من السمات فإن هناك نطاقًا، وكل مرة تتعلم خلالها
طبقة جديدة، تحصل على نطاق جديد وكان النطاق الجديد دومًا
أفضل من النطاق القديم. >> ويتم إظهار النطاقات المتغيرة
حينما تضيفون الطبقات. نعم، أتذكر هذا الفيديو. >> فقد كان هذا هو الشيء الثاني
الذي كنت متحمسًا بشأنه. وأعتقد أن الشيء الثالث كان العمل
الذي أنجزته من خلال الطرق المتغيرة. وتبيّن أن الأشخاص العاملين في الإحصاء
قد قاموا بعمل مشابه من قبل، ولكننا لم نكن على علم بذلك. فقد تمكّنا من جعل عمل EN أفضل تمامًا من خلال توضيح
أنك لست بحاجة لتنفيذ خطوة E مثالية. بل يمكنك تنفيذ خطوة E تقريبية. وكانت EN خوارزمية كبيرة في الإحصاء. وتمكّنا من إظهار
تعميم كبير لها. وخاصة في 1993،
أعتقد مع فان كامب. قمت بإجراء بحث، من خلال
أول أبحاث بايز المتغيرة، والتي أظهرنا خلاله أنه يمكنك
إعداد نسخة من التعلم البايزي والتي كانت أكثر مرونة، من خلال
تقريب الجزء الخلفي من خلال غاوس. ويمكنك فعل ذلك في شبكة عصبية. وكنت متحمسًا بشدة لهذا الأمر. >> أرى ذلك.
رائع، أعتقد أنني أتذكر
كل هذه الأبحاث. قضيت أنت وهينتون، في البحث التقريبي،
ساعات كثيرة في قراءة هذا. وأعتقد أن بعضًا من
الخوارزميات التي تستخدمها اليوم أو بعضًا من الخوارزميات التي يستخدمها
الكثير من الأشخاص يوميًا تقريبًا، هي أشياء مثل dropouts (الحذف العشوائي) أو
أعتقد حالات التنشيط الآتية من مجموعتك؟ >> نعم ولا. فكّر الآخرون في
الوحدات الخطية المعدلة. وقد قمنا بالفعل ببعض العمل المتعلق
بآلات بولتزمان المقيدة والذي يظهر أن ReLU كانت مكافئة تقريبًا
لمجموعة كاملة من الوحدات اللوجستية. وكانت هذه واحدة من الأشياء
التي ساعدت وحدات ReLU في الانتشار. >> كنت فضوليًا بخصوص هذا الأمر. كان البحث القيّم يحتوي على الكثير من الأمور
المتعلقة بالرياضيات التي توضح أن هذه الدالة يمكن تقريبها بواسطة هذه
الصيغة المعقدة تمامًا. هل قمت بهذه الحسابات حتى يتم
قبول بحثك كمرجع أكاديمي، أو أن إجراء كل هذه الحسابات قد أثر حقًا
في تطور الحد الأقصى لـ 0 وx؟ >> كانت هذه واحدة من الحالات
التي كانت الرياضيات خلالها مهمة فيما يتعلق بتطور الفكرة. لذا فقد عرفت الوحدات الخطية المعدلة،
وعرفت بوضوح الوحدات اللوجستية. ونظرًا للعمل
في آلات بولتزمان، فقد تم إجراء كل العمل الأساسي
باستخدام الوحدات اللوجستية. لذا فإن السؤال كان، هل تعمل خوارزمية التعلم
مع الوحدات الخطية المعدلة؟ ومن خلال إظهار أن الوحدات الخطية المعدلة
كانت مكافئة تمامًا لمجموعة من الوحدات اللوجستية، فقد أظهرنا أنها
قد تنجح مع كل ما يتعلق بالرياضيات. >> صحيح. وقد قدمت الإلهام اليوم،
حيث يستخدم الكثير من الأشخاص ReLU فهي تنجح بدون-
>> نعم. >> بدون الحاجة الضرورية
لفهم نفس الدافع. >> نعم، فقد لاحظت شيئًا
مؤخرًا عندما ذهبت إلى Google. أعتقد في 2014، قدمت محاضرة
في Google حول استخدام وحدات ReLU والبدء من خلال مصفوفة الهوية. لأن الشيء الرائع حول وحدات ReLU
هو أنه إذا واصلت تكرار الطبقات المخفية
وقمت بالبدء من خلال الهوية، فإنها ستنسخ النمط
في الطبقة أدناه. وبالتالي كنت أوضح أنه يمكنك
تدريب الشبكات من خلال 300 طبقة مخفية ويمكنك تدريبها بكفاءة كبيرة
إذا بدأت من خلال هويتها. ولكنني لم أواصل هذا الأمر
وأنا نادم حقًا على عدم مواصلته. نشرنا بحثًا مع kwok lee يوضح أنه
يمكنك بدء يوضح أنه يمكنك بدء
شبكات متكررة مثل هذه. ولكن كان يجب علي مواصلة
هذا الأمر أكثر لأنه لاحقًا ستكون هذه الشبكات المتبقية بمثابة شيء مهم. >> على مدار سنوات، لقد سمعتك
تتحدث كثيرًا عن العقل. لقد سمعتك تتحدث عن العلاقة
بين الانتشار الخلفي والعقل. ما أفكارك الحالية حول هذا الأمر؟ >> أعمل حاليًا على
بحث حول هذا الأمر. وأعتقد أن فكرتي الأساسية تنطوي على، أنه إذا تبيّن أن الانتشار الخلفي يمثل
خوارزمية جيدة بالفعل للتعلم. فبالتأكيد كان بإمكان التطور
اكتشاف كيفية منع ذلك. أعني أنه لديك خلايا قد
تصبح بمثابة مقل للعيون أو أسنان. والآن، إذا كان بإمكان الخلايا فعل ذلك،
فبالتأكيد يمكنها تنفيذ الانتشار الخلفي ومن المحتمل هذا
الضغط الانتقائي الكبير من أجله. لذلك أعتقد أن فكرة علماء الأعصاب أن هذا
لا يبدو قابلاً للتصديق، وأنه مجرد شيء سخيف. قد يكون هناك
إمكانية تطبيق دقيق للأمر. وأعتقد أن العقل ربما لديه
شيء قد لا يكون الانتشار الخلفي بالتحديد، ولكنه
قريب جدًا منه. وعلى مدار السنين، قد توصّلت إلى
مجموعة من الأفكار حول كيف قد يعمل هذا الأمر. ففي عام 1987، وبالتعاون مع جيمس مكليلاند، توصلت إلى
خوارزمية إعادة التوزيع، حيث تكمن الفكرة في قيامك بإرسال
معلومات حول تكرار حلقي. وتحاول تنفيذ ذلك بحيث لا تتغير الأمور بينما
تنتقل المعلومات في هذا التكرار الحلقي. وبالتالي فإن الإصدار الأبسط يكون من خلال وجود
وحدات إدخال ووحدات مخفية لديك، وترسل المعلومات من وحدات الإدخال إلى
الوحدات المخفية، ثم تعود إلى الإدخال وبعدها تعود إلى المخفية،
ثم إلى الإدخال وهكذا. وما تريده هو،
أنك تريد تدريب autoencoder، ولكنك تريد تدريبه بدون
الحاجة للقيام بالانتشار الخلفي. لذلك فإنك تكتفي بتدريبه للمحاولة
والتخلص من كل الاختلافات في الأنشطة. فالفكرة أن قاعدة التعلم للتشابك هو تغيير نسبة الأوزان
للإدخال قبل المشبكي وبما يتناسب مع معدل
التغيير في الإدخال بعد المشبكي. ولكن في إعادة التوزيع، فإنك تحاول
أن تجعل الإدخال بعد المشبكي، تحاول جعل الوحدات القديمة
جيدة والوحدات الجديدة سيئة، لذا فإنك تقوم بالتغيير في هذا الاتجاه. وقد ابتكرنا هذه الخوارزمية قبل
توصل علماء الأعصاب إلى spike-timing-dependent plasticity "اللدونة الدماغية المعتمدة على توقيت الحسكة" وتعد Spike-timing-dependent plasticity
نفس الخوارزمية ولكن بالعكس، حيث يكون الشيء الجديد جيدًا
والقديم سيئًا في قاعدة التعلم. لذلك، فإنك تغيّر نسب الوزن
للنشاط قبل المشبكي مضروبًا في النشاط بعد
المشبكي الجديد مطروحًا منه القديم. وبعد ذلك، أدركت في 2007،
أنه إذا أخذت مجموعة من آلات بولتزمان المقيدة
وقمت بتدريبها. بعد تدريبها، ستكون لديك
الشروط المناسبة تمامًا لتنفيذ الانتشار الخلفي
من خلال محاولة إعادة البناء. إذا نظرت إلى خطأ إعادة البناء،
فإن خطأ إعادة البناء هذا يوضح لك بالفعل مشتقة
الأداء التمييزي. وفي أول ورشة عمل حول التعلم العميق
في مؤتمر NIPS في 2007، قدمت محاضرة حول ذلك. وهو ما تم تجاهله تمامًا. بعد ذلك، أخذ
يوشوا بينغيو الفكرة وقام بالكثير من
العمل في هذا الأمر. أكثر مما قمت بنفسي
من العمل في هذا الأمر. وأعتقد أن هذه الفكرة تنطوي على أنه إذا كان لديك
مجموعة من شبكات autoencoders، فحينها يمكنك الحصول على المشتقات من خلال إرسال الأنشطة
للخلف وتحديد موضع أخطاء إعادة البناء، وهي فكرة مثيرة حقًا
وقد تكون جيدة من خلال كيفية تنفيذ العقل لها. >> هناك موضوع آخر أعلم أنك تفكر فيه كثيرًا
وسمعت أنك ما زلت تعمل عليه هو كيفية التعامل مع
المقاييس متعددة التوقيتات في التعلم العميق؟ هل يمكنك مشاركة أفكارك حول هذا الأمر؟ >> نعم، في الواقع، يعود هذا الأمر إلى
سنواتي الأولى كطالب في الدراسات العليا. فقد كانت أول محاضرة ألقيتها حول
استخدام ما أطلقت عليه الأوزان السريعة. وأعني الأوزان التي تتكيف سريعًا،
ولكنها تتدهور سريعًا. وبالتالي يمكنها أن تحمل الذاكرة قصيرة الأمد. وأوضحت من خلال نظام بسيط
للغاية في 1973 أنه يمكنك القيام بارتداد حقيقي
من خلال هذه الأوزان. وما أعنيه بالارتداد الحقيقي
هو أنه يتم إعادة استخدام الخلايا العصبية المستخدمة في تمثيل الأشياء مجددًا
لتمثيل الأشياء في النواة التكرارية. ويتم إعادة استخدام الأوزان المستخدمة في تقديم المعرفة مجددًا
في النواة التكرارية. ويقودنا هذا إلى السؤال
عندما تُخرج النواة التكرارية، كيف تتذكر ما الشيء الذي
كنت في خضم القيام به؟ أين هذه الذاكرة؟ لأنك استخدمت الخلايا العصبية
للنواة التكرارية. والإجابة هي أنه يمكنك وضع هذه
الذاكرة في الأوزان السريعة ويمكنك استرجاع الخلايا العصبية
للأنشطة من هذه الأوزان السريعة. ومن خلال التعاون حديثًا مع جيمي با، تمكّنا من إجراء بحث في مؤتمر NIPS حول هذا الأمر
باستخدام الأوزان السريعة للتكرار مثل هذا. >> صحيح. >> فقد كانت هذه فجوة كبيرة جدًا. فقد كان النموذج الأول
الذي لم يتم نشره في 1973 وبعد ذلك كان نموذج جيمي با في 2015،
أعتقد أو 2016. وبالتالي فهو بعده بحوالي 40 عامًا. >> وأعتقد أنه من الأفكار التي سمعتك
تتحدث عنها قبل بضع سنوات الآن، أعتقد منذ أكثر من خمس سنوات، الكبسولات،
إلى أين وصلت؟ >> حسنًا، لقد عدت إلى
الوضع الذي اعتدت على أن أكون عليه. حيث توجد لدي هذه الفكرة والتي
أؤمن بها تمامًا ولكن لا يؤمن بها أي شخص آخر. وقدّمت أبحاث حول هذا الأمر
وتم رفضها. ولكنني أؤمن حقًا بهذه الفكرة
وسأواصل دعمها. وهي تعتمد على،
بعض الأفكار الرئيسية. إحداها تدور حول كيف يمكنك
تمثيل الكيانات متعددة الأبعاد ويمكنك تمثيل الكيانات متعددة الأبعاد
من خلال متجه من الأنشطة. وكما تعرف
هناك أي منها. لذا فالفكرة تنطوي على أنه في كل منطقة
بالصورة، ستفترض أن هناك بحد أقصى، واحدة من أنواع السمات الخاصة. وحينها ستستخدم مجموعة
من الخلايا العصبية وستمثل أنشطتها الجوانب
المختلفة لهذه السمة، مثل، ما إحداثيات x وy
ضمن هذه المنطقة تحديدًا؟ ما اتجاه هذه الصورة؟ ما مدى سرعة تحركها؟ ما لونها؟ ما مدى سطوعها؟ وأشياء من هذا القبيل. لذا، يمكنك استخدام مجموعة كاملة من
الخلايا العصبية لتمثيل أبعاد مختلف للشيء نفسه. شريطة وجود واحد منها فقط. وهذه طريقة مختلفة
تمامًا للقيام بالتمثيل عما اعتدنا على استخدامه
عادة في الشبكات العصبية. عادة في الشبكات العصبية،
لدينا طبقة كبيرة للغاية، وكل الوحدات تنطلق
وتفعل أيًا كان ما تفعله. ولكنك لا تفكر في تجميعها
في مجموعات أصغر تمثل إحداثيات مختلفة لنفس الشيء. لذا أعتقد أنها ينبغي أن
تكون هذه البنية الإضافية. والفكرة الأخرى
التي تتماشى مع ذلك. >> يعني هذا التمثيل
الموزع، أنك تقوم بتقسيم التمثيل. >> نعم.
>> إلى مجموعات فرعية مختلفة. >> نعم.
>> لتمثيل، بدلاً من >> أطلق على كل مجموعة من هذه المجموعات الفرعية الكبسولة. >> صحيح. >> والفكرة في أن الكبسولة بإمكانها
تمثيل نموذج للسمة، ولكن واحد فقط. وتمثل كل الخصائص
المختلفة لهذه السمة. فهي سمة لديها الكثير
من الخصائص على عكس الخلية العصبية العادية،
والشبكة العصبية التي لديها مقياس واحد للخصائص. >> نعم، أفهم ذلك. >> وبعد ذلك ما الذي يمكنك فعله إذا حصلت
على ذلك، هو أنه يمكنك القيام بشيء تعد الشبكات العصبية العادية سيئة جدًا فيه، وهو قدرتك
على القيام بما أطلق عليه التوجيه بموجب اتفاق. دعونا نفترض أنك
تريد إجراء تقسيم وأن لديك شيئًا قد يكون الفم
ولديك شيئًا آخر قد تكون الأنف. وتريد معرفة ما إذا كان يجب عليك
وضعهما معًا لتكوين شيء واحد. لذا فإن الفكرة يجب أن تحتوي على كبسولة .للفم تحتوي على
معلمات الفم وأن تكون لديك كبسولة للأنف
تكون لديها معلمات الأنف. ولكي تتمكن من اتخاذ قرار 
وضعهما معًا أم لا فإنك تحصل على كل منهم للتصويت على
ما المعلمات التي يجب أن تكون موجودة للوجه. والآن إذا كان الفم والأنف في
العلاقة المكانية المناسبة، فإنهما سيتفقان. عندما تكون لديك كبسولتان في مستوى واحد
ومن خلال التصويت لنفس مجموعة المعلمات في المستوى التالي، يمكنك
افتراض أنها من المحتمل أن تكون صحيحة، لأن الاتفاق في حيز ذي
أبعاد كبيرة أمر غير مرجح. وهذه طريقة مختلفة
تمامًا للقيام بالتصفية، عما نستخدمه عادة في الشبكات العصبية. لذا، فإنني أعتقد أن هذا التوجيه بموجب اتفاق
سيكون شديد الأهمية للحصول على الشبكات العصبية لتعميمها
بصورة أفضل من البيانات المحدودة. أعتقد أن ذلك سيكون أمرًا جيدًا للغاية
فيما يتعلق بإجراء التغييرات في وجهة النظر، وسيكون جيدًا للغاية في إجراء التقسيم. وآمل أن يكون أكثر كفاءة
من الناحية الإحصائية عما نفعله حاليًا في الشبكات العصبية. إذا كنت تريد التعامل
مع التغييرات في وجهة النظر، فما عليك إلا تقديم مجموعة كاملة من التغييرات
في وجهة النظر إلى جانب التدريب عليها جميعًا. >> أفهم ذلك، لذا بدلاً من
التعلم الخاضع للإشراف، يمكنك تعلم ذلك بطريقة مختلفة. >> حسنًا، ما زلت أخطط للقيام بذلك
من خلال التعلم الخاضع للإشراف، ولكن آليات المسارات الأمامية
تكون مختلفة تمامًا. فهو ليس مسارًا أماميًا خالصًا بمعنى
أن هناك أجزاءً قليلة للتكرار حيث تعتقد إنك وجدت الفم
وتعتقد أيضًا إنك وجدت الأنف. واستخدام القليل
من التكرار لتحديد ما إذا كان يجب تجميعهما معًا
لتكوين الوجه أم لا. ويمكنك القيام بالانتشار الخلفي
من هذا التكرار. لذا يمكنك المحاولة
والقيام بالأمر بشكل مميز قليلاً، ونعمل على ذلك الأمر
الآن في مجموعتي في تورنتو. فلدي الآن فريق Google صغير
في تورنتو، جزء من فريق العقل. وهذا ما يثير حماسي حاليًا. >> نعم، رائع. نتطلع إلى هذا البحث
حينما يظهر. >> نعم، إذا ظهر [ضحك]. >> لقد عملت في التعلم العميق
لعقود عديدة. أنا أشعر بالفضول حقًا،
كيف تغيّر تفكيرك، وفهمك للذكاء الاصطناعي
على مدار هذه السنوات؟ >> أعتقد أن الكثير من تاريخي
الفكري كان يدور حول الانتشار الخلفي، وكيفية استخدام الانتشار الخلفي،
وكيفية الاستفادة من قوته. لذا للبدء في هذا، في منتصف الثمانينات،
كنا نستخدمه من أجل التعلم التمييزي
وكان يعمل بصورة جيدة. وبعد ذلك قررت في مطلع التسعينات، أن معظم التعلم البشري كان
سيكون من خلال التعلم الخاضع للإشراف. وكنت متحمسًا بشدة
بخصوص التعلم الخاضع للإشراف وكان هذا عندما عملت في أشياء
مثل خوارزمية wake-sleep. >> وقد أثرت تعليقاتك في هذا الوقت
تمامًا في تفكيري أيضًا. عندما كنت أقود مشروع Google Brain،
مشروعنا الأول، بذلت الكثير من العمل في التعلم الخاضع للإشراف
بسبب تأثيرك. >> حسنًا، وربما تسببت في تضليلك. لأنه على المدى الطويل، أعتقد أن التعلم الخاضع للإشراف
سيكون شديد الأهمية. ولكن يتعين عليك مواجهة الواقع. والذي نجح على مدار السنوات العشر الماضية
أو نحو ذلك هو التعلم الخاضع للإشراف. التدريب التمييزي،
حيث تكون لديك تسميات أو تحاول توقع الشيء التالي
في السلسلة، لذا فهذا يكون بمثابة التسمية. ونجح هذا بصورة لا تصدق. ما زلت أعتقد أن التعلم الخاضع للإشراف
سيكون شديد الأهمية، وأن الأمور ستنجح بصورة لا تصدق وأفضل مما هي عليه الآن،
عندما ننفذ هذا العمل بصورة صحيحة، ولكن لم ننفذه جيدًا حتى الآن. >> نعم، أعتقد أن الكثير من
كبار الشخصيات في التعلم العميق، بما في ذلك أنا،
نبقى متحمسين للغاية حول ذلك. ولكن ليس لدى أحد منّا أي فكرة
تقريبًا عن كيفية تنفيذ الأمر حتى الآن. ربما لديك فكرة، ولكن لا أعتقد أن لدي أي فكرة. >> تعتبر autoencoders المتغيرة هي الموضع
الذي استخدمت خلاله الحيل الخاصة بإعادة وضع المعلمات. وقد بدت لي كفكرة رائعة. وبدت لي كذلك خوارزميات generative
adversarial nets بمثابة فكرة جيدة حقًا. وأعتقد أن خوارزميات generative
adversarial nets هي واحدة من أكبر الأفكار في
التعلم العميق التي تعد جديدة حقًا. آمل أن أتمكن من وضع
كبسولات ناجحة، ولكن حتى الآن أعتقد أن generative
adversarial nets كانت بمثابة طفرة كبيرة. >> ماذا حدث لسمات
البطء والتضاؤل، حيث كانتا اثنتين من المبادئ الأخرى
لبناء النماذج الخاضعة للإشراف؟ لم أكن أبدًا متحمسًا بشأن
التضاؤل كما كنت، يا صديقي. ولكن بالنسبة لسمات البطء، أعتقد أنها تمثل خطأ. يجب ألا تقول بطيئة. الفكرة الأساسية صحيحة، ولكن يجب ألا
تختار سمات لا تتغير، يجب أن تختار
السمات التي تتغير بطرق متوقعة. فإليك أحد المبادئ الأساسية
حول كيف تصوغ أي شيء. تأخذ القياسات الخاصة بك
وتعمل على تطبيق التحولات غير الخطية على
القياسات حتى تصل إلى تمثيل كمتجه ثابت
يكون في الواقع خطيًا. لذا، فإنك لا تتظاهر بأنه خطي فحسب
مثلما تفعل مع مرشحات كالمان. ولكنك تجد بالفعل تحولاً
من الملاحظات إلى المتغيرات الأساسية
حيث تقوم العمليات الخطية، مثل مضاعفات المصفوفة في
المتغيرات الأساسية، بتنفيذ العمل. لذا على سبيل المثال،
إذا أردت تغيير وجهات النظر. إذا أردت إنتاج الصورة
من وجهة نظر أخرى، ما يجب عليك فعله هو الانتقال من
وحدات البكسل إلى الإحداثيات. وبمجرد وصولك إلى
تمثيل الإحداثيات، وهو شيء آمل
أن تجده الكبسولات. يمكنك حينها تنفيذ مضاعفة المصفوفة
لتغيير وجهة النظر ثم يمكنك ربطها مرة أخرى بوحدات البكسل. >> حسنًا، هذا هو السبب الذي دفعك للقيام بكل هذا. >> أعتقد أن هذا
مبدأ عام للغاية. >> لهذا السبب قمت بكل هذا العمل في تجميع الوجه، أليس كذلك؟ حيث تأخذ الوجه وتضغطه
إلى متجه ذي أبعاد منخفضة للغاية، وبالتالي يمكنك معالجة هذا الأمر
واسترجاع وجوه أخرى. >> كان لدي طالب عمل في هذا الأمر،
ولكن لم أقم بالكثير من العمل في هذا الأمر بنفسي. >> الآن أنا متأكد من أنك ما زلت تتلقى الأسئلة طوال الوقت، إذا كان شخص يريد بدء العمل في التعلم
العميق، فما الذي يجب عليه فعله؟ وما النصائح التي ستقدمها؟ أنا متأكد من أنك قدمت نصائح كثيرة إلى
الأشخاص في سياقات مباشرة، ولكن الجمهور العالمي من الناس
يشاهد هذا الفيديو. ما النصيحة التي تود توجيهها
لهم للبدء في التعلم العميق؟ >> حسنًا، نصيحتي هي أنه يجب عليهم قراءة
المؤلفات، ولكن لا تبالغوا في مرحلة القراءة. فهذه هي النصيحة التي حصلت عليها من الموجه الخاص بي،
وهو على عكس ما يقوله معظم الناس. يقول معظم الناس إنه يجب عليك قضاء
سنوات عديدة في قراءة المؤلفات وبعد ذلك، يجب أن تبدأ
العمل معتمدًا على أفكارك الخاصة. وقد يكون هذا صحيحًا لبعض الباحثين
ولكن بالنسبة للباحثين المبدعين أعتقد أن ما يجب عليك فعله هو قراءة
القليل من المؤلفات. ولاحظ شيئًا تعتقد أن
الجميع يفعله بصورة خاطئة، أنا ضد هذا المنطلق. يمكنك النظر في الأمر
ولا يبدو صحيحًا. ثم تتوصل بعد ذلك إلى طريقة القيام بالأمر بصورة صحيحة. وعندما يقول لك الناس
هذا ليس جيدًا، فما عليك إلا مواصلة فعل الأمر. ولدي مبدأ مهم جدًا لمساعدة
الأشخاص في مواصلة الأمر، حيث تكون أفكارك
إما جيدة أو غير ذلك. إذا كانت أفكارك جيدة،
فيجب عليك اتباعها وستكون ناجحًا في النهاية. وإذا لم تكن أفكارك جيدة،
فلا يهم ما تفعله. >> صحيح [ضحك]. نصيحة ملهمة، ربما أعمل بها أيضًا. >> قد تثق
في أفكارك أيضًا. لا يوجد معنى لعدم ثقتك فيها. >> صحيح، نعم. عادة أنصح الناس بعدم القراءة فحسب،
بل بمحاكاة الأبحاث المنشورة. وربما يضع هذا محددًا طبيعيًا
حول المقدار الذي يمكنك إنجازه، لأن نتائج المحاكاة
مستهلكة للوقت بشدة. نعم، هذا صحيح فعندما
تحاول محاكاة بحث منشور تتمكّن من استكشاف كل الحيل
البسيطة اللازمة لإنجاح الأمر. النصيحة الأخرى لدي هي،
لا تتوقف أبدًا عن البرمجة. لأنه إذا أعطيت طالبًا
شيئًا للقيام به، وكان طالبًا سيئًا، فسيعود ويقول لك، لم ينجح الأمر. وسبب عدم نجاحه قد يكون
بعض القرارات البسيطة التي اتخذها، والتي لم يدرك أنها شديدة الأهمية. بينما إذا أعطيته لطالب جيد،
مثل UY-Tay على سبيل المثال. يمكنك منحه أي شيء
وسيعود لك ويقول، لقد نجح الأمر. أتذكر فعل هذا مرة واحدة،
وقلت حينها، انتظر دقيقة UY. منذ تحدثنا في المرة الأخيرة، أدركت أنه لا يمكن أن يعمل
للسبب التالي. وقال UY، نعم، أدركت ذلك
فورًا، لذلك فإنني افترضت أنك لم تقصد ذلك. >> [ضحك] صحيح، نعم،
هذا رائع. دعونا نرى، هل هناك أي نصيحة أخرى للأشخاص الذين يريدون بدء دخول
الذكاء الاصطناعي والتعلم العميق؟ >> أعتقد بالأساس، أنه يجب عليك القراءة بما يكفي
حتى تبدأ في تطوير الأفكار. وبعدها، ثق في أفكارك
وحاول تحقيقها، لا تشعر بالقلق إذا قال لك الجميع
إنها ليست لها معنى. >> وأعتقد أنه لا توجد أي طريقة
لتعلم من خلالها ما إذا كان الآخرون على حق أم خطأ عندما يقولون إنها ليست ذات معنى، ولكن يجب عليك
تحقيقها واكتشاف الأمر حينها. >> حسنًا، ولكن هناك شيئًا واحدًا، والذي
، إذا فكرت في إنها فكرة جيدة حقًا، وقال لك الآخرون
إنها ليست لها معنى تمامًا، فحينها تعرف
أنك تخطط لشيء. فمثال على ذلك عندما
وتوصلت أولاً إلى الأساليب المتغيرة. أرسلت رسالة بريد إلى
طالب سابق لي اسمه بيتر براون، ونعلم الكثير حوله. وقد عرضها على الأشخاص
الذين عملوا معه، ويُعرفون باسم الأشقاء،
فقد كانوا توأمين. وقد أخبرني لاحقًا ماذا قالوا،
وقد قالوا، إما أن هذا الشخص سكير
أو مجرد شخص غبي، فقد كانوا يظنون
بالفعل إنه هراء. الآن، كان من الممكن جزئيًا
أن تكون الطريقة التي أوضحتها، لأنني أوضحتها فيما يتعلق بالأفكار. ولكن عندما تكون لديك
ما تعتقد أنها فكرة جيدة ويعتقد الآخرون أنها هراء تام،
فهذه علامة الفكرة الجيدة في الواقع. >> صحيح، ومواضيع الأبحاث، يجب أن يعمل طلاب الدراسات العليا
الجدد على الكبسولات وربما التعلم غير الخاضع للإشراف، هل هناك شيء آخر؟ >> من النصائح الجيدة
لطلاب الدراسات العليا الجدد هو، يجب عليك معرفة ما إذا كان لديك مستشار
لديه نفس معتقدات مشابهة لتلك الخاصة بكم. لأنه إذا كنت تعمل في أشياء
يشعر مستشارك بإحساس عميق تجاهها، فإنك ستحظى بالكثير من النصائح الجيدة
والوقت من مستشارك. إذا كنت تعمل في أشياء
لا يعد المستشار مهتمًا بها، فكل ما ستحصل عليه، هو بعض النصائح،
ولكنها لن تكون مفيدة للغاية. >> نعم، 
وآخر شيء حول النصيحة للمتعلمين، كيف تشعر بخصوص الأشخاص
الذين يدخلون برنامج دكتوراه؟ بالمقارنة مع الانضمام إلى شركة كبيرة،
أو مجموعة أبحاث مرموقة؟ >> نعم، إنه أمر معقد،
أفكر الآن في ما يجري، لا يوجد عدد كافٍ من الأكاديميين المدربين
في التعلم العميق لتثقيف كل الناس الذين نحتاج إلى تثقيفهم في الجامعات. لا يوجد النطاق الترددي
لأعضاء هيئة التدريس، ولكن أعتقد أن هذا سيكون مؤقتًا. أعتقد أن ما حدث هو أن
معظم الأقسام كانت بطيئة جدًا في فهم نوع التطور
الذي يجري. أوافقك الرأي إلى حد ما، هذا
ليس تطورًا صناعيًا ثانيًا، ولكنه شيء بهذا الحجم تقريبًا. وهنا تغيير كبير للغاية يحدث في وجهات النظر، بشكل أساسي لأن علاقتنا
مع أجهزة الكمبيوتر قد تغيرت. بدلاً من برمجتها،
نحن الآن نوضح لها، وهي تكتشف الأمر. وهذه طريقة مختلفة تمامًا
في استخدام أجهزة الكمبيوتر وقد تم تصميم أقسام علوم الكمبيوتر
حول فكرة برمجة أجهزة الكمبيوتر. وهي لا تفهم هذه النوعية، أجهزة كمبيوتر العرض هذه ستكون
كبيرة بحجم أجهزة كمبيوتر البرمجة. باستثناء عدم فهمها أن نصف الأشخاص
في الأقسام يجب أن يكونوا أشخاصًا يحضرون أجهزة الكمبيوتر لتنفيذ
الأمور من خلال عرضها. ويرفض قسمي الإقرار
بضرورة وجود الكثير من الأشخاص الذين يفعلون هذا الأمر. فهم يعتقدون أنه يمكنك توفير مجموعة،
ربما أكثر قليلاً، ولكن ليس كثيرًا للغاية. وفي هذه الحالة يجب عليك تذكير الشركات الكبيرة
للقيام بالكثير من التدريب. إن Google يدرب الناس الآن،
وهو ما نطلق عليه موطن العقل، أعتقد أن الجامعات
في النهاية ستواكب الأمر. >> نعم، في الواقع، ربما
اكتشف الكثير من الطلاب هذا. ترغب الكثير من البرامج المدرجة في أول
50 برنامجًا، أكثر من نصف المتقدمين بالفعل في العمل على العرض
بدلاً من البرمجة. نعم، رائع، في الواقع،
لإعطاء الفضل لمن يستحقه، حيث يقوم الذكاء الاصطناعي للتعلم العميق
بإنشاء تخصص التعلم العميق. إلى حد علمي، فإن أول دورة تدريبية هائلة مفتوحة عبر
الإنترنت في التعلم العميق كانت تلك التي قمت بتدريسها على كورسيرا، وتعود لعام 2012، أيضًا. وبطريقة غريبة إلى حد ما، حدث هذا عندما نشرت خوارزمية RMS
لأول مرة، وهو أمر صعب. >> حسنًا، نعم، كما تعلم، كان هذا لأنك دعوتني
لدراسة دورة تدريبية هائلة مفتوحة عبر الإنترنت. وعندما كنت غير متيقن بخصوص
التنفيذ، فإنك واصلت تشجيعي للقيام بالأمر، لذا فهذا عمل رائع مني، على الرغم
من أنه كان ينطوي على الكثير من العمل. >> نعم، وشكرًا لك على فعل ذلك،
أتذكر أنك قدمت الشكوى لي، ما مقدار العمل المبذول. وأنت تبقى لوقت متأخر في الليل،
ولكنني أعتقد أن الكثير من المتعلمين قد استفادوا من أول دورة تدريبية هائلة مفتوحة
عبر الإنترنت، وبالتالي فأنا ممتن جدًا لك نظير ذلك. >> هذا جيد، نعم
>> نعم، على مدار السنين، رأيتك مشتركًا في مناقشات حول
أمثلة للذكاء الاصطناعية وما إذا كان هناك تحول في
المثال للذكاء الاصطناعي. ما،
هل يمكنك مشاركة أفكارك حول هذا الأمر؟ >> نعم، بكل سعادة، أعتقد أنه في
الأيام الأولى، منذ الخمسينات، الأشخاص مثل فون نيومان
ولم يؤمنوا بالذكاء الاصطناعي الرمزي، حصلوا على الإلهام من قِبل العقل. لسوء الحظ، توفى كلاهما بسن صغير جدًا
ولم يكن صوتهما مسموعًا. وفي الأيام الأولى من الذكاء الاصطناعي، اقتنع الناس تمامًا
أن التمثيلات التي تحتاج إليها للذكاء كانت التعبيرات
الرمزية إلى حد ما. أحد أشكال المنطق النظيف،
والذي يمكنك خلاله أداء الأشياء وليس المنطق بصورة مطلقة، ولكنه شيء أشبه بالمنطق،
وجوهر الذكاء كان الاستدلال. ما يحدث الآن هو
أن هناك وجهة نظر مختلفة تمامًا، وهي أن الفكرة عبارة عن
متجه كبير رائع للنشاط العصبي، على النقيض من ذلك،
الفكرة التي تعد تعبيرًا رمزيًا. وأعتقد أن الأشخاص الذين اعتقدوا أن
الأفكار كانت عبارة عن تعبيرات رمزية قد ارتكبوا خطأ كبيرًا. فما يأتي عبارة عن سلسلة كلمات،
وما يخرج عبارة عن سلسلة كلمات. ونظرًا لذلك، فإن سلاسل الكلمات
هي الطريقة الواضحة لتمثيل الأشياء. وبالتالي فقد اعتقدوا أن ما يجب أن يكون في الوسط
كان سلسلة كلمات أو شيئًا مثل سلسة كلمات. وأعتقد أن ما يأتي في الوسط
ليس شيئًا مثل سلسلة كلمات. أعتقد أن الفكرة في أن الأفكار يتعين أن تكون
بلغة ما هي فكرة سخيفة مثل الفكرة التي تفيد بأن فهم
التخطيط في مشهد مكاني يتعين أن يكون بالبكسل. وإذا كانت لدينا طابعة
مصفوفة نقطية مرتبطة بنا، فيتعين أن تخرج وحدات البكسل ولكن
ما بين ذلك ليس بكسل. لذلك أعتقد أن الأفكار هي
مجرد متجهات كبيرة رائعة وأن هذه المتجهات الكبيرة لديها قوى سببية. فهي تتسبب في متجهات كبيرة أخرى، وهذا مخالف تمامًا لوجهة نظر الذكاء الاصطناعي
القياسي بأن الأفكار هي تعبيرات رمزية. >> نعم، جيد، أعتقد أن الذكاء الاصطناعي بالتأكيد سيأتي
إلى وجهة النظر الجديدة هذه في الأيام الحالية. >> بعض ذلك، أعتقد أن الكثير من الناس في الذكاء الاصطناعي ما زالوا
يعتقدون أن الأفكار يجب أن تكون تعبيرات رمزية. >> شكرًا كثيرًا لك
على إجراء هذه المقابلة. كان من الرائع أن نعرف كيف تطور
التعلم العميق على مر السنين، وكذلك كيف تكونوا ما زلتم تساعدون في توجيهه
نحو المستقبل، إذًا شكرًا لك، جيف. >> حسنًا، شكرًا لك على
منحي هذه الفرصة. >> شكرًا.