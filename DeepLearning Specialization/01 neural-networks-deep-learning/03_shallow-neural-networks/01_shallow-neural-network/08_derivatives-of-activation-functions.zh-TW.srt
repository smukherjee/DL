1
00:00:00,000 --> 00:00:03,030
當您在您的神經網路建置反向傳播時,

2
00:00:03,030 --> 00:00:07,620
您需要能夠對於這些啟動函數
計算斜率或者說導數

3
00:00:07,620 --> 00:00:09,990
所以,讓我們來看看我們選擇的

4
00:00:09,990 --> 00:00:14,565
啟動函數,和您如何可以計算
這些函數的斜率

5
00:00:14,565 --> 00:00:18,225
這是您熟悉的S型函數 Sigmoid
啟動函數

6
00:00:18,225 --> 00:00:20,835
因此,對於任何給定的 z 值,

7
00:00:20,835 --> 00:00:22,160
也許這個 z 值。

8
00:00:22,160 --> 00:00:27,075
此函數在這將會有對應的一些斜率, 或者導數,

9
00:00:27,075 --> 00:00:28,860
如果你在那裡畫一條小線

10
00:00:28,860 --> 00:00:32,460
這個高除以寬的這個小三角形

11
00:00:32,460 --> 00:00:36,630
所以,如果 g(z) 是sigmoid函數,

12
00:00:36,630 --> 00:00:39,930
函數的斜率為 ,

13
00:00:39,930 --> 00:00:41,655
d(g(z)) / dz

14
00:00:41,655 --> 00:00:48,685
從微積分我們知道
這是 g(z) 在 z 的斜率

15
00:00:48,685 --> 00:00:53,210
如果您熟悉微積分
知道如何求導數

16
00:00:53,210 --> 00:00:56,060
如果您求S狀函數的導數

17
00:00:56,060 --> 00:00:59,915
這可以證明
是這個公式

18
00:00:59,915 --> 00:01:02,930
再次說明
我不做這些微積分的步驟

19
00:01:02,930 --> 00:01:04,730
但如果你熟悉微積分,

20
00:01:04,730 --> 00:01:08,180
歡迎隨時暫停影片
試著自己證明

21
00:01:08,180 --> 00:01:12,545
所以這也是等於 g(z) 

22
00:01:12,545 --> 00:01:16,505
乘 (1 - g(z))

23
00:01:16,505 --> 00:01:21,465
讓我們檢查
這個公式是合理的

24
00:01:21,465 --> 00:01:24,045
首先,如果 z 非常大,

25
00:01:24,045 --> 00:01:25,800
假設 z 等於10,

26
00:01:25,800 --> 00:01:30,315
g(z) 將接近 1,

27
00:01:30,315 --> 00:01:38,760
這個公式告訴我們
d/dz g(z) 趨近於 g(z) (1 - g(z))

28
00:01:38,760 --> 00:01:43,210
也就是等於 1 乘 (1 - 1)

29
00:01:43,210 --> 00:01:46,575
也就是趨近於 0

30
00:01:46,575 --> 00:01:49,110
這是正確的, 因為當 z 很大時,

31
00:01:49,110 --> 00:01:51,135
斜率會趨近於 0.

32
00:01:51,135 --> 00:01:53,955
相反的, ,如果 z 等於 -10,

33
00:01:53,955 --> 00:01:55,965
所以它在那裡,

34
00:01:55,965 --> 00:01:59,340
然後 g(z) 接近 0。

35
00:01:59,340 --> 00:02:04,560
這個公式告訴我們
d/dz g(z) 趨近於 g(z) (1 - g(z))

36
00:02:04,560 --> 00:02:07,095
這是 0 乘以 1 減去 0。

37
00:02:07,095 --> 00:02:10,685
也是趨近於 0
這個也是正確的

38
00:02:10,685 --> 00:02:13,675
最後,如果 z 等於 0,

39
00:02:13,675 --> 00:02:17,355
然後 g(z) 等於 1/2,

40
00:02:17,355 --> 00:02:19,275
這就是sigmoid函數在這兒

41
00:02:19,275 --> 00:02:26,620
所以導數
等於 1/2 乘 (1 - 1/2)

42
00:02:26,620 --> 00:02:28,665
等於 1/4,

43
00:02:28,665 --> 00:02:32,330
而這個實際上是正確的

44
00:02:32,330 --> 00:02:36,140
導數值或者說這個函數的斜率,當 z = 0

45
00:02:36,140 --> 00:02:39,370
最後, 再介紹一個符號

46
00:02:39,370 --> 00:02:42,895
有時候, 與其寫這個東西,

47
00:02:42,895 --> 00:02:46,340
導數的簡寫
是 g 一撇 of z

48
00:02:46,340 --> 00:02:48,440
所以,在微積分中z的g prime of z , g'(z)

49
00:02:48,440 --> 00:02:52,250
上面的小破折號叫做 prime,

50
00:02:52,250 --> 00:02:55,970
g'(z) 一個微積分的簡寫, 是

51
00:02:55,970 --> 00:03:01,250
g 函數的導數
相對於輸入變數 z。

52
00:03:01,250 --> 00:03:05,295
在神經網路中,

53
00:03:05,295 --> 00:03:10,740
我們有 a = g(z),

54
00:03:10,740 --> 00:03:17,530
等於這個,那麼這個公式
也簡化為 a(1-a)。

55
00:03:17,530 --> 00:03:19,710
有時候在建置時,

56
00:03:19,710 --> 00:03:25,355
您或許會看到
g'(z) 等於 a(1 - a)

57
00:03:25,355 --> 00:03:30,330
而指的是
這 g'(z),

58
00:03:30,330 --> 00:03:31,710
它的導數,

59
00:03:31,710 --> 00:03:33,390
等於這一個項目.

60
00:03:33,390 --> 00:03:38,980
這個公式的好處是，如果你已經計算了 a 值,

61
00:03:38,980 --> 00:03:40,705
然後使用此運算式,

62
00:03:40,705 --> 00:03:44,860
您可以非常快速地計算
斜率值, g'(z)。

63
00:03:44,860 --> 00:03:47,980
好的,這是有關於 S型啟動函數 Sigmoid.

64
00:03:47,980 --> 00:03:51,220
讓我們看 tanh 啟動函數.

65
00:03:51,220 --> 00:03:53,285
類似於我們前面做的,

66
00:03:53,285 --> 00:03:57,330
d(g(z))/dz 的定義是

67
00:03:57,330 --> 00:04:04,225
g(z) 的斜率在一個特定點 z,

68
00:04:04,225 --> 00:04:10,605
如果您看這個 tanh,
雙曲正切函數公式,

69
00:04:10,605 --> 00:04:12,390
如果你知道微積分,

70
00:04:12,390 --> 00:04:15,905
你可以取導數和
這簡化成為

71
00:04:15,905 --> 00:04:21,230
這個公式,和使用

72
00:04:21,230 --> 00:04:27,050
我們之前的簡寫
我們再次用 g'(z) 。

73
00:04:27,050 --> 00:04:30,735
如果您要的話, 您可以檢查
這個公式是不是合理的.

74
00:04:30,735 --> 00:04:33,395
例如,如果 z 等於 10,

75
00:04:33,395 --> 00:04:37,545
Tanh(z) 將非常接近 1。

76
00:04:37,545 --> 00:04:42,330
這個從+1 到-1,

77
00:04:42,330 --> 00:04:45,030
然後 g'(z),

78
00:04:45,030 --> 00:04:46,425
根據這個公式,

79
00:04:46,425 --> 00:04:48,300
大約是 1 減 1平方,

80
00:04:48,300 --> 00:04:50,115
所以非常接近 0。

81
00:04:50,115 --> 00:04:52,190
所以,這是 z 是非常大時,

82
00:04:52,190 --> 00:04:53,765
斜率接近 0。

83
00:04:53,765 --> 00:04:56,375
相反的, 如果 z 很小

84
00:04:56,375 --> 00:04:58,750
假設 z 等於 -10,

85
00:04:58,750 --> 00:05:02,715
然後 Tanh(z) 將接近 -1,

86
00:05:02,715 --> 00:05:08,970
所以 g'(z)將是
接近 1 減 -1 平方。

87
00:05:08,970 --> 00:05:10,470
所以,它接近 1 減 1,

88
00:05:10,470 --> 00:05:12,420
也接近 0。

89
00:05:12,420 --> 00:05:14,775
最後,如果 z 等於 0,

90
00:05:14,775 --> 00:05:18,844
然後 Tanh(z) 等於 0,

91
00:05:18,844 --> 00:05:21,630
然後斜率是實際上等於 1,

92
00:05:21,630 --> 00:05:25,740
也正是
當 z 等於 0 時的斜率

93
00:05:25,740 --> 00:05:27,255
總結一下,

94
00:05:27,255 --> 00:05:29,955
如果 a 等於 g(z),

95
00:05:29,955 --> 00:05:34,170
所以,如果 a 等於這個 Tanh(z),
然後導數是,

96
00:05:34,170 --> 00:05:38,580
g'(z),等於 1 減去 a平方。

97
00:05:38,580 --> 00:05:41,990
再一次
如果您已經計算 a 的值

98
00:05:41,990 --> 00:05:46,285
您可以用這個公式很
快的計算導數

99
00:05:46,285 --> 00:05:48,740
最後,下面是你如何
計算導數, 應用

100
00:05:48,740 --> 00:05:51,560
ReLU 或 Leaky ReLU 啟動函數

101
00:05:51,560 --> 00:05:57,710
對於 ReLU, g(z) = max(0,z)

102
00:05:57,710 --> 00:06:00,840
因此,導數等於,

103
00:06:00,840 --> 00:06:02,460
原來是0,

104
00:06:02,460 --> 00:06:09,525
如果 z 小於 0 和; 
是1 如果 z 大於 0。

105
00:06:09,525 --> 00:06:16,300
實際上 g'(z) 是未定義
如果 z 剛好為 0

106
00:06:16,300 --> 00:06:19,399
但如果您在軟體中建置

107
00:06:19,399 --> 00:06:21,960
也許不是百分之百正確的數學,

108
00:06:21,960 --> 00:06:26,630
但還是可以運作,
如果 z 真的是 0 -

109
00:06:26,630 --> 00:06:28,960
如果您設置導數等於 1。

110
00:06:28,960 --> 00:06:32,095
或您設置導數等於 0,
都沒關係。

111
00:06:32,095 --> 00:06:34,540
如果您是優化專家,技術上,

112
00:06:34,540 --> 00:06:39,380
g'(z),成為所謂的
g(z)啟動函數的子梯度,

113
00:06:39,380 --> 00:06:41,795
這就是為什麼梯度下降仍然有效。

114
00:06:41,795 --> 00:06:43,490
但是你也可以這樣想,

115
00:06:43,490 --> 00:06:47,505
z 正好是 0.0000.....00,

116
00:06:47,505 --> 00:06:51,080
它太小了,幾乎沒關係,你在哪裡

117
00:06:51,080 --> 00:06:54,245
將導數設置為等於,當 z 等於 0 時。

118
00:06:54,245 --> 00:06:59,090
在實踐上, 這是人們一般用來建置 g(z) 的導數.

119
00:06:59,090 --> 00:07:04,645
最後,如果您在訓練神經網路
 利用 Leaky ReLU 啟動函數,

120
00:07:04,645 --> 00:07:14,630
g(z) 會是 max(0.01z, z)

121
00:07:14,630 --> 00:07:20,300
g'(z) 等於 0.01, 如果 z

122
00:07:20,300 --> 00:07:26,685
小於 0
等於 1, 如果 z 大於 0.

123
00:07:26,685 --> 00:07:31,250
再次,技術上,梯度是未定義,
當 z 完全等於 0 ,

124
00:07:31,250 --> 00:07:34,250
但如果您建置一些程式, 設這個

125
00:07:34,250 --> 00:07:38,585
導數或設 g'(z) 為 0.01 或 1,

126
00:07:38,585 --> 00:07:40,160
無論哪種方式,這並不重要。

127
00:07:40,160 --> 00:07:42,610
當 z 正好為 0 時,
您的程式將正常工作。

128
00:07:42,610 --> 00:07:44,430
所以,根據這些公式,

129
00:07:44,430 --> 00:07:49,355
您需要能夠對於這些啟動函數
計算斜率或者說導數.

130
00:07:49,355 --> 00:07:51,260
現在您有了這些建構基石,

131
00:07:51,260 --> 00:07:55,235
你已經準備好如何實現
神經網路的梯度下降。

132
00:07:55,235 --> 00:07:57,330
讓我們繼續看下一段影片