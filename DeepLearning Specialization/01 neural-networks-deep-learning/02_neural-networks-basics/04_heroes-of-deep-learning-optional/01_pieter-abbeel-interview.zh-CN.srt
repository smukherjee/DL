1
00:00:02,420 --> 00:00:04,575
非常感谢你 Pieter

2
00:00:04,575 --> 00:00:06,690
今天来参加访谈

3
00:00:06,690 --> 00:00:08,560
我想很多人觉得你是一个

4
00:00:08,560 --> 00:00:12,150
知名的机器学习 深度学习 和机器人学研究者

5
00:00:12,150 --> 00:00:15,550
我希望能让观众们听一听你的故事

6
00:00:15,550 --> 00:00:18,220
你是如何最终走上了现在的道路的呢?

7
00:00:18,220 --> 00:00:22,300
这是个好问题 其实如果你问14岁的我这个问题

8
00:00:22,300 --> 00:00:24,775
我要立志做什么

9
00:00:24,775 --> 00:00:26,775
问题的答案大概不会是这些

10
00:00:26,775 --> 00:00:28,285
实际上 在当时

11
00:00:28,285 --> 00:00:32,565
我认为成为一名专业篮球运动员应该不错

12
00:00:32,565 --> 00:00:34,680
但我觉得没有能力实现那个目标

13
00:00:34,680 --> 00:00:36,430
我感觉 对机器学习来说这是一件幸事

14
00:00:36,430 --> 00:00:38,250
因为篮球的打算没能实现

15
00:00:38,250 --> 00:00:39,510
对 篮球之梦没有实现

16
00:00:39,510 --> 00:00:41,890
虽然打篮球本身非常有乐趣 但是

17
00:00:41,890 --> 00:00:44,885
把它当成事业却行不通

18
00:00:44,885 --> 00:00:48,530
我在学校时真正喜欢的是物理和数学

19
00:00:48,530 --> 00:00:50,005
所以 在此基础之上

20
00:00:50,005 --> 00:00:52,120
学习工程 就是很自然的事情

21
00:00:52,120 --> 00:00:55,735
因为工程就是物理和数学在真实生活中的应用

22
00:00:55,735 --> 00:00:58,150
事实上 在我本科修完电气工程之后

23
00:00:58,150 --> 00:01:00,355
我不太确定接下来应该做什么 因为

24
00:01:00,355 --> 00:01:03,981
事实上 任何工程学科都我都有兴趣

25
00:01:03,981 --> 00:01:07,680
像是理解世间万物是如何工作的就很有趣

26
00:01:07,680 --> 00:01:09,595
尝试去建造一些东西 也是有趣的

27
00:01:09,595 --> 00:01:11,470
在某种意义上

28
00:01:11,470 --> 00:01:13,690
人工智能是最有意思的 因为看起来

29
00:01:13,690 --> 00:01:18,280
它能够从某种方式上对所有的领域都提供一些帮助

30
00:01:18,280 --> 00:01:22,370
同时 它看起来也更接近万物的核心

31
00:01:22,370 --> 00:01:24,575
你得去思考如何让机器思考

32
00:01:24,575 --> 00:01:30,160
也许这一点比选择任何具体领域都更接近万物的核心

33
00:01:30,160 --> 00:01:33,260
我曾说过人工智能就是新时代的电力

34
00:01:33,260 --> 00:01:35,020
这么听起来你早在14岁时

35
00:01:35,020 --> 00:01:37,923
就更早地提出那种想法了

36
00:01:37,923 --> 00:01:44,465
在过去几年中 你在深度强化学习中做了许多工作

37
00:01:44,465 --> 00:01:49,315
当中发生了什么? 为什么深度强化学习突然间就火了呢?

38
00:01:49,315 --> 00:01:51,030
在我从事深度强化学习的工作之前

39
00:01:51,030 --> 00:01:52,765
我做过很多 强化学习 的工作

40
00:01:52,765 --> 00:01:56,115
当然 正是与你和Durrant在斯坦福一起完成的

41
00:01:56,115 --> 00:01:59,863
我们曾经研究过直升机自动飞行

42
00:01:59,863 --> 00:02:02,440
之后在伯克利我和我的学生

43
00:02:02,440 --> 00:02:05,440
研究了如何让机器人学会叠衣服

44
00:02:05,440 --> 00:02:09,340
这些工作的特点是一种机器学习技法

45
00:02:09,340 --> 00:02:13,015
它能够使得之前不可能的一些事情成为可能

46
00:02:13,015 --> 00:02:18,120
另一方面 学习还需要辅以许多领域知识才能成功

47
00:02:18,120 --> 00:02:20,975
这很有意思

48
00:02:20,975 --> 00:02:22,600
因为收集所需要的那些领域知识

49
00:02:22,600 --> 00:02:24,310
这个过程很有趣 但是同时

50
00:02:24,310 --> 00:02:28,234
想要在新任务上取得不错的效果 这一步就会变得很费时

51
00:02:28,234 --> 00:02:31,060
总之你既需要领域知识也需要机器学习的专业知识

52
00:02:31,060 --> 00:02:34,240
在我看来 深度学习是起于2012年

53
00:02:34,240 --> 00:02:39,910
多伦多大学的Geoff Hinton研究组在ImageNet数据集上的突破

54
00:02:39,910 --> 00:02:42,880
AlexNet的结果表明 一夜之间 为某个专门领域

55
00:02:42,880 --> 00:02:48,220
完成监督学习所需的工程努力就突然可以减少很多

56
00:02:48,220 --> 00:02:50,410
在AlexNet中 机算机视觉方面上的专门工程设计是很少的

57
00:02:50,410 --> 00:02:53,075
这件事让我认为我们需要重新审视强化学习

58
00:02:53,075 --> 00:02:57,610
从同样的视角去审视强化学习 来试试看

59
00:02:57,610 --> 00:03:01,075
我们是否能提出一种深度强化学习方法

60
00:03:01,075 --> 00:03:05,950
就像深度监督学习一样 完成同样有趣的事情

61
00:03:05,950 --> 00:03:08,565
所以 听起来你比别人更早看到

62
00:03:08,565 --> 00:03:12,250
深度强化学习的潜力

63
00:03:12,250 --> 00:03:14,365
那么现在展望一下未来

64
00:03:14,365 --> 00:03:16,180
你觉得接下来的会怎样呢?

65
00:03:16,180 --> 00:03:17,260
你对于未来深度强化学习的

66
00:03:17,260 --> 00:03:20,440
发展趋势有何预测呢?

67
00:03:20,440 --> 00:03:23,270
我认为深度强化学习中有趣的地方在于

68
00:03:23,270 --> 00:03:26,795
在某种意义上 深度强化学习比深度监督学习存在更多问题

69
00:03:26,795 --> 00:03:29,817
监督学习的主要内容是习得从输入到输出的映射

70
00:03:29,817 --> 00:03:34,505
而在强化学习中甚至存在着 这些数据究竟从哪里来? 这个观念

71
00:03:34,505 --> 00:03:36,580
所以那就是探索(exploration)问题

72
00:03:36,580 --> 00:03:38,470
而有了数据 又如何做信用分配(credit assignment)呢?

73
00:03:38,470 --> 00:03:43,315
你如何弄清楚之前哪个动作导致了之后的反馈呢?

74
00:03:43,315 --> 00:03:44,830
再接下来 还有安全问题

75
00:03:44,830 --> 00:03:47,335
当你让一个系统去自动收集信息时

76
00:03:47,335 --> 00:03:50,140
大多数情况下其实是蛮危险的

77
00:03:50,140 --> 00:03:51,880
想象一家自动驾驶汽车公司说

78
00:03:51,880 --> 00:03:53,825
"我们打算运行深度强化学习方法"

79
00:03:53,825 --> 00:03:55,690
那就很有可能导致他们的车

80
00:03:55,690 --> 00:03:57,985
还没学到什么就惹出不少的车祸吧

81
00:03:57,985 --> 00:03:59,650
你需要一个这个方面的反例 是吗

82
00:03:59,650 --> 00:04:02,000
你确实需要一些反例啊 是的

83
00:04:02,000 --> 00:04:04,930
不过也需要正面的例子的

84
00:04:04,930 --> 00:04:07,540
我认为在深度强化学习中

85
00:04:07,540 --> 00:04:09,760
还有为数不少的挑战

86
00:04:09,760 --> 00:04:12,635
主要是在于明白让方法起作用的细节上

87
00:04:12,635 --> 00:04:14,520
深度 是指表现(representation)这一层

88
00:04:14,520 --> 00:04:18,455
而强化学习 这部分本身依然有很多问题

89
00:04:18,455 --> 00:04:20,485
我的感觉是

90
00:04:20,485 --> 00:04:22,810
随着深度学习的发展

91
00:04:22,810 --> 00:04:27,430
强化学习中的一部分 不管怎么说已经很大程度上解决了

92
00:04:27,430 --> 00:04:29,075
也就是表现(representation)的部分

93
00:04:29,075 --> 00:04:31,540
比如说 如果数据中有一种模式

94
00:04:31,540 --> 00:04:34,795
那我们大概可以用一个深层网络来概括 并表现它

95
00:04:34,795 --> 00:04:39,400
但是如何把这个模式解构成不同的部分<br />在强化学习中还是一个大挑战

96
00:04:39,400 --> 00:04:41,740
我认为大的挑战包括

97
00:04:41,740 --> 00:04:45,695
如何使得系统能够在长的时间视野(time horizon)上进行推理

98
00:04:45,695 --> 00:04:47,770
目前 我认为在深度强化学习中

99
00:04:47,770 --> 00:04:50,650
很多的成功的算法都仅限于很短的时间视野

100
00:04:50,650 --> 00:04:52,000
在那些问题中

101
00:04:52,000 --> 00:04:54,445
如果模型在五秒的时间视野内表现良好

102
00:04:54,445 --> 00:04:57,815
那就表示在整个问题中表现都良好了

103
00:04:57,815 --> 00:05:02,599
而五秒钟的视野却是很不同于一天长的视野的 或者说很不同于

104
00:05:02,599 --> 00:05:06,930
作为一个机器人或某个软件主体的生存一生的能力的

105
00:05:06,930 --> 00:05:09,240
我认为在这里有许多挑战

106
00:05:09,240 --> 00:05:12,790
我认为关于安全就有许多挑战 比如说

107
00:05:12,790 --> 00:05:14,920
如何安全地学习 以及

108
00:05:14,920 --> 00:05:17,785
如何在已经学习得比较好的情况下继续学习?

109
00:05:17,785 --> 00:05:20,305
所以如果要再举一个例子的话

110
00:05:20,305 --> 00:05:23,070
举一个很多人都熟悉的例子 自动驾驶汽车

111
00:05:23,070 --> 00:05:26,375
如果自动驾驶汽车的表现想要超越人类的话

112
00:05:26,375 --> 00:05:31,990
假定人类驾驶员每三百万小时才卷入一场恶性交通事故

113
00:05:31,990 --> 00:05:35,763
那么当你已经和人类驾驶员一样好时

114
00:05:35,763 --> 00:05:37,510
想要获得负面样本就要花很长时间

115
00:05:37,510 --> 00:05:40,835
但你的目标却是让自动驾驶汽车比人类驾驶员更优秀

116
00:05:40,835 --> 00:05:43,930
所以到那个时候 得要有意思的样本才能让系统继续改善

117
00:05:43,930 --> 00:05:48,175
而那种数据的获得就会变得非常非常困难

118
00:05:48,175 --> 00:05:52,420
关于探索问题的这部分 有许多相关的挑战

119
00:05:52,420 --> 00:05:57,190
但其中我最感到兴奋的一件事情是

120
00:05:57,190 --> 00:06:02,720
看看我们能否退后一步 转而学习强化算法本身

121
00:06:02,720 --> 00:06:05,030
强化学习算法很复杂

122
00:06:05,030 --> 00:06:07,450
信用分配很复杂 探索也是很复杂的

123
00:06:07,450 --> 00:06:08,905
所以 可能就像在监督学习中

124
00:06:08,905 --> 00:06:13,795
深度学习可以替代很多领域专家的知识

125
00:06:13,795 --> 00:06:17,320
或许我们也能通过学习来得到程序

126
00:06:17,320 --> 00:06:20,140
得到一个强化学习程序 来完成所有的事情

127
00:06:20,140 --> 00:06:22,510
而不是由我们来设计其中的细节

128
00:06:22,510 --> 00:06:25,560
只是学习奖励函数还是学习整个程序?

129
00:06:25,560 --> 00:06:28,150
这里要学习的是 整个强化学习程序

130
00:06:28,150 --> 00:06:30,430
也就是 想像一下

131
00:06:30,430 --> 00:06:34,255
你有一个强化学习程序 无论是什么样的程序

132
00:06:34,255 --> 00:06:38,320
然后你丢给它一个问题 看它能用多少时间完成学习

133
00:06:38,320 --> 00:06:41,020
然后你看到 嗯 这用了一些时间

134
00:06:41,020 --> 00:06:44,950
然后你让另一个程序来修改这个强化学习程序

135
00:06:44,950 --> 00:06:48,045
在修改之后 再看它学习的速度有多快

136
00:06:48,045 --> 00:06:49,641
如果它学习得更快

137
00:06:49,641 --> 00:06:54,380
那这个修改就是好的 你可以保留它 再在其上提升

138
00:06:54,380 --> 00:06:57,630
嗯 明白了 这可是个很远大的目标

139
00:06:57,630 --> 00:06:59,290
我觉得有一件事情与之关系很大

140
00:06:59,290 --> 00:07:01,510
也就是我们现在能动用的计算力

141
00:07:01,510 --> 00:07:05,860
因为这相当于把强化学习算法放在循环内层

142
00:07:05,860 --> 00:07:08,975
而现在强化学习算法却是最终目标

143
00:07:08,975 --> 00:07:11,260
所以我们的计算力越强的话

144
00:07:11,260 --> 00:07:14,545
那就越有可能 能够把类似强化学习这种任务

145
00:07:14,545 --> 00:07:19,160
放进某个更大的问题的内层循环当中去运行

146
00:07:19,160 --> 00:07:22,080
从你14岁时开始

147
00:07:22,080 --> 00:07:25,355
你已经在人工智能领域工作了20多年了

148
00:07:25,355 --> 00:07:32,795
告诉我一些你对人工智能在这些年中取得的进化的理解吧

149
00:07:32,795 --> 00:07:35,280
当我开始接触人工智能时

150
00:07:35,280 --> 00:07:38,230
我觉得它很有意思 因为

151
00:07:38,230 --> 00:07:41,445
当时恰逢我来斯坦福念硕士

152
00:07:41,445 --> 00:07:46,998
所以我得以与一些标志性人物交谈 比如John McCarthy

153
00:07:46,998 --> 00:07:49,300
他对人工智能有非常不同的见解

154
00:07:49,300 --> 00:07:50,460
在2000年时

155
00:07:50,460 --> 00:07:52,115
他做的事情与大多数人不一样

156
00:07:52,115 --> 00:07:54,958
然后我还得以与Daphne Koller聊过

157
00:07:54,958 --> 00:07:59,320
我想Daphne的思考塑造了我对于人工智能许多最初的想法

158
00:07:59,320 --> 00:08:04,300
她的人工智能课程 和概率图模型课程

159
00:08:04,300 --> 00:08:06,820
当时让我觉得很着迷的是

160
00:08:06,820 --> 00:08:11,450
就是一个简单的许多随机变量的组合分布 然后在一些变量上

161
00:08:11,450 --> 00:08:14,950
加上限定条件 并在其它变量上做出结论

162
00:08:14,950 --> 00:08:19,015
就能让你获得如此丰富的结论 只要它是可被计算的

163
00:08:19,015 --> 00:08:23,170
能让图模型的计算变得可行 着实是一项挑战

164
00:08:23,170 --> 00:08:25,090
从那以后

165
00:08:25,090 --> 00:08:28,335
当我开始念博士时 你来到了斯坦福

166
00:08:28,335 --> 00:08:30,910
我想你给了我一个非常好的在实践中检验的机会

167
00:08:30,910 --> 00:08:35,350
让我知道那并不是评价一项工作的正确标准

168
00:08:35,350 --> 00:08:38,470
正确的标准应当是 看到你正做的工作

169
00:08:38,470 --> 00:08:41,710
与它能真正对现实产生的影响之间的联系

170
00:08:41,710 --> 00:08:46,660
应该看你能带来多大改变 而不是你的工作中的数学技巧

171
00:08:46,660 --> 00:08:48,425
对吧 太令人惊讶了

172
00:08:48,425 --> 00:08:50,685
我没想起来 我不记得了

173
00:08:50,685 --> 00:08:54,267
是的 这个问题其实是人们经常问的问题中的一个

174
00:08:54,267 --> 00:09:01,090
就是 吴恩达的建议中有哪一句令你至今记忆犹新

175
00:09:01,090 --> 00:09:05,995
那就是你要看到工作与现实影响之间的联系

176
00:09:05,995 --> 00:09:11,332
你目前的人工智能生涯相当成功 并且成功还在继续

177
00:09:11,332 --> 00:09:14,750
所以 对于那些正在收看视频的观众们

178
00:09:14,750 --> 00:09:18,815
如果他们也想进入或从事人工智能方面的工作

179
00:09:18,815 --> 00:09:20,985
你有什么给他们的建议吗?

180
00:09:20,985 --> 00:09:25,185
我想现在是进入人工智能领域的非常好的时间

181
00:09:25,185 --> 00:09:28,965
你看人们对这个领域的需求是如此之高

182
00:09:28,965 --> 00:09:30,741
有这么多的工作机会

183
00:09:30,741 --> 00:09:32,365
有这么多可做的事情 无论是研究

184
00:09:32,365 --> 00:09:34,735
还是创立新公司 还是其它

185
00:09:34,735 --> 00:09:39,240
所以我会说 是的 决定去从事人工智能绝对是明智的决定

186
00:09:39,240 --> 00:09:41,140
有许多东西 你可以自学

187
00:09:41,140 --> 00:09:42,635
无论你还在学校 或是不在学校

188
00:09:42,635 --> 00:09:44,150
有许多在线课程 比如说

189
00:09:44,150 --> 00:09:45,585
您的机器学习课程

190
00:09:45,585 --> 00:09:48,400
还有 比如说

191
00:09:48,400 --> 00:09:52,030
Andrej Karpathy的深度学习课程 在网上都有视频

192
00:09:52,030 --> 00:09:54,280
这都是很好的开始学习的方式

193
00:09:54,280 --> 00:09:57,460
伯克利也有一门深度强化学习课程

194
00:09:57,460 --> 00:09:59,260
那门课程所有的课件也都能在网上看到

195
00:09:59,260 --> 00:10:01,235
所以这些都是很好的开始学习的地方

196
00:10:01,235 --> 00:10:06,470
我认为有一件非常重要的事情 就是确保你亲自去动手做

197
00:10:06,470 --> 00:10:10,055
不光是读文章或看视频 而是要动手尝试

198
00:10:10,055 --> 00:10:14,347
现在有很多深度学习框架 比如Tensorflow

199
00:10:14,347 --> 00:10:16,040
比如Chainer, Theano, PyTorch 等等

200
00:10:16,040 --> 00:10:17,350
无论你喜欢什么

201
00:10:17,350 --> 00:10:21,980
都能够很容易地开始 很快搭建起一个能运行的东西

202
00:10:21,980 --> 00:10:24,669
亲自动手练习 对吗?

203
00:10:24,669 --> 00:10:27,105
通过实现来看什么方法行得通 什么行不通

204
00:10:27,105 --> 00:10:29,360
上个星期 在Mashable网站上有篇文章

205
00:10:29,360 --> 00:10:31,715
讲的是英国的一个16岁的少年

206
00:10:31,715 --> 00:10:34,580
在Kaggle比赛中名列前茅

207
00:10:34,580 --> 00:10:36,690
文章中说

208
00:10:36,690 --> 00:10:39,290
他就只是开始 去着手开始学习了

209
00:10:39,290 --> 00:10:41,510
在网上找到了素材 所有东西都自学

210
00:10:41,510 --> 00:10:44,915
而没有参与任何正式的正儿八经的课程

211
00:10:44,915 --> 00:10:49,180
一个16岁的少年都能在Kaggle比赛中名列前茅

212
00:10:49,180 --> 00:10:50,990
所以自学当然是可能的

213
00:10:50,990 --> 00:10:53,120
我们活在一个好时代

214
00:10:53,120 --> 00:10:54,560
人们想学习就能学习

215
00:10:54,560 --> 00:10:55,940
完全正确

216
00:10:55,940 --> 00:10:57,980
我想你经常被问到的一个问题是

217
00:10:57,980 --> 00:11:00,160
如果某人想进入人工学习 机器学习或深度学习领域

218
00:11:00,160 --> 00:11:06,885
他们应当申请一个博士项目 还是应该去大公司找一个工作呢?

219
00:11:06,885 --> 00:11:12,395
我觉得很大一部分应该取决于你能得到多少的指导

220
00:11:12,395 --> 00:11:14,780
在博士项目中

221
00:11:14,780 --> 00:11:16,400
你的指导能得到有力保证

222
00:11:16,400 --> 00:11:17,787
因为教授 也就是你的导师

223
00:11:17,787 --> 00:11:18,830
他的职责就是

224
00:11:18,830 --> 00:11:20,800
密切照看你的研究

225
00:11:20,800 --> 00:11:21,950
做一切他们能做的事情

226
00:11:21,950 --> 00:11:23,565
去从某种意义上塑造你

227
00:11:23,565 --> 00:11:28,720
助你在想做的任何事情上变得更强 比方说人工智能

228
00:11:28,720 --> 00:11:32,060
所以总是有一个专注于你的人 有时你还会有两个导师

229
00:11:32,060 --> 00:11:34,955
他们的工作就是指导 也就是他们身为教授的原因

230
00:11:34,955 --> 00:11:37,755
他们大多数当教授最喜欢的一点是能够

231
00:11:37,755 --> 00:11:41,200
帮助塑造学生 增进他们的才能

232
00:11:41,200 --> 00:11:43,250
不过这不意味着在公司就不可能学习

233
00:11:43,250 --> 00:11:46,730
因为有很多公司有很好的职业导师

234
00:11:46,730 --> 00:11:51,110
他们热爱的事情是教育人 加强人 等等

235
00:11:51,110 --> 00:11:55,515
区别在于 相比博士项目 这种指导的保障并不是那么强

236
00:11:55,515 --> 00:12:00,540
因为博士项目的关键之处就是

237
00:12:00,540 --> 00:12:06,020
你是想学习的 并且有一个人帮助你学习

238
00:12:06,020 --> 00:12:09,675
所以确实要看具体公司和具体博士项目的

239
00:12:09,675 --> 00:12:14,130
当然是的 所以关键还是 自学能学到的也是相当之多

240
00:12:14,130 --> 00:12:17,910
但如果有更有经验的人相助 你的进步速度能快得多

241
00:12:17,910 --> 00:12:20,469
特别是当这样的人

242
00:12:20,469 --> 00:12:24,945
将花费时间加速你的进步作为他们的责任时

243
00:12:24,945 --> 00:12:28,780
所以你已经是深度强化学习领域中最有名的带头人之一

244
00:12:28,780 --> 00:12:30,720
所以有什么事情

245
00:12:30,720 --> 00:12:32,930
是深度强化学习已经能做得很好了的呢?

246
00:12:32,930 --> 00:12:37,450
我想 如果你去看一看深度强化学习的成功案例

247
00:12:37,450 --> 00:12:39,000
你会觉得非常非常吸引人

248
00:12:39,000 --> 00:12:42,810
比如说 通过观察显示的像素来玩雅达利(Atari)游戏

249
00:12:42,810 --> 00:12:45,540
通过处理这些像素 也就是一堆数字

250
00:12:45,540 --> 00:12:49,150
像素以某种方式处理 变成操纵杆操作

251
00:12:49,150 --> 00:12:52,605
另一个例子是 我们在伯克利完成的一些工作

252
00:12:52,605 --> 00:12:57,105
我们模拟了一个机器人 它悟出了走路技巧

253
00:12:57,105 --> 00:12:59,340
我们给它的回报只是简单的 一直向北走 走越远越好

254
00:12:59,340 --> 00:13:02,170
对地面的施力用得越小越好

255
00:13:02,170 --> 00:13:06,949
然后机器人就以某种方式做出决策 发明了 走路/跑步 的动作

256
00:13:06,949 --> 00:13:10,095
而甚至并没有任何人告诉它走路和跑步是什么样的

257
00:13:10,095 --> 00:13:14,220
或者把儿童故事片段给机器人 让它学习如何把片段组合起来

258
00:13:14,220 --> 00:13:16,935
把一段内容与故事开头匹配起来 等等之类的

259
00:13:16,935 --> 00:13:20,280
所以我认为在这所有事情中有意思的是

260
00:13:20,280 --> 00:13:24,510
从原始感官输入 就能学习出 最终的控制动作

261
00:13:24,510 --> 00:13:27,990
比如说 输出马达的力矩

262
00:13:27,990 --> 00:13:29,225
但在同一时间

263
00:13:29,225 --> 00:13:32,460
所以有意思的是 你只需要有一个算法

264
00:13:32,460 --> 00:13:35,310
比如说 通过推力轨迹优化算法

265
00:13:35,310 --> 00:13:36,745
你能让机器人学习跑步

266
00:13:36,745 --> 00:13:38,135
让机器人学习站立

267
00:13:38,135 --> 00:13:40,395
你可以在教完双腿机器人之后

268
00:13:40,395 --> 00:13:42,445
把它换成一个四腿机器人

269
00:13:42,445 --> 00:13:46,465
你可以用同样的强化学习算法让机器人学习跑步

270
00:13:46,465 --> 00:13:49,280
所以强化学习算法本身并没有变化

271
00:13:49,280 --> 00:13:51,615
它是非常通用的 这对雅达利游戏也是适用的

272
00:13:51,615 --> 00:13:54,565
对于每一个游戏的深度Q-网络(DQN)是一样的

273
00:13:54,565 --> 00:13:56,640
不过还有一些前沿研究方向上的东西

274
00:13:56,640 --> 00:14:00,060
是现在尚不可能的

275
00:14:00,060 --> 00:14:03,490
目前 它只能从头开始学习每个任务 这并不差

276
00:14:03,490 --> 00:14:07,405
但是如果能重新利用之前所学的知识就更好了

277
00:14:07,405 --> 00:14:09,640
这样对下一个任务的学习能够完成得更快

278
00:14:09,640 --> 00:14:13,100
那还是前沿研究题目 目前还不可能

279
00:14:13,100 --> 00:14:16,490
实质上它每次都是从头开始学习的

280
00:14:16,490 --> 00:14:19,390
那你认为还要多少时间

281
00:14:19,390 --> 00:14:22,420
深度强化学习就会被布署在我们身边的机器人里

282
00:14:22,420 --> 00:14:25,935
这些正逐渐进入我们的世界的机器人里

283
00:14:25,935 --> 00:14:29,380
我认为在实践中 比较实际的情况是

284
00:14:29,380 --> 00:14:32,770
它会从监督学习的方式开始

285
00:14:32,770 --> 00:14:35,960
行为模仿 也就是还是由人类进行工作

286
00:14:35,960 --> 00:14:38,530
我认为有许多商业化部署会是这样的

287
00:14:38,530 --> 00:14:41,790
就是在后台有许多人类在工作

288
00:14:41,790 --> 00:14:44,980
比如Facebook Messenger助手

289
00:14:44,980 --> 00:14:47,980
这个助手可以在后台有一个真人

290
00:14:47,980 --> 00:14:51,310
在幕后做许多工作 而机器学习技法

291
00:14:51,310 --> 00:14:54,380
则是对人类进行匹配 为人类提供行动建议

292
00:14:54,380 --> 00:14:58,130
给人类少数选项以供选择 这样人就只要点选就行了

293
00:14:58,130 --> 00:14:59,640
然后当时间渐长

294
00:14:59,640 --> 00:15:01,130
机器在任务上也表现良好

295
00:15:01,130 --> 00:15:04,465
你就会开始将强化学习融合进来 给机器提出实际目标

296
00:15:04,465 --> 00:15:06,565
并不只是与后台的人类进行匹配

297
00:15:06,565 --> 00:15:09,040
而是给予带有奖励的目标

298
00:15:09,040 --> 00:15:14,110
比如 这两个人要多久才能商定好会议时间

299
00:15:14,110 --> 00:15:16,385
或者他们预订一张机票要多少时间

300
00:15:16,385 --> 00:15:18,340
或者其它 能用时间衡量的事情

301
00:15:18,340 --> 00:15:20,065
或者 他们的满意程度如何?

302
00:15:20,065 --> 00:15:22,815
这可能需要利用自助法(bootstrap)

303
00:15:22,815 --> 00:15:27,605
从大量对人类的模仿中明白这些任务如何达成

304
00:15:27,605 --> 00:15:30,690
所以听起来行为模仿就是 先用监督学习

305
00:15:30,690 --> 00:15:33,580
来模仿人类做的无论什么事情 之后渐渐地

306
00:15:33,580 --> 00:15:37,434
用强化学习来让机器从更长时间视野上去思考

307
00:15:37,434 --> 00:15:38,500
这样的总结合适吗?

308
00:15:38,500 --> 00:15:39,715
我觉得可以的

309
00:15:39,715 --> 00:15:43,540
因为从头开始的强化学习观察起来相当有意思

310
00:15:43,540 --> 00:15:46,780
非常引人入胜 没有太多东西比这有意思

311
00:15:46,780 --> 00:15:50,440
能胜过看一个强化学习机器人从零开始 开始学会新本领

312
00:15:50,440 --> 00:15:54,280
只是它很耗时而且并不总是安全的

313
00:15:54,280 --> 00:15:56,200
非常感谢 非常有意思

314
00:15:56,200 --> 00:15:58,005
能一同交谈 我感到非常荣幸

315
00:15:58,005 --> 00:16:02,670
谢谢你Andrew 感谢你邀请 我也非常感激