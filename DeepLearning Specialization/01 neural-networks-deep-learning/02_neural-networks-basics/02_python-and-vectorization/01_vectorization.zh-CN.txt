欢迎回来.向量化基本上就是 一项让你的代码变得更高效的艺术 在深度学习的实际应用中 你可能会遇到大量的训练数据 因为深度学习算法在这个情况下表现更好 所以你的代码运行的运行速度非常重要，否则 如果它运行在一个大的数据集上面 你的代码可能花费很长时间去运行，你会发现 你将要等待非常长的时间去得到结果 所以在深度学习领域 我认为实现向量化的能力已经变成一个关键的技巧 让我们从一个例子开始 让我们用一个例子开始 什么是向量化？ 在逻辑回归中，你需要去计算Z=WTX+B W是列向量，X也是列向量 如果你有很多的特征，那么就会有一个非常大的向量，所以W和X是R内的nx维向量 所以去计算WTX 如果你有一个非向量化的实现 你将会做一些事情，例如Z=0 *pythn代码   i in range(n-x) *python代码  所以i=1,2....nx Z plus equals W I times XI. Z+=W[i]*X[i] 所以你在最后z+=b 所以，这是一个非向量化的实现 你会发现这是真的很慢 作为对比，一个向量化的实现将会非常直接计算WTX 在Python 或者numpy 你实现的命令是Z=np.dot(W,X) 这是在计算WTX 你也可以直接加上B 你将会发现这个非常快 让我们用一个小例子说明一下 在我的Jupyter notebook 我将会写一些Python代码 首先，让我们导入numpy库 作为 np，例如 像下面这样我将要创建一个数据A 让我们看下打印A 现在，写下这些代码块 如果我在键盘敲击shift 和 enter 两个键 它将会执行这个代码 所以，它创建了数组A以及打印它 现在，让我们完成向量化的例子 我将要导入time库 因为我要使用那个 为了去计算两次不同的操作花费了多长时间 他们能创建一个数组A吗 通过random.rand函数随机得到 用随机数值创建了一个百万维度的数组 b = np.random.rand.(1000000) 另外一个百万维度的数组 现在 tic=time.time() 测量一下当前时间 c = np.dot (a, b). toc = time.time. 打印一下 向量化的版本 这是一个向量化的版本 现在让我们打印一下 让我们看一下持续时间 python代码*  toc - tic x 1000 所以我们表达这个在毫秒级上 ms代表毫秒 我将要同时敲击Shift和 Enter 所以这个代码花费3毫秒或者这个时间的1.5倍 或许大概 1.5 或者3.5毫秒 它有点变化当我再次运行它的时候 但是好像，平均她要花费1.5毫秒 或许我这次运行是2毫秒 好吧那就这样吧！ 让我们继续增加这个代码 这是非向量化的版本 让我们看看，c=0 tic = time.time. 现在它实现了一个loop python 代码:for i in range 1:1000000 我将要取出0右边的数字 C += (a,i) x (b,i) 以及 toc = time.time. 最后，打印for loop 它花费的时间是1000*toc-tic ms 目的是为了知道我们正在做这个在毫秒级别 让我们再做点其他的事情 我们打印出C的值 计算一下它，确认在两个案例中他们是相同的 我打算去敲击shift和enter去运行这个，检查一下结果 在两个案例中，向量化版本 和非向量化版本计算了相同的值 正如你知道的，250286左右 向量化版本花费了1.5毫秒 很明确，for loop和非向量化版本花费了大约400，几乎500毫秒 非向量化版本多花费了 300倍向量化版本的时间 用这个例子你将会看见如果你仅仅记住去向量化你的代码 你的代码完全运行300倍快 让我们再次运行一下它 再次运行一下它 向量化版本1.5毫秒，循环使用了 481毫秒 大约慢300倍用循环做这个 如果时间变慢 这个有很大的不同在你的代码花费一分钟去运行和 花费5个小时去运行 当你正在实现深度学习算法 你能真正的快速得到一个返回的结果 它将会更快，如果你向量化你的代码 你可能听过很多这样的话 大规模的深度学习使用了GPU或者图像处理单元实现 但是我做的所有的案例都是在Jupiter notebook上面实现，这里只有CPU CPU和GPU都有并行化的指令 他们有时候会叫做SIMD指令 这个代表了一个单独指令多维数据 这个的基础意义是什么？ 如果你使用了built-in函数，像这样 np.function 或者 并不要求你实现循环的函数 这使得python中的numpy充分 利用并行化去更快的计算 这是事实在GPU和CPU上面计算 GPU被标记更加擅长 SIMD计算但是CPU事实上也不是太差 可能没有GPU那么擅长吧 你看下，怎么向量化能够加速你的代码 经验规律是无论什么时候 都避免使用明确的for循环 让我们进入到下一个视频去看下更多的向量化的案例 和开始学习向量化逻辑回归