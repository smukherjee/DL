1
00:00:00,920 --> 00:00:02,860
嗨,歡迎回來.

2
00:00:02,860 --> 00:00:08,860
這個禮拜我們將學習
基本的神經網路程式

3
00:00:08,860 --> 00:00:11,990
實際上當您
建立神經網路時

4
00:00:11,990 --> 00:00:16,260
有一些技巧
將非常重要

5
00:00:16,260 --> 00:00:21,150
例如, 如果您訓練
一組m個訓練例子

6
00:00:21,150 --> 00:00:25,110
您可能習慣處理
這個訓練集使用迴圈

7
00:00:25,110 --> 00:00:28,240
一個接著一個經過您m個訓練例子

8
00:00:28,240 --> 00:00:31,260
但實際上當您
建置一個神經網路

9
00:00:31,260 --> 00:00:34,540
您通常想要處理
您整個訓練集

10
00:00:34,540 --> 00:00:39,040
不需要使用明顯的迴圈來
迴過您整個訓練集

11
00:00:39,040 --> 00:00:42,940
您會看到如何做到的
在本週的課程裡

12
00:00:42,940 --> 00:00:47,700
另一個觀念，當你組織
運算時，在您的網路中

13
00:00:47,700 --> 00:00:51,670
通常您有所謂的正向
路徑或者正向傳播步驟

14
00:00:51,670 --> 00:00:56,100
接著是反向路徑或者
稱為反向傳播步驟

15
00:00:56,100 --> 00:01:00,010
所以在這個星期的課程
您也會學習到為什麼

16
00:01:00,010 --> 00:01:04,830
在運算中, 在神經
網路可以組織成正向

17
00:01:04,830 --> 00:01:08,010
傳播跟
分別的反向傳播

18
00:01:09,100 --> 00:01:12,620
對於本週的課程我想
傳達這些觀念使用

19
00:01:12,620 --> 00:01:16,170
羅吉斯迴歸分析為了讓
這些觀念易懂

20
00:01:16,170 --> 00:01:19,970
但即使您見過羅吉斯
迴歸分析, 我想還是有

21
00:01:19,970 --> 00:01:23,845
一些新的有趣的觀念
讓您在這週的課程學習到

22
00:01:23,845 --> 00:01:25,815
所以，我們開始吧

23
00:01:25,815 --> 00:01:30,605
羅吉斯迴歸分析是一種演算法
使用在二元分類

24
00:01:30,605 --> 00:01:33,145
讓我們開始設定問題

25
00:01:33,145 --> 00:01:36,925
這是一個例子有關於二元
分類問題

26
00:01:36,925 --> 00:01:41,545
您也許有一個輸入的影像
像這樣

27
00:01:41,545 --> 00:01:47,260
想要輸出一個標籤來識別
這個影像是否是一隻貓

28
00:01:47,260 --> 00:01:52,140
是貓您輸出是1,或者
不是貓輸出是0

29
00:01:52,140 --> 00:01:57,740
而您將使用y
來記這個輸出標籤

30
00:01:57,740 --> 00:02:01,550
讓我們看看一個影像如何
在電腦中呈現

31
00:02:01,550 --> 00:02:05,680
儲存一個影像在電腦
您儲存了三個分別的矩陣

32
00:02:05,680 --> 00:02:09,890
相當是紅,綠跟
藍色通道對於這個影像

33
00:02:10,990 --> 00:02:15,900
所以如果您輸入一個影像是
64像素乘64像素

34
00:02:15,900 --> 00:02:21,700
那您會得到三個64乘64矩陣

35
00:02:21,700 --> 00:02:27,230
相當於紅,綠跟藍
像素強度值對於您的影像

36
00:02:27,230 --> 00:02:31,290
雖然這張小投影片我
畫的是小一點的矩陣

37
00:02:31,290 --> 00:02:35,320
其實是5乘4
矩陣而不是64乘64

38
00:02:35,320 --> 00:02:41,640
所以轉換這些像素強度值
成為一個特徵向量, 我們

39
00:02:41,640 --> 00:02:48,000
將展開這些所有的像素
值變成一個輸入特徵向量x

40
00:02:48,000 --> 00:02:53,782
為了展開所有這些強度
值成為特徵向量我們

41
00:02:53,782 --> 00:02:59,580
將定義一個特徵向量x
相當於這個影像像這樣

42
00:02:59,580 --> 00:03:03,960
我們將拿所有
像素值255,231,..等等

43
00:03:03,960 --> 00:03:10,827
255,231..等等
直到我們列出所有紅的像素

44
00:03:10,827 --> 00:03:15,737
然後終究是255,134,.255,
134..等

45
00:03:15,737 --> 00:03:20,952
直到我們得到一個長的特徵
向量列出所有紅

46
00:03:20,952 --> 00:03:25,570
綠跟
藍像素強度值對於這個影像

47
00:03:25,570 --> 00:03:31,043
如果這是一個64乘64影像
總共的維度

48
00:03:31,043 --> 00:03:36,401
對於這個向量x會是64
乘64乘3因為那是

49
00:03:36,401 --> 00:03:41,320
所有的數字我們
在這些矩陣中

50
00:03:41,320 --> 00:03:44,097
在這個例子
實際上是12,288

51
00:03:44,097 --> 00:03:47,330
這是您得到的數字如果您
將所有這些數字相乘

52
00:03:47,330 --> 00:03:51,870
所以我們將使用nx=12288

53
00:03:51,870 --> 00:03:55,080
來表示
輸入特徵x的維度

54
00:03:55,080 --> 00:03:59,280
有時候為了省略
我也會用小寫的 n

55
00:03:59,280 --> 00:04:02,720
來代表
這個輸入特徵向量的維度

56
00:04:02,720 --> 00:04:07,510
在二元分類中, 我們的目標是
學習一個分類子可以用來輸入

57
00:04:07,510 --> 00:04:10,760
一個影像
用這個特徵向量x表示

58
00:04:10,760 --> 00:04:15,460
來預測是否
相對於標籤y是1還是0

59
00:04:15,460 --> 00:04:19,000
也就是, 是否這是一張貓的影像或
不是貓的影像

60
00:04:19,000 --> 00:04:21,560
讓我們佈置一些
我們將用到的符號

61
00:04:21,560 --> 00:04:23,820
一直到本課程結束

62
00:04:23,820 --> 00:04:29,453
一個單一的訓練例子
是用一對來表示

63
00:04:29,453 --> 00:04:34,446
(x,y)而x是nx維度的特徵

64
00:04:34,446 --> 00:04:39,320
向量, y,標籤則不是0就是1

65
00:04:39,320 --> 00:04:44,550
您的訓練集將包含
小寫m個訓練例子

66
00:04:44,550 --> 00:04:50,320
所以您訓練及會是
寫成(x1,y1)也就是輸入及

67
00:04:50,320 --> 00:04:55,370
輸出對於您的一個訓練
例子, (x2, y2)是

68
00:04:55,370 --> 00:05:01,980
第二個訓練例子直到(xm,
ym)就是最後一個例子

69
00:05:01,980 --> 00:05:05,650
而全部這些
就是您整個訓練集

70
00:05:05,650 --> 00:05:10,170
我將使用小寫m
來表示訓練例子的數目

71
00:05:10,170 --> 00:05:14,418
有時候為了強調這是
訓練例子的數目

72
00:05:14,418 --> 00:05:16,437
我會寫成 m = m下標train

73
00:05:16,437 --> 00:05:18,692
而當我們談到測試集時

74
00:05:18,692 --> 00:05:24,430
我也許有時候使用m下標test 來記測試例子的數量

75
00:05:24,430 --> 00:05:27,430
所以那是測試例子的數量

76
00:05:27,430 --> 00:05:33,440
最後, 輸出所有訓練
例子到更緊湊的記號

77
00:05:33,440 --> 00:05:36,840
我們將定義一個矩陣, 大寫的 X

78
00:05:36,840 --> 00:05:41,592
這樣定義著拿您的
訓練輸入x1,x2...

79
00:05:41,592 --> 00:05:44,568
等等將他們放在一欄一欄上

80
00:05:44,568 --> 00:05:49,958
所以我們拿x1
將它放在第一欄的這個矩陣

81
00:05:49,958 --> 00:05:54,798
x2放在第二欄等等
一直到xm

82
00:05:54,798 --> 00:05:58,000
那這就是矩陣大寫的X

83
00:05:58,000 --> 00:06:03,005
這個矩陣X會有m欄
而m是

84
00:06:03,005 --> 00:06:08,665
訓練例子的數目, 而行數
或者說矩陣的高度是nx

85
00:06:08,665 --> 00:06:14,400
請注意在其他課程裡
您也許看過矩陣大寫

86
00:06:14,400 --> 00:06:19,390
X定義為堆疊訓練
例子在行, 像這樣

87
00:06:19,390 --> 00:06:23,940
x1轉置一直到xm轉置

88
00:06:23,940 --> 00:06:27,704
實際上當您
建置神經網路時使用

89
00:06:27,704 --> 00:06:32,218
這種左邊的方式
會讓建置更快

90
00:06:32,218 --> 00:06:37,171
所以總結一下
X是nx乘m維度的矩陣而

91
00:06:37,171 --> 00:06:40,404
當您用Python建置這個

92
00:06:40,404 --> 00:06:45,362
您看到x.shape
那是Python指令來

93
00:06:45,362 --> 00:06:50,325
找出矩陣的形狀
也就是nx, m

94
00:06:50,325 --> 00:06:53,255
那就意味著它是 nx 
乘 m 維矩陣

95
00:06:53,255 --> 00:06:58,785
所以這是您如何組織訓練
例子,輸入x變成矩陣

96
00:06:58,785 --> 00:07:01,315
如何處理輸出標籤y呢?

97
00:07:01,315 --> 00:07:04,815
實際上為了讓您
建置神經網路更容易些

98
00:07:04,815 --> 00:07:10,030
將y疊在欄也是比較容易

99
00:07:10,030 --> 00:07:14,650
所以我們將定義大寫
Y為y1, y2...

100
00:07:14,650 --> 00:07:18,580
一直到ym像這樣

101
00:07:18,580 --> 00:07:24,980
所以Y是1乘
m維度矩陣

102
00:07:24,980 --> 00:07:30,530
同樣地, 使用Python記號
用shape of Y 會是1, m

103
00:07:30,530 --> 00:07:34,810
也就是這是一個1乘m矩陣

104
00:07:34,810 --> 00:07:39,660
而當您日後建置神經網路
在這個課程中您會發現這是有用的

105
00:07:39,660 --> 00:07:43,630
慣例就是拿資料
對應到不同的訓練

106
00:07:43,630 --> 00:07:48,580
例子時, 而這裡的資料指的是x或是
y或是其他的量以後會見到

107
00:07:48,580 --> 00:07:49,900
但拿這些東西或者

108
00:07:49,900 --> 00:07:52,990
資料對應到
不同的訓練例子

109
00:07:52,990 --> 00:07:57,430
堆疊到不同的欄位
像我們這樣做x跟y

110
00:07:58,450 --> 00:08:01,380
所以這就是我們即將用在
羅吉斯迴歸分析跟

111
00:08:01,380 --> 00:08:04,060
神經網路
在往後的課程的記號

112
00:08:04,060 --> 00:08:07,430
如果您忘記了
其中一個記號代表的意思, 像是什麼是m

113
00:08:07,430 --> 00:08:08,300
什麼是n或者

114
00:08:08,300 --> 00:08:12,630
什麼是...我們也發佈在
課程網站上的符號指南

115
00:08:12,630 --> 00:08:17,430
您可以使用它快速的查找
任何特定的記號代表的意思

116
00:08:17,430 --> 00:08:20,890
所以有了這個,讓我們繼續到下一段
影片我們開始來進行

117
00:08:20,890 --> 00:08:23,190
羅吉斯迴歸分析使用這些符號