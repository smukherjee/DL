1
00:00:01,050 --> 00:00:03,840
Поняття глибоке навчання (ГН) відноситься 
до тренування нейронних мереж (НМ),

2
00:00:03,840 --> 00:00:06,050
інколи дуже великих НМ.

3
00:00:06,050 --> 00:00:08,400
Тож, що таке НМ?

4
00:00:08,400 --> 00:00:11,340
В цьому відео давай спробуємо дати тобі 
базове розуміння.

5
00:00:12,850 --> 00:00:16,540
Давай почнемо з прикладу передбачення вартості житла.

6
00:00:16,540 --> 00:00:20,599
Скажімо, ми маємо набір даних про 6 будинків. 
Тож, ми знаємо площу будинків

7
00:00:20,599 --> 00:00:24,478
в квадратних футах чи метрах і знаємо їх ціну. І хочемо

8
00:00:24,478 --> 00:00:28,501
підібрати функцію, щоб передбачатиме ціну будинків, 
як функцію від площі.

9
00:00:28,501 --> 00:00:33,509
Тож, якщо ти знайомий з лінійною регресією, 
то, можливо, скажеш: що ж,

10
00:00:33,509 --> 00:00:38,450
давайте намалюємо пряму через ці точки. 
Тож, скажімо, ми отримаємо приблизно таку пряму.

11
00:00:38,450 --> 00:00:41,850
Включивши уяву, ми можемо сказати: що ж, ми знаємо, що ціни

12
00:00:41,850 --> 00:00:43,770
не можуть бути від'ємними. Правильно?

13
00:00:43,770 --> 00:00:48,050
Тож, замість підбору прямої, яка, врешті-решт, 
стане від'ємною,

14
00:00:48,050 --> 00:00:49,960
давай зробимо її ламаною ось тут.

15
00:00:49,960 --> 00:00:51,530
Так, щоб вона закінчувалась нулем.

16
00:00:51,530 --> 00:00:56,770
Тож, ця товста синя лінія буде нашою функцією

17
00:00:56,770 --> 00:00:59,760
передбачення вартості будинку, як функція від площі.

18
00:00:59,760 --> 00:01:03,310
Тож ми маємо отут 0, а далі вправо - пряму, що підходить для наших точок.

19
00:01:04,408 --> 00:01:08,735
Тож, ця функція, яку ми щойно підібрали по цінах будинків, -

20
00:01:08,735 --> 00:01:11,880
є дуже простою НМ.

21
00:01:11,880 --> 00:01:14,230
Це майже найпростіша НМ.

22
00:01:14,230 --> 00:01:15,000
Давай я її тут опишу.

23
00:01:17,220 --> 00:01:22,170
Вхідними даними для НМ у нас тут є житлова площа. 
Ми називаємо їх x.

24
00:01:22,170 --> 00:01:26,791
x входить в цей вузол (це маленьке коло) і

25
00:01:26,791 --> 00:01:30,940
виходить ціною, яку ми називаємо y.

26
00:01:30,940 --> 00:01:37,183
Тож, це маленьке коло, 
що являє собою єдиний нейрон нашої НМ,

27
00:01:37,183 --> 00:01:41,830
реалізує цю функцію, яку ми намалювали зліва.

28
00:01:43,350 --> 00:01:48,940
І все, що робить цей нейрон, це - приймає площу, 
обчислює цю лінійну функцію,

29
00:01:48,940 --> 00:01:51,960
бере максимум відносно 0, 
а потім видає обчислену ціну.

30
00:01:53,190 --> 00:01:58,230
І, до речі, в літературі по НМ ця функція зустрічається дуже часто.

31
00:01:58,230 --> 00:02:00,992
Ця функція, яка рівна 0 на певному проміжку, а

32
00:02:00,992 --> 00:02:03,550
потім піднімається вгору прямою лінією.

33
00:02:03,550 --> 00:02:09,108
Ця функція називається функцією ВЛВ [ReLU], що означає

34
00:02:09,108 --> 00:02:17,620
випрямлений лінійний вузол 
[rectified linear unit]

35
00:02:17,620 --> 00:02:18,252
(R-E-L-U).

36
00:02:18,252 --> 00:02:22,520
Випрямлений означає максимум відносно 0. 
Ось що надає їй такої форми.

37
00:02:23,640 --> 00:02:25,550
Не переймайся щодо ВЛВ поки що.

38
00:02:25,550 --> 00:02:30,200
Просто ти ще побачиш його пізніше в цьому курсі.

39
00:02:30,200 --> 00:02:33,790
Тож, якщо цей єдиний нейрон НМ

40
00:02:33,790 --> 00:02:38,870
(дійсно дуже маленької НМ), то більша НМ

41
00:02:38,870 --> 00:02:44,520
потім формується з більшої кількості таких нейронів, 
складених докупи.

42
00:02:44,520 --> 00:02:50,700
Тож, якщо ти уявиш, що цей нейрон - 
окрема деталь Lego, то

43
00:02:50,700 --> 00:02:55,270
більшу НМ можна отримати, з'єднавши ці деталі Lego.

44
00:02:55,270 --> 00:02:56,110
Давай розглянемо приклад.

45
00:02:57,260 --> 00:03:02,220
Скажімо, замість лише самої площі будинку 
для передбачення вартості житла

46
00:03:02,220 --> 00:03:04,330
нам дано ще й інші характеристики.

47
00:03:04,330 --> 00:03:08,164
Ми знаємо і інші характеристики будинку, 
такі як кількість спалень.

48
00:03:08,164 --> 00:03:13,630
Запишу це "№ спалень". 
Якщо задуматись, то ще одна з характеристик,

49
00:03:13,630 --> 00:03:18,820
яка справді впливає на ціну, це - розмір сім'ї, правильно? 
Тобто, скажімо,

50
00:03:18,820 --> 00:03:21,882
чи підходить цей будинок сім'ї з 3-ох, чи 4-ох, чи

51
00:03:21,882 --> 00:03:22,687
5-ти людей.

52
00:03:22,687 --> 00:03:26,351
І дійсно, базуючись на розмірі в квадратних футах чи метрах і

53
00:03:26,351 --> 00:03:28,960
кількості спалень, можна визначити чи

54
00:03:28,960 --> 00:03:31,462
підходить будинок сім'ї, розміром як твоя.

55
00:03:31,462 --> 00:03:34,909
Крім цього, можливо, нам відомі zip коди.

56
00:03:34,909 --> 00:03:40,520
В інших країнах вони називаються 
поштовими кодами будинку.

57
00:03:40,520 --> 00:03:48,820
І zip код, можливо, - характеристика, 
що говорить про пішу доступність.

58
00:03:48,820 --> 00:03:51,434
Тобто, що знаходиться в пішій доступності.

59
00:03:51,434 --> 00:03:53,635
Тобто, чи можна пішки дійти до продуктового магазину

60
00:03:53,635 --> 00:03:54,194
чи до школи?

61
00:03:54,194 --> 00:03:55,250
Чи потрібно їхати машиною?

62
00:03:55,250 --> 00:03:57,870
Декому подобається, щоб все було в пішій доступності.

63
00:03:57,870 --> 00:04:06,145
Тож, zip коди вкупі з, можливо, інфраструктурою, 
дають нам розуміння

64
00:04:06,145 --> 00:04:09,200
(зазвичай в США, але і в інших країнах також)

65
00:04:09,200 --> 00:04:13,590
наскільки якісна шкільна освіта.

66
00:04:13,590 --> 00:04:17,820
Тож, кожне з цих маленьких кіл, що я 
намалював, може бути однією з тих ВЛВ

67
00:04:17,820 --> 00:04:22,670
(випрямлених лінійних вузлів) або 
іншою нелінійною функцією.

68
00:04:22,670 --> 00:04:24,936
Отож, базуючись на площі будинку і кількості спалень,

69
00:04:24,936 --> 00:04:28,420
ми можемо визначити розмір сім'ї. 
Zip код визначає пішу доступність.

70
00:04:28,420 --> 00:04:32,050
Базуючись на zip коді і інфраструктурі, ми можемо 
визначити якість шкільної освіти.

71
00:04:32,050 --> 00:04:35,660
І, врешті-решт, ми можемо подумати: 
що ж, люди вирішують скільки готові

72
00:04:35,660 --> 00:04:38,880
заплатити за будинок, 
оцінюючи важливі для них характеристики.

73
00:04:38,880 --> 00:04:43,060
В цьому випадку: розмір сім'ї, що в пішій доступності 
і якість шкільної освіти. І

74
00:04:43,060 --> 00:04:45,210
це допомагає нам передбачити ціну.

75
00:04:46,330 --> 00:04:51,740
Тож, в цьому прикладі, x - це оці 4 вхідні ознаки,

76
00:04:53,470 --> 00:04:56,460
а y - ціна, яку ми намагаємося передбачити.

77
00:04:57,960 --> 00:05:03,350
Тож, групуючи кілька одиночних нейронів або простих предикторів,

78
00:05:03,350 --> 00:05:07,360
що ми бачили на попередньому слайді, 
ми отримуємо дещо більшу НМ.

79
00:05:07,360 --> 00:05:10,850
Магія НМ заключається в тому, що ми її реалізуємо,

80
00:05:10,850 --> 00:05:15,860
ми просто даємо їй вхідні x і

81
00:05:15,860 --> 00:05:20,740
вихідні y для певної кількості елементів тренувального набору, а

82
00:05:20,740 --> 00:05:23,580
всі оці штуки посередині зроблять все самі.

83
00:05:25,435 --> 00:05:29,225
Тож ми впровадили ось це.

84
00:05:29,225 --> 00:05:32,055
Тут ми маємо НМ з 4-ма вхідними ознаками.

85
00:05:32,055 --> 00:05:35,455
Цими вхідними ознаками можуть бути площа, кількість спалень,

86
00:05:35,455 --> 00:05:40,365
zip або поштовий код і інфраструктура.

87
00:05:40,365 --> 00:05:44,805
Тож, маючи ці вхідні параметри,

88
00:05:44,805 --> 00:05:50,200
роботою НМ буде - передбачення ціни y.

89
00:05:50,200 --> 00:05:55,942
Також варто відмітити, що кожен з цих кружечків 
(вони називаються прихованими вузлами НМ),

90
00:05:55,942 --> 00:06:02,310
кожен з них приймає всі ці 4 вхідні ознаки.

91
00:06:02,310 --> 00:06:08,139
Тож, наприклад, замість казати, 
що оцей перший вузол відображає розмір сім'ї, а

92
00:06:08,139 --> 00:06:12,056
розмір сім'ї залежить лише від ознак x₁ і x₂,

93
00:06:12,056 --> 00:06:15,302
ми збираємось сказати: "Що ж, НМ,

94
00:06:15,302 --> 00:06:18,200
вирішуй сама, що це має бути за вузол,

95
00:06:18,200 --> 00:06:21,070
Бо ми даємо тобі всі 4 вхідні ознаки, 
а ти вже дій як вважаєш за потрібне".

96
00:06:21,070 --> 00:06:26,170
Тож, ми кажемо, що ці шари - цей вхідний шар і

97
00:06:26,170 --> 00:06:28,960
цей шар всередині НМ - щільно зв'язані.

98
00:06:28,960 --> 00:06:31,740
Тому що кожна вхідна ознака пов'язана з кожним

99
00:06:31,740 --> 00:06:33,980
із цих кружечків всередині.

100
00:06:33,980 --> 00:06:38,630
Тож дивовижність НМ в тому, що, 
маючи достатньо відомостей про

101
00:06:38,630 --> 00:06:43,290
x та y, маючи достатньо тренувальних зразків, 
що містять з x та y,

102
00:06:43,290 --> 00:06:47,450
НМ дивовижно впоруються з обчисленням 
функцій, що співвідносять x до y.

103
00:06:48,990 --> 00:06:51,680
Отож, це - базова НМ.

104
00:06:51,680 --> 00:06:54,290
Виявляється, що розбудовуючи власну НМ,

105
00:06:54,290 --> 00:06:57,130
може дійти висновку, що вона найбільш корисна і потужна

106
00:06:57,130 --> 00:07:01,620
для налаштування керованого навчання. 
Тобто, коли ми намагаємось співвіднести вхідне x

107
00:07:01,620 --> 00:07:06,980
до деякого вихідного y, як ми щойно бачили 
на прикладі передбачення вартості житла.

108
00:07:06,980 --> 00:07:11,490
В наступному відео давай розглянемо трохи 
більше прикладів керованого навчання і

109
00:07:11,490 --> 00:07:15,670
кілька прикладів, де ти, можливо, виявиш, 
що твоя НМ неймовірно корисна

110
00:07:15,670 --> 00:07:16,670
також і для твоїх застосунків.