1
00:00:00,000 --> 00:00:01,440
前のビデオでは、最急降下法の数学的定義をしました。

2
00:00:01,440 --> 00:00:05,700
予測値を計算するために
ベクトル化を使う方法を見てきました

3
00:00:05,700 --> 00:00:11,485
トレーニングデータ全体に対して
１度で小文字のa を計算する方法です

4
00:00:11,485 --> 00:00:15,030
このビデオでは
トレーニングデータ全体に対して

5
00:00:15,030 --> 00:00:19,205
勾配計算の実行を
ベクトル化する方法を見ます

6
00:00:19,205 --> 00:00:21,380
今回も１度に実行する方法です

7
00:00:21,380 --> 00:00:22,890
このビデオの終わりには

8
00:00:22,890 --> 00:00:26,175
これまでのことをまとめて
ロジステック回帰を

9
00:00:26,175 --> 00:00:29,730
非常に効率的な実行ができるように
実装を行えるようになります

10
00:00:29,730 --> 00:00:32,505
勾配の計算では
最初のデータに対して

11
00:00:32,505 --> 00:00:36,910
dz(1)を行うのを
覚えているでしょうか

12
00:00:36,910 --> 00:00:43,870
a(1)-y(1)です
次に

13
00:00:43,870 --> 00:00:52,134
dz(2)=a(2)-y(2)です

14
00:00:52,134 --> 00:00:56,425
m 個のトレーニングデータ全体に
続いていきます

15
00:00:56,425 --> 00:01:01,218
これの替わりに
新しい変数dZを定義します

16
00:01:01,218 --> 00:01:08,595
dZはdz(1)、dz(2)、dz(m)となります

17
00:01:08,595 --> 00:01:13,910
ここでもdzの変数は
水平に重ねられます

18
00:01:13,910 --> 00:01:21,200
ここでは1とmの行列になり
別の言い方ではm要素の列ベクトルです

19
00:01:21,200 --> 00:01:23,520
前回のスライドから思い出してください

20
00:01:23,520 --> 00:01:28,405
既に見たように大文字のA を計算するには
a(1)からa(m)とします

21
00:01:28,405 --> 00:01:36,735
大文字のY は
y(1)からy(m)と定義します

22
00:01:36,735 --> 00:01:39,200
そして水平方向に重ねます

23
00:01:39,200 --> 00:01:42,780
これらの定義に基づいて

24
00:01:42,780 --> 00:01:46,770
既に分かるかもしれませんが

25
00:01:46,770 --> 00:01:52,750
dz=A-Yですが
これはa(1)-y(1)を

26
00:01:52,750 --> 00:01:55,670
最初の要素として

27
00:01:55,670 --> 00:01:59,980
a(2)-y(2)があり
続いていきます

28
00:01:59,980 --> 00:02:06,115
１つ目のa(1)-y(1)は
dz(1)の定義と同じで

29
00:02:06,115 --> 00:02:11,670
２つ目のa(2)-y(2)は
dz(2)の定義と同じで以後続きます

30
00:02:11,670 --> 00:02:13,965
これを１行のコードで

31
00:02:13,965 --> 00:02:20,095
これらのすべてを
一度に計算できます

32
00:02:20,095 --> 00:02:24,010
前回の実装では

33
00:02:24,010 --> 00:02:27,695
for loop を
１つ排除しましたが

34
00:02:27,695 --> 00:02:31,600
トレーニングデータに対して繰り返す
２つ目のfor loop がまだあります

35
00:02:31,600 --> 00:02:35,440
dwを０のベクトルで
初期化しますが

36
00:02:35,440 --> 00:02:38,905
トレーニングデータに対して繰り返して

37
00:02:38,905 --> 00:02:43,015
dw+=x(1)かけるdz(1)を

38
00:02:43,015 --> 00:02:50,440
最初のトレーニングデータに実行し
dw+=x(2)かけるdz(2)と続けます

39
00:02:50,440 --> 00:02:56,980
これをm 回繰り返した後に
dm/=mを実行します

40
00:02:56,980 --> 00:03:03,370
dbに対しても同様で０で初期化し
db+=dz(1)をし

41
00:03:03,370 --> 00:03:09,120
db+=dz(2)をし
dz(m)まで続けます

42
00:03:09,120 --> 00:03:16,835
db/=m へと続きます
これが前回の実装方法です

43
00:03:16,835 --> 00:03:18,700
１つのfor loop は
すでに排除したので

44
00:03:18,700 --> 00:03:25,045
dwはベクトルになっていますが
元は個別にdw(1)、dw(2)のように

45
00:03:25,045 --> 00:03:26,850
更新してました

46
00:03:26,850 --> 00:03:29,860
これはもう排除しましたが

47
00:03:29,860 --> 00:03:33,630
トレーニングセットのm 個のデータに対して
for loop が残っています

48
00:03:33,630 --> 00:03:36,290
ではこれらの命令を
ベクトル化しましょう

49
00:03:36,290 --> 00:03:38,380
こうやります

50
00:03:38,380 --> 00:03:42,745
dbのベクトル化の実装は
基本的にはdzを

51
00:03:42,745 --> 00:03:47,940
まず加算して
mで割ります

52
00:03:47,940 --> 00:03:51,580
dbは1/mです

53
00:03:51,580 --> 00:03:56,530
シグマでi=1からmまでで
dz(i)をし

54
00:03:56,530 --> 00:04:03,055
この列ベクトルの中のdzは
Python では

55
00:04:03,055 --> 00:04:04,765
こう実装できます

56
00:04:04,765 --> 00:04:08,155
1/mかけるnp.sum(dz)で

57
00:04:08,155 --> 00:04:12,210
できます

58
00:04:12,210 --> 00:04:15,115
この変数を使って
この変数に対して

59
00:04:15,115 --> 00:04:19,195
np.sum関数を呼ぶだけで
dbが求められます

60
00:04:19,195 --> 00:04:22,330
dwはどうでしょうか

61
00:04:22,330 --> 00:04:26,375
正しいやり方を確認できるように
正しい式を書き出します

62
00:04:26,375 --> 00:04:28,164
dwは1/mかける

63
00:04:28,164 --> 00:04:34,485
行列Xかけるdzの
転置になります

64
00:04:34,485 --> 00:04:37,990
なぜこうなるでしょうか

65
00:04:37,990 --> 00:04:41,806
これは1/mと行列Xの

66
00:04:41,806 --> 00:04:48,325
x(1)からx(m)をこのように
列で重ねたようになり

67
00:04:48,325 --> 00:04:56,040
dzの転置はdz(1)からdz(m)になります

68
00:04:56,040 --> 00:05:00,900
この行列とベクトルを掛けると

69
00:05:00,900 --> 00:05:05,585
1/mかける

70
00:05:05,585 --> 00:05:12,523
x(1)dz(1)から続けて
x(m)dz(m)を出したものです

71
00:05:12,523 --> 00:05:21,405
これはn×1のベクトルで
dwとなります

72
00:05:21,405 --> 00:05:24,725
ご存知のようにdwは

73
00:05:24,725 --> 00:05:27,710
x(i)dz(i)を合計したもので

74
00:05:27,710 --> 00:05:32,300
この行列ベクトルの積が行っているものです

75
00:05:32,300 --> 00:05:35,655
１行のコードで
dwが計算できます

76
00:05:35,655 --> 00:05:40,010
微分の計算をベクトル化で実装すると
これだけです

77
00:05:40,010 --> 00:05:44,540
この式をdb で実装し

78
00:05:44,540 --> 00:05:50,540
この式でdw を実装します
トレーニングセットに対するfor loop が無いことに注目してください

79
00:05:50,540 --> 00:05:55,265
パラメーターを更新する値を
計算できます

80
00:05:55,265 --> 00:06:01,185
これまでの全体を纏めて
ロジステック回帰の実装方法を見ましょう

81
00:06:01,185 --> 00:06:02,550
これが元々で

82
00:06:02,550 --> 00:06:07,866
かなり非効率で
ベクトル化なしの実装です

83
00:06:07,866 --> 00:06:11,775
前のビデオで最初に行ったのは
このfor loop を排除しました

84
00:06:11,775 --> 00:06:14,400
dw1、dw2と続けるループを

85
00:06:14,400 --> 00:06:15,755
やめて

86
00:06:15,755 --> 00:06:23,595
この部分をベクトル値のdwと置き換え
dw+=x(i)とし

87
00:06:23,595 --> 00:06:28,775
dz(i)と掛けました

88
00:06:28,775 --> 00:06:32,000
これから実施するのは
下のfor loop を排除するだけでなく

89
00:06:32,000 --> 00:06:36,670
このfor loop も排除します

90
00:06:36,670 --> 00:06:38,654
次のようにやります

91
00:06:38,654 --> 00:06:42,925
前のスライドにあるように

92
00:06:42,925 --> 00:06:46,085
大文字のZが

93
00:06:46,085 --> 00:06:57,625
Z=w(転置)かけるX+bで
コードではnp.dot(w.T,X)+bと書きます

94
00:06:57,625 --> 00:07:07,315
Aは大文字Zのシグモイド関数です

95
00:07:07,315 --> 00:07:12,710
この２つの式のすべてのiに対して
計算ができました

96
00:07:12,710 --> 00:07:14,715
さらに前のスライドでは

97
00:07:14,715 --> 00:07:21,070
dz=A-Yを計算しました

98
00:07:21,070 --> 00:07:24,460
この行の全てのiに対する
計算を行います

99
00:07:24,460 --> 00:07:31,495
さらにdwは1/mかけるXかけるdzの転置です

100
00:07:31,495 --> 00:07:39,700
db=1/mとnp.sum(dz)と

101
00:07:39,700 --> 00:07:43,328
なります

102
00:07:43,328 --> 00:07:49,120
これで誤差順伝播法と誤差逆伝播法を
行ったことになります

103
00:07:49,120 --> 00:07:53,030
for loop 無しで
全てのトレーニングデータm に対して

104
00:07:53,030 --> 00:07:57,340
予測と微分を
計算したことになります

105
00:07:57,340 --> 00:08:00,835
勾配降下法の更新はこうなります

106
00:08:00,835 --> 00:08:04,462
w=w引く学習率かける
上で計算したdwになり

107
00:08:04,462 --> 00:08:12,020
bはb引く学習率かけるdbになります

108
00:08:12,020 --> 00:08:17,341
コロンを入れることで
代入であることを表します

109
00:08:17,341 --> 00:08:21,675
表記方法について
一貫して記載していませんでしたが

110
00:08:21,675 --> 00:08:25,450
ここまでの作業によって

111
00:08:25,450 --> 00:08:29,635
ロジステック回帰での
１回分の勾配降下の更新を実装できました

112
00:08:29,635 --> 00:08:32,308
これまでの話では
できる限りのfor loop を

113
00:08:32,308 --> 00:08:35,260
排除するように言ってきましたが

114
00:08:35,260 --> 00:08:38,230
複数回分の勾配降下の

115
00:08:38,230 --> 00:08:42,880
実行をするには
for loop で回数分を繰り返す必要があります

116
00:08:42,880 --> 00:08:47,860
千回の勾配降下を
実行したい場合には

117
00:08:47,860 --> 00:08:53,675
繰り返しの数に基づいて
for loop が必要になります

118
00:08:53,675 --> 00:08:55,870
ここのように一番外側の
for loop で

119
00:08:55,870 --> 00:08:59,210
このfor loop を排除する方法は
無いように思います

120
00:08:59,210 --> 00:09:02,390
ただfor loop を使うことなく

121
00:09:02,390 --> 00:09:07,117
最低でも１回分の勾配降下法を
実行できるのは信じられないほど良いことだと思います

122
00:09:07,117 --> 00:09:09,880
さてこれで終わりです
これでロジステック回帰の

123
00:09:09,880 --> 00:09:14,745
かなりベクトル化されて
非常に効率化された実装ができました

124
00:09:14,745 --> 00:09:18,850
次のビデオでは
あと１つだけ詳細を話します

125
00:09:18,850 --> 00:09:24,155
ここの記述で少しほのめかしましたが
ブロードキャストのことです

126
00:09:24,155 --> 00:09:28,240
ブロードキャストは
Python と numpy を使うと

127
00:09:28,240 --> 00:09:32,915
コードの一部を
はるかに効率的にすることができるテクニックです

128
00:09:32,915 --> 00:09:37,090
次のビデオで
ブロードキャストの詳細を見ましょう