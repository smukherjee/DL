1
00:00:00,000 --> 00:00:01,530
Dans une vidéo précédente,

2
00:00:01,530 --> 00:00:04,227
Vous avez vu le modèle 
de régression logistique.

3
00:00:04,227 --> 00:00:07,526
Pour apprendre les paramètres W et b
 du modèle de régression logistique,

4
00:00:07,526 --> 00:00:10,570
vous devez définir une fonction de coût.

5
00:00:10,570 --> 00:00:14,430
Nous allons voir la fonction de coût 
que vous pouvez utiliser pour 
entraîner une régression logistique.

6
00:00:14,430 --> 00:00:18,195
Pour rappel, voici ce que nous avons
 défini dans la diapositive précédente.

7
00:00:18,195 --> 00:00:20,792
Votre sortie ŷ est la sigmoïde de 

8
00:00:20,792 --> 00:00:24,690
la transformée de W x + b
 avec la sigmoïde de z définie ici.

9
00:00:24,690 --> 00:00:27,600
Pour apprendre les paramètres pour 
votre modèle, on vous donne

10
00:00:27,600 --> 00:00:31,200
un set d’apprentissage de 
m exemples d'apprentissage et

11
00:00:31,200 --> 00:00:34,060
naturellement, vous voulez 
trouver les paramètres W

12
00:00:34,060 --> 00:00:37,781
et b de façon que, au moins sur le set 
d’apprentissage, les sorties que vous avez,

13
00:00:37,781 --> 00:00:40,225
les prédictions que vous avez
 sur le set d’apprentissage,

14
00:00:40,225 --> 00:00:43,260
que nous écrirons ŷ(i) soient proches

15
00:00:43,260 --> 00:00:47,720
de la vérité, c'est à dire des étiquettes y(i)
 qui sont dans le set d’apprentissage.

16
00:00:47,720 --> 00:00:52,110
Pour ajouter un peu plus de détails
 à l’équation au-dessus,

17
00:00:52,110 --> 00:00:56,205
Nous avons dit que ŷ 
est défini comme ceci en haut

18
00:00:56,205 --> 00:01:00,930
pour un exemple d'apprentissage x et, bien
 sûr, pour chaque exemple d'apprentissage,

19
00:01:00,930 --> 00:01:03,240
nous utilisons ces exposants avec

20
00:01:03,240 --> 00:01:07,710
des parenthèses pour indexer 
et différencier les exemples.

21
00:01:07,710 --> 00:01:12,870
Votre prédiction sur l'exemple
 d'apprentissage i est ŷ(i) et

22
00:01:12,870 --> 00:01:18,835
sera obtenu en prenant la fonction sigmoïde
 et en l'appliquant à la transposée de Wx(i)

23
00:01:18,835 --> 00:01:25,905
l'entrée de l'exemple d'apprentissage,
 plus b. Et vous pouvez définir

24
00:01:25,905 --> 00:01:30,110
z(i) = W.T x(i) + b

25
00:01:30,110 --> 00:01:31,350
Tout au long de ce cours,

26
00:01:31,350 --> 00:01:33,966
nous allons utiliser cette 
convention de notation,

27
00:01:33,966 --> 00:01:41,605
que les exposants i entre parenthèses
 renvoient aux données

28
00:01:41,605 --> 00:01:47,615
x, y ou z ou autre chose,
 associé à l'exemple d'apprentissage i,

29
00:01:47,615 --> 00:01:50,885
avec le i-ième exemple.

30
00:01:50,885 --> 00:01:54,840
C’est ce que signifie 
l’exposant i entre parenthèses.

31
00:01:54,840 --> 00:01:57,630
Maintenant, nous allons voir quelle 
fonction de perte, ou fonction d’erreur,

32
00:01:57,630 --> 00:02:01,315
nous pouvons utiliser pour mesurer 
la performance de notre algorithme.

33
00:02:01,315 --> 00:02:06,015
Une chose que vous pourriez faire, c’est définir 
la perte ainsi : quand votre algorithme

34
00:02:06,015 --> 00:02:12,320
donne ŷ et que la vraie étiquette est y,
 prendre l'erreur au carré ou
 la moitié de l'erreur au carré.

35
00:02:12,320 --> 00:02:14,975
Il s’avère que vous pourriez faire cela,

36
00:02:14,975 --> 00:02:17,670
mais en régression logistique,
 d'habitude les gens ne font pas ça,

37
00:02:17,670 --> 00:02:21,000
parce que quand vous devez 
apprendre les paramètres,

38
00:02:21,000 --> 00:02:25,682
vous trouvez que le problème d’optimisation
 dont nous parlerons plus tard
 devient non convexe.

39
00:02:25,682 --> 00:02:30,105
Donc vous vous retrouvez avec un problème 
d’optimisation avec de multiples optima locaux.

40
00:02:30,105 --> 00:02:33,285
Et la descente de gradient peut
 ne pas trouver l’optimum global.

41
00:02:33,285 --> 00:02:35,580
Si vous n'avez pas compris
 ces derniers commentaires,

42
00:02:35,580 --> 00:02:38,320
ne vous inquiétez pas, nous en reparlerons
 dans une vidéo plus tard.

43
00:02:38,320 --> 00:02:40,990
Mais l’intuition à garder est que

44
00:02:40,990 --> 00:02:44,620
cette fonction L appelée la fonction de perte 
est une fonction que vous

45
00:02:44,620 --> 00:02:51,265
devrez définir pour mesurer 
à quel point notre sortie ŷ
 est bonne quand l'étiquette est y.

46
00:02:51,265 --> 00:02:54,345
Et le carré de l'erreur semble 
être un choix raisonnable

47
00:02:54,345 --> 00:02:58,160
sauf qu’elle ne permet pas à la descente
 de gradient de bien fonctionner.

48
00:02:58,160 --> 00:03:00,500
Donc pour la régression logistique, 
nous définirons en fait

49
00:03:00,500 --> 00:03:05,695
une fonction de perte différente, qui joue 
le même rôle que l'erreur quadratique,

50
00:03:05,695 --> 00:03:08,910
mais qui nous donnera un 
problème d’optimisation qui est

51
00:03:08,910 --> 00:03:13,530
convexe et donc, comme nous allons
 le voir dans une vidéo plus tard, devient
 beaucoup plus facile à optimiser.

52
00:03:13,530 --> 00:03:17,310
Donc, ce que nous utilisons dans
 la régression logistique est en fait

53
00:03:17,310 --> 00:03:21,795
la fonction de perte suivante
 que je vais écrire ici,

54
00:03:21,795 --> 00:03:31,740
- ( y log(ŷ) + (1-y) log

55
00:03:31,740 --> 00:03:34,600
(1 - ŷ))

56
00:03:34,600 --> 00:03:38,785
Voici une explication intuitive de 
pourquoi cette fonction de perte est logique.

57
00:03:38,785 --> 00:03:41,285
Gardez à l’esprit que si nous utilisons

58
00:03:41,285 --> 00:03:45,820
l'erreur quadratique alors vous voulez
 que l’erreur quadratique soit 
aussi petite que possible.

59
00:03:45,820 --> 00:03:48,680
Et avec cette fonction de perte 
de régression logistique,

60
00:03:48,680 --> 00:03:51,495
nous voulons également qu'elle soit
 la plus petite possible.

61
00:03:51,495 --> 00:03:53,508
Pour comprendre pourquoi c'est logique,

62
00:03:53,508 --> 00:03:55,260
nous allons regarder les deux cas.

63
00:03:55,260 --> 00:03:56,570
Dans le premier cas,

64
00:03:56,570 --> 00:03:59,430
disons que y est égal à 1, 
alors la fonction de perte

65
00:03:59,430 --> 00:04:05,415
L(ŷ, y) vaut juste ce terme, avec le signe moins.

66
00:04:05,415 --> 00:04:08,735
- log (ŷ)

67
00:04:08,735 --> 00:04:10,770
si y vaut 1. Parce que si y vaut 1,

68
00:04:10,770 --> 00:04:14,070
alors le second terme 1 - y est égal à zéro.

69
00:04:14,070 --> 00:04:19,880
Donc, si y vaut 1, nous voulons que 
-log(ŷ) soit le plus grand possible.

70
00:04:19,880 --> 00:04:26,040
Ce qui signifie que vous voulez 
que log( ŷ) soit grand,

71
00:04:26,040 --> 00:04:32,935
aussi grand que possible et cela signifie
 que ŷ doit être grand.

72
00:04:32,935 --> 00:04:35,170
Mais puisque ŷ est égal à, vous savez,

73
00:04:35,170 --> 00:04:38,440
cette fonction sigmoïde, il ne peut
 jamais être plus grand que 1.

74
00:04:38,440 --> 00:04:41,850
Donc c’est dire que si y = 1,

75
00:04:41,850 --> 00:04:44,050
vous voulez que ŷ soit le plus grand possible

76
00:04:44,050 --> 00:04:48,220
Mais il ne peut jamais être plus grand que 1,
 donc vous voulez que ŷ soit proche
 de 1 également.

77
00:04:48,220 --> 00:04:50,740
L’autre cas est si y est égal à zéro.

78
00:04:50,740 --> 00:04:55,375
Si y est égal à zéro, alors, ce premier terme 
dans la fonction de perte est égal à zéro car

79
00:04:55,375 --> 00:05:01,290
y vaut zéro et donc le deuxième terme
 définit la fonction de perte.

80
00:05:01,290 --> 00:05:07,210
Donc la perte devient - log( 1 - ŷ)

81
00:05:07,210 --> 00:05:11,480
Et donc, si dans votre processus 
d’apprentissage, vous essayez de 
minimiser la fonction de perte,

82
00:05:11,480 --> 00:05:19,450
cela signifie que vous voulez que
 1 - ŷ soit grand,

83
00:05:19,450 --> 00:05:22,050
parce qu'il y a un moins ici.

84
00:05:22,050 --> 00:05:24,660
Et avec un raisonnement similaire,
 vous pouvez conclure

85
00:05:24,660 --> 00:05:30,870
que cette fonction de perte essaie de rendre 
ŷ aussi petit que possible.

86
00:05:30,870 --> 00:05:34,320
Et encore une fois, puisque ŷ
 doit être entre zéro et un,

87
00:05:34,320 --> 00:05:38,155
ça signifie que si y est égal à zéro, alors

88
00:05:38,155 --> 00:05:43,790
votre fonction de perte va pousser
 les paramètres pour rendre ŷ 
aussi proche de zéro que possible.

89
00:05:43,790 --> 00:05:48,305
Il y a beaucoup de fonctions 
avec ce genre d'effet, qui poussent

90
00:05:48,305 --> 00:05:52,950
ŷ à être grand si y =1
 et petit si y = 0.

91
00:05:52,950 --> 00:05:55,150
Nous avons juste donné ici en vert

92
00:05:55,150 --> 00:05:59,920
une justification un peu informelle
 pour cette fonction de perte.

93
00:05:59,920 --> 00:06:03,970
Dans une vidéo en option plus tard nous 
donnerons une justification plus formelle de

94
00:06:03,970 --> 00:06:08,500
pourquoi, en régression logistique, 
nous aimons utiliser une fonction de perte 
avec cette forme particulière.

95
00:06:08,500 --> 00:06:13,630
Enfin, la fonction de perte a été définie
 pour un seul exemple d'apprentissage.

96
00:06:13,630 --> 00:06:16,760
Il mesure la performance 
sur un seul exemple d'apprentissage.

97
00:06:16,760 --> 00:06:21,148
Je vais maintenant définir 
ce qu’on appelle la fonction de coût,

98
00:06:21,148 --> 00:06:24,690
qui mesure la performance sur 
le set d'apprentissage en entier.

99
00:06:24,690 --> 00:06:28,660
Donc la fonction de coût J s'applique

100
00:06:28,660 --> 00:06:33,130
à vos paramètres W et b 
va être la moyenne

101
00:06:33,130 --> 00:06:43,269
1/m fois la somme de la fonction de perte 
appliquée à chacun des exemples
 d'apprentissage

102
00:06:43,269 --> 00:06:45,435
où ici ŷ est bien sûr

103
00:06:45,435 --> 00:06:49,570
la prédiction en sortie de votre algorithme 
de régression logistique utilisant

104
00:06:49,570 --> 00:06:52,430
un ensemble de paramètres W et b.

105
00:06:52,430 --> 00:06:54,480
Et pour étendre ça,

106
00:06:54,480 --> 00:06:58,010
ça vaut

107
00:06:58,010 --> 00:07:03,550
- 1/m fois la somme de 1 à m 
de la fonction de perte,

108
00:07:03,550 --> 00:07:07,530
c'est à dire y(i) log(ŷ(i)) +

109
00:07:07,530 --> 00:07:14,530
(1 - y(i)) log(1 - ŷ(i))

110
00:07:14,530 --> 00:07:17,880
Je suppose que je pourrais
 mettre entre crochets ici.

111
00:07:17,880 --> 00:07:20,945
Le signe moins est donc devant tout le reste.

112
00:07:20,945 --> 00:07:23,665
La terminologie que je vais utiliser est que

113
00:07:23,665 --> 00:07:29,120
la fonction de perte est appliquée à 
un seul exemple d'apprentissage comme ici.

114
00:07:29,120 --> 00:07:33,010
Et la fonction de coût représente
 le coût de vos paramètres.

115
00:07:33,010 --> 00:07:36,115
Ainsi, lors de l'entraînement de 
votre modèle de régression logistique,

116
00:07:36,115 --> 00:07:38,980
nous allons essayer de trouver 
des paramètres W et b qui

117
00:07:38,980 --> 00:07:43,475
minimisent la fonction de coût globale J, 
écrite en bas.

118
00:07:43,475 --> 00:07:48,040
Donc, vous avez vu la mise en place de
 l’algorithme de régression logistique,

119
00:07:48,040 --> 00:07:50,770
la fonction de perte pour
 un exemple d'apprentissage et

120
00:07:50,770 --> 00:07:54,190
la fonction de coût globale 
pour les paramètres de votre algorithme.

121
00:07:54,190 --> 00:07:59,485
Il s’avère que la régression logistique 
peut être considérée comme 
un tout petit réseau de neurones.

122
00:07:59,485 --> 00:08:01,905
Dans la vidéo suivante, nous verrons cela 
pour que vous puissiez commencer

123
00:08:01,905 --> 00:08:04,965
à avoir une intuition sur ce que
 les réseaux de neurones font.

124
00:08:04,965 --> 00:08:08,230
Alors rendez vous dans
 la prochaine vidéo sur

125
00:08:08,230 --> 00:08:11,000
la régression logistique vue comme
 un tout petit réseau de neurones.