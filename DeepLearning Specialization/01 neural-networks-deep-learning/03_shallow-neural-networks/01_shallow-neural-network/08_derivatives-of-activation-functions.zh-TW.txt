當您在您的神經網路建置反向傳播時, 您需要能夠對於這些啟動函數
計算斜率或者說導數 所以,讓我們來看看我們選擇的 啟動函數,和您如何可以計算
這些函數的斜率 這是您熟悉的S型函數 Sigmoid
啟動函數 因此,對於任何給定的 z 值, 也許這個 z 值。 此函數在這將會有對應的一些斜率, 或者導數, 如果你在那裡畫一條小線 這個高除以寬的這個小三角形 所以,如果 g(z) 是sigmoid函數, 函數的斜率為 , d(g(z)) / dz 從微積分我們知道
這是 g(z) 在 z 的斜率 如果您熟悉微積分
知道如何求導數 如果您求S狀函數的導數 這可以證明
是這個公式 再次說明
我不做這些微積分的步驟 但如果你熟悉微積分, 歡迎隨時暫停影片
試著自己證明 所以這也是等於 g(z) 乘 (1 - g(z)) 讓我們檢查
這個公式是合理的 首先,如果 z 非常大, 假設 z 等於10, g(z) 將接近 1, 這個公式告訴我們
d/dz g(z) 趨近於 g(z) (1 - g(z)) 也就是等於 1 乘 (1 - 1) 也就是趨近於 0 這是正確的, 因為當 z 很大時, 斜率會趨近於 0. 相反的, ,如果 z 等於 -10, 所以它在那裡, 然後 g(z) 接近 0。 這個公式告訴我們
d/dz g(z) 趨近於 g(z) (1 - g(z)) 這是 0 乘以 1 減去 0。 也是趨近於 0
這個也是正確的 最後,如果 z 等於 0, 然後 g(z) 等於 1/2, 這就是sigmoid函數在這兒 所以導數
等於 1/2 乘 (1 - 1/2) 等於 1/4, 而這個實際上是正確的 導數值或者說這個函數的斜率,當 z = 0 最後, 再介紹一個符號 有時候, 與其寫這個東西, 導數的簡寫
是 g 一撇 of z 所以,在微積分中z的g prime of z , g'(z) 上面的小破折號叫做 prime, g'(z) 一個微積分的簡寫, 是 g 函數的導數
相對於輸入變數 z。 在神經網路中, 我們有 a = g(z), 等於這個,那麼這個公式
也簡化為 a(1-a)。 有時候在建置時, 您或許會看到
g'(z) 等於 a(1 - a) 而指的是
這 g'(z), 它的導數, 等於這一個項目. 這個公式的好處是，如果你已經計算了 a 值, 然後使用此運算式, 您可以非常快速地計算
斜率值, g'(z)。 好的,這是有關於 S型啟動函數 Sigmoid. 讓我們看 tanh 啟動函數. 類似於我們前面做的, d(g(z))/dz 的定義是 g(z) 的斜率在一個特定點 z, 如果您看這個 tanh,
雙曲正切函數公式, 如果你知道微積分, 你可以取導數和
這簡化成為 這個公式,和使用 我們之前的簡寫
我們再次用 g'(z) 。 如果您要的話, 您可以檢查
這個公式是不是合理的. 例如,如果 z 等於 10, Tanh(z) 將非常接近 1。 這個從+1 到-1, 然後 g'(z), 根據這個公式, 大約是 1 減 1平方, 所以非常接近 0。 所以,這是 z 是非常大時, 斜率接近 0。 相反的, 如果 z 很小 假設 z 等於 -10, 然後 Tanh(z) 將接近 -1, 所以 g'(z)將是
接近 1 減 -1 平方。 所以,它接近 1 減 1, 也接近 0。 最後,如果 z 等於 0, 然後 Tanh(z) 等於 0, 然後斜率是實際上等於 1, 也正是
當 z 等於 0 時的斜率 總結一下, 如果 a 等於 g(z), 所以,如果 a 等於這個 Tanh(z),
然後導數是, g'(z),等於 1 減去 a平方。 再一次
如果您已經計算 a 的值 您可以用這個公式很
快的計算導數 最後,下面是你如何
計算導數, 應用 ReLU 或 Leaky ReLU 啟動函數 對於 ReLU, g(z) = max(0,z) 因此,導數等於, 原來是0, 如果 z 小於 0 和; 
是1 如果 z 大於 0。 實際上 g'(z) 是未定義
如果 z 剛好為 0 但如果您在軟體中建置 也許不是百分之百正確的數學, 但還是可以運作,
如果 z 真的是 0 - 如果您設置導數等於 1。 或您設置導數等於 0,
都沒關係。 如果您是優化專家,技術上, g'(z),成為所謂的
g(z)啟動函數的子梯度, 這就是為什麼梯度下降仍然有效。 但是你也可以這樣想, z 正好是 0.0000.....00, 它太小了,幾乎沒關係,你在哪裡 將導數設置為等於,當 z 等於 0 時。 在實踐上, 這是人們一般用來建置 g(z) 的導數. 最後,如果您在訓練神經網路
 利用 Leaky ReLU 啟動函數, g(z) 會是 max(0.01z, z) g'(z) 等於 0.01, 如果 z 小於 0
等於 1, 如果 z 大於 0. 再次,技術上,梯度是未定義,
當 z 完全等於 0 , 但如果您建置一些程式, 設這個 導數或設 g'(z) 為 0.01 或 1, 無論哪種方式,這並不重要。 當 z 正好為 0 時,
您的程式將正常工作。 所以,根據這些公式, 您需要能夠對於這些啟動函數
計算斜率或者說導數. 現在您有了這些建構基石, 你已經準備好如何實現
神經網路的梯度下降。 讓我們繼續看下一段影片