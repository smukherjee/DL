1
00:00:00,028 --> 00:00:04,605
При реалізації глибинних нейронних мереж (НМ)
я частенько беру в руки інструмент

2
00:00:04,605 --> 00:00:08,118
для перевірки правильності свого коду - аркуш паперу - і

3
00:00:08,118 --> 00:00:11,727
записую розміри тих матриць, з якими працюю.

4
00:00:11,727 --> 00:00:15,895
Давай покажу, як я це роблю, бо сподіваюсь полегшити

5
00:00:15,895 --> 00:00:18,275
реалізацію і твоєї глибокої НМ.

6
00:00:18,275 --> 00:00:23,174
Тож L=5. Правильно? 
Це легко порахувати. Вхідний шар не враховуємо.

7
00:00:23,174 --> 00:00:27,390
Тож ми маємо тут 5 шарів: 4 прихованих і 1 вихідний.

8
00:00:27,390 --> 00:00:34,878
Отже, якщо ми реалізуємо пряме поширення,

9
00:00:34,878 --> 00:00:41,408
то першим кроком буде z[1]=w[1]x+b[1].

10
00:00:41,408 --> 00:00:48,144
Давай поки проігноруємо параметр зсуву 
і сфокусуємось на параметрі w.

11
00:00:48,144 --> 00:00:54,501
Тож, перший прихований шар має три приховані вузли. 
Рахуємо спочатку - це нульовий шар,

12
00:00:54,501 --> 00:00:59,517
це перший, другий, третій, четвертий і п'ятий шари.

13
00:00:59,517 --> 00:01:05,741
Використовуючи позначення з попереднього відео, 
матимемо, що n[1], що є кількістю прихованих

14
00:01:05,741 --> 00:01:11,265
вузлів в 1-ому шарі, =3. Дня наступного ми матимемо

15
00:01:11,265 --> 00:01:16,202
n[2]=5, n[3]=4,

16
00:01:16,202 --> 00:01:23,018
n[4]=2 і, нарешті, n[5]=1.

17
00:01:23,018 --> 00:01:27,715
Досі ми бачили НМ лише з одним вихідним вузлом, але пізніше,

18
00:01:27,715 --> 00:01:32,497
в наступних лекціях, ми говоритимемо про НМ 
з багатьма вихідними вузлами.

19
00:01:32,497 --> 00:01:36,989
Нарешті, для вхідного шару

20
00:01:36,989 --> 00:01:40,443
матимемо n[0]=n[x]=2.

21
00:01:40,443 --> 00:01:45,860
Тепер давай подумаємо про розміри z, w та x.

22
00:01:45,860 --> 00:01:49,120
z - це вектор активаторів для

23
00:01:49,120 --> 00:01:54,244
1-ого прихованого шару, тож матиме розмір (3, 1).

24
00:01:54,244 --> 00:01:58,675
Буде 3-елементним вектором.

25
00:01:58,675 --> 00:02:03,093
Я запишу це як вектор розміру (n[1], 1),

26
00:02:03,093 --> 00:02:08,546
як матриця розміру (n[1], 1). В цьому випадку - (3, 1).

27
00:02:08,546 --> 00:02:12,319
А як щодо вхідних ознак x? Ми маємо 2 вхідні ознаки.

28
00:02:12,319 --> 00:02:18,622
Тож x в цьому випадку - (2, 1), а в загальному - (n[0], 1).

29
00:02:18,622 --> 00:02:24,082
Тож нам необхідно, щоб матриця w[1] була такою, щоб при

30
00:02:24,082 --> 00:02:30,181
множенні на вектор (n[0], 1), ми отримали вектор (n[1], 1). 
Правильно?

31
00:02:30,181 --> 00:02:34,747
Тож ми маємо щось на зразок 3-елементного вектору

32
00:02:34,747 --> 00:02:38,600
помноженого на 2-елементний вектор.

33
00:02:38,600 --> 00:02:42,993
І, згідно правил множення матриць, в резултаті

34
00:02:42,993 --> 00:02:46,041
повинна бути матриця (3, 2).

35
00:02:46,041 --> 00:02:51,138
Правильно? Бо матриця (3, 2) помножена на матрицю (2, 1)

36
00:02:51,138 --> 00:02:56,249
(або на вектор (2, 1)), дає вектор (3, 1).

37
00:02:56,249 --> 00:03:02,771
В загальному випадку це буде матриця розмірності (n[1], n[0]).

38
00:03:02,771 --> 00:03:07,167
Тож ми вияснили, що

39
00:03:07,167 --> 00:03:12,665
розміри w[1] мають бути (n[1], n[0]).

40
00:03:12,665 --> 00:03:20,191
В більш загальному випадку розміри w[l] мають бути (n[l], n[l-1]).

41
00:03:20,191 --> 00:03:26,021
Тож, наприклад, розміри w[2] повинні бути

42
00:03:26,021 --> 00:03:31,508
(5, 3). Або ж це буде

43
00:03:31,508 --> 00:03:35,119
(n[2], n[1]).

44
00:03:35,119 --> 00:03:40,036
Тепер обчислимо

45
00:03:40,036 --> 00:03:45,132
z[2], що дорівнює w[2]a[1]

46
00:03:45,132 --> 00:03:50,059
І, знову ж, давай поки проігноруємо зсув.

47
00:03:50,059 --> 00:03:54,584
Тож це буде (3, 1).

48
00:03:54,584 --> 00:03:59,432
А оце потрібно щоб було (5, 1).

49
00:03:59,432 --> 00:04:03,169
Тож оце буде (5, 3).

50
00:04:03,169 --> 00:04:10,273
І, аналогічно, w[3] буде (розмір наступного шару,

51
00:04:10,273 --> 00:04:15,501
розмір попереднього шару),

52
00:04:15,501 --> 00:04:19,266
тобто буде (4, 5). w[4]

53
00:04:22,055 --> 00:04:27,489
буде (2, 4), а

54
00:04:27,489 --> 00:04:34,405
w[5] буде (1, 2). Добре?

55
00:04:34,405 --> 00:04:38,730
Тож загальна формула для перевірки

56
00:04:38,730 --> 00:04:43,416
розмірів матриці l-ого шару:

57
00:04:43,416 --> 00:04:48,475
розмір матриці має бути (n[l], n[l-1]).

58
00:04:48,475 --> 00:04:55,362
Тепер давай подумаємо про розмір вектора b.

59
00:04:55,362 --> 00:05:01,017
Оце буде розміру (3, 1). Тож ми маємо додати вектор

60
00:05:01,017 --> 00:05:06,008
такого ж розміру - (3, 1), щоб і на виході отримати вектор (3, 1).

61
00:05:06,008 --> 00:05:11,287
А в цьому випадку, нам треба додавати до оцього. 
Значить це буде (5, 1).

62
00:05:11,287 --> 00:05:14,823
Тож це має бути ще один вектор (5, 1),

63
00:05:14,823 --> 00:05:19,122
щоб після додавання цих обведених доданків

64
00:05:19,122 --> 00:05:22,767
ми отримали оцей вектор (5, 1).

65
00:05:22,767 --> 00:05:30,090
Тож загальне правило (на прикладі зліва): b[1] матиме розмір

66
00:05:30,090 --> 00:05:35,470
(n[1], 1). В другому випадку

67
00:05:35,470 --> 00:05:41,156
це буде (n[2], 1).

68
00:05:41,156 --> 00:05:45,891
І, отже, загальне правило: b[l] має мати

69
00:05:45,891 --> 00:05:50,637
розмір (n[l], 1).

70
00:05:50,637 --> 00:05:56,402
Я сповнений надії, що ці 2 рівняння допоможуть впевнитись, 
що розміри твоїх матриць w

71
00:05:56,402 --> 00:06:02,091
і векторів b мають правильні розміри.

72
00:06:02,091 --> 00:06:06,206
І, звичайно, при реалізації зворотного поширення, 
розмір

73
00:06:06,206 --> 00:06:10,657
dw[l] повинно мати розмір w[l].

74
00:06:10,657 --> 00:06:16,373
Повторю, dw[l] має мати такий же розмір як w[l],

75
00:06:16,373 --> 00:06:22,276
а db[l] має мати розмір такий же як b[l].

76
00:06:22,276 --> 00:06:28,399
Тепер. Наступний набір величин буде для перевірки розмірів z,

77
00:06:28,399 --> 00:06:33,658
x і a[l], про яке ми мало сьогодні говорили.

78
00:06:33,658 --> 00:06:39,856
Але, через те, що z[l]=g[l](a[l])

79
00:06:39,856 --> 00:06:46,914
застосовується поелементно, то z і a повинні мати 
однакові розміри в таких типах НМ.

80
00:06:46,914 --> 00:06:51,582
Тепер давай подивимось що буде 
при векторизованій реалізації (для

81
00:06:51,582 --> 00:06:53,258
багатьох зразків одночасно).

82
00:06:53,258 --> 00:06:56,092
Навіть для векторизованої реалізації, звичайно,

83
00:06:56,092 --> 00:07:00,687
розміри w, b, dw і db залишаються незмінними.

84
00:07:00,687 --> 00:07:04,929
Але розміри z, a і x

85
00:07:04,929 --> 00:07:09,771
дещо зміняться при векторизованій реалізації.

86
00:07:09,771 --> 00:07:13,420
Тож на попередньому слайді ми мали

87
00:07:13,420 --> 00:07:18,372
z[1]=w[1]x+b[1],

88
00:07:18,372 --> 00:07:23,845
де оце було розміру (n[1], 1),

89
00:07:23,845 --> 00:07:28,276
це було (n[1], n[0]),

90
00:07:28,276 --> 00:07:35,846
x було (n[0], 1),

91
00:07:35,846 --> 00:07:40,979
а b було (n[1], 1).

92
00:07:40,979 --> 00:07:46,398
Тепер у векторизованій реалізації матимемо

93
00:07:46,398 --> 00:07:53,536
Z[1]=W[1]X+b[1],

94
00:07:53,536 --> 00:07:58,023
де тепер Z[1] утворюється із z[1] для

95
00:07:58,023 --> 00:08:03,575
окремих зразків - z[1]⁽¹⁾, z[1]⁽²⁾ і до

96
00:08:03,575 --> 00:08:10,207
z[1]⁽ᵐ⁾ складених ось так. І це дає нам Z[1].

97
00:08:10,207 --> 00:08:15,042
Тож розмір Z[1] замість (n[1], 1)

98
00:08:15,042 --> 00:08:20,285
стає (n[1], m), де m - розмір тренувального набору.

99
00:08:20,285 --> 00:08:26,140
Розмір W[1] залишається тим же - (n[1], n[0]).

100
00:08:26,140 --> 00:08:29,201
А X замість (n[0], 1)

101
00:08:29,201 --> 00:08:33,431
тепер міститиме всі тренувальні зразки складені по горизонталі,

102
00:08:33,431 --> 00:08:38,565
тож буде (n[0], m). Тож зверни увагу, коли ми беремо

103
00:08:38,565 --> 00:08:43,833
матрицю (n[1], n[0]) і множимо на матрицю (n[0], m),

104
00:08:43,833 --> 00:08:50,160
то отримаємо матрицю (n[1], m), як і очікується.

105
00:08:50,160 --> 00:08:55,030
І остання ремарка. b[1] все ще (n[1], 1).

106
00:08:55,030 --> 00:09:01,147
Але коли ми візьмемо оце і додамо b, з допомогою посіву Python,

107
00:09:01,147 --> 00:09:08,218
це посіється до матриці (n[1], m) і поелементно додасться.

108
00:09:08,218 --> 00:09:14,977
Тож на попередньому слайді ми говорили про розмірність w, b, dw і db.

109
00:09:14,977 --> 00:09:21,143
Тепер можемо бачити, що якщо z[l] і a[l]

110
00:09:21,143 --> 00:09:26,922
мають розмір (n[l], 1),

111
00:09:26,922 --> 00:09:34,650
то зараз ми маємо, що Z[l] і A[l] будуть

112
00:09:34,650 --> 00:09:40,410
(n[l], m). Окремий випадок - коли L=0.

113
00:09:40,410 --> 00:09:45,188
В цьому випадку A[0]

114
00:09:45,188 --> 00:09:49,543
(наш тренувальний набір, вхідні ознаки X)

115
00:09:49,543 --> 00:09:54,616
буде (n[0], m), як і очікується.

116
00:09:54,616 --> 00:10:01,259
І, звичайно, коли ми це реалізуємо в

117
00:10:01,259 --> 00:10:06,749
зворотному поширенні і отримаємо dZ і dA, то побачимо,

118
00:10:06,749 --> 00:10:11,327
що вони мають ті ж

119
00:10:11,327 --> 00:10:15,736
розміри, що й Z і A.

120
00:10:15,736 --> 00:10:19,467
Отже, надіюсь, що ця маленька вправа допомогла зрозуміти де брати розміри

121
00:10:19,467 --> 00:10:21,685
тих багатьох матриць, з якими ти працюватимеш.

122
00:10:21,685 --> 00:10:25,947
Коли ти реалізуєш зворотне поширення для глибокої НМ,

123
00:10:25,947 --> 00:10:30,350
перевіряй код і переконуйся, 
що матриці мають відповідні розміри.

124
00:10:30,350 --> 00:10:31,825
Це, зазвичай, допомагає

125
00:10:31,825 --> 00:10:35,908
запобігати появі певних можливих помилок.

126
00:10:35,908 --> 00:10:40,325
Я радий, якщо вправа з визначення розмірів цих різноманітних матриць

127
00:10:40,325 --> 00:10:41,979
була корисною.

128
00:10:41,979 --> 00:10:44,788
Якщо ти реалізуватимеш глибоку НМ і чітко дотримуватимешся

129
00:10:44,788 --> 00:10:48,241
розмірів матриць і векторів, з якими працюватимеш,

130
00:10:48,241 --> 00:10:52,162
то, надіюсь, це допоможе уникнути певних можливих помилок.

131
00:10:52,162 --> 00:10:54,467
Безумовно, це допомагає і мені писати коректний код.

132
00:10:54,467 --> 00:10:58,882
Ти вже знайомий/а з деякими механізмами

133
00:10:58,882 --> 00:11:01,227
прямого поширення НМ.

134
00:11:01,227 --> 00:11:04,163
Але чому ж глибокі НМ такі ефективні?

135
00:11:04,163 --> 00:11:07,243
Чому вони працюють краще ніж "мілкі"?

136
00:11:07,243 --> 00:11:09,939
Давай витратимо кілька хвилин і 
в наступному відео про це поговоримо.