Bonjour, et bon retour parmi nous. Cette semaine, nous passerons en revue
 les bases de la programmation 
d'un réseau de neurones. Il s’avère que lorsque vous implémentez
 un réseau de neurones il y a des techniques qui vont être
 vraiment importantes. Par exemple, si vous avez un ensemble
 d’apprentissage de m exemples, vous pouvez avoir l'habitude de traiter votre
 set d'apprentissage avec une boucle for qui parcourt vos m exemples d'apprentissage. Mais il s’avère que lorsque vous 
implémentez un réseau de neurones, habituellement, vous voulez traiter
 l’ensemble du set d'apprentissage sans utiliser de boucle for explicite 
pour parcourir le set d'apprentissage. Ainsi, vous verrez comment faire 
dans le contenu de cette semaine. Une autre idée, lorsque vous organisez
 le calcul dans votre réseau, habituellement, vous avez
 ce qu’on appelle un passage direct ou
 étape de propagation avant, suivi d’un passage en sens inverse,
 ce qu’on appelle une étape de 
propagation inverse (ou rétro-propagation). Et donc dans le contenu de cette semaine, vous
 aurez également une introduction au pourquoi les calculs, dans l'apprentissage d'un réseau de
 neurones, peuvent être organisés selon ces modes de propagations directe
 et inverse séparées. Pour les matériaux de cette semaine,
 je veux faire passer ces idées à l’aide de la régression logistique afin de rendre
 les idées plus facile à comprendre. Mais même si vous avez vu la régression
 logistique avant, je pense qu’il va y avoir des idées nouvelles et intéressantes 
pour vous dans le contenu de cette semaine. Alors, allons-y. La régression logistique est un 
algorithme de classification binaire. Commençons donc par la
 mise en place du problème. Voici un exemple d’un problème
 de classification binaire. Vous pouvez avoir en entrée 
une image, comme ça, et vouloir en sortie une étiquette pour 
reconnaître que cette image est soit un chat, dans ce cas vous avez 1 en sortie, ou est
 un non chat auquel cas vous avez 0. Nous utiliserons y pour désigner
 l’étiquette de sortie. Regardons comment une image est
 représentée dans un ordinateur. Pour stocker une image, votre ordinateur
 stocke trois matrices distinctes correspondant aux canaux de couleur
 rouge, vert et bleu de cette image. Donc, si votre image d’entrée est 
de 64 pixels par 64 pixels, alors vous aurez 3 matrices 64 x 64 correspondant aux valeurs d’intensité des
 pixels rouges, verts et bleus pour vos images. Pour cette diapositive j’ai dessiné ces
 matrices beaucoup plus petites, donc ce sont en fait des matrices 5 par 4 
plutôt que 64 par 64. Pour transformer ces valeurs d’intensité de
 pixel en un vecteur de caractéristiques, nous allons dérouler toutes ces valeurs de pixels 
dans un vecteur de caractéristiques d’entrée x. Pour dérouler toutes ces valeurs d’intensité
 de pixel en un vecteur de caractéristiques nous allons définir un vecteur de
 caractéristiques x correspondant
 à cette image comme suit. Nous allons juste prendre toutes les
 valeurs de pixels, 255, 231 et ainsi de suite. 255, 231 et ainsi de suite jusqu'à ce que 
nous ayons listé tous les pixels rouges. Et puis ensuite 255, 134, 255, 134
 et ainsi de suite jusqu'à ce que nous obtenions un long vecteur 
de caractéristiques contenant toutes
 les valeurs d'intensité de rouge, de vert et de bleu 
de tous les pixels de cette image. Si cette image est une image de 64 par 64,
 la dimension totale de ce vecteur x sera 64 par 64 par 3 car c’est le nombre total de valeurs que nous avons
 dans l’ensemble de ces matrices. Donc dans ce cas 12'288, C’est ce que vous obtenez si 
vous multipliez tous ces nombres. Et donc nous allons utiliser nx = 12'288 pour représenter la dimension 
des caractéristiques d'entrée x. Et parfois par souci de concision,
 j’utiliserai juste n minuscule pour représenter la dimension de ce 
vecteur de caractéristiques d’entrée. Dans la classification binaire, notre but est donc
 d’apprendre à un classifieur qui peut prendre en entrée une image représentée 
par ce vecteur de caractéristiques x à prédire si l'étiquette y 
correspondante est 1 ou 0, autrement dit, s’il s’agit d’une image 
de chat ou une image de non chat. Nous allons maintenant établir une partie 
de la notation que nous allons utiliser tout au long du reste de ce cours. Un exemple d'apprentissage unique 
est représenté par un couple, (x, y) où x est un vecteur de 
caractéristiques de taille nx et y, l’étiquette, est égale à 0 ou 1. Vos sets d'apprentissage 
comprendront m exemples. Et vos sets d'apprentissage seront écrit
 (x1, y1) qui correspond à l'entrée et la sortie pour votre premier exemple
 d'apprentissage, (x2, y2) pour le deuxième exemple d'apprentissage jusqu'à
 (xm, ym) qui est votre dernier
 exemple d'apprentissage. Et tout ça ensemble forme votre
 ensemble d'apprentissage entier. Donc je vais utiliser m minuscule pour désigner
 le nombre d’échantillons d'apprentissage. Et parfois pour souligner que c’est 
le nombre d’exemples d'apprentissage, Je pourrai écrire m = m indice train. Et lorsque nous parlons du set de test, Nous pouvons parfois utiliser m indice test 
pour désigner le nombre d’exemples de test. Donc ceci est le nombre d’exemples de test. Enfin, pour avoir tous les exemples d'ap-
prentissage dans une notation plus compacte, Nous allons définir une matrice, grand X. On la définit en prenant les exemples
 du set d'apprentissage, x1, x2 et ainsi de suite et
 en les empilant en colonnes. Donc nous prenons x1 et en faisons
 la première colonne de cette matrice, x2, qui va être une deuxième colonne
 et ainsi de suite jusqu'à la xm, et c’est la matrice grand X. Ainsi, cette matrice X aura m colonnes, 
où m est le nombre d'exemples d'apprentissage et le nombre de lignes 
c'est-à-dire la hauteur de cette matrice est nx. Notez que dans d'autres cours, 
vous pourriez voir la matrice grand X définie par l'empilement des exemples
 d'apprentissages en ligne comme ceci, x1 transpose jusqu'à xm transpose. Mais il s’avère que lorsque vous implémentez
 des réseaux de neurones avec cette convention que j’ai sur la gauche, 
la mise en œuvre sera beaucoup plus facile. Donc, juste pour rappel, X est 
une matrice de dimensions nx par m et quand vous implémentez ça en Python, vous voyez que X.shape, 
la commande python pour trouver la forme de la matrice,
 vous renvoie (nx, m). Cela signifie simplement que c’est
 une matrice de dimensions nx par m Voilà donc comment vous regroupez les 
exemples d'apprentissage,
 l’entrée x dans une matrice. Qu'en est-il des étiquettes de sortie y ? Il s’avère que pour faciliter l'implémentation 
d’un réseau de neurones, il sera commode d’empiler aussi y en colonnes. Nous allons donc définir grand Y égal à y1, y2, jusqu'à ym comme cela. Ainsi Y ici sera une matrice de
 dimensions 1 par m. Et encore une fois, en utilisant la
 notation Python, la forme de Y sera (1,m) ce qui signifie que c'est une
 matrice de dimensions 1 par m. Et quand vous implémenterez votre réseau
 de neurones plus tard dans le cours,
 vous trouverez utile cette convention de prendre les données
 associées aux différents exemples
 d’apprentissage, et par les données, je veux dire soit x ou y ou
 d'autres quantités que vous verrez plus tard. Mais de prendre les choses ou les données associées aux différents
 exemples d'apprentissage et de les empiler en différentes colonnes,
 comme nous l’avons fait ici pour x et y. Donc, c’est la notation nous utiliserons
 pour la régression logistique et pour les réseaux de réseaux de neurones
 plus tard dans ce cours. Si vous oubliez ce que signifie 
une des notations, par exemple qu'est ce que m ou 
qu'est ce que n ou autre chose, nous avons également posté sur
 le site Web du cours un guide des notations que vous pouvez utiliser pour chercher
 rapidement ce que signifie
 n’importe quelle notation. Ceci dit, allons à la prochaine video
 où nous allons aborder la régression logistique en utilisant cette notation.