신경망의 계산법이 forward pass 또는 전 방향전파 step 방식으로 이루어진다고 제가 말한 적이 있는데요, 이 경우, 신경망의 결과값을 계산하고, backward pass 또는 후 방향전파 step를 통해 기울기나 derivative를 계산하는데요, 왜 이런 구조를 갖는지 계산 그래프를 통해 알아보겠습니다. 이번 비디오에서는 사례를 공부해볼텐데요, 계산 그래프를 그려보기 위해서, 로지스틱 회귀분석법 또는 full blown 신경망보다 조금 더 간단한 사례를 보겠습니다. 만약 우리가 J함수를 계산하려고 하면, a, b, c를 변수로 갖는 J함수 인데요, 이 함수가 3(a+bc)라고 해봅시다. 이 함수를 계산하는 방법은 3가지의 절차가 있습니다. 첫번째로, bc가 어떤값을 갖는지 계산해야하고, u라고하는 변수에 저장한다고 하죠. 그러면 u=bc이고, V=a*u를 계산하면 되겠죠. 그러면 이것이 V라고 해봅시다. 마지막으로, J 결과값은 3V입니다. 그러면 계산하려고하는 최종적인 J함수가 이것입니다. 이러한 3가지의 절차를 통해 다음과 같이 계산그래프로 그릴 수 있습니다. 여기 a, b, c 변수를 그린다고 해보죠. 처음으로 한 것은, u=bc를 계산한 것입니다. 이곳에 직사각형의 박스를 두르도록 하겠습니다. 그러면 이것의 잆력값이 b와 c가 될 것입니다. 그리고, V=a+u 가 있겠죠. 이것의 입력값은 V입니다. 이것의 입력값은 u이죠, a와 함께 계산했던 것 처럼요. 마지막으로, J=3V가 있습니다. 구체적인 예로, 만약 a=5, b=3 그리고 c=2 이면 u=bc 가 6의 값을 가질 것입니다. a+u는 5+6으로 11이되구요. J는 이 값의 3배이기 때문에 33입 됩니다. 실제로 이렇게해서 이 것은 3 곱하기 5 더하기 3 곱하기 2 라는 것을 입증하실 수 있을 것입니다. 그리고 이것을 확장하면 J의 값이 33을 갖게 됩니다. 이렇게 각각으로 나뉘어지거나 특정 결과값에 대한 변수가 있는 경우에는 계산그래프로 유용히 쓰일 수 있습니다. 앞서 말한 J 와 같이 최적화시키고 싶은 경우에 말이죠, 로지스틱 회귀분석법 같은 경우에는, J는 당연히 최소화시키고 싶은 비용함수가 되겠죠. 간단한 예제를 통해서 저희가 알 수 있는 것은, 왼쪽에서 오른쪽으로 통과하는 식으로, J의 값을 계산할 수 있다는 것입니다. 다음 몇개의 슬라이드에서 볼 것은, derivative를 계산하기 위해서 오른쪽에서 왼쪽으로 통과하는 식이 마련될 텐데요 파란색 화살표와 반대로 가는 방식이죠. 이것이 derivative를 계산하는 가장 자연스러운 방법일 것입니다. 복습하자면, 계산 그래프는 이 파란색 화살표, 왼쪽에서 오른쪽으로 넘어가는 식을 통해 계산을 진행합니다. 다름 비디오 강의는 반대로 빨간색 화살표로 오른쪽에서 왼쪽으로 derivative를 계산하는
방법에 대해 배우겠습니다. 다음 비디오로 넘어가겠습니다.