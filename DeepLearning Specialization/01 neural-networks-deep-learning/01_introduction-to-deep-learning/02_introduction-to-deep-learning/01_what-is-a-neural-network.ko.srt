1
00:00:01,050 --> 00:00:03,840
딥러닝 이라는 용어는 신경망의 트레이닝을 일컫는 말인데요,

2
00:00:03,840 --> 00:00:06,050
가끔은 매우 큰 신경망을 의미하기도 합니다.

3
00:00:06,050 --> 00:00:08,400
그럼 신경망이라고 하는 것은 정확히 무엇을 뜻하는 걸까요?

4
00:00:08,400 --> 00:00:11,340
이번 비디오를 통해 몇가지 기본적이면서 직관적인 부분을 설명해드리도록 하겠습니다.

5
00:00:12,850 --> 00:00:16,540
집값을 예측하는 툴을 예시로 살펴보도록 하겠습니다.

6
00:00:16,540 --> 00:00:20,599
6개의 가구로 이루어져있는 데이터 세트가 있다고 해봅시다.

7
00:00:20,599 --> 00:00:24,478
제곱 피트나 제곱티어 단위로 말이죠.
또한, 집값 또한 알고 있고

8
00:00:24,478 --> 00:00:28,501
집 크기의 함수에 대입하여 미래 집값을 예측합니다.

9
00:00:28,501 --> 00:00:33,509
그래서 만약 여러분이 linear regression에 익숙하시면,

10
00:00:33,509 --> 00:00:38,450
여기 데이터에 일직선을 그으면
이런 선이 나올텐데요.

11
00:00:38,450 --> 00:00:41,850
조금 더 멋있게 설명하자면

12
00:00:41,850 --> 00:00:43,770
가격이 마이너스가 될 수는 없기 때문에

13
00:00:43,770 --> 00:00:48,050
일직선이라고 표현하기보다는,

14
00:00:48,050 --> 00:00:49,960
여기에 이렇게 커브로 바꾸어보도록 하겠습니다.

15
00:00:49,960 --> 00:00:51,530
그러면 이 부분은 0이 되겠죠.

16
00:00:51,530 --> 00:00:56,770
그렇게 해서 두꺼운 파란색 선은
미래의 집값을 예측하는,

17
00:00:56,770 --> 00:00:59,760
집 크기를 변수로 하는 함수가 됩니다.

18
00:00:59,760 --> 00:01:03,310
여기는 값이 0인 부분이고
그 다음 우측 부분은 일직선의 일차함수 선이 됩니다.

19
00:01:04,408 --> 00:01:08,735
이렇게해서 방금 맞춰 놓은 집값 함수는

20
00:01:08,735 --> 00:01:11,880
아주 간단한 신경망이란 비슷한 개념으로 생각하시면 됩니다.

21
00:01:11,880 --> 00:01:14,230
가장 간단할 수 있는 신경망이라고 볼 수 있죠.

22
00:01:14,230 --> 00:01:15,000
여기 한번 그려봅시다.

23
00:01:17,220 --> 00:01:22,170
집의 크기를 나타내는 x값을 신경망의 입력값으로 지정하고

24
00:01:22,170 --> 00:01:26,791
이 노드로 들어가는데요,
이렇게 생긴 원형 모양입니다.

25
00:01:26,791 --> 00:01:30,940
이렇게 입력되어 y라는 결과 값이 나옵니다.

26
00:01:30,940 --> 00:01:37,183
이 동그란 원은, 신경망에 있는
1개의 신경세포인데요,

27
00:01:37,183 --> 00:01:41,830
왼쪽에 그린 이 함수를 도입시킵니다.

28
00:01:43,350 --> 00:01:48,940
신경세포가 하는 것은 바로
크기를 입력값으로 갖고, 이 일차함수를 만드는 것이죠.

29
00:01:48,940 --> 00:01:51,960
최대값 0을 갖고, 예상 가격을 결과값으로 추출하는 것입니다.

30
00:01:53,190 --> 00:01:58,230
신경망 분야에서 이 함수를 많이 볼 수 있습니다.

31
00:01:58,230 --> 00:02:00,992
특정 부분까지 0의 값을 갖고,

32
00:02:00,992 --> 00:02:03,550
어느 시점 이후, 일차함수로 값이 증가하는 함수 말이죠.

33
00:02:03,550 --> 00:02:09,108
이 함수는 ReLu(렐류) 함수라고 하는데요,

34
00:02:09,108 --> 00:02:17,620
rectified linear units의 약자입니다.

35
00:02:17,620 --> 00:02:18,252
R-E-L-U 이죠. 그리고,

36
00:02:18,252 --> 00:02:22,520
rectifiy라고 하는 것은 0을 최대값으로 한다는 뜻입니다.
그래서 이런 모양의 함수가 나오게 되는 것이죠.

37
00:02:23,640 --> 00:02:25,550
일단은 ReLU 유닛과 관련해서는 크게

38
00:02:25,550 --> 00:02:30,200
신경쓰실 필요는 없습니다.
나중에 다른 코스에서 다루도록 하겠습니다.

39
00:02:30,200 --> 00:02:33,790
자 그럼, 이게 1개의 신경세포라고하면, 
이렇게 신경망이구요,

40
00:02:33,790 --> 00:02:38,870
아주 작은 신경망이죠.

41
00:02:38,870 --> 00:02:44,520
더 큰 신경망은 신경세포들이 쌓아 뭉쳐져서 만들어집니.

42
00:02:44,520 --> 00:02:50,700
이 신경세포를 하나의 레고블럭이라고 생각하시면

43
00:02:50,700 --> 00:02:55,270
더 큰 신경망은 레고블럭을 같이 쌓으면서
만들어진다고 볼 수 있습니다.

44
00:02:55,270 --> 00:02:56,110
예시를 한번 볼까요?

45
00:02:57,260 --> 00:03:02,220
단순히 집의 크기로 미래의 집값을 예측하기보다는

46
00:03:02,220 --> 00:03:04,330
다른 특성이 있다고 가정해보죠,

47
00:03:04,330 --> 00:03:08,164
호스트에 대해 더 많은 정보를 안다고 해봅시다,
예를 들어, 방의 갯수,

48
00:03:08,164 --> 00:03:13,630
여기에 s를 안 적었군요,
그리고 여러분은 가족의 크기 또한

49
00:03:13,630 --> 00:03:18,820
집값에 영향을 줄 수 있다고 생각할 수 있겠죠?

50
00:03:18,820 --> 00:03:21,882
이 집이 3명으로 구성된 가족에게 적합할지, 4명 가족이 살 수 있을지,

51
00:03:21,882 --> 00:03:22,687
또는 5명 가족 등등 말입니다.

52
00:03:22,687 --> 00:03:26,351
실질적으로 제곱피트 또는 제곱미터의
집 크기와,

53
00:03:26,351 --> 00:03:28,960
방의 개수가 특정 인원의 가족이

54
00:03:28,960 --> 00:03:31,462
살 수 있는지 여부를 결정짓게 됩니다.

55
00:03:31,462 --> 00:03:34,909
추가로, zip code도 알 수 있죠.

56
00:03:34,909 --> 00:03:40,520
다른 나라에서는 zip code를 postal code라고도 합니다.

57
00:03:40,520 --> 00:03:48,820
zip code (우편번호)는 미래에 도보가능 여부를
알려주는 요소일 수 있습니다.

58
00:03:48,820 --> 00:03:51,434
이 지역은 걷기에 알맞은가?

59
00:03:51,434 --> 00:03:53,635
장을 보러 걸어갈 수 있는가?

60
00:03:53,635 --> 00:03:54,194
학교는 걸어갈 수 있는가?

61
00:03:54,194 --> 00:03:55,250
운전을 해야하는가?

62
00:03:55,250 --> 00:03:57,870
어떤 사람들은 걸어서 다닐 수 있는 지역을 선호할 수 있습니다.

63
00:03:57,870 --> 00:04:06,145
그럼 zip code와 재산같은 경우에,

64
00:04:06,145 --> 00:04:09,200
미국에선 확실히 그렇고,
다른 나라도 적용될 수 있지만

65
00:04:09,200 --> 00:04:13,590
학교의 질이 얼마나 좋은지 알 수 있습니다.

66
00:04:13,590 --> 00:04:17,820
제가 그리고 있는 조금한 동그라미가
ReLU가 될 수 있습니다.

67
00:04:17,820 --> 00:04:22,670
rectified linear units 또는 다른 비선형 함수죠.

68
00:04:22,670 --> 00:04:24,936
그렇게 되면 방의 크기와 개수에 따라서,

69
00:04:24,936 --> 00:04:28,420
가족의 인원수와, 도보 가능한 정도를 알려주는
우편번호와,

70
00:04:28,420 --> 00:04:32,050
우편번호와 재산에 따라 학교의 질을 예측할 수 있는
부분이 있습니다.

71
00:04:32,050 --> 00:04:35,660
마지막으로 사람들이 집값에 값어치를

72
00:04:35,660 --> 00:04:38,880
부여하는 경우, 본인이 가장 중시하는
부분이 있을 수 있습니다.

73
00:04:38,880 --> 00:04:43,060
이 사례 같은 경우엔,
가족 구성 인원 수, 도보가능한 정도,
학교의 질,

74
00:04:43,060 --> 00:04:45,210
들 여러가지 집값의 영향을 줄 수 있는 요소들이 있습니다.

75
00:04:46,330 --> 00:04:51,740
이번 사례에선,
모든 4가지 입력값이 모두 x입니다.

76
00:04:53,470 --> 00:04:56,460
그리고 y는 예측하려고 하는 집값입니다.

77
00:04:57,960 --> 00:05:03,350
그러므로, 신경세포 또는 예측해주는 요소들을 쌓으면서,

78
00:05:03,350 --> 00:05:07,360
앞 슬라이드에서도 보았듯이,
조금 더 큰 신경망을 갖추었습니다.

79
00:05:07,360 --> 00:05:10,850
신경망을 어떻게 관리하냐면,
이를 도입하는 경우에,

80
00:05:10,850 --> 00:05:15,860
x의 입력값과,

81
00:05:15,860 --> 00:05:20,740
y라는 결과값을 트레이닝세트에 도입시키면 됩니다.

82
00:05:20,740 --> 00:05:23,580
가운데 부분은 알아서 해결됩니다.

83
00:05:25,435 --> 00:05:29,225
그러므로 실질적으로 도입하는 부분은 이것입니다.

84
00:05:29,225 --> 00:05:32,055
여기서는, 4개의 입력값을 가지고 있는 신경망이 있습니다.

85
00:05:32,055 --> 00:05:35,455
입력값의 특성은 크기, 방 개수,

86
00:05:35,455 --> 00:05:40,365
zip code 또는 우편번호, 이웃집의 재산 등이
될 수 있습니다.

87
00:05:40,365 --> 00:05:44,805
이런 입력 값의 특성을 바탕으로

88
00:05:44,805 --> 00:05:50,200
y의 값을 예측하는 것이
신경망의 역할입니다.

89
00:05:50,200 --> 00:05:55,942
이 동그라미들은
숨겨진 유닛이라고도 하는데요

90
00:05:55,942 --> 00:06:02,310
이 유닛들은 각각 4가지 특성을 반영합니다.

91
00:06:02,310 --> 00:06:08,139
예를 들어, 첫 번째 노드가 가족 규모를 뜻하고

92
00:06:08,139 --> 00:06:12,056
이 규모는 X1과 X2에 의존한다고 이야기하기보다는,

93
00:06:12,056 --> 00:06:15,302
그 대신에, 신경망이 어떤 것이던

94
00:06:15,302 --> 00:06:18,200
선택할 수 있도록 합니다.

95
00:06:18,200 --> 00:06:21,070
그렇게 하고나서 4가지의 특성을 제공하여
자유로운 옵션을 제공합니다.

96
00:06:21,070 --> 00:06:26,170
층이라고도 하는데,
이 입력 층을

97
00:06:26,170 --> 00:06:28,960
신경망 가운데에 있는 층은 밀집하게 연결되어 있습니다.

98
00:06:28,960 --> 00:06:31,740
그 이유는 모든 입력 값이

99
00:06:31,740 --> 00:06:33,980
모든 동그라미에 연결되어 있기 때문입니다.

100
00:06:33,980 --> 00:06:38,630
신경망의 가장 놀라운 부분은 어느 정도

101
00:06:38,630 --> 00:06:43,290
x와 y에 대한 정보가 있으면, x와y에 대한
충분한 트레이닝 example도 있는 경우,

102
00:06:43,290 --> 00:06:47,450
x에서 y를 그리는 함수를 굉장히 잘 파악합니다.

103
00:06:48,990 --> 00:06:51,680
기본적인 신경망에 대한 내용을 다루어 보았는데요,

104
00:06:51,680 --> 00:06:54,290
여러분이 직접 고유의 신경망을 만들어보면,

105
00:06:54,290 --> 00:06:57,130
지도학습 부문에서

106
00:06:57,130 --> 00:07:01,620
매우 유용하고, 강력하다는 것을 느낄 것입니다.
즉, 조금 전에 봤던 집값을 예측하는 사례처럼

107
00:07:01,620 --> 00:07:06,980
x를 이용하여 y를 산출하려고 하는 경우와 같이 말입니다.

108
00:07:06,980 --> 00:07:11,490
다음 비디오에서는 지도학습의 몇가지 예를 더 살펴 보겠습니다.

109
00:07:11,490 --> 00:07:15,670
본인 어플에 큰 도움이 될 수 있는 네트워크 example을

110
00:07:15,670 --> 00:07:16,670
다뤄보도록 하겠습니다.