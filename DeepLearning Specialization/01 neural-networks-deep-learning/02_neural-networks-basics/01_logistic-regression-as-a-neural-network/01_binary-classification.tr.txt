Merhaba, tekrar hoş geldiniz. Bu hafta sinir ağ programlamanın
temellerini gözden geçireceğiz. Bir sinir ağını uygularken gerçekten önemli olacak bazı teknikler ortaya çıkıyor. Örneğin, eğer eğitim setiniz m tane
eğitim örneğinden oluşuyorsa, Eğitim örnekleriniz aracılığıyla bir for döngüsüne sahip olarak eğitim setini işlemek için kullanılabilir. Ancak görünen o ki bir sinir ağını uygularken, genellikle tüm eğitim setinizin tamamını,
tüm eğitim setinizin üzerinde döngü içine döngü
kullanmadan işlemek isteyebilirsiniz. Böylece, bu haftaki materyallerde bunu
nasıl yapacağınızı göreceksiniz. Başka bir fikir ise, ağınızdaki
hesaplamayı düzenlerken, genellikle ileriye doğru duraklama veya
ileri yayılma adımınız olur, bunu ise geriye doğru bir duraklama ya da 
geriye doğru yayılma adı verilen adım takip eder. Ve böylece bu haftaki materyallerde,
bir sinir ağının öğrenilmesinde, yayılım ve ayrı bir geri yayılım
için bu hesaplamalarda neden düzenlenebileceğine dair
bir giriş elde edersiniz. Bu haftanın materyalleri için, fikirlerin
anlaşılmasını kolaylaştırmak için bu fikirleri lojistik regresyon kullanarak aktarmak istiyorum. Fakat daha önce lojistik regresyon görseniz bile, eminim bu haftaki materyalinde öğrenmek için yeni ve
ilginç fikirler bulacaksınız. Böylece bununla başlayalım. Lojistik regresyon, ikili sınıflandırma 
için bir algoritmadır. O zaman sorunu belirterek başlayalım. İşte bir ikili sınıflandırma
probleminin bir örneği. Bir resmin girişine sahip olabilirsiniz, bunun gibi ve bu görüntüyü bir kedi olarak algılamak
için bir etiket çıkarmak isteyebilirsiniz, Bu durumda çıktı 1 veya kedi değil yani 0 olacak ve çıkış etiketini göstermek için y kullanacağız. Bir bilgisayarda bir görüntünün
nasıl temsil edildiğine bakalım. Bir görüntüyü saklamak için,
bilgisayarınız bu görüntünün kırmızı, yeşil ve mavi renk kanallarına
karşılık gelen üç ayrı matrisi saklar. Dolayısıyla, giriş resminiz 64 piksele 64 piksel ise, resimleriniz için kırmızı, yeşil ve mavi piksel yoğunluk değerlerine karşılık gelen 3 tane 64 x 64 matrisiniz olur. Her ne kadar bu küçük slaytı yapmak için bu kadar küçük matrisler çizmiş olsam da, bunlar aslında 5 x 4 değil 64 x 64 matristir. Dolayısıyla, bu piksel yoğunluğu değerlerini
bir özellik vektörüne döndürmek için, yapacağımız şey bu piksel değerlerinin tümünü
bir giriş özelliği vektörüne (x) döndürmektir. Dolayısıyla, bu piksel yoğunluğu değerlerini bir özellik vektörüne döndürmek için, yapacağımız şey aşağıdaki gibi bu görüntüye karşılık gelen bir özellik vektörünü (x) tanımlamaktır. Sadece tüm piksel değerlerini 255, 231 vb. alacağız. 255, 231 ve tüm kırmızı pikseller listelenene kadar. Ve sonunda 255 134 255, 134 ve böylece, bu görüntünün tüm kırmızı, yeşil ve
mavi piksel yoğunluk değerlerini listeleyen uzun bir özellik vektör elde ederiz. Eğer bu görüntü bir 64 x 64 görüntü ise bu x vektörünün toplam boyutu 64 x 64 x 3 olacaktır, çünkü bu tüm bu matrislerde sahip olduğumuz toplam sayılardır. Bu durumda, 12.288 olur, tüm bu sayıları çoğalırsanız
elde edeceğiniz şey budur. Ve böylece giriş özellik vektörü x'in boyutunu temsil etmek için nx = 12288 kullanacağız. Ve bazen kısa olması için, bu giriş özellik vektörünün boyutunu göstermek için sadece 
küçük harf n kullanacağım. Yani, ikili sınıflandırmada amacımız, bu özellik vektörü x tarafından temsil edilen bir görüntüyü
girebilen bir sınıflandırıcıyı öğrenmektir. Ve karşılık gelen etiketin 1 mi, yoksa 0 mı olduğunu, yani bunun bir kedi resmi mi yoksa kedi olmayan bir görüntü mi olduğunu tahmin edin. Şimdi bu dersin geri kalanında kullanacağımız notasyonun bir kısmını belirleyelim. Tek bir eğitim örneği bir çiftle temsil edilir (x, y), burada x bir x-boyutlu özellik vektörüdür ve y, ya 0 ya da 1'dir. Eğitim setleriniz , küçük harf m eğitim
örneklerinden oluşacaktır. Ve böylece eğitim setleriniz yazılırsa, (x1, y1) ilk eğitim örneğiniz için giriş ve çıkış, (x(2), y(2)) ikinci eğitim örneği için ve (xm, ym) 'e kadar olan son eğitim örneği. Ve bunların tamamı eğitim setiniz. Bu yüzden eğitim örneklerinin sayısını göstermek
için küçük harf m kullanacağım. Ve bazen bunun eğitim örneklerinin sayısı olduğunu vurgulamak için bunu M = M train olarak yazabilirim. Ve test seti hakkında konuştuğumuzda, test örneklerinin sayısını göstermek için bazen M test olarak kullanabiliriz. Yani bu test örneklerinin sayısı. Son olarak, tüm eğitim örneklerini daha küçük bir notasyona çıkarmak için, bir X matrisini tanımlayacağız. Eğitim seti girişlerini x1,x2 ve bunları sütunlarda istifleyerek tanımlandığı gibi. Bu yüzden x1'i alıp bu matrisin bir ilk sütunu olarak x2, bunu ikinci bir sütun olarak ve xm'ye kadar koyduğumuzda, bu X matrisidir. Yani bu X matrisi M sütununa sahip olacaktır, burada M eğitim sayısı ve sütun sayısıdır veya bu matrisin yüksekliği NX'dir. Diğer nedenlerden dolayı, bu gibi satırlardaki eğitim örneklerini sıralayarak tanımlanan X matrisinde X1'in transpose'unun Xm'in transpose'una indirgendiğini görebiliriz. Sol tarafta var olan bu kuralı kullanarak sinir ağlarını uygularken, uygulamayı daha kolaylaştıracağı ortaya çıkıyor. Tekrar edecek olursak, x, m boyutlu bir matrisle bir nx'dir ve bunu Python'da uyguladığınızda, x.shape'yi görürsünüz, bu matrisin şeklini bulmak için kullanılan Python komutudur, bu bir (nx, m)'dir. Bu sadece (nx,m) boyutlu bir matris olduğu anlamına gelir. Yani eğitim örneklerini bu şekilde gruplandırırsanız, giriş değeri x'i matrise aktarırsınız. Çıkış etiketleri Y nedir? Bir sinir ağının uygulanmasını kolaylaştırmak için, Y'nin sütunlarını da sıralamak uygun olacaktır. Bu yüzden Y'yi Y1, Y2,..,Ym'e eşit olacak şekilde tanımlayacağız. Yani Y, (1,m) boyutlu bir matris olacaktır. Ve yine, Python gösterimini Y şekliyle kullanmak için (1, m) olacaktır. Bu sadece (1,m) matris olduğu anlamına gelir. Ve ilerleyen bölümde sinir ağınızı uygularken bunun farklı eğitim örnekleri ile ilişkili verileri almak için
kullanışlı bir yöntem olduğunu göreceksiniz, ve burada veriden kasıt x, y yahut ileride göreceğiniz başka değerler olacak. Ancak farklı eğitilmiş örnekler ile ilişkili verileri alıp farklı sütunlarda tutmak için x ve y de yaptığımız gibi bu metot kullanılabilir. Yani, bu lojistik regresyon ve bu dersin ilerleyen dönemlerinde sinir ağları için kullanacağımız bir yöntemdir. Eğer gösterimlerin ne anlama geldiğini unutursanız, M'nin ne olduğu ya da N'nin ne olduğu gibi aynı zamanda kurs web sitesinde herhangi bir gösterimin ne olduğunu hızlı bir şekilde aramak için kullanabileceğiniz bir notasyon rehberi yayınladık. Bu nedenle, bu gösterimi kullanarak lojistik regresyona başlayacağımız bir sonraki videoya geçelim.