1
00:00:00,620 --> 00:00:03,610
部分的deeplearning.ai 課程

2
00:00:03,610 --> 00:00:07,590
希望不只是教您在
深度學習的技術思維, 同時

3
00:00:07,590 --> 00:00:11,658
介紹一些人
一些在深度學習的英雄們

4
00:00:11,658 --> 00:00:13,160
邀請這些人是

5
00:00:13,160 --> 00:00:17,700
因為您在這個專業或這課堂上您所學到的觀念

6
00:00:17,700 --> 00:00:21,420
在這段影片中, 我希望
問問這些在深度學習的領袖

7
00:00:21,420 --> 00:00:24,990
給於您一些職涯上的建議
您如何進入深度學習

8
00:00:24,990 --> 00:00:27,805
您如何做研究
或者在深度學習找到工作

9
00:00:27,805 --> 00:00:30,156
在第一個面談系列

10
00:00:30,156 --> 00:00:34,228
我非常高興邀請到
 Geoffrey Hinton (傑佛里.辛頓)

11
00:00:38,427 --> 00:00:44,150
歡迎 Geoff, 謝謝您
加入 deeplearing.ai 的面談

12
00:00:44,150 --> 00:00:46,550
>>謝謝您的邀請

13
00:00:46,550 --> 00:00:50,088
>>我想在這一時間點您比
這星球上任何一個人

14
00:00:50,088 --> 00:00:52,835
發現了
這麼多深度學習的觀念

15
00:00:52,835 --> 00:00:57,650
而許多人都稱您為
深度學習的教父

16
00:00:57,650 --> 00:01:01,529
雖然直到不久前
我才發現

17
00:01:01,529 --> 00:01:05,600
您覺得我是第一位這樣稱呼您的
我很高興是我先說的

18
00:01:06,780 --> 00:01:11,320
但我想問的是
很多人都知道您是傳奇

19
00:01:11,320 --> 00:01:15,030
我想要問您
在這傳奇背後個人的故事

20
00:01:15,030 --> 00:01:19,980
所以您如何涉入
回到從前， 您如何進入 AI 跟

21
00:01:19,980 --> 00:01:21,520
機器學習跟神經網路?

22
00:01:22,730 --> 00:01:26,960
>>當我在中學時
我有一個同學一直

23
00:01:26,960 --> 00:01:31,220
比我行
他是個聰明的數學家

24
00:01:31,220 --> 00:01:37,010
有一天他到學校說
您知道頭腦使用全息影像

25
00:01:38,190 --> 00:01:44,161
我想那是大約在 1966 年
我說什麼是全息影像

26
00:01:44,161 --> 00:01:47,390
他解釋說一個全息影像
您可以砍對半

27
00:01:47,390 --> 00:01:49,730
您還是可以看到整個影像

28
00:01:49,730 --> 00:01:53,466
而這在腦中的記憶也許
分散在整個腦中

29
00:01:53,466 --> 00:01:56,022
我猜他可能讀到
有關 Lashley 實驗

30
00:01:56,022 --> 00:01:57,939
您切掉一部分
老鼠的頭腦

31
00:01:57,939 --> 00:02:01,740
發現很難去找到一點
它儲存一段特別的記憶

32
00:02:04,411 --> 00:02:08,920
所以這是我第一次對於
頭腦儲存記憶有興趣

33
00:02:10,180 --> 00:02:12,220
當我進入大學時

34
00:02:12,220 --> 00:02:15,130
我學習生理學跟
物理學

35
00:02:16,400 --> 00:02:17,731
我想是在劍橋大學

36
00:02:17,731 --> 00:02:20,260
我是唯一的大學生
學習生理學跟物理學

37
00:02:21,888 --> 00:02:25,270
然後我放棄了

38
00:02:25,270 --> 00:02:29,170
試著念哲學, 因為我
覺得也許可以給我一些洞察力

39
00:02:29,170 --> 00:02:32,780
但似乎對我而言實際上

40
00:02:32,780 --> 00:02:37,130
缺乏方法去分辨
當他們說某些東西是假的

41
00:02:37,130 --> 00:02:39,420
所以我轉向心理學

42
00:02:41,988 --> 00:02:45,920
在心理學他們有
很簡單的定理那似乎對我而言

43
00:02:45,920 --> 00:02:49,620
是一種絕望的不足的方式
來解釋頭腦的運作

44
00:02:49,620 --> 00:02:52,737
所以我休學
變成一個木匠

45
00:02:52,737 --> 00:02:57,169
然後我決定試試 AI 
 去了愛丁堡

46
00:02:57,169 --> 00:02:59,580
跟 Langer Higgins 學 AI

47
00:02:59,580 --> 00:03:02,662
他曾經做了很棒的
神經網路工作

48
00:03:02,662 --> 00:03:07,830
他放棄了神經網路
但留下 Winograd's 論文令世人留下深刻印象

49
00:03:07,830 --> 00:03:11,460
所以當我到那裡時他想我
應該做一些舊東西

50
00:03:11,460 --> 00:03:14,210
我應該從符號AI 開始

51
00:03:14,210 --> 00:03:18,210
我們有很大的爭論關於這點, 但
我還是做我相信的

52
00:03:18,210 --> 00:03:21,138
>>然後呢?

53
00:03:21,138 --> 00:03:28,033
>>我最終拿到 AI 的博士
但沒法在英國找到工作

54
00:03:28,033 --> 00:03:30,979
但我看到了一個很棒的廣告在

55
00:03:30,979 --> 00:03:36,070
加州的史隆獎學金
我拿到這個獎學金

56
00:03:36,070 --> 00:03:40,625
我到了加州
所有的東西有很大的不同

57
00:03:40,625 --> 00:03:46,685
在英國
神經網路有一點蠢

58
00:03:46,685 --> 00:03:50,272
在加州, Don Norman 跟

59
00:03:50,272 --> 00:03:56,640
David Rumelhart 對於
神經網路的觀念非常開放

60
00:03:56,640 --> 00:04:00,720
這是第一次我在想
頭腦如何運作

61
00:04:00,720 --> 00:04:03,290
想著如何跟
心理學的關係

62
00:04:03,290 --> 00:04:05,650
被視為正向的想法

63
00:04:05,650 --> 00:04:06,936
而有很多的樂趣在裡面

64
00:04:06,936 --> 00:04:09,792
特別是跟
 David Rumelhart 一起工作非常棒

65
00:04:09,792 --> 00:04:12,968
>>懂了
所以這是您在 UCSD (加州聖地牙哥分校) 時

66
00:04:12,968 --> 00:04:16,177
您跟Rumelhart 大約是在 1982年

67
00:04:16,177 --> 00:04:20,182
最後寫了
反向傳播的論文, 對吧?

68
00:04:20,182 --> 00:04:23,292
>> 實際上，比這更複雜。

69
00:04:23,292 --> 00:04:24,796
>> 發生了什麼事？

70
00:04:24,796 --> 00:04:28,214
>>我想, 在 1982年初

71
00:04:28,214 --> 00:04:32,900
David Rumlhart 跟我跟 Ron Williams

72
00:04:32,900 --> 00:04:37,967
我們開發這個
反向傳播演算法

73
00:04:37,967 --> 00:04:42,291
主要是 David Rumelhart 的想法

74
00:04:42,291 --> 00:04:46,390
我們發現其他很多人
已經發現它

75
00:04:46,390 --> 00:04:52,798
David Parker 已經發現也許
比我們晚，但比我們早發表

76
00:04:52,798 --> 00:04:56,425
Paul Werbos 已經發表
幾年了

77
00:04:56,425 --> 00:04:58,860
但沒有人注意到

78
00:04:58,860 --> 00:05:01,923
而有其他人也
發展類似的演算法

79
00:05:01,923 --> 00:05:04,340
當時並不清楚反向傳播的意義

80
00:05:04,340 --> 00:05:08,055
但使用連結規則來得到
導數並不是新奇的想法

81
00:05:08,055 --> 00:05:12,484
>>了解, 但您想為什麼
是您們的論文幫助

82
00:05:12,484 --> 00:05:15,940
這個社群連起了反向傳播

83
00:05:15,940 --> 00:05:20,540
似乎是您們的論文被標註為
接受

84
00:05:20,540 --> 00:05:22,934
這演算法的影響, 不管誰接受它

85
00:05:22,934 --> 00:05:26,675
>>我們能夠讓
自然雜誌(Nature)接受這篇論文

86
00:05:26,675 --> 00:05:30,580
我做了許多政治上
的工作讓這份論文被接受

87
00:05:30,580 --> 00:05:34,622
我發現其中一個裁判
將會是 Stuart Sutherland

88
00:05:34,622 --> 00:05:36,992
是一位有名的
英國心理學家

89
00:05:36,992 --> 00:05:38,815
我去跟他
談了很久

90
00:05:38,815 --> 00:05:41,480
跟他解釋
到底這是怎麼回事

91
00:05:41,480 --> 00:05:44,140
而他對此印象深刻

92
00:05:44,140 --> 00:05:48,970
我們展示了反向傳播可以
學習字元表示

93
00:05:48,970 --> 00:05:52,490
您可以看這些
表示法, 是一些向量

94
00:05:52,490 --> 00:05:55,950
您可以理解
每一個特徵的意義

95
00:05:55,950 --> 00:06:01,600
我們實際上訓練了
三個字有關於家族樹

96
00:06:01,600 --> 00:06:06,420
像是瑪莉的母親是維多莉雅

97
00:06:06,420 --> 00:06:11,550
您給他前面兩個字
它會預測最後的字

98
00:06:11,550 --> 00:06:12,970
而在訓練後

99
00:06:12,970 --> 00:06:17,780
您可以見到所有的特徵
表示在每一個字元

100
00:06:17,780 --> 00:06:19,950
像是這個人的國籍

101
00:06:19,950 --> 00:06:25,180
是第幾代, 是
哪一枝旁枝在家族樹中等等

102
00:06:25,180 --> 00:06:27,680
這使得 Stuart Sutherland 
印象深刻

103
00:06:27,680 --> 00:06:29,666
我想這是為什麼論文被接受

104
00:06:29,666 --> 00:06:33,905
>>非常早期的字元嵌入
而您已經見到了

105
00:06:33,905 --> 00:06:38,390
語意的學習特徵
從訓練演算法發起

106
00:06:38,390 --> 00:06:44,090
>>是的, 從心理學的角度
有趣的是它結合了

107
00:06:44,090 --> 00:06:49,740
兩股完全不同的
觀念有關於知識的樣子

108
00:06:49,740 --> 00:06:53,460
有舊式心理學的
觀點, 亦即觀念是一大堆

109
00:06:53,460 --> 00:06:56,810
的特徵
有很多的證據展現這個觀點

110
00:06:56,810 --> 00:07:02,180
也有 AI 的觀點
就是正式的結構觀點

111
00:07:02,180 --> 00:07:06,190
亦即一個觀點
如何跟另一個觀點相關

112
00:07:06,190 --> 00:07:09,820
而為了捕捉觀點
您必須用圖形結構或者

113
00:07:09,820 --> 00:07:11,640
也許語意網路

114
00:07:11,640 --> 00:07:15,875
而反向傳播
的例子展現的是, 您可以給與

115
00:07:15,875 --> 00:07:21,070
一些資訊進入這個圖形
結構, 在這個例子是家族樹

116
00:07:22,080 --> 00:07:26,920
而它可以轉化這些資訊到
特徵藉此用

117
00:07:26,920 --> 00:07:33,470
這些特徵來導出新的
一致性的資訊, 像是第幾世代

118
00:07:33,470 --> 00:07:38,438
但重要的是在
圖形表示中, 或者

119
00:07:38,438 --> 00:07:43,000
樹狀結構表示的家族樹中跟

120
00:07:43,000 --> 00:07:46,715
代表人的巨大特徵向量中來回

121
00:07:46,715 --> 00:07:50,873
而實際上圖形表現
您可以得到特徵

122
00:07:50,873 --> 00:07:51,469
跟向量

123
00:07:51,469 --> 00:07:54,995
而從特徵向量中您可以
得到圖形表現

124
00:07:54,995 --> 00:07:57,730
>>所以這是在 1986?

125
00:07:57,730 --> 00:08:02,430
是在 1990 早期, Bengio 展示了
您可以使用真正的資料

126
00:08:02,430 --> 00:08:07,420
您可以拿英文句子
使用同樣技巧來

127
00:08:07,420 --> 00:08:13,980
得到英文句子的嵌入字
這真的令人印象深刻

128
00:08:13,980 --> 00:08:18,682
>>我猜我們最近使用
很多快速電腦像 GPU 跟

129
00:08:18,682 --> 00:08:21,750
超級電腦也
推動了深度學習

130
00:08:21,750 --> 00:08:26,376
我並不知道在 1986
到90年代早期, 似乎

131
00:08:26,376 --> 00:08:29,570
您跟 Benjio 已經
開始了這個趨勢

132
00:08:30,600 --> 00:08:32,630
>>是的, 那是很大的進步

133
00:08:32,630 --> 00:08:41,440
在 1986我用的機器
是小於 十分之ㄧ的百萬浮點運算

134
00:08:41,440 --> 00:08:47,720
而在大約 1993 
人們已經使用 10 倍的百萬浮點運算

135
00:08:47,720 --> 00:08:49,600
>>是的
>> 所以相差 100 倍

136
00:08:49,600 --> 00:08:51,770
而就是這個觀點
讓它容易使用

137
00:08:51,770 --> 00:08:53,580
因為電腦
越來越快

138
00:08:53,580 --> 00:08:56,960
>>過去幾個世紀
您發明了

139
00:08:56,960 --> 00:08:59,970
這麼多的神經網路跟
深度學習的片段

140
00:08:59,970 --> 00:09:02,670
我很好奇
在所有您發明中

141
00:09:02,670 --> 00:09:05,050
哪一個在今天您還是
最令您興奮

142
00:09:06,940 --> 00:09:09,590
>>我想最漂亮的是
我跟

143
00:09:09,590 --> 00:09:12,620
Terry Sejnowski 一起做的 Boltzmann Machine (玻爾茲曼機)

144
00:09:12,620 --> 00:09:14,500
我們所發現的是真的

145
00:09:14,500 --> 00:09:18,830
很簡單的學習演算法
應用在大型的

146
00:09:18,830 --> 00:09:23,550
密度連結網路, 而您
只能見到一些節點

147
00:09:23,550 --> 00:09:27,730
所以它會學習做隱藏層
它是很簡單的演算法

148
00:09:27,730 --> 00:09:31,130
而它就像
您從人腦得到的東西般因為

149
00:09:31,130 --> 00:09:34,210
每個突觸只需要知道
兩個它連結

150
00:09:34,210 --> 00:09:35,940
的神經元的動作

151
00:09:37,010 --> 00:09:41,230
而這個資訊的
傳導是一樣的

152
00:09:41,230 --> 00:09:45,160
有兩種不同的情況
我們稱之為醒來跟睡著

153
00:09:45,160 --> 00:09:46,820
在不同的情況下

154
00:09:46,820 --> 00:09:48,760
您傳導資訊的
方法是一樣的

155
00:09:48,760 --> 00:09:52,360
而就像反向
傳播一樣, 有正向跟

156
00:09:52,360 --> 00:09:54,820
反向
但作用不同

157
00:09:54,820 --> 00:09:56,379
它們傳達
不同的訊號

158
00:09:58,100 --> 00:10:01,190
所以我想那是
最美麗的事

159
00:10:01,190 --> 00:10:03,730
這幾年來它似乎
只剩好奇心

160
00:10:03,730 --> 00:10:05,090
因為看來它
跑得太慢了

161
00:10:06,210 --> 00:10:10,420
但後來, 我去掉了一些
漂亮的東西, 它開始讓

162
00:10:10,420 --> 00:10:13,730
我安心下來, 只使用一次遞迴
一種簡單的網路

163
00:10:13,730 --> 00:10:16,570
這就是受限制
玻爾茲曼機

164
00:10:16,570 --> 00:10:19,430
實際上
已經可以實作

165
00:10:19,430 --> 00:10:21,586
舉個例子
像在 Netflix 競爭中

166
00:10:21,586 --> 00:10:26,170
受限玻爾茲曼機是
得獎者使用的其中一種成分

167
00:10:26,170 --> 00:10:30,210
>>實際上, 很多最近
再次興起的神經網路跟

168
00:10:30,210 --> 00:10:34,790
深度學習, 從 2007 開始
是受限波爾茲曼機

169
00:10:34,790 --> 00:10:37,710
而受限波爾茲曼機
就是您跟您的實驗室做的

170
00:10:38,940 --> 00:10:42,130
>>是的所以那是另一段
我喜歡做的事

171
00:10:42,130 --> 00:10:46,290
這個觀念是您可以訓練您的
受限波爾茲曼機, 亦即

172
00:10:46,290 --> 00:10:51,120
一層的隱藏特徵
您可以學習一層的特徵

173
00:10:51,120 --> 00:10:54,850
然後您可以視這些
特徵為資料再做一次

174
00:10:54,850 --> 00:10:57,953
然後您可以視這些新學習的特徵
為資料再做一次

175
00:10:57,953 --> 00:10:59,570
喜歡做多少次就做多少次

176
00:10:59,570 --> 00:11:03,060
所以這很棒, 也實際可行

177
00:11:03,060 --> 00:11:08,709
然後 UY Tay 發現這整個
事件可以視為單一模型

178
00:11:08,709 --> 00:11:11,110
只是是很奇怪的模型

179
00:11:11,110 --> 00:11:15,946
這個模型是在上面有
受限波爾茲曼機

180
00:11:15,946 --> 00:11:20,626
下面是 S狀信念
網路是

181
00:11:20,626 --> 00:11:23,060
很多年以前發明的

182
00:11:23,060 --> 00:11:24,620
這是一個直接模型

183
00:11:24,620 --> 00:11:28,651
我們已經設法
訓練這些受限波爾茲曼機

184
00:11:28,651 --> 00:11:32,760
在S狀信念網路能有效的做
推演

185
00:11:33,830 --> 00:11:36,870
所以在那時

186
00:11:36,870 --> 00:11:41,270
也有人做神經網路
他們使用緊密連結網路, 但

187
00:11:41,270 --> 00:11:45,500
沒有好的方法做
機率印記

188
00:11:45,500 --> 00:11:50,050
而您讓人們使用圖形模型
不像我孩子們

189
00:11:50,050 --> 00:11:55,603
可以做好推衍但
侷限在稀疏連結網路上

190
00:11:55,603 --> 00:12:01,140
我們設法做到的是
使用這些深度

191
00:12:01,140 --> 00:12:06,280
信念網路設法接近
很快的推衍的形式

192
00:12:06,280 --> 00:12:10,578
它只是使用單一正向
是一個很漂亮的結果

193
00:12:10,578 --> 00:12:14,890
您可以保證每一次
您學習額外一層的特徵

194
00:12:16,010 --> 00:12:19,980
這裡有一群帶, 每次您學習一個新的層, 您得到一個新的帶, 而

195
00:12:19,980 --> 00:12:22,700
新的帶永遠
比舊的帶好

196
00:12:22,700 --> 00:12:25,810
>>這個變化帶
展示了您加入新的層

197
00:12:25,810 --> 00:12:26,970
是的, 我記得這段影片

198
00:12:26,970 --> 00:12:29,680
>>所以這是我第二件事
我非常興奮

199
00:12:29,680 --> 00:12:35,600
我想第三件事是
我做的變異方法

200
00:12:35,600 --> 00:12:40,750
事實上人們在統計學上
早期已經有類似的

201
00:12:40,750 --> 00:12:43,100
但我們並不知道

202
00:12:44,610 --> 00:12:47,260
所以我們設法讓

203
00:12:47,260 --> 00:12:50,250
EN 作用得更好來顯示
您並不需要用完美的 E 步驟

204
00:12:50,250 --> 00:12:52,800
您可以使用趨近E步驟

205
00:12:52,800 --> 00:12:55,320
而EN是一個大的統計演算法

206
00:12:55,320 --> 00:12:58,380
我們顯示了一個大型的
一般化

207
00:12:58,380 --> 00:13:02,490
特別是在 1993年
我想, 跟 Van Camp

208
00:13:02,490 --> 00:13:07,040
我做了一篇論文
第一篇貝式變異論文

209
00:13:07,040 --> 00:13:12,090
我們展示了您可以
作貝式學習的版本

210
00:13:12,090 --> 00:13:17,950
這是遠遠可以追蹤
趨近於統計後驗

211
00:13:17,950 --> 00:13:20,320
您可以在神經網路做到

212
00:13:20,320 --> 00:13:22,600
而我一直非常興奮

213
00:13:22,600 --> 00:13:23,680
>>我懂了
哇

214
00:13:23,680 --> 00:13:26,670
是的, 我想我記得
這些論文

215
00:13:26,670 --> 00:13:32,630
您 Hinton, 趨近論文
花了許多的時間讀它

216
00:13:32,630 --> 00:13:36,070
而我想一些
您今天使用的演算法

217
00:13:36,070 --> 00:13:41,110
一些演算法許多
人每天使用的, 

218
00:13:41,110 --> 00:13:46,570
像是丟棄法(dropout)
我想是來自您團隊的激發

219
00:13:46,570 --> 00:13:47,390
>>是跟不是

220
00:13:47,390 --> 00:13:51,470
所以一些人想到
線性整流函數

221
00:13:51,470 --> 00:13:56,860
我們確實做一些事
用受限波爾茲曼機展示

222
00:13:56,860 --> 00:14:02,880
線性整流函數幾乎相當於
一大疊的羅吉斯單元

223
00:14:02,880 --> 00:14:05,190
而那是其中之一
我們幫助線性整流函數的運用

224
00:14:05,190 --> 00:14:07,440
>>我對此相當好奇

225
00:14:07,440 --> 00:14:12,570
這篇論文有一大堆
數學顯示這個函數

226
00:14:12,570 --> 00:14:15,530
可以趨近於這個
相當複雜的方程式

227
00:14:15,530 --> 00:14:19,140
您做這些數學所以您的論文
可以被學院接受

228
00:14:19,140 --> 00:14:24,840
或者做這些數學真的影響了
取0跟x最大值的開發

229
00:14:26,450 --> 00:14:30,440
>>這是一個例子說明了
數學很重要

230
00:14:30,440 --> 00:14:32,350
去發展一個觀念

231
00:14:32,350 --> 00:14:35,262
很明顯我知道有關線性整流函數

232
00:14:35,262 --> 00:14:36,821
我也知道羅吉斯單元

233
00:14:36,821 --> 00:14:39,250
而因為做
波爾茲曼機

234
00:14:39,250 --> 00:14:42,720
所有基本工作
使用羅吉斯單元

235
00:14:42,720 --> 00:14:45,120
所以問題是

236
00:14:45,120 --> 00:14:49,070
這個學習演算法可以
用線性整流函數?

237
00:14:49,070 --> 00:14:54,400
而顯示了線性整流函數
幾乎相等於一疊

238
00:14:54,400 --> 00:15:00,350
羅吉斯單元, 我們展示了
使用所需的數學來證明

239
00:15:00,350 --> 00:15:01,508
>>了解

240
00:15:01,508 --> 00:15:05,890
而今天它提供了許多啟示
很多人使用 ReLU

241
00:15:05,890 --> 00:15:08,000
它就是可行, 不需要...>>喔

242
00:15:08,000 --> 00:15:12,130
>>不需要必須去
了解同樣的動機

243
00:15:13,150 --> 00:15:16,850
>>是的, 我注意到一件事
在我去谷歌之後

244
00:15:16,850 --> 00:15:22,796
我記得是2014年, 我做一個演講
在谷歌有關使用ReLU 

245
00:15:22,796 --> 00:15:26,660
跟使用單位矩陣來做初始化

246
00:15:26,660 --> 00:15:30,300
因為有關ReLU很棒的是
如果您一直複製隱藏

247
00:15:30,300 --> 00:15:32,667
層然後
您用單位矩陣來做初始化

248
00:15:32,667 --> 00:15:35,050
它就只是複製這個
在這一層底下的模式

249
00:15:36,140 --> 00:15:40,120
所以我可以顯示您可以訓練
300隱藏層的網路

250
00:15:40,120 --> 00:15:44,760
您可以有效地訓練他們
如果您用單位矩陣來做初始化

251
00:15:44,760 --> 00:15:48,065
但我並沒有繼續追下去
而我很後悔沒有追下去

252
00:15:48,065 --> 00:15:52,507
我們公布一篇論文來展示
您可以初始

253
00:15:52,507 --> 00:15:55,565
展示您可以初始
重複像那樣

254
00:15:55,565 --> 00:16:00,370
但我應該繼續追下去
因為往後在剩餘

255
00:16:00,370 --> 00:16:03,572
網路實際上就是這樣的東西

256
00:16:03,572 --> 00:16:06,660
>>過去幾年我聽到
您談論有關人腦

257
00:16:06,660 --> 00:16:09,447
我聽到您談論有關於
反向傳播與人腦的關係

258
00:16:09,447 --> 00:16:13,720
您現在的想法如何?

259
00:16:13,720 --> 00:16:16,910
>>我實際上正在寫
一篇論文

260
00:16:18,250 --> 00:16:21,160
我想我主要的想法是

261
00:16:21,160 --> 00:16:25,570
如果實際上反向傳播是真的
好的學習演算法

262
00:16:26,620 --> 00:16:31,610
那確定的是進化會
發現到如何去建立它

263
00:16:32,730 --> 00:16:37,270
我的意思是細胞可以
變成眼睛或牙齒

264
00:16:37,270 --> 00:16:42,440
如果細胞可以這樣做, 他們可以
確定可以建立反向傳播

265
00:16:42,440 --> 00:16:45,860
假設有一股強大的
壓力在上面

266
00:16:45,860 --> 00:16:50,490
所以我想神經學家的觀念是
覺得不可行有點蠢

267
00:16:50,490 --> 00:16:52,890
有一些障礙
阻止建立它

268
00:16:52,890 --> 00:16:56,000
但我想人腦也許
不完全是

269
00:16:56,000 --> 00:16:58,620
反向傳播但
也相去不遠

270
00:16:58,620 --> 00:17:02,566
而過去幾年, 我想出
一些想法也關於它如何作用

271
00:17:02,566 --> 00:17:06,994
所以在1987年,跟 Jay McClelland 一起工作

272
00:17:06,994 --> 00:17:11,202
我想出了
再循環演算法

273
00:17:11,202 --> 00:17:16,090
而這個想法是您送
資訊進入一個迴圈

274
00:17:17,470 --> 00:17:18,686
而您試著讓

275
00:17:18,686 --> 00:17:22,206
這些東西保持不變當
資訊在這個迴圈時

276
00:17:22,206 --> 00:17:26,490
所以最簡單的版本是您
有輸入單元跟隱藏單元

277
00:17:26,490 --> 00:17:31,046
您送資訊從輸入
到隱藏然後回到輸入

278
00:17:31,046 --> 00:17:34,388
再回到隱藏跟
回到輸入等等

279
00:17:34,388 --> 00:17:38,001
而您想要
想要訓練一個自動編碼機

280
00:17:38,001 --> 00:17:42,300
但您希望訓練它不
使用反向傳播

281
00:17:42,300 --> 00:17:47,250
您只是訓練它試著除掉
所有不同的動作

282
00:17:47,250 --> 00:17:51,922
這個觀念是學習規則是對於

283
00:17:51,922 --> 00:17:57,930
突觸改變權重
相當於突觸前輸入及

284
00:17:57,930 --> 00:18:01,780
相當於突觸後的
改變率輸入

285
00:18:01,780 --> 00:18:04,060
但在再循環, 您試著
讓突觸後輸入

286
00:18:04,060 --> 00:18:08,330
您試著讓舊的
變好的而新的變壞的

287
00:18:08,330 --> 00:18:09,620
您改變了方向

288
00:18:11,010 --> 00:18:14,472
我們發明了這個演算法在
神經學家提出

289
00:18:14,472 --> 00:18:16,521
尖峰時段依賴可塑性之前

290
00:18:16,521 --> 00:18:20,700
尖峰時段依賴可塑性實際是
一樣的演算法但是

291
00:18:20,700 --> 00:18:26,220
是相反方向, 新的是好的而
舊的是不好的在學習規則中

292
00:18:26,220 --> 00:18:30,010
您改變權重
相對於預設的動作

293
00:18:30,010 --> 00:18:35,690
乘上新的動作減去舊的

294
00:18:37,060 --> 00:18:42,020
後來在2007我理解了
如果您用一疊

295
00:18:42,020 --> 00:18:47,830
受限玻爾茲曼機而
您訓練它們

296
00:18:47,830 --> 00:18:52,620
當訓練完, 您有
完全對的情況來

297
00:18:52,620 --> 00:18:56,450
建立反向傳播
只要重新建構

298
00:18:56,450 --> 00:19:01,124
如果您看這重構
這重構會

299
00:19:01,124 --> 00:19:05,728
實際上告訴您
差別表現的導數

300
00:19:05,728 --> 00:19:12,079
而在第一次深度學習研討會
在2007年, 我演講過這個主題

301
00:19:12,079 --> 00:19:16,454
但完全被忽略了

302
00:19:16,454 --> 00:19:19,799
後來, Joshua Benjo,
重拾起這個觀念

303
00:19:19,799 --> 00:19:24,340
然後實際上做了相當
多的工作

304
00:19:24,340 --> 00:19:26,490
我自己也做了
更多的工作

305
00:19:26,490 --> 00:19:33,280
我想這個觀念是如果您有
一疊的自動編碼機, 您可以

306
00:19:33,280 --> 00:19:38,440
用發送動作
反向跟找出重構者來得到導數

307
00:19:38,440 --> 00:19:42,520
這真是有趣的觀念
也許人腦就是這樣作用

308
00:19:42,520 --> 00:19:47,520
>>我知道您還有其他的主題
是我聽說您還在

309
00:19:47,520 --> 00:19:51,930
做如何處理
深度學習的多重時間技巧

310
00:19:51,930 --> 00:19:54,468
您可以分享您的想法嗎?

311
00:19:54,468 --> 00:19:58,910
>>是的, 實際上, 要回到
我在當研究生的第一年

312
00:19:58,910 --> 00:20:04,040
我第一次的演講是有關
使用我稱為快速權重

313
00:20:04,040 --> 00:20:07,560
也就是權重會快速用上
也迅速衰退

314
00:20:07,560 --> 00:20:08,832
所以可以用來保有短期記憶

315
00:20:08,832 --> 00:20:13,496
我顯示一個很簡單的例子
在1973, 您可以

316
00:20:13,496 --> 00:20:16,590
真的使用這些權重做循環

317
00:20:16,590 --> 00:20:23,010
而我所謂真的循環
是神經元用來

318
00:20:23,010 --> 00:20:28,470
重現事情是回收
那些表現事情在循環核心

319
00:20:30,210 --> 00:20:31,750
而權重是用來

320
00:20:31,750 --> 00:20:34,388
回收真的知識
在循環核心

321
00:20:34,388 --> 00:20:39,170
所以這導出一個問題
當您倒出循環核心時

322
00:20:39,170 --> 00:20:41,600
您如何記得
這過程中的事情

323
00:20:41,600 --> 00:20:42,970
記憶放在哪裡?

324
00:20:42,970 --> 00:20:45,015
因為您使用神經元來
做循環核心

325
00:20:46,080 --> 00:20:49,240
而這個答案是您放
記憶在快速權重

326
00:20:49,240 --> 00:20:53,940
您可以重現這些活動
神經元從這些快速權重

327
00:20:53,940 --> 00:20:56,151
而最近跟 Jimmy Ba 一起工作

328
00:20:56,151 --> 00:21:00,141
我們實際上得到一篇論文使用
循環的快速權重

329
00:21:00,141 --> 00:21:00,898
>>了解

330
00:21:00,898 --> 00:21:04,145
>>所以那距離很久

331
00:21:04,145 --> 00:21:08,746
第一個模型是
在1973沒出版

332
00:21:08,746 --> 00:21:14,966
而 Jimmy Ba 模型是在2015
我想, 或者2016

333
00:21:14,966 --> 00:21:16,469
所以是在40年後

334
00:21:16,469 --> 00:21:22,840
>>我想
另一個觀念也是很久以前

335
00:21:22,840 --> 00:21:29,350
超過5年, 我想的是膠囊
現在狀況如何

336
00:21:29,350 --> 00:21:34,150
>>這個要回到
當年我在美國時

337
00:21:34,150 --> 00:21:39,320
我有這個想法, 我真的
相信但是沒有其他人相信

338
00:21:39,320 --> 00:21:42,120
我提出有關的論文而
被拒絕了

339
00:21:42,120 --> 00:21:45,938
但我真的相信這個想法
我持續的推動它

340
00:21:45,938 --> 00:21:53,880
它取決於
幾個關鍵的想法

341
00:21:53,880 --> 00:22:00,000
一個是有關您如何去表示
多重維度的實體, 您

342
00:22:00,000 --> 00:22:05,070
可以用小小的捨棄法來表現多重維度實體

343
00:22:05,070 --> 00:22:07,630
只要您知道
其中任何一個

344
00:22:07,630 --> 00:22:12,150
這個想法是每個影像區域
您假設最多

345
00:22:12,150 --> 00:22:14,000
一個特別的特徵

346
00:22:15,200 --> 00:22:18,020
而您使用一堆神經元
然後

347
00:22:18,020 --> 00:22:23,190
他們的活動會表示
對於這特徵不同的面向

348
00:22:24,230 --> 00:22:27,270
像是在區域裡確實
它的x和y座標

349
00:22:27,270 --> 00:22:28,780
它的方向?

350
00:22:28,780 --> 00:22:29,930
多快速的移動?

351
00:22:29,930 --> 00:22:30,630
什麼顏色?

352
00:22:30,630 --> 00:22:31,270
它多亮?

353
00:22:31,270 --> 00:22:32,590
這些東西

354
00:22:32,590 --> 00:22:36,350
您可以用一大堆的神經元
來表示不同的維度

355
00:22:36,350 --> 00:22:37,710
對於同一件東西

356
00:22:37,710 --> 00:22:39,410
前提是只有一件東西

357
00:22:40,490 --> 00:22:46,110
有很多不同的方式
可以來表示

358
00:22:46,110 --> 00:22:48,155
從我們通常
使用的神經網路

359
00:22:48,155 --> 00:22:49,820
通常在神經網路
我們有一個大層

360
00:22:49,820 --> 00:22:52,080
所有的單元
做他們做的事

361
00:22:52,080 --> 00:22:55,770
但您不會想說將他們綁一起
變成一些小群來表示

362
00:22:55,770 --> 00:22:57,310
不同的座標對於同一件事

363
00:22:58,660 --> 00:23:02,080
所以我想我應該用
這個額外的架構

364
00:23:02,080 --> 00:23:05,020
所以有了另一種想法
來實現它

365
00:23:05,020 --> 00:23:07,410
>>這個意思是在整個的
的表示

366
00:23:07,410 --> 00:23:09,280
您切割這個表示

367
00:23:09,280 --> 00:23:11,270
>>是的
>>到不同的子集

368
00:23:11,270 --> 00:23:13,900
>>是的
>>來表示, 而不是...

369
00:23:13,900 --> 00:23:15,600
>>我稱這些子集為膠囊

370
00:23:15,600 --> 00:23:16,180
>>了解

371
00:23:16,180 --> 00:23:21,078
>>而膠囊的想法是能夠
表示一個特徵的實例, 但

372
00:23:21,078 --> 00:23:21,794
只有一個

373
00:23:21,794 --> 00:23:27,130
而它代表了這個特徵所有不同的
屬性

374
00:23:27,130 --> 00:23:29,880
它是一個特徵有很多的
屬性相對於

375
00:23:29,880 --> 00:23:34,530
一個平常的神經元跟一個神經網路
只有一個屬性

376
00:23:34,530 --> 00:23:36,240
>> 我明白了，沒錯

377
00:23:36,240 --> 00:23:41,423
>>而您可以做的是, 如果您了解了
您可以做一些平常

378
00:23:41,423 --> 00:23:48,980
神經網路做不好的, 您
可以做我稱為協議程序

379
00:23:48,980 --> 00:23:52,960
假設您想要
做分割

380
00:23:52,960 --> 00:23:56,660
您有一些也許是嘴巴
一些也許是鼻子

381
00:23:57,910 --> 00:24:02,179
您想知道是否您應該
把他們放在一起做一件事

382
00:24:02,179 --> 00:24:03,879
觀念應該是有一個膠囊相對到

383
00:24:03,879 --> 00:24:06,040
嘴巴, 有一些
嘴巴的參數

384
00:24:06,040 --> 00:24:10,582
您有一個鼻子膠囊
有鼻子參數

385
00:24:10,582 --> 00:24:13,797
然後解碼是否
將他們放在一起

386
00:24:13,797 --> 00:24:18,670
您讓他們每一個投票對於
什麼參數會成為一張臉

387
00:24:19,930 --> 00:24:23,718
如果嘴巴跟鼻子是
正確的空間關係

388
00:24:23,718 --> 00:24:24,725
他們會同意

389
00:24:24,725 --> 00:24:28,888
當您讓兩個膠囊在同一水準
投票相同的參數集在

390
00:24:28,888 --> 00:24:32,106
下一個水準上
您可以假設他們是對的

391
00:24:32,106 --> 00:24:35,350
因為協議在高
維度空間是不太可能的

392
00:24:36,950 --> 00:24:42,109
而這是非常不同
方式做篩選

393
00:24:42,109 --> 00:24:46,130
比起我們通常使用在神經網路

394
00:24:46,130 --> 00:24:50,708
我想這是協議程序
將會是非常關鍵對於

395
00:24:50,708 --> 00:24:56,700
讓神經網路一般化
比起有限資料好很多

396
00:24:56,700 --> 00:24:59,797
我想這是很棒的在
改變看事情的角度

397
00:24:59,797 --> 00:25:01,500
很棒的去做分割

398
00:25:01,500 --> 00:25:04,794
我希望它會更
有統計效率比起我們

399
00:25:04,794 --> 00:25:06,147
目前在神經網路

400
00:25:06,147 --> 00:25:08,575
如果您想要
處理改變慨事情的角度

401
00:25:08,575 --> 00:25:12,000
您就給它一堆改變
視角然後全部訓練他們

402
00:25:12,000 --> 00:25:16,460
>>了解, 與其用
先進先出學習, 監督式學習

403
00:25:16,460 --> 00:25:19,120
您可以用不同方式學習這個

404
00:25:20,220 --> 00:25:24,120
>>我還是想用它
在監督式學習

405
00:25:24,120 --> 00:25:27,720
但正向的機制
是非常不同的

406
00:25:27,720 --> 00:25:32,010
它並非是純粹正向
感覺上有一點做遞迴

407
00:25:32,010 --> 00:25:36,550
您想您發現
一張嘴跟您想您發現一個鼻子

408
00:25:36,550 --> 00:25:39,127
用一些
遞迴來決定

409
00:25:39,127 --> 00:25:42,530
是否他們應該真的
在一起變成一張臉

410
00:25:42,530 --> 00:25:46,352
您可以做反向傳播
從這個遞迴

411
00:25:46,352 --> 00:25:50,286
您可以試著
做一點差異

412
00:25:50,286 --> 00:25:54,417
我們多倫多的團隊正在做這件事

413
00:25:54,417 --> 00:26:00,260
現在我有一個小的谷歌團隊
在多倫多是大腦團隊的一部份

414
00:26:00,260 --> 00:26:02,127
這是我現在很興奮的事

415
00:26:02,127 --> 00:26:02,891
>>了解了，沒錯

416
00:26:02,891 --> 00:26:05,366
非常期待這篇論文

417
00:26:05,366 --> 00:26:10,750
>>是啊, 如果出得來的話[笑]

418
00:26:10,750 --> 00:26:13,040
>>您在深度學習
幾十年

419
00:26:13,040 --> 00:26:15,330
我實在很好奇
您如何想的

420
00:26:15,330 --> 00:26:18,760
您的了解AI
在這幾年的改變?

421
00:26:20,380 --> 00:26:27,678
>>我想很多我的思考
一直圍繞著反向傳播

422
00:26:27,678 --> 00:26:33,531
如何使用反向傳播
如何使用它的力量

423
00:26:33,531 --> 00:26:36,966
所以從80年中開始
我們使用它來

424
00:26:36,966 --> 00:26:40,203
差異學習
做得很好

425
00:26:40,203 --> 00:26:42,405
然後在90年初我決定

426
00:26:42,405 --> 00:26:46,749
實際上大部分人類學習是
在非監督式學習

427
00:26:46,749 --> 00:26:50,138
我非常有興趣在
非監督式學習

428
00:26:50,138 --> 00:26:54,300
當時我做了
像Wegstein演算法

429
00:26:54,300 --> 00:26:58,306
>>而當時您的意見
真的影響我的想法

430
00:26:58,306 --> 00:27:03,010
當我領導谷歌大腦團隊
我們第一個專案花了很多

431
00:27:03,010 --> 00:27:07,900
工作在非監督式學習
因為您的影響

432
00:27:07,900 --> 00:27:09,740
>>是啊, 我也許誤導您了

433
00:27:09,740 --> 00:27:11,470
因為長期來看

434
00:27:11,470 --> 00:27:13,840
我想非監督式學習
將會是絕對關鍵

435
00:27:15,160 --> 00:27:19,376
但您要面對現實

436
00:27:19,376 --> 00:27:24,107
最近10年真正作用的
是監督式學習

437
00:27:24,107 --> 00:27:27,179
差異訓練
您有標籤

438
00:27:27,179 --> 00:27:31,810
您試著去預測
序列的下一個東西, 那也是標籤

439
00:27:31,810 --> 00:27:33,769
而那作用得非常良好

440
00:27:37,528 --> 00:27:42,266
我還是相信非監督式學習
將會是關鍵，而

441
00:27:42,266 --> 00:27:47,145
會做得比現在好很多
當我們正確得做時

442
00:27:47,145 --> 00:27:48,200
但我們還沒到那個地步

443
00:27:49,990 --> 00:27:53,225
>>是的, 我想很多資深
深度學習的人

444
00:27:53,225 --> 00:27:56,074
包括我在內
仍然保有興奮的期待

445
00:27:56,074 --> 00:28:01,513
就只是我們沒有人
有任何觀念來做它

446
00:28:01,513 --> 00:28:04,983
也許您有, 我不覺得我有

447
00:28:04,983 --> 00:28:08,160
>>差異改變編碼是
您可用來做重新參數化的技巧

448
00:28:08,160 --> 00:28:10,120
在我看來是一個很棒的主意

449
00:28:10,120 --> 00:28:15,260
生成對抗網路
對我而言似乎也是個好主意

450
00:28:15,260 --> 00:28:18,645
我想生成
對抗網路將是一個

451
00:28:18,645 --> 00:28:23,430
很大的觀念在
深度學習中且很新

452
00:28:23,430 --> 00:28:26,363
我希望我可以讓
膠囊那樣成功但

453
00:28:26,363 --> 00:28:31,740
現在而言生成對抗網路
我想有大的突破

454
00:28:31,740 --> 00:28:34,439
>>稀疏跟緩慢的特徵呢?

455
00:28:34,439 --> 00:28:38,806
這是另外兩個原則來
建立非監督性模型

456
00:28:41,556 --> 00:28:47,788
我對稀疏
不像您研究這麼深

457
00:28:47,788 --> 00:28:52,672
但緩慢特徵,我想,是個錯誤

458
00:28:52,672 --> 00:28:53,660
您不應該用緩慢這個字眼

459
00:28:53,660 --> 00:28:57,880
基本的觀念是對的但您不應該
針對沒有改變的特徵

460
00:28:57,880 --> 00:29:00,660
您應該針對
那些可預期改變的特徵

461
00:29:01,680 --> 00:29:07,060
這是基本原則
有關於您如何建模

462
00:29:08,620 --> 00:29:13,391
您拿您的測量
您用在非線性

463
00:29:13,391 --> 00:29:17,612
轉換對於您的
測量直到您得到

464
00:29:17,612 --> 00:29:22,672
一種狀態向量
而您可以用在線性方式

465
00:29:22,672 --> 00:29:26,103
您不要假裝它是線性
像您用一般的篩選器

466
00:29:26,103 --> 00:29:29,625
但您可以發現一種轉換
從觀測到

467
00:29:29,625 --> 00:29:32,616
底下的變數
是線性操作

468
00:29:32,616 --> 00:29:37,480
像是矩陣相乘到底下
變數,會做到您要的

469
00:29:37,480 --> 00:29:39,700
舉例來說
如果您想改變觀點

470
00:29:39,700 --> 00:29:42,890
如果您想要產生一個影像
從另一個觀點

471
00:29:42,890 --> 00:29:46,900
您應該做的是從
像素到座標

472
00:29:47,950 --> 00:29:50,686
一旦您進入
座標展示

473
00:29:50,686 --> 00:29:54,120
這是一種
我希望找到的

474
00:29:54,120 --> 00:29:57,350
您可以做矩陣相乘
來改變觀點

475
00:29:57,350 --> 00:29:59,210
然後您可以回到像素

476
00:29:59,210 --> 00:29:59,893
>>是啊,那是為什麼您要做這些

477
00:29:59,893 --> 00:30:02,170
>>我想這是
很一般的原則

478
00:30:02,170 --> 00:30:04,773
>>這是為什麼您做了所有
臉孔合成的事, 對嗎?

479
00:30:04,773 --> 00:30:09,355
您拿一張臉孔壓縮它
到很低維度向量

480
00:30:09,355 --> 00:30:12,450
您可以擺弄它
得到另一張臉孔

481
00:30:12,450 --> 00:30:15,950
>>我有個學生做這個
我並沒有在上面做太多

482
00:30:17,100 --> 00:30:19,180
>>我相信您還是
常常被問到這個

483
00:30:19,180 --> 00:30:23,920
如果有人想進入深度
學習,他們該怎麼做?

484
00:30:23,920 --> 00:30:25,040
您可以給一點建議?

485
00:30:25,040 --> 00:30:28,938
我相信您給予很多的建議
在一對一的情況下

486
00:30:28,938 --> 00:30:31,550
對於全球的觀眾
觀看這段影片的人

487
00:30:31,550 --> 00:30:35,999
對於進入深度學習
您有何建議?

488
00:30:35,999 --> 00:30:42,171
>>好的, 我的建議是讀一些
論文, 但不要讀太多

489
00:30:42,171 --> 00:30:48,030
所以這是我的指導老師的建議，
非常不同于大多數人所說的忠告。

490
00:30:48,030 --> 00:30:52,474
大多數人說，你應該花數
年時間，閱讀論文和

491
00:30:52,474 --> 00:30:55,421
然後你應該開始
致力於自己的想法。

492
00:30:55,421 --> 00:31:00,295
對於某些研究人員也許是對的
但對於有創意的研究人員

493
00:31:00,295 --> 00:31:03,803
您要的是讀
一些論文

494
00:31:03,803 --> 00:31:07,792
而注意到一些您
想每個人都做錯的事

495
00:31:07,792 --> 00:31:10,340
我用相反的方式

496
00:31:10,340 --> 00:31:13,568
您看它
覺得不太對勁

497
00:31:13,568 --> 00:31:15,660
然後想辦法把它弄對

498
00:31:16,890 --> 00:31:22,476
當有人告訴您
這不好, 要用原來的

499
00:31:22,476 --> 00:31:26,339
而我有ㄧ個很好的原則
來幫人們保有它

500
00:31:26,339 --> 00:31:29,996
要麼是你的直覺很好，要麼不是。

501
00:31:29,996 --> 00:31:32,030
如果你的直覺是好的你應該跟隨它們和

502
00:31:32,030 --> 00:31:34,060
你最終會成功

503
00:31:34,060 --> 00:31:36,478
如果你的直覺不是好的
你做什麼都無所謂

504
00:31:36,478 --> 00:31:40,329
>>我明白了[笑]

505
00:31:40,329 --> 00:31:43,420
真是有啟發的建議，我也許會照著做

506
00:31:43,420 --> 00:31:45,410
>> 你也要相信你的直覺。

507
00:31:45,410 --> 00:31:47,847
沒有理由不信任他們

508
00:31:47,847 --> 00:31:49,420
>> 我明白了，沒錯

509
00:31:49,420 --> 00:31:55,193
我通常建議人們不要只讀論文
要複製發表的論文

510
00:31:55,193 --> 00:31:58,161
也許會自然地
侷限您可以做多少

511
00:31:58,161 --> 00:32:00,800
因為複製結果是
相當耗時的

512
00:32:01,910 --> 00:32:05,312
是的的確，當您
想要複製出版論文

513
00:32:05,312 --> 00:32:08,100
你會發現所有必要的小
技巧來使它可行

514
00:32:08,100 --> 00:32:11,938
另一個建議是，
永遠都不要停止程式設計

515
00:32:11,938 --> 00:32:15,577
因為如果您讓一個學生做
一些事，如果他們搞砸了

516
00:32:15,577 --> 00:32:18,550
他們會回來跟您說, 它不可行

517
00:32:18,550 --> 00:32:22,030
它不可行的原因，是他們
所做的一些小的決定

518
00:32:22,030 --> 00:32:25,100
他們沒有意識到那是至關重要的

519
00:32:25,100 --> 00:32:28,850
如果您給它一個好學生
舉個例子 UY Tay

520
00:32:28,850 --> 00:32:31,120
你能給他任何東西，
他會回來，並且說，它可行

521
00:32:32,670 --> 00:32:36,420
我記得有一次，
我說, 稍等一下

522
00:32:36,420 --> 00:32:37,330
UY 自從我們上次談完之後

523
00:32:37,330 --> 00:32:40,380
您說我意識到這並不可行
因為以下原因

524
00:32:40,380 --> 00:32:43,586
然後UY說，我立刻意識到說
我以為你不是那個意思

525
00:32:43,586 --> 00:32:47,627
>>[笑]了解了，沒錯

526
00:32:47,627 --> 00:32:51,575
有沒有其他建議對於

527
00:32:51,575 --> 00:32:57,782
人們想要進入AI或者
深度學習

528
00:32:57,782 --> 00:33:02,000
>>我想基本上, 讀足夠後
開始從直覺開發

529
00:33:02,000 --> 00:33:05,811
然後，信任你的直覺，
就去做

530
00:33:05,811 --> 00:33:10,783
不要太擔心，如果別人說
這是一派胡言

531
00:33:10,783 --> 00:33:14,352
>>我猜沒有其他方法
去知道別人是對

532
00:33:14,352 --> 00:33:19,950
或錯當他們說一派胡言, 但您
就是去做然後,再來發現是對或錯

533
00:33:19,950 --> 00:33:24,350
>> 是吧，但是有這麼回事，就是，
如果你認為它是個很好的主意

534
00:33:24,350 --> 00:33:27,201
而其他人告訴您
這完全是一派胡言

535
00:33:27,201 --> 00:33:29,761
那您知道您
真的在一件很重要的事情上

536
00:33:29,761 --> 00:33:33,960
一個例子是當
我第一次想到差異方法

537
00:33:35,420 --> 00:33:40,690
我送電子郵件去一位以前
學生叫 Peter Brown

538
00:33:40,690 --> 00:33:42,560
他知道很多EN這方面的知識

539
00:33:43,570 --> 00:33:46,967
他拿給跟他
一起工作的人看

540
00:33:46,967 --> 00:33:51,253
稱他為兄弟
他們是雙胞胎

541
00:33:51,253 --> 00:33:55,914
然後他後來告訴我
他們說

542
00:33:55,914 --> 00:34:00,277
這傢伙不是喝醉了
就是太傻了

543
00:34:00,277 --> 00:34:04,260
他們真的
覺得是一派胡言

544
00:34:04,260 --> 00:34:06,460
也許部分的原因
是我的解釋它的方式

545
00:34:06,460 --> 00:34:08,043
因為我用直覺的方式來解釋

546
00:34:09,150 --> 00:34:13,100
但是當你有你
認為是一個好主意時

547
00:34:13,100 --> 00:34:16,810
其他人覺得是垃圾的時候
那是一個很好的跡象

548
00:34:18,026 --> 00:34:21,555
>>我明白了, 而研究主題

549
00:34:21,555 --> 00:34:26,183
新研究生應該
研究膠囊

550
00:34:26,183 --> 00:34:30,707
或是非監督式學習, 還是其他?

551
00:34:30,707 --> 00:34:34,078
>>對於新研究生的
一個忠告

552
00:34:34,078 --> 00:34:38,344
看是否能找到指導老師
跟您相信的一致

553
00:34:38,344 --> 00:34:42,637
因為如果您做的東西
您指導教授深深覺得可行

554
00:34:42,637 --> 00:34:47,170
您會得到很好的建議跟
時間從您的指導教授

555
00:34:47,170 --> 00:34:50,590
如果您做的東西您的
指導老師沒有興趣

556
00:34:50,590 --> 00:34:55,262
您得到的會是一些建議
但幾乎不會有所幫助

557
00:34:55,262 --> 00:34:58,386
>>了解,
最後給一些建議給學生

558
00:34:58,386 --> 00:35:02,440
您覺得一個人
去拿博士學位?

559
00:35:02,440 --> 00:35:09,687
或者是去大公司
或是去大的研究單位?

560
00:35:09,687 --> 00:35:13,890
>>這個很複雜
我想現在,正在發生的是

561
00:35:13,890 --> 00:35:18,727
沒有足夠的深度學習的學院訓練在
來教育所有人們

562
00:35:18,727 --> 00:35:21,125
在大學所需的教育

563
00:35:21,125 --> 00:35:25,011
就是沒有足夠的
師資

564
00:35:25,011 --> 00:35:27,780
但我想這是短期的問題

565
00:35:27,780 --> 00:35:32,410
我想
大部分的科系已經慢慢的

566
00:35:32,410 --> 00:35:34,890
理解這種
革命正在發生

567
00:35:34,890 --> 00:35:38,720
我有點同意您, 這不像
二次工業革命, 但

568
00:35:38,720 --> 00:35:41,000
是是差不多的規模

569
00:35:41,000 --> 00:35:43,691
這是一個海洋般巨大的改變

570
00:35:43,691 --> 00:35:47,980
基本上因為我們與電腦的關係
發生了變化。

571
00:35:47,980 --> 00:35:53,920
與其用程式設計他們，
我們現在展示給它們，讓它們自己弄明白

572
00:35:53,920 --> 00:35:56,570
這是完全不同的
方式使用電腦，而

573
00:35:56,570 --> 00:36:01,210
電腦科學系都是圍繞
電腦程式設計的想法

574
00:36:01,210 --> 00:36:03,480
他們不明白的是

575
00:36:05,000 --> 00:36:09,330
這樣展示給電腦將會跟
電腦程式設計一樣大

576
00:36:09,330 --> 00:36:13,940
除了他們不了解一半科系的人
應該是

577
00:36:13,940 --> 00:36:16,510
讓電腦做
那些顯示給電腦事情的人

578
00:36:16,510 --> 00:36:22,183
所以我的部門拒絕承認
要很多很多

579
00:36:22,183 --> 00:36:24,790
人做這件事

580
00:36:24,790 --> 00:36:28,730
他們想一些
也許少數，但不要太多

581
00:36:31,260 --> 00:36:32,452
而在這種狀況下

582
00:36:32,452 --> 00:36:36,510
您必須提醒大公司
要做很多的培訓

583
00:36:36,510 --> 00:36:40,335
谷歌現在訓練人
我們稱為大腦居民

584
00:36:40,335 --> 00:36:43,792
我懷疑大學
終究會趕上來

585
00:36:43,792 --> 00:36:48,360
>>了解, 實際上, 也許很多
學生已經發現了

586
00:36:48,360 --> 00:36:53,131
很多頂尖50大學
超過一半確實是

587
00:36:53,131 --> 00:36:57,079
希望工作於展示
而不是程式設計

588
00:36:57,079 --> 00:37:00,720
是的很酷，是的事實上，
把功勞歸到哪

589
00:37:00,720 --> 00:37:04,930
應該是深度學習AI創造了
深度學習的專業化

590
00:37:04,930 --> 00:37:09,239
就我所知，他們第一次深度
學習公開課是實際上你

591
00:37:09,239 --> 00:37:11,752
在Coursera的課, 在2012年

592
00:37:12,828 --> 00:37:14,430
而奇怪的是

593
00:37:14,430 --> 00:37:18,900
那剛好是您第一次出版RMS
演算法, 也是相當的挑戰

594
00:37:20,240 --> 00:37:25,910
>>是的, 如您所知
那是因為您邀我做公開課

595
00:37:25,910 --> 00:37:30,239
然後很懷疑這樣做的時候
，你推我做到這一點，所以

596
00:37:30,239 --> 00:37:34,340
它是很棒的
雖然它是很多的工作

597
00:37:34,340 --> 00:37:37,409
>>是的, 謝謝您的幫忙
我記得您向我抱怨過

598
00:37:37,409 --> 00:37:38,351
它是多麼多的工作

599
00:37:38,351 --> 00:37:42,413
讓您很多次熬夜工作
但我想很多很多學生

600
00:37:42,413 --> 00:37:47,330
從您第一個公開課獲益
所以我很感謝您

601
00:37:47,330 --> 00:37:49,260
>>，很好，是 >> 是的多年來

602
00:37:49,260 --> 00:37:53,290
我看到您被牽連到
有關人工智慧的典範爭論中

603
00:37:53,290 --> 00:37:57,030
是否已經是人工智慧的典範轉移

604
00:37:57,030 --> 00:37:59,984
您可以分享您的想法嗎?

605
00:37:59,984 --> 00:38:05,157
>>是的很高興,我想在
早期, 回到50年代

606
00:38:05,157 --> 00:38:10,335
人們像 von Neumann跟Turing
並不相信符號人工智慧

607
00:38:10,335 --> 00:38:14,220
他們遠從人腦啟發

608
00:38:14,220 --> 00:38:20,127
不幸的是，他們都太早逝，
聽不到他們的聲音。

609
00:38:20,127 --> 00:38:21,806
在早期的 AI，

610
00:38:21,806 --> 00:38:26,259
人們完全相信
您需要

611
00:38:26,259 --> 00:38:30,500
智慧的表現是符號
運算式

612
00:38:30,500 --> 00:38:35,509
一種清理過的邏輯，您可以
做非單調邏輯, 並不是

613
00:38:35,509 --> 00:38:41,143
邏輯, 但像是邏輯但那是
推理智慧的本質

614
00:38:41,143 --> 00:38:45,662
現在發生的是
發生完全不同的觀點

615
00:38:45,662 --> 00:38:50,984
這就是所謂的思考, 亦即
一個大的神經活動向量

616
00:38:50,984 --> 00:38:55,200
對比於思考
是符號運算

617
00:38:55,200 --> 00:38:59,087
我想人們想
思考是符號運算是

618
00:38:59,087 --> 00:39:00,140
一個巨大的錯誤

619
00:39:01,210 --> 00:39:07,030
從一個字串進來, 然後
出去一個字串

620
00:39:08,140 --> 00:39:12,580
因為這樣,字串
變成明顯的方式還代表事情

621
00:39:12,580 --> 00:39:15,710
所以他們想一定是
中間也是字串

622
00:39:15,710 --> 00:39:18,360
或者像字串一般

623
00:39:18,360 --> 00:39:21,310
而我想的是中間
一點都不像是字串

624
00:39:21,310 --> 00:39:26,060
我想的是思考應該是
一種語言笨得像

625
00:39:26,060 --> 00:39:30,980
用這種觀念來了解
空間場景

626
00:39:30,980 --> 00:39:34,280
應該是像素, 像素進來

627
00:39:34,280 --> 00:39:37,930
而如果我們可以, 如果有點
矩陣印表機連接

628
00:39:37,930 --> 00:39:41,929
那像素會印出來, 但
中間並不是像素

629
00:39:43,210 --> 00:39:46,620
所以我想思考是
這些巨大的向量, 而

630
00:39:46,620 --> 00:39:48,460
這個巨大的向量有因果能力

631
00:39:48,460 --> 00:39:50,490
他們能導致其他巨大的向量

632
00:39:50,490 --> 00:39:56,100
這是完全不像標準AI的看法
思考是符號運算

633
00:39:56,100 --> 00:39:56,700
>> 明白，太好了

634
00:39:57,740 --> 00:40:01,560
我猜AI應該會走到
這樣的觀點最近的日子

635
00:40:01,560 --> 00:40:02,660
>>有一些

636
00:40:02,660 --> 00:40:08,230
我想很多AI的人還是
想著符號雲算

637
00:40:08,230 --> 00:40:09,780
>> 非常感謝你做這個採訪

638
00:40:09,780 --> 00:40:12,970
聽到這麼迷人的深度
學習如何發展這幾年來

639
00:40:12,970 --> 00:40:17,680
同時聽到我們如何朝向未來
謝謝您, Geoff

640
00:40:17,680 --> 00:40:19,038
>> 好的，謝謝你給我這個機會。

641
00:40:19,038 --> 00:40:20,147
謝謝