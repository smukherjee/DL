1
00:00:00,000 --> 00:00:03,339
여러 가지 문제에서 심층신경망이 잘
작동한다고 많이 들었을텐데요,

2
00:00:03,339 --> 00:00:07,073
단순히 신경망의 크기가 커서 되는 것이 아닙니다.

3
00:00:07,073 --> 00:00:10,718
신경망 네트워크는 깊고, 숨겨진 레이어가 많아야 합니다.

4
00:00:10,718 --> 00:00:12,208
왜 그런걸까요?

5
00:00:12,208 --> 00:00:15,833
몇개의 예제를 통해
직관을 얻겠습니다.

6
00:00:15,833 --> 00:00:17,720
왜 깊은 네트워크가 잘 작동하는지 말이죠.

7
00:00:17,720 --> 00:00:22,181
첫째로,
깊은 네트워크는 무엇을 계산하죠?

8
00:00:22,181 --> 00:00:25,393
여러분이 얼울 인식 또는 얼굴

9
00:00:25,393 --> 00:00:29,631
감지 시스템을 만들때,
심층 신경망이 하는 일은 이렇습니다.

10
00:00:29,631 --> 00:00:35,059
아마도 얼굴 사진을 넣었을때에,
첫번째 층의 신경망은

11
00:00:35,059 --> 00:00:40,000
feature detector 또는 edge detector같은 것일수도 있겠죠.

12
00:00:40,000 --> 00:00:45,519
이번 예제에서는, 이 이미지에서

13
00:00:45,519 --> 00:00:48,017
아마 20개의 숨겨진 유닛을 통해 신경망이
계산을 하는 것을 그린 것인데요.

14
00:00:48,017 --> 00:00:52,357
여기 사각형의 박스로 20개의 숨겨진 유닛이
시각화 시킵니다.

15
00:00:52,357 --> 00:00:57,325
예를 들어서, 여기 이 작은 visualization은

16
00:00:57,325 --> 00:01:01,978
숨겨진 유닛이 끝의 모서리가 어딘지
이 이미지에서 파악하려는 것입니다.

17
00:01:01,978 --> 00:01:05,914
이 숨겨진 유닛은

18
00:01:05,914 --> 00:01:09,955
가로 모서리가 어디인지 파악하려고
할 수 있게죠.

19
00:01:09,955 --> 00:01:13,184
나중의 코스에서
컨볼루션 신경망 에 대해 이야기 할 텐데요,

20
00:01:13,184 --> 00:01:16,129
이러한 시각화에 대한 내용이
이후에 더 이해가 빨리 되실 것입니다.

21
00:01:16,129 --> 00:01:19,562
공식적으로 말씀드리자면,
신경망의 첫번째 층은

22
00:01:19,562 --> 00:01:22,690
이 이미지를 보고
어디가 모서리인지 파악하려고 하는
것이라고 볼 수 있습니다.

23
00:01:22,690 --> 00:01:27,356
이제 픽셀을 같이 그루핑하여

24
00:01:27,356 --> 00:01:28,730
모서리를 구성할텐데요, 이를 통해
모서리를 파악하는 것입니다.

25
00:01:28,730 --> 00:01:34,670
그 이후로, 파악된 모서리에 대해
모서리들을 그룹으로 만들고,
얼굴의 일부를 만들어 나갑니다.

26
00:01:34,670 --> 00:01:40,289
예를 들어, 신경세포가
눈을 탖으려고 할 수 있습니다.

27
00:01:40,289 --> 00:01:44,480
또는, 다른 신경세포가
여기 이부분의 코를 찾으려고 할 수도 있고요.

28
00:01:44,480 --> 00:01:47,463
이렇게, 모서리들을 취합하는 과정을 통해

29
00:01:47,463 --> 00:01:50,970
얼굴의 다른 부분들을 감지할 수 있는 것입니다.

30
00:01:50,970 --> 00:01:56,035
그렇게하여 최종적으로는 여러 얼굴부위를
합치게 되는 것인데요,

31
00:01:56,035 --> 00:02:01,006
눈, 코, 귀, 또는 턱 이렇게 말이죠.
그 이후로, 다른 얼굴들의

32
00:02:01,006 --> 00:02:03,564
유형을 인식하거나 감지할 수 있게 됩니다.

33
00:02:03,564 --> 00:02:07,755
직관적으로, 이런 초기의 층을

34
00:02:07,755 --> 00:02:10,190
간단한 모서리와 같은 함수를 감지하는 것이라고
생각할 수 있습니다.

35
00:02:10,190 --> 00:02:14,573
그리고나서, 다음 단계의 신경 층에서 이런
내용을 취합할 수 있습니다.

36
00:02:14,573 --> 00:02:17,625
그렇게해서 더욱 복잡한 함수를
배울 수 있는것이죠.

37
00:02:17,625 --> 00:02:23,640
컨볼루션얼 신경망에 대한 내용을 나중에 다룰 때
이런 시각화 내용을 더 빨리 이해하실 수 있을것입니다.

38
00:02:23,640 --> 00:02:26,203
시각화의 기술적인 내용중 하나는,

39
00:02:26,203 --> 00:02:29,802
이러한 모서리 감지 기능이
이미지의 조금한 부분을 볼텐데요,

40
00:02:29,802 --> 00:02:31,703
이런 아주 조금한 이미지 범위 말이죠.

41
00:02:31,703 --> 00:02:36,616
그리고나서, 얼굴 인식기능은
조금 더 큰 이미지 부분을 볼 수 있겠습니다.

42
00:02:36,616 --> 00:02:41,308
이 부분에서 기억하실 것은
일단 먼저 이미지에서 간단한 것들을 찾은 뒤에,

43
00:02:41,308 --> 00:02:43,675
모서리와 같은 것 말이죠, 그 다음에 취합하는 것입니다.

44
00:02:43,675 --> 00:02:47,216
이러한 부분들을 합쳐서 조금 더 복잡한 것들을
감지할 수 있습니다. 눈과 코같은 부위 말이죠.

45
00:02:47,216 --> 00:02:50,530
그리고 이런 부위를 또 합쳐서
더욱 복잡한 내용도 감지할 수 있는 것입니다.

46
00:02:50,530 --> 00:02:55,665
이러한 복잡한 계층적인 representation이

47
00:02:55,665 --> 00:02:58,508
또는 compositional representation이

48
00:02:58,508 --> 00:03:04,114
이미지 또는 얼굴 인식 분야외에도
다른 분야의 데이터에도 적용됩니다.

49
00:03:04,114 --> 00:03:08,593
예를 들어, 여러분이 음성 인식 시스템을
만드는 경우에,

50
00:03:08,593 --> 00:03:10,908
음성을 시각화하기는 쉽지 않지만,

51
00:03:10,908 --> 00:03:15,684
오디오 음성 파일을 삽입하면,
첫번째 층의 신경망이

52
00:03:15,684 --> 00:03:20,863
낮은 레벨 음성 wave 형식을
감지하도록 배울 수 있습니다.
예를 들어, 이 톤이 올라가는 것인지

53
00:03:20,863 --> 00:03:21,703
내려가는지 감지하는 것과 같이 말이죠.

54
00:03:21,703 --> 00:03:26,869
백색소음인지, slithering 음성인지,

55
00:03:26,869 --> 00:03:27,903
또는 피치는 어떤지 감지할 수 있습니다.

56
00:03:27,903 --> 00:03:31,124
이렇게 low level wave form 특성들을
감지할 수 있도록 가르칠 수 있습니다.

57
00:03:31,124 --> 00:03:34,233
기 이후에, low level wave forms를 취합하여

58
00:03:34,233 --> 00:03:37,937
기본적인 음성유닛을 감지할 수 있도록 만들 수 있습니다.

59
00:03:37,937 --> 00:03:40,297
음성학에서는 이것을 phonemes라고 하는데요.

60
00:03:40,297 --> 00:03:45,098
예를 들어, cat이라는 단어에서 C가 phoneme이고
A가 phoneme입니다

61
00:03:45,098 --> 00:03:46,787
T도 또 하나의 phoneme입니다.

62
00:03:46,787 --> 00:03:49,987
이렇게 기본 음성 유닛을 감지하도록 배울 수 있고요,

63
00:03:49,987 --> 00:03:54,688
이러한 phoneme을 취합하여
단어를 알아듣게 만들 수 있습니다.

64
00:03:54,688 --> 00:03:58,270
그리고 단어를 합쳐서

65
00:03:58,270 --> 00:04:02,912
전체 문구를 이해하거나 문장들을 이해할 수도 있겠죠.

66
00:04:02,912 --> 00:04:07,572
그러므로 복수의 숨겨진 레이어가 있는 심층신경망 같은 경우,

67
00:04:07,572 --> 00:04:10,477
초기의 층에서는 이런 낮은 레벨의
간단한 특성들을 배울 수 있게 만들고,

68
00:04:10,477 --> 00:04:15,339
나중에 따라오는 층에서는 감지된
이런 간단한 것들을 합칠 수 있게 하고,

69
00:04:15,339 --> 00:04:19,392
조금 더 복잡한 단어나 문구 또는

70
00:04:19,392 --> 00:04:21,040
문장들, 발음을 감지할 수 있도록 만듭니다.

71
00:04:21,040 --> 00:04:24,745
음성인식 기능을 수행하기 위해서 말이죠.

72
00:04:24,745 --> 00:04:30,168
저희가 볼 수 있는 것은 첫번째 초기 단계에서는

73
00:04:30,168 --> 00:04:35,673
입력값에 대한 간단한 함수를,
예를 들어 모서리 관한 정보를 다루겠지만

74
00:04:35,673 --> 00:04:41,046
네트워크 깊숙히 진입하면
놀랍게도 복잡한 것들을 다루게 됩니다.

75
00:04:41,046 --> 00:04:44,876
얼굴을 감지하거나, 단어를 감지하거나,
문구 또는 문장까지 말이죠.

76
00:04:44,876 --> 00:04:48,767
어떤 사람들은 심승신경망을

77
00:04:48,767 --> 00:04:52,656
인간의 두뇌로 비유하는데요, 저희가 믿는 내용과,
신경과학자들이 생각하는 것은

78
00:04:52,656 --> 00:04:57,162
인간의 두뇌도 일단 먼저 간단한 것을
모서리나, 눈이 보는 어떠한 내용을

79
00:04:57,162 --> 00:05:00,370
시작으로 점점 취합한다는 점입니다.

80
00:05:00,370 --> 00:05:02,440
조금 더 복잡한 얼굴과도 같은 것 말이죠.

81
00:05:02,440 --> 00:05:05,038
딥러닝과 인간 두놔의

82
00:05:05,038 --> 00:05:08,276
비유는 간혹 위험하다고 생각은 드는데요,

83
00:05:08,276 --> 00:05:13,301
인간의 두뇌가 어떤 원리로 사물을 받아들이는지와

84
00:05:13,301 --> 00:05:18,102
간단한 것들을 먼저 시작으로

85
00:05:18,102 --> 00:05:22,598
정보들을 취합하여 더 복잡한
물체를 만들어 간다는 점에서

86
00:05:22,598 --> 00:05:27,430
딥러닝 분야에서 느슨한 영감을 준 것은
사실입니다.

87
00:05:27,430 --> 00:05:29,850
인간의 두뇌에 대해서,

88
00:05:29,850 --> 00:05:33,065
생물한적 뇌에 대한 내용은
다음주에 더 다루도록 하겠습니다.

89
00:05:35,534 --> 00:05:40,407
심층 네트워크가 왜 더 잘 작동하는지에 대한

90
00:05:40,407 --> 00:05:42,756
직관적인 부분이 또 한가지 더 있는데요,

91
00:05:42,756 --> 00:05:47,868
이 결과는 circuit theory에서 유래되는데요,
다른 logic gates에 대해 어떤 유형의

92
00:05:47,868 --> 00:05:53,760
함수를 쓸 수 있는지에 대한 생각을 담았습니다.

93
00:05:53,760 --> 00:05:58,860
비공식적으로, 이 함수들은
작지만 깊은 네트워크로 계산하는데요,

94
00:05:58,860 --> 00:06:03,595
여기서 작다고 하는 것은
숨겨진 유닛이 비교적 작다는 뜻입니다.

95
00:06:03,595 --> 00:06:07,553
같은 함수를 얇은 네트워크로
계산하려고 하면,

96
00:06:07,553 --> 00:06:09,178
즉, 숨겨진 레이어 가 충분하지 않으므로

97
00:06:09,178 --> 00:06:13,296
계산을 하기 위해서는 기하급수적으로 많은
숨겨진 레이어의 수가 필요할 것입니다.

98
00:06:13,296 --> 00:06:18,109
한가지 예제를 통해 한번 보여드리겠습니다.

99
00:06:18,109 --> 00:06:21,423
여러분이 exclusive or를 계산하려고 한다 해보겠습니다.

100
00:06:21,423 --> 00:06:23,349
입력특성 값의 차이를 구하는 것입니다.

101
00:06:23,349 --> 00:06:28,430
즉 x1, xor, x2, xor

102
00:06:28,430 --> 00:06:33,064
x3, xor, xn까지 계산하려고 합니다.
n 또는 nx개의 특성이 있는 경우 말이죠.

103
00:06:33,064 --> 00:06:39,924
xor tree를 이렇게 그리면,
xor1에서 x1과

104
00:06:39,924 --> 00:06:44,586
x2를 갖고, x3와 x4에 대해서 또
xor을 계산합니다.

105
00:06:44,586 --> 00:06:49,392
엄밀히 이야기하면, AND 와 NOT 게이지를 이용하는 경우,

106
00:06:49,392 --> 00:06:54,196
XOR 함수를 계산하는데 2개정도의 층이 필요할 수 있습니다.

107
00:06:54,196 --> 00:06:58,791
하지만 비교적 작은 circuit에서는
XOR를 계산할 수 있습니다.

108
00:06:58,791 --> 00:07:03,987
그 다름에 XOR tree를 이와 같이 그릴 수 있습니다.

109
00:07:03,987 --> 00:07:12,090
이렇게 Y라는 결과값을 주는 circuit을
만들 때까지 말이죠.

110
00:07:12,090 --> 00:07:15,236
y hat은 Y입니다.

111
00:07:15,236 --> 00:07:18,398
exclusive or 또는 parity of all these input입니다.

112
00:07:18,398 --> 00:07:24,790
XOR 를 계산하기 위해서는 네트워크의 깊이는
order of log N일 것입니다.

113
00:07:24,790 --> 00:07:27,410
이런 XOR tree의 경우 말이죠.

114
00:07:27,410 --> 00:07:30,836
그러므로 노드의 개수,
circuit components 개수, 또는

115
00:07:30,836 --> 00:07:33,929
gates 숫자는 여기 네트워크에서는 그리 많지 않습니다.

116
00:07:33,929 --> 00:07:38,452
exclusive OR를 계산하기 위해서 그리 많은
gates를 요하지 않습니다.

117
00:07:38,452 --> 00:07:43,458
그러나 만약 복수의 숨겨진 레이어가 있는 신경망을

118
00:07:43,458 --> 00:07:48,203
사용할 수 없는 경우,
이 경우는 order log and 숨겨진 레이어s 인데요

119
00:07:48,203 --> 00:07:53,382
하나의 숨겨진 레이어로 함수를 계산해야하는 경우,

120
00:07:53,382 --> 00:07:57,912
여기 이 것들이 특정 숨겨진 유닛으로 가는 것인데요,

121
00:07:57,912 --> 00:08:02,116
그러면 이 것들은 Y를 결과값으로 줍니다.

122
00:08:02,116 --> 00:08:07,120
XOR 함수의 parity를 계산하기 위해서는

123
00:08:07,120 --> 00:08:12,124
여기 숨겨진 레이어가 기하급수적으로 커야할 것입니다.

124
00:08:12,124 --> 00:08:18,397
2의 n승의 배열을 열거해하기 때문이죠

125
00:08:18,397 --> 00:08:23,139
즉, 2의 n승입니다,
가능한 입력값의 배치인데요,

126
00:08:23,139 --> 00:08:27,898
exclusive or 가 1또는 0이 되는 경우입니다.

127
00:08:27,898 --> 00:08:32,213
결과적으로 숨겨진 레이어가
기하급수적으로 큰 값이 필요하게 됩니다.

128
00:08:32,213 --> 00:08:33,554
bit의 단위로 말이죠

129
00:08:33,554 --> 00:08:38,229
제가 생각하기엔,
엄밀히 맒하면 이것은 2의 n-1승으로 할 수 있을 것입니다.

130
00:08:38,229 --> 00:08:43,948
이것은 order 2의 n승인데요,
기하급수적으로 큰 number of bits입니다.

131
00:08:43,948 --> 00:08:49,149
앞서 다룬 내용을 통해
더 깊은 네트워크가 얇은 네트워크보다

132
00:08:49,149 --> 00:08:55,275
더 쉽게 계산할 수 있는 수학적 함수가 있다는 것을
알게해준 계기가 됐길 바랍니다

133
00:08:55,275 --> 00:09:01,028
저도 인정해야하는데요,
직관적으로 도움을 주는 부분에 대해서는
circuit theory가 덜

134
00:09:01,028 --> 00:09:05,985
도움이 되었습니다. 하지만 이 방법이
여러 사람들이

135
00:09:05,985 --> 00:09:11,223
인용하는 값들인데요,
깊은 네트워크를 대표해서 설명할 때 말이죠.

136
00:09:11,223 --> 00:09:13,600
깊은 네트워크를 선호하는 것에 대한

137
00:09:13,600 --> 00:09:16,897
이런 이유 말고도,

138
00:09:16,897 --> 00:09:22,204
다른 이유는 사실 솔직히 말씀드리면
브랜딩의 효과인 것 같습니다.

139
00:09:22,204 --> 00:09:26,776
이전에는 숨겨진 레이어가 많은 신경망이라고 했었는데요,

140
00:09:26,776 --> 00:09:31,198
"딥 러닝" 이라는 용어가 굉장히 훌륭한 브랜딩입니다.
굉장히 "deep"하게 다가오기 때문입니다.

141
00:09:31,198 --> 00:09:36,284
이 단어가 익숙해지자
신경망이 rebranding 되었습니다.

142
00:09:36,284 --> 00:09:39,622
숨겨진 레이어가 많은 신경망이라는 이름이
rebranding 된 것이죠.

143
00:09:39,622 --> 00:09:42,970
인기가 많은 상상에 대한 부분도 사로잡았습니다.

144
00:09:42,970 --> 00:09:47,479
PR brading 을 감안하지 않더라도,
딥네트워크는 작 작동합니다.

145
00:09:47,479 --> 00:09:51,342
가끔 사람들은 오버해서
굉장히 많은 양읜 숨겨진 레이어를 사용하기 권고하는데,

146
00:09:51,342 --> 00:09:55,500
새로운 문제를 시작하는 경우에
저는 주로

147
00:09:55,500 --> 00:09:58,803
심지어 로지스틱 회귀분석으로 시작합니다.
그 다음으로 한개 또는

148
00:09:58,803 --> 00:10:01,722
2개의 숨겨진 레이어를 시도하고요
그 다음 그것을 하이퍼 파라미터로 이용하는 것이죠.

149
00:10:01,722 --> 00:10:05,731
그것을 하이퍼 파라미터도 이용하거나,
튜닝을 하기 위한 파라미터로 사용해서

150
00:10:05,731 --> 00:10:07,935
신경망에 적합한 깊이를 찾아내는 것입니다.

151
00:10:07,935 --> 00:10:12,800
지난 몇 년간 특정 어플에서는

152
00:10:12,800 --> 00:10:17,590
아주 굉장히 깊은 신경망 네트워크와
수 많은 숨겨진 레이어로 구성되어 있는 것이

153
00:10:17,590 --> 00:10:22,264
가끔은 가장 좋은 모델로 쓰이는 것이
트렌드화 되었습니다.

154
00:10:22,264 --> 00:10:27,605
이것으로 딥러닝이 왜 잘 작동하는지에 대한
직관적인 부분은 모두 설명해 드렸는데요,

155
00:10:27,605 --> 00:10:31,411
이제는 전 방향전파에서 뿐만 아니라

156
00:10:31,411 --> 00:10:33,769
후 방향전파에서도 도입할 수 있는 과정을 살펴보겠습니다.