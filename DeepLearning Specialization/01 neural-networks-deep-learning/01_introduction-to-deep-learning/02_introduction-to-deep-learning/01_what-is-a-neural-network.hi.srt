1
00:00:01,050 --> 00:00:03,840
टर्म डीप लर्निंग का मतलब है ट्रेन करना 
न्यूरल नेटवर्क्स को

2
00:00:03,840 --> 00:00:06,050
कई बार बहुत बड़े न्यूरल नेटवर्क को.

3
00:00:06,050 --> 00:00:08,400
तो क्या है वास्तव में एक न्यूरल नेटवर्क?

4
00:00:08,400 --> 00:00:11,340
इस वीडियो में, चलो आप को एक मूल 
अनुभव देने की कोशिश करते हैं.

5
00:00:12,850 --> 00:00:16,540
चलो शुरू करते हैं घर की क़ीमत प्रिडिक्ट करने के उदाहरण से.

6
00:00:16,540 --> 00:00:20,599
मान लो आपके पास है एक डेटा सेट छः घरों का, 
तो आप जानते हैं साइज़ घरों का

7
00:00:20,599 --> 00:00:24,478
स्क्वेर फ़ीट या स्क्वेर मीटर में और आप जानते हैं 
क़ीमत घर की और आप चाहते हैं

8
00:00:24,478 --> 00:00:28,501
फ़िट करना एक फ़ंक्शन प्रिडिक्ट करने के
 लिए क़ीमत घरों की, जो साइज़ का फ़ंक्शन है.

9
00:00:28,501 --> 00:00:33,509
तो यदि आप परिचित हैं लिनीअर रेग्रेशन से 
आप शायद कहें, ठीक है, चलो

10
00:00:33,509 --> 00:00:38,450
डालते हैं एक सीधी लाइन इस डेटा में तो 
और हमें मिलती है एक लाइन उस तरह की.

11
00:00:38,450 --> 00:00:41,850
लेकिन जानते हुए, आप शायद कहें ठीक है 
हम जानते हैं कि क़ीमतें

12
00:00:41,850 --> 00:00:43,770
कभी नेगेटिव नहीं हो सकती, ठीक है.

13
00:00:43,770 --> 00:00:48,050
तो बजाय सीधी लाइन फ़िट के, 
जो अन्तत: नेगेटिव हो जाएगी,

14
00:00:48,050 --> 00:00:49,960
चलो थोड़ा मोड़ देते हैं कर्व को यहाँ.

15
00:00:49,960 --> 00:00:51,530
तो यह हो जाता है ज़ीरो यहाँ.

16
00:00:51,530 --> 00:00:56,770
तो यह मोटी लाइन यहाँ बन जाती है 
आपका फ़ंक्शन करने के लिए

17
00:00:56,770 --> 00:00:59,760
प्रिडिक्ट क़ीमत घर की जो है फ़ंक्शन इस साइज़ का.

18
00:00:59,760 --> 00:01:03,310
जबकि ज़ीरो यहाँ और फिर वहाँ है एक सीधी लाइन है 
फ़िट की हुई दाईं तरफ़.

19
00:01:04,408 --> 00:01:08,735
तो आप सोच सकते है इस फ़ंक्शन को जो अपने 
अभी फ़िट किया है घर कि क़ीमत के लिए

20
00:01:08,735 --> 00:01:11,880
एक बहुत सरल न्यूरल नेटवर्क की तरह.

21
00:01:11,880 --> 00:01:14,230
यह लगभग उतना सरल है जितना सम्भव 
न्यूरल नेटवर्क हो सकता है.

22
00:01:14,230 --> 00:01:15,000
चलो मैं बनाता हूँ यहाँ.

23
00:01:17,220 --> 00:01:22,170
हमारे पास है न्यूरल नेटवर्क को इनपुट 
साइज़ एक घर का जिसे हमें कहँगे x.

24
00:01:22,170 --> 00:01:26,791
यह जाता है इस नोड में, यह छोटा वृत्त और

25
00:01:26,791 --> 00:01:30,940
फिर यह आउट्पुट करता है क़ीमत जिसे हम कहते हैं y.

26
00:01:30,940 --> 00:01:37,183
तो यह छोटा वृत्त, जो है एक अकेला न्यूरॉन 
एक न्यूरल नेटवर्क में,

27
00:01:37,183 --> 00:01:41,830
जो इम्प्लमेंट करता है इस फ़ंक्शन को जो हमने बनाया बाईं तरफ़.

28
00:01:43,350 --> 00:01:48,940
और न्यूरॉन सिर्फ़ इनपुट करता है साइज़, कम्प्यूट करता है 
यह लिनीअर फ़ंक्शन,

29
00:01:48,940 --> 00:01:51,960
लेता है अधिकतम शून्य का और फिर 
आउट्पुट करता है अनुमानित क़ीमत.

30
00:01:53,190 --> 00:01:58,230
और वैसे तो न्यूरल नेटवर्क साहित्य में, 
आप देखेंगे यह फ़ंक्शन बहुत बार.

31
00:01:58,230 --> 00:02:00,992
यह फ़ंक्शन जो होता है ज़ीरो कभी और

32
00:02:00,992 --> 00:02:03,550
फिर यह बनेगा एक सीधी रेखा.

33
00:02:03,550 --> 00:02:09,108
इस फ़ंक्शन को कहते हैं एक RELU फ़ंक्शन 
जिसका मतलब है

34
00:02:09,108 --> 00:02:17,620
रेक्टिफ़ायड लिनीअर यूनिट्स.

35
00:02:17,620 --> 00:02:18,252
इसलिए, R-E-L-U. और

36
00:02:18,252 --> 00:02:22,520
रेक्टिफ़ाई का सिर्फ़ मतलब है लेना अधिकतम 0 
जिस वजह से आपको मिलता है 
एक फ़ंक्शन का आकार इस तरह का.

37
00:02:23,640 --> 00:02:25,550
आपको RELU यूनिट्स के बारे में चिंता करने की जरूरत नहीं है

38
00:02:25,550 --> 00:02:30,200
अभी लेकिन यह है सिर्फ़ कुछ जो आप 
देखेंगे बाद में इस कोर्स में.

39
00:02:30,200 --> 00:02:33,790
तो यदि यह है एक अकेला न्यूरॉन, न्यूरल नेटवर्क,

40
00:02:33,790 --> 00:02:38,870
वास्तव में एक बहुत छोटा न्यूरल नेटवर्क, 
एक इससे बड़ा न्यूरल नेटवर्क

41
00:02:38,870 --> 00:02:44,520
तब बनता है लेने से बहुत से पृथक न्यूरॉन्स 
और स्टैक करने से उन्हें एक साथ.

42
00:02:44,520 --> 00:02:50,700
तो, यदि आप सोचते हैं इस न्यूरॉन को एक अकेली 
लेग़ो ब्रिक जैसे, आपको फिर

43
00:02:50,700 --> 00:02:55,270
मिलता है एक बड़ा न्यूरल नेटवर्क स्टैक करने 
से बहुत सी ये लेग़ो ब्रिक्स.

44
00:02:55,270 --> 00:02:56,110
आइये एक उदाहरण देखते हैं.

45
00:02:57,260 --> 00:03:02,220
मान लो बजाय करने के प्रिडिक्ट 
एक घर की क़ीमत सिर्फ़ साइज़ से,

46
00:03:02,220 --> 00:03:04,330
अब आपके पास हैं अन्य फ़ीचर्ज़

47
00:03:04,330 --> 00:03:08,164
आप जानते हैं अन्य चीज़ें घर के बारे में, 
जैसे संख्या बेडरूम की,

48
00:03:08,164 --> 00:03:13,630
मुझे लिखना चाहिए बेडरूम्स, और आप 
शायद सोचें कि एक चीज़ जो

49
00:03:13,630 --> 00:03:18,820
वास्तव में प्रभावित करती है क़ीमत एक घर 
की वह है परिवार का साइज़, सही है?

50
00:03:18,820 --> 00:03:21,882
तो क्या यह घर पूरा है आपके तीन के परिवार के लिए, 
चार के परिवार या

51
00:03:21,882 --> 00:03:22,687
पाँच के परिवार के लिए?

52
00:03:22,687 --> 00:03:26,351
और यह वास्तव में आधारित है साइज़ पर 
स्क्वेर फ़ीट या स्क्वेर मीटर में और

53
00:03:26,351 --> 00:03:28,960
बेडरूम की संख्या जो निर्धारित करता है कि क्या

54
00:03:28,960 --> 00:03:31,462
एक घर फ़िट कर सकता है आपके परिवार के 
साइज़ को या नहीं.

55
00:03:31,462 --> 00:03:34,909
और फिर आप जानते हैं शायद ज़िप कोड.

56
00:03:34,909 --> 00:03:40,520
विभिन्न देशों में इसे कहते हैं पोस्टल कोड एक घर का.

57
00:03:40,520 --> 00:03:48,820
और ज़िप कोड शायद एक फ़ीचर की तरह बताता है 
आपको, चलने की योग्यता?

58
00:03:48,820 --> 00:03:51,434
तो क्या यह पड़ोस बहुत अधिक चलने योग्य है?

59
00:03:51,434 --> 00:03:53,635
क्या किराने की दुकान पर चल कर जा सकते हैं?

60
00:03:53,635 --> 00:03:54,194
स्कूल तक पैदल?

61
00:03:54,194 --> 00:03:55,250
क्या आपको ड्राइव करने की आवश्यकता है?

62
00:03:55,250 --> 00:03:57,870
और कुछ लोग अत्यधिक चलने लायक पड़ोस पसंद करते हैं.

63
00:03:57,870 --> 00:04:06,145
और फिर ज़िप कोड तथा आर्थिक स्थिति
 शायद बताए आपको, ठीक है?

64
00:04:06,145 --> 00:04:09,200
निश्चित रूप से संयुक्त राज्य अमेरिका में, 
लेकिन कुछ अन्य देशों में भी.

65
00:04:09,200 --> 00:04:13,590
आपको बताता है कि स्कूल की गुणवत्ता कितनी अच्छी है.

66
00:04:13,590 --> 00:04:17,820
तो प्रत्येक ये छोटे वृत्त मैं बना रहा हूँ, हो सकते हैं वे RELU,

67
00:04:17,820 --> 00:04:22,670
रेक्टिफ़ायड लिनीअर यूनिट्स या कोई अन्य
 थोड़ा नॉन-लिनीअर फ़ंक्शन.

68
00:04:22,670 --> 00:04:24,936
ताकि साइज़ और बेडरूम की संख्या पर निर्भर करते हुए,

69
00:04:24,936 --> 00:04:28,420
आप अनुमान कर सकते हैं परिवार का साइज़, 
उनका ज़िप कोड, निर्भर करते हुए 
चलने योग्यता पर,

70
00:04:28,420 --> 00:04:32,050
ज़िप कोड और आर्थिक स्थिति के आधार पर स्कूल 
की गुणवत्ता का अनुमान कर सकते हैं.

71
00:04:32,050 --> 00:04:35,660
और फिर अंत में आपको लगता है कि ठीक है 
जिस तरह लोग निर्णय करते हैं कि कितना वे

72
00:04:35,660 --> 00:04:38,880
अदा करेंगे एक घर के लिए, है कि वे देखते हैं 
चीज़ों को जिनसे उन्हें फ़र्क़ पड़ता है.

73
00:04:38,880 --> 00:04:43,060
इस केस में परिवार का साइज़, पैदल चलने योग्य और 
स्कूल की गुणवत्ता और

74
00:04:43,060 --> 00:04:45,210
जो मदद करती है आपको 
प्रिडिक्ट करने में क़ीमत.

75
00:04:46,330 --> 00:04:51,740
तो उदाहरण में x है ये सब चार इन्पुट्स.

76
00:04:53,470 --> 00:04:56,460
और y है क़ीमत जो आप प्रिडिक्ट 
करना चाह रहे हैं.

77
00:04:57,960 --> 00:05:03,350
और स्टैक करके एस साथ कुछ पृथक न्यूरॉन्स 
या पृथक प्रिडिक्टर्स

78
00:05:03,350 --> 00:05:07,360
हमारे पास थे पिछली स्लाइड से, 
हमारे पास अब है थोड़ा बड़ा न्यूरल नेटवर्क.

79
00:05:07,360 --> 00:05:10,850
कैसे आप मैनिज करते हैं न्यूरल नेटवर्क को है 
कि जब आप इसे इम्प्लमेंट करते हैं,

80
00:05:10,850 --> 00:05:15,860
आपको देना होता है इसे सिर्फ़ इनपुट x और

81
00:05:15,860 --> 00:05:20,740
आउट्पुट y बहुत से इग्ज़ाम्पल्ज़ के लिए 
आपके ट्रेनिंग सेट में और

82
00:05:20,740 --> 00:05:23,580
ये सब चीज़ें मध्य में, वे अपने आप समझ लेते हैं.

83
00:05:25,435 --> 00:05:29,225
तो आप वास्तव में जो इम्प्लमेंट
 करते हैं वह यह है.

84
00:05:29,225 --> 00:05:32,055
जहाँ, यहाँ, आपके पास है 
एक न्यूरल नेटवर्क चार इन्पुट्स का.

85
00:05:32,055 --> 00:05:35,455
तो इनपुट फ़ीचर्ज़ हो सकते हैं 
साइज़ और बेडरूम की संख्या,

86
00:05:35,455 --> 00:05:40,365
ज़िप कोड या पोस्टल कोड, 
और पड़ोस की आर्थिक स्थिति.

87
00:05:40,365 --> 00:05:44,805
और इसलिए दिए होने पर ये इनपुट फ़ीचर्ज़,

88
00:05:44,805 --> 00:05:50,200
न्यूरल नेटवर्क का काम होगा 
प्रिडिक्ट करना क़ीमत y.

89
00:05:50,200 --> 00:05:55,942
और ध्यान दें कि प्रत्येक ये वृत्त भी, 
इन्हें कहते हैं हिडन यूनिट्स

90
00:05:55,942 --> 00:06:02,310
न्यूरल नेटवर्क में, कि प्रत्येक उनमें से लेता है 
उसकी इनपुट सभी इनपुट फ़ीचर्ज़.

91
00:06:02,310 --> 00:06:08,139
तो उदाहरण के लिए, बजाय कहने के कि ये 
पहले नोड्ज़ दर्शाते हैं परिवार का साइज़ और

92
00:06:08,139 --> 00:06:12,056
परिवार का साइज़ निर्भर करता हैं 
सिर्फ़ फ़ीचर x1 और x2 पर.

93
00:06:12,056 --> 00:06:15,302
इसके बजाय, हम कहेंगे, 
ठीक है न्यूरल नेटवर्क,

94
00:06:15,302 --> 00:06:18,200
आप तय करो जो भी आप 
चाहते हो यह होना चाहिए.

95
00:06:18,200 --> 00:06:21,070
और हम देंगे आपको सारे चार फ़ीचर्ज़ 
पूरा करने के लिए जो भी आप चाहते हो.

96
00:06:21,070 --> 00:06:26,170
तो हम कहते हैं कि लेयर्स कि 
यह है इनपुट लेयर और

97
00:06:26,170 --> 00:06:28,960
यह लेयर मध्य में न्यूरल नेटवर्क के है 
घने रूप से जुड़ी हुई.

98
00:06:28,960 --> 00:06:31,740
क्योंकि प्रत्येक इनपुट फ़ीचर जुड़ा है प्रत्येक

99
00:06:31,740 --> 00:06:33,980
इन वृत्तों से मध्य में.

100
00:06:33,980 --> 00:06:38,630
और उल्लेखनीय बात न्यूरल नेटवर्क की है कि,
 दिया होने पर पर्याप्त डेटा

101
00:06:38,630 --> 00:06:43,290
x और y, दिया होने पर पर्याप्त ट्रेनिंग इग्ज़ाम्पल्ज़ 
दोनो x और y के साथ, न्यूरल नेटवर्क्स है

102
00:06:43,290 --> 00:06:47,450
उल्लेखनीय रूप से बढ़िया समझने में 
फ़ंक्शनस जो सही रूप से मैप करते हैं x से y तक.

103
00:06:48,990 --> 00:06:51,680
तो वह है एक मूल न्यूरल नेटवर्क.

104
00:06:51,680 --> 00:06:54,290
ऐसा होता है जब आप बनाते हैं आपके अपने न्यूरल नेटवर्क्स,

105
00:06:54,290 --> 00:06:57,130
आप शायद पाएँ उन्हें सबसे अधिक उपयोगी, 
सबसे अधिक प्रभावशाली

106
00:06:57,130 --> 00:07:01,620
सूपर्वायज़्ड लर्निंग सेट्टिंग में, मतलब कि आप 
प्रयास कर रहे हैं लेने का एक इनपुट x और

107
00:07:01,620 --> 00:07:06,980
मैप करने का इसे किसी आउट्पुट y से, 
जैसे कि हमने देखा घर की क़ीमत प्रिडिक्ट 
करने के उदाहरण में.

108
00:07:06,980 --> 00:07:11,490
अगले वीडियो में चलो देखते हैं कुछ और 
उदाहरण सूपर्वायज़्ड लर्निंग के और

109
00:07:11,490 --> 00:07:15,670
कुछ उदाहरण जहाँ आप शायद पाएँ आपके 
नेटवर्क्स अविश्वसनीय रूप से उपयोगी

110
00:07:15,670 --> 00:07:16,670
आपकी ऐप्लिकेशन्स के लिए भी.