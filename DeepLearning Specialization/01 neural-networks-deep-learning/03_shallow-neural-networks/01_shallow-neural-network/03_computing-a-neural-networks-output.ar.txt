في الفيديو الأخير، رأيتم كيف
تبدو الشبكة العصبية ذات الطبقة المخفية الواحدة. في هذا الفيديو، دعونا نتعرف على تفاصيل كيفية حساب هذه الشبكة العصبية لمخرجاتها بدقة. ما ترونه هو أمر مشابه للانحدار اللوجستي، ولكن مع التكرار في كل المرات. دعونا نلقِ نظرة، فهذا ما تبدو عليه
الشبكة العصبية ثنائية الطبقات. دعونا نتعمق أكثر وأكثر فيما تقوم هذه
الشبكة العصبية بحسابه بدقة. الآن، قلنا من قبل إن الانحدار اللوجستي الدائرة في الانحدار اللوجستي تمثل بالفعل خطوتين من صفوف العملية الحسابية. يمكنكم حساب "z" كما يلي، والثانية تقومون بحساب التنشيط كدالة سينية لـ "z". وبالتالي، تقوم الشبكة العصبية
بذلك لعدد أكبر بكثير من المرات. دعونا نبدأ بالتركيز على واحدة فقط
من العقد في الطبقة المخفية. دعونا نلقِ نظرة على العقدة الأولى
في الطبقة المخفية. لقد قمت بتظليل العقد الأخرى الآن. بما يشبه الانحدار اللوجستي على اليسار، وهذه العقد الموجودة في الطبقة
المخفية تقوم بعمل خطوتين من الحساب. الخطوة الأولى، والتي يمكن التفكير فيها
على أنها النصف الأيسر من هذه العقدة، فهي تحسب z يساوي w منقول x زائد b، والرمز الذي سنستخدمه هو، هذه هي كل الكميات المقترنة بالطبقة الأولى المخفية، ولهذا فإن لدينا مجموعة من الأقواس المربعة هناك. هذه هي العقدة الأولى في الطبقة المخفية. لذا، سيكون لدينا الرقم السفلي واحد هناك. إذًا، في البداية تقوم بذلك، ثم الخطوة الثانية، تحسب a_[1]_1 يساوي الدالة
السينية لـ z_[1]_1، هكذا. إذًا، لكلٍ من z وa، فإن العرف الرمزي المستخدم هو a, l, i، حيث يشير حرف "l" هنا في
الأقواس المربعة العلوية، إلى رقم الطبقة، ويشير حرف "i" السفلي هنا، إلى العقد في تلك الطبقة. إذًا، العقدة التي سننظر إليها هي الطبقة الأولى، وهي العقدة الأولى لطبقة مخفية. ولهذا السبب كان الرقم السفلي
والرقم العلوي كليهما 1.1. حسنًا، هذه الدائرة الصغيرة، هذه العقدة الأولى في الشبكة العصبية، تمثل تنفيذ هاتين الخطوتين من العملية الحسابية. الآن، دعونا نلقِ نظرة على
العقدة الثانية الشبكة العصبية، أو العقدة الثانية في الطبقة المخفية للشبكة العصبية. بما يشبه وحدة الانحدار اللوجستي على اليسار، تمثل هذه الدائرة الصغيرة
خطوتين من العملية الحسابية. الخطوة الأولى تحسب قيمة "z"، وهذه ما زالت الطبقة الأولى، لكن الآن العقدة الثانية تساوي w منقول x، زائد b_[1]_2، ثم a_[1] two
يساوي الدالة السينية لـ z_[1]_2. ومرة أخرى، لا تترددوا في إيقاف
الفيديو مؤقتًا إذا كنتم ترغبون في ذلك، لكن يمكنكم التحقق من أن الرمز العلوي والرمز السفلي متفقان مع ما كتبناه
هنا أعلاه باللون الأرجواني. إذًا، تناقشنا حول أول وحدتين
مخفيتين في الشبكة العصبية، وتمثل الوحدتان المخفيتان الثالثة
والرابعة بعض العمليات الحسابية أيضًا. الآن، دعونا نأخذ هاتين المعادلتين، وهاتين المعادلتين، وننسخها إلى الشريحة التالية. إذًا، هذه هي شبكتنا العصبية، وهذه أول، وفيما يلي المعادلات الثانية التي عملنا عليها من قبل للوحدات المخفية الأولى والثانية. بعد ذلك، إذا قمتم بالمرور على المعادلات المقابلة للوحدتين المخفيتين الثالثة والرابعة وكتابتها
 فإنكم تحصلون على ما يلي. دعوني أوضح هذا الرمز، هذا هو المتجه w_[1]_1، هذا متجه منقول عدد x من المرات. وهذا ما يشير إليه الحرف العلوي "T" هناك، أن المتجه منقول. والآن، كما كنت قد خمنت، إذا كنتم تنفذون شبكة عصبية، فإن فعل ذلك باستخدام حلقة "for"
يبدو غير فعال في الواقع. إذًا ما سنقوم بعمله هو، أخذ هذه المعادلات الأربع وتحويلها إلى متجهات. لذا، سوف نبدأ من خلال إظهار
كيفية حساب "z" كمتجه، ويتضح أنه يمكنكم فعل ذلك من خلال ما يلي. سوف أقوم بأخذ متجهات "w"
هذه وتجميعها في مصفوفة، ثم يكون لديكم w_[1]_1 منقول، فإن هذا متجه صف، أو يعطيكم منقول متجه العمود هذا
 متجه صف، ثم w_[1]_2، منقول، w_[1]_3 منقول، w_[1]_4 منقول. ومن خلال تجميع هذه المتجهات الأربعة معًا، ينتهي بك الأمر بمصفوفة. وهناك طريقة أخرى للتفكير في ذلك
وهي أن لدينا أربع وحدات للانحدار اللوجستي هنا، وكل وحدة من وحدات الانحدار اللوجستي، لديها متجه معلمة مقابلة، w. ومن خلال تجميع هذه المتجهات الأربعة معًا، ينتهي الحال بكم بمصفوفة أربعة في ثلاثة هذه. فإذا أخذنا هذه المصفوفة، وضربناها في
سمات المدخلات الخاصة بكم x1، ×2، ×3، فإنه ينتهي بكم الحال
من خلال كيفية عمل مضاعفة المصفوفات. ينتهي بكم الحال ولديكم w_[1]_1 منقول x، w_2_[1] منقول x، ثم w_3_[1]
منقول x، ثم w_4_[1] منقول x. وبعد ذلك، دعونا لا نحسب b. إذًا، نضيف الآن إلى هذا المتجه b_[1]_1 one
وb_[1]_2 وb_[1]_3 وb_[1]_4. إذًا، هذا بالأساس، إذًا هكذا b_[1]_1 وb_[1]_2
وb_[1]_3 وb_[1]_4. وبالتالي، ترون أن كل صف من الصفوف الأربعة من هذا الناتج يتوافق تمامًا مع كل
صف من هذه الصفوف الأربعة، كل كمية من هذه الكميات الأربع
التي حصلنا عليها من قبل. بمعنى آخر، لقد أظهرنا للتو
أن هذا الشيء يساوي بالتالي z_[1]_1، وz_[1]_2، وz_[1]_3
 وz_[1]_4، كما هو محدد هنا. وربما لن يدهشكم ذلك، وسوف نقوم
بتسمية كل هذا الشيء بالمتجه z_[1]، والذي يمكن الوصول إليه من خلال تجميع
قيم "z" المفردة هذه في متجه عمود. عند التحويل إلى متجهات، من بين القواعد
الأساسية التي قد تساعدكم على استكشاف ذلك، أنه عندما يكون لدينا عقد مختلفة في الطبقة، فإننا نقوم بتجميعها عموديًا. لهذا السبب لدينا من z_[1]_1 إلى z_[1]_4، كان ذلك يطابق أربع عقد مختلفة في الطبقة المخفية، لذا، قمنا بتجميع هذه الأرقام الأربعة بشكل
عمودي لتكوين المتجه z[1]. لاستخدام جزء آخر من الرموز، هذه المصفوفة أربعة في ثلاثة هنا التي حصلنا
عليها من خلال تجميع w_[1]_1 بحرف صغير، وw_[1]_2 وما إلى ذلك، وسنطلق
على هذه المصفوفة W capital [1]. بصورة مشابهة، سنطلق على هذا المتجه
b قوس مربع علوي [1]. إذًا، فهذا هو متجه أربعة في واحد. إذًا، الآن قمنا بحساب قيمة "z" باستخدام
ترميز مصفوفة المتجه هذه، الشيء الأخير الذي نريد عمله كذلك
هو حساب قيم "a" هذه. وبالتالي لن تندهش عندما تكتشف أننا
سوف نقوم بتعريف a_[1]، كمجرد تجميع معًا، لقيم التنشيط هذه، a [1]، من 1 حتى a [1]‎،‏ 4 يمكنكم فقط أخذ هذه القيم الأربع
وتجميعها في متجه يطلق عليه اسم a[1]. ستكون تلك دالة سينية لـ z[1]، حيث يكون ذلك بمثابة تنفيذ للدالة السينية التي تضم العناصر الأربعة لـ z، وتقوم بتطبيق الدالة السينية حسب العناصر عليها. ولتلخيص ذلك، حسبنا أن z_[1] يساوي w_[1] مضروبًا
في المتجه x زائد المتجه b_[1]، وa_[1] عبارة عن دالة سينية مضروبة في z_[1]. لننسخ ذلك إلى الشريحة التالية. ما نراه هو أنه للطبقة الأولى من الشبكة
العصبية مع وضع المدخلات x في الاعتبار، لدينا z_[1] يساوي w_[1]
مضروبًا في x زائد b_[1]، وa_[1] عبارة عن دالة سينية لـ z_[1]. أبعاد هذا هي أربعة في واحد متساوية، فقد كانت هذه مصفوفة أربعة في ثلاثة مضروبة
في متجه ثلاثة في واحد زائد متجه b أربعة في واحد، وهذه مصفوفة أربعة في واحد بنفس أبعاد النهاية. وتذكروا أننا قلنا إن x يساوي a_[0]. نقول فقط إن y hat تساوي أيضًا a two. إذا كنتم ترغبون في ذلك، يمكنكم بشكل فعلي
أخذ "x" هذا واستبداله بـ a_[0]، ونظرًا لأن a_[0] يكون إذا أردتم استخدامه
كاسم مستعار للمتجه الخاص بخصائص الإدخال، x. الآن، من خلال اشتقاق مماثل، يمكنكم معرفة أن التمثيل للطبقة التالية يمكن أن تتم كتابته أيضًا بشكل مشابه حيث
يكون ما تفعله طبقة المخرجات هو، أنها مرتبطة به، لذا فإن المعلمات w_[2] وb_[2]. وبالتالي، فإن w_[2] في هذه الحالة ستكون
عبارة عن مصفوفة واحد في أربعة، في حين تكون b_[2] عبارة عن رقم
حقيقي مثل واحد في واحد. وبالتالي، فإن z_[2] تكون رقمًا حقيقيًا
سنكتبه في شكل مصفوفة واحد في واحد. حيث ستكون مصفوفة واحد في أربعة مضروبة
في مصفوفة واحد في أربعة، زائد b_[2] واحد في واحد، ويعطيكم هذا عددًا حقيقيًا وحسب، إذا فكرتم في هذه الوحدة العلوية الأخيرة على أنها مماثلة للانحدار اللوجستي، الذي
يحتوي على المعلمتين "w" و"b"، حيث تلعب "w" في الواقع دورًا
مشابهًا لدور w_[2] منقول، أو w_[2] في الواقع عبارة عن W
منقول و"b" تساوي b_[2]. ذكرت أننا نرغب في تغطية الجزء الأيسر
من هذه الشبكة، وتجاهل هذا كله الآن، فإن هذه الوحدة الأخيرة العلوية
تشبه كثيرًا الانحدار اللوجستي، باستثناء أنه بدلاً من كتابة المعلمات
في شكل "w" و"b"، فإننا نكتبها في شكل w_[2] وb_[2]، من خلال الأبعاد، واحد في أربعة وواحد في واحد. ولتلخيص ذلك، بالنسبة للانحدار اللوجستي
 لتنفيذ المخرجات أو لتنفيذ التنبؤ، يمكنكم حساب z يساوي w منقول x زائد b، وa أو y hat يساوي a، يساوي دالة سينية لـ z. عندما تكون لديكم شبكة
عصبية ذات طبقة مخفية واحدة، فإن ما تحتاجون إلى تنفيذه، هو حساب هذه المخرجات
لهذه المعادلات الأربع فقط، ويمكنك التفكير فيها كتنفيذ
محول إلى متجهات لحساب مخرجات هذه لوحدات الانحدار
اللوجستي في الطبقة المخفية، وهذا ما يتم فعله، ثم هذا، وهو عبارة عن الانحدار اللوجستي
في طبقة المخرجات وهو ما يقوم هذا بعمله. أتمنى أن يكون هذا الوصف مفهومًا، ولكن الشيء الأساسي هو حساب
مخرجات هذه الشبكة العصبية، كل ما تحتاجون إليه هو هذه السطور
الأربعة من التعليمات البرمجية. إذًا، الآن رأيتم كيف يمكنكم من خلال
متجه "a" لخصائص مدخلات واحدة من خلال أربعة سطور من التعليمات البرمجية، حساب مخرجات هذه الشبكة العصبية. ومثل ما فعلناه في الانحدار اللوجستي، سوف نحتاج كذلك إلى التحويل إلى
متجهات عبر أمثلة تدريبية متعددة. سنرى من خلال تكديس الأمثلة التدريبي
في أعمدة مختلفة في المصفوفة، من خلال تعديل طفيف لذلك، بصورة مماثلة لما رأيتموه في هذا الانحدار، أنكم ستتمكنون من حساب مخرجات
هذه الشبكة العصبية، ليس مثالاً واحدًا في كل مرة، لنقل على مدار مجموعة التدريب برمتها في المرة. إذًا، دعونا نرى تفاصيل ذلك في الفيديو التالي.