1
00:00:00,620 --> 00:00:03,610
كجزء من هذه الدورة التدريبية من
خلال deeplearning.ai،

2
00:00:03,610 --> 00:00:07,590
أتمنى ألا أكتفي بتعليمكم الأفكار
الفنية في التعلم العميق، ولكن

3
00:00:07,590 --> 00:00:11,658
أتمنى أن أقدم لكم بعض الناس،
بعض الأبطال في التعلم العميق.

4
00:00:11,658 --> 00:00:13,160
الذين ابتكروا العديد

5
00:00:13,160 --> 00:00:17,700
من هذه الأفكار التي سنتعلمها
في هذه الدورة التدريبية أو في هذا التخصص.

6
00:00:17,700 --> 00:00:21,420
وفي هذه الفيديوهات، أتمنى أيضًا أن أطلب من
هؤلاء القادة في مجال التعلم العميق

7
00:00:21,420 --> 00:00:24,990
أن يقدموا لكم نصيحة مهنية تتعلق
بكيفية خوض مجال التعلم العميق،

8
00:00:24,990 --> 00:00:27,805
وبكيفية إجراء البحث أو
إيجاد وظيفة في التعلم العميق.

9
00:00:27,805 --> 00:00:30,156
وكأول سلسلة المقابلات هذه،

10
00:00:30,156 --> 00:00:34,228
أنا سعيد لأقدم لكم
مقابلة مع جيوفري هينتون.

11
00:00:38,427 --> 00:00:44,150
مرحبًا جيوفري، وشكرًا لك
على إجراء هذه المقابلة مع deeplearning.ai.

12
00:00:44,150 --> 00:00:46,550
>> شكرًا لدعوتك لي.

13
00:00:46,550 --> 00:00:50,088
>> أعتقد أنك في هذه المرحلة
قد ابتكرت الكثير من الأفكار المتعلقة بالتعلم العميق

14
00:00:50,088 --> 00:00:52,835
أكثر من أي شخص
آخر في هذا العالم.

15
00:00:52,835 --> 00:00:57,650
والكثير من الناس يدعونك
بالأب الروحي للتعلم العميق.

16
00:00:57,650 --> 00:01:01,529
على الرغم من أنني لم أدرك
حتى قيامنا بالدردشة منذ بضع دقائق،

17
00:01:01,529 --> 00:01:05,600
أنك تعتقد أنني أول شخص يطلق عليك
هذا اللقب، وهو شيء يسعدني للغاية.

18
00:01:06,780 --> 00:01:11,320
ولكن ما أريد أن أسأله هو،
الكثير من الناس يعرفونك كأسطورة،

19
00:01:11,320 --> 00:01:15,030
ولكنني أريد أن أسألك عن
قصتك الشخصية خلف تلك الأسطورة.

20
00:01:15,030 --> 00:01:19,980
إذًا كيف اشتركت في، من خلال العودة للوراء،
كيف اشتركت في الذكاء الاصطناعي

21
00:01:19,980 --> 00:01:21,520
التعلم الآلي والشبكات العصبية؟

22
00:01:22,730 --> 00:01:26,960
>> عندما كنت في المدرسة الثانوية،
كان لدي زميل في الفصل

23
00:01:26,960 --> 00:01:31,220
أفضل مني في كل شيء دومًا،
فقد كان رائعًا في الرياضيات.

24
00:01:31,220 --> 00:01:37,010
وجاء إلى المدرسة ذات يوم وقال، هل تعلم
أن العقل يستخدم الصور ثلاثية الأبعاد؟

25
00:01:38,190 --> 00:01:44,161
وأعتقد أن ذلك كان حوالي عام 1966،
وقلت له، ما المقصود بالصورة ثلاثية الأبعاد؟

26
00:01:44,161 --> 00:01:47,390
وأوضح لي أنه في الصورة ثلاثية الأبعاد،
يمكنك قطع نصف الصورة

27
00:01:47,390 --> 00:01:49,730
مع استمرار الحصول على الصورة بأكملها.

28
00:01:49,730 --> 00:01:53,466
وأن الذكريات في العقل
قد تكون موزعة على العقل كله.

29
00:01:53,466 --> 00:01:56,022
وبالتالي كنت أعتقد أنه
قرأ حول تجارب ﻻشلي،

30
00:01:56,022 --> 00:01:57,939
حيث يمكنك قطع أجزاء
من عقل الفأر

31
00:01:57,939 --> 00:02:01,740
واكتشاف أنه من الصعب جدًا
العثور على جزء معيّن يخزّن ذكرى معيّنة.

32
00:02:04,411 --> 00:02:08,920
وقد كان هذا أول شيء يجعلني
مهتمًا بكيفية تخزين العقل للذكريات.

33
00:02:10,180 --> 00:02:12,220
وبعد ذلك عندما ذهبت إلى الجامعة،

34
00:02:12,220 --> 00:02:15,130
بدأت دراسة علم
وظائف الأعضاء والفيزياء.

35
00:02:16,400 --> 00:02:17,731
أعتقد عندما كنت في كامبريدج،

36
00:02:17,731 --> 00:02:20,260
وكنت الطالب الجامعي الوحيد
الذي يدرس علم وظائف الأعضاء والفيزياء.

37
00:02:21,888 --> 00:02:25,270
ثم توقفت عن ذلك

38
00:02:25,270 --> 00:02:29,170
وحاولت دراسة الفلسفة، لأنني
اعتقدت أن ذلك قد يجعلني أتمتع برؤية أكبر.

39
00:02:29,170 --> 00:02:32,780
ولكن بدا لي هذا الأمر في الواقع

40
00:02:32,780 --> 00:02:37,130
غير مكتمل فيما يتعلق بسبل التمييز
عند قولهم لشيء خاطئ.

41
00:02:37,130 --> 00:02:39,420
ولذلك فقد تحولت إلى علم النفس.

42
00:02:41,988 --> 00:02:45,920
وفي علم النفس، كانت لديهم
نظريات بسيطة جدًا، وبدت لي

43
00:02:45,920 --> 00:02:49,620
غير كافية بصورة واضحة
لشرح ما يقوم به العقل.

44
00:02:49,620 --> 00:02:52,737
وحينها قررت أخذ راحة
لبعض الوقت وأصبحت نجارًا.

45
00:02:52,737 --> 00:02:57,169
وبعد ذلك قررت أن أجرّب دراسة
الذكاء الاصطناعي، وذهبت إلى إدنبرة،

46
00:02:57,169 --> 00:02:59,580
لدراسة الذكاء الاصطناعي مع لانجر هيغينز.

47
00:02:59,580 --> 00:03:02,662
وقد قام بعمل رائع جدًا
في الشبكات العصبية

48
00:03:02,662 --> 00:03:07,830
وكان قد توقف عن الشبكات العصبية،
وأُعجب جدًا بأطروحة وينوغراد.

49
00:03:07,830 --> 00:03:11,460
فعندما وصلت كان يعتقد
أنني أقوم بهذه الأشياء القديمة

50
00:03:11,460 --> 00:03:14,210
وكان يجب علي البدء من خلال
رمزية الذكاء الاصطناعي.

51
00:03:14,210 --> 00:03:18,210
وكان يحدث بيننا الكثير من الخلافات، ولكنني
واصلت القيام بما أؤمن به.

52
00:03:18,210 --> 00:03:21,138
>> ثم ماذا؟

53
00:03:21,138 --> 00:03:28,033
>> في نهاية المطاف حصلت على شهادة الدكتوراه في الذكاء
الاصطناعي وبعدها لم أستطع الحصول على وظيفة في بريطانيا.

54
00:03:28,033 --> 00:03:30,979
ولكنني رأيت هذا الإعلان الرائع جدًا

55
00:03:30,979 --> 00:03:36,070
عن زمالات سلوان في كاليفورنيا،
وتمكنت من الحصول على واحدة منها.

56
00:03:36,070 --> 00:03:40,625
وذهبت إلى ولاية كاليفورنيا،
وكان كل شيء مختلفًا هناك.

57
00:03:40,625 --> 00:03:46,685
ففي بريطانيا، كانت الشبكات العصبية
تعتبر شيئًا سخيفًا،

58
00:03:46,685 --> 00:03:50,272
وفي كاليفورنيا، كان كل من دونالد نورمان

59
00:03:50,272 --> 00:03:56,640
وديفيد روملهارت منفتحين جدًا
للأفكار حول الشبكات العصبية.

60
00:03:56,640 --> 00:04:00,720
كانت المرة الأولى التي أذهب فيها إلى مكان
يُنظر خلاله إلى التفكير في كيفية عمل العقل،

61
00:04:00,720 --> 00:04:03,290
والتفكير في أن ذلك قد
يكون مرتبطًا بعلم النفس،

62
00:04:03,290 --> 00:04:05,650
كشيء إيجابي جدًا.

63
00:04:05,650 --> 00:04:06,936
وكان هناك الكثير من المرح،

64
00:04:06,936 --> 00:04:09,792
خاصة التعاون مع
ديفيد روملهارت كان رائعًا.

65
00:04:09,792 --> 00:04:12,968
>> أراه أمرًا عظيمًا. كان هذا عندما
كنت في جامعة كاليفورنيا، سان دييغو (UCSD)

66
00:04:12,968 --> 00:04:16,177
فقد كنت أنت وروملهارت حوالي، عام 1982،

67
00:04:16,177 --> 00:04:20,182
تختتمون كتابة بحث
الانتشار الخلفي المؤثر، أليس كذلك؟

68
00:04:20,182 --> 00:04:23,292
>> في الواقع، كان الأمر
أكثر تعقيدًا من ذلك.

69
00:04:23,292 --> 00:04:24,796
>> ماذا حدث؟

70
00:04:24,796 --> 00:04:28,214
>> أعتقد، أوائل عام 1982،

71
00:04:28,214 --> 00:04:32,900
تمكّن ديفيد روملهارت وأنا، ورون ويليامز،

72
00:04:32,900 --> 00:04:37,967
بيننا من تطوير
خوارزمية الانتشار الخلفي،

73
00:04:37,967 --> 00:04:42,291
لقد كانت بالأساس فكرة ديفيد روملهارت.

74
00:04:42,291 --> 00:04:46,390
واكتشفنا لاحقًا أن الكثير
من الآخرين قد ابتكروها.

75
00:04:46,390 --> 00:04:52,798
فقد ابتكرها ديفيد باركر،
ربما بعدنا، ولكن قبل أن ننشرها.

76
00:04:52,798 --> 00:04:56,425
وكان بول ويربوس قد نشرها بالفعل
قبل بضع سنوات، ولكن

77
00:04:56,425 --> 00:04:58,860
لم ينتبه إليها أحد.

78
00:04:58,860 --> 00:05:01,923
وكان هناك أشخاص آخرون نجحوا
في تطوير خوارزميات مشابهة جدًا،

79
00:05:01,923 --> 00:05:04,340
فإنه ليس من الواضح ما المقصود بالانتشار الخلفي.

80
00:05:04,340 --> 00:05:08,055
ولكن استخدام قاعدة التسلسل
للحصول على المشتقات لم تكن فكرة جديدة.

81
00:05:08,055 --> 00:05:12,484
>> فهمت ذلك، لماذا تظن أن
البحث الخاص بكم هو من ساعد

82
00:05:12,484 --> 00:05:15,940
المجتمع كثيرًا في فهم الانتشار الخلفي؟

83
00:05:15,940 --> 00:05:20,540
فقد كان الأمر يبدو وأن بحثكم قد أبرز
انتشار عدوى فيما يتعلق بقبول

84
00:05:20,540 --> 00:05:22,934
هذه الخوارزمية، أيًا كان من وافق عليها.

85
00:05:22,934 --> 00:05:26,675
>> تمكّنا من نشر البحث في
مجلة Nature في عام 1986.

86
00:05:26,675 --> 00:05:30,580
وفعلت الكثير من العمل السياسي
لجعل البحث مقبولاً.

87
00:05:30,580 --> 00:05:34,622
واكتشفت أن أحد المُحكمين
ربما سيكون ستيوارت سوثيرلاند،

88
00:05:34,622 --> 00:05:36,992
والذي كان طبيب نفسي
معروف جدًا في بريطانيا.

89
00:05:36,992 --> 00:05:38,815
وذهبت للتحدث معه
لفترة طويلة

90
00:05:38,815 --> 00:05:41,480
وشرح له بالضبط
ما يجري.

91
00:05:41,480 --> 00:05:44,140
وكان معجبًا جدًا بحقيقة

92
00:05:44,140 --> 00:05:48,970
إظهارنا أن الانتشار الخلفي
يمكنه تعلم تمثيلات للكلمات.

93
00:05:48,970 --> 00:05:52,490
ويمكنكم النظر إلى هذه التمثيلات،
والتي تكون عبارة عن متجهات صغيرة،

94
00:05:52,490 --> 00:05:55,950
ويمكنكم فهم معنى
الميزات الفردية.

95
00:05:55,950 --> 00:06:01,600
وقد قمنا بتدريبها على الكلمات الثلاثية
حول الأشجار العائلية،

96
00:06:01,600 --> 00:06:06,420
مثل ماري والدتها فيكتوريا.

97
00:06:06,420 --> 00:06:11,550
ويمكنكم أن تذكروا لها أول كلمتين،
وسيتعين عليها التنبؤ بالكلمة الأخيرة.

98
00:06:11,550 --> 00:06:12,970
وبعد تدريبكم لها،

99
00:06:12,970 --> 00:06:17,780
يمكنكم أن تروا جميع أنواع الميزات
في تمثيلات الكلمات الفردية.

100
00:06:17,780 --> 00:06:19,950
مثل جنسية الشخص هناك،

101
00:06:19,950 --> 00:06:25,180
في أي جيل كان، وإلى أي فرع
من شجرة العائلة كان ينتمي، وهلم جرا.

102
00:06:25,180 --> 00:06:27,680
وهذا ما جعل ستيوارت
سوثيرلاند مذهولاً تمامًا

103
00:06:27,680 --> 00:06:29,666
وأعتقد أن ذلك كان السبب وراء قبول البحث.

104
00:06:29,666 --> 00:06:33,905
>> تضمينات كلمات مبكرة
وتشاهد بالفعل سمات مستخلصة

105
00:06:33,905 --> 00:06:38,390
للمعاني الدلالية التي
تظهر من خوارزمية التدريب.

106
00:06:38,390 --> 00:06:44,090
>> نعم، من وجهة نظر عالم نفسي،
ما كان مثيرًا هو نجاح الفكرة في توحيد

107
00:06:44,090 --> 00:06:49,740
عنصري أفكار مختلفين تمامًا
حول كيف كانت المعرفة.

108
00:06:49,740 --> 00:06:53,460
فقد كانت هناك وجهة نظر العالم النفسي القديمة
أن المفهوم هو مجرد مجموعة كبيرة

109
00:06:53,460 --> 00:06:56,810
من السمات وأن هناك
الكثير من الأدلة على ذلك.

110
00:06:56,810 --> 00:07:02,180
وبعد ذلك كانت هناك وجهة نظر الذكاء الاصطناعي،
والتي تعد وجهة نظر رسمية للأشخاص ذوي العلاقة بالبنيوية.

111
00:07:02,180 --> 00:07:06,190
والتي كانت تفيد بأن المفهوم هو
كيف يكون متصلاً بالمفاهيم الأخرى.

112
00:07:06,190 --> 00:07:09,820
ولتجسيد مفهوم، يتعين عليك القيام بشيء
مثل هيكل الرسم البياني أو

113
00:07:09,820 --> 00:07:11,640
ربما شبكة دلالية.

114
00:07:11,640 --> 00:07:15,875
وما أظهره مثال الانتشار الخلفي هذا
هو أنه يمكنك تزويده بالمعلومات

115
00:07:15,875 --> 00:07:21,070
التي يمكن أن تندرج في هيكل
الرسم البياني أو في هذه الحالة شجرة عائلة.

116
00:07:22,080 --> 00:07:26,920
وسيقوم بتحويل هذه المعلومات إلى
سمات بطريقة يمكنها

117
00:07:26,920 --> 00:07:33,470
استخدام السمات لاشتقاق
معلومات متسقة جديدة، أي تعميمها.

118
00:07:33,470 --> 00:07:38,438
ولكن الشيء المهم للغاية هو هذا التنقل بين
التمثيل الرسومي أو

119
00:07:38,438 --> 00:07:43,000
التمثيل الهيكلي
لشجرة العائلة

120
00:07:43,000 --> 00:07:46,715
وتمثيل الأشخاص
كمتجهات سمات كبيرة.

121
00:07:46,715 --> 00:07:50,873
وفي الواقع من خلال التمثيل الرسومي
يمكنك الحصول على متجهات

122
00:07:50,873 --> 00:07:51,469
السمات.

123
00:07:51,469 --> 00:07:54,995
ومن متجهات السمات، يمكنك
الحصول على المزيد حول التمثيل الرسومي.

124
00:07:54,995 --> 00:07:57,730
>> إذًا كان هذا في 1986؟

125
00:07:57,730 --> 00:08:02,430
كان ذلك في بداية التسعينات، أظهر بينغيو أنه
يمكنك أخذ بيانات حقيقية،

126
00:08:02,430 --> 00:08:07,420
يمكنك أخذ نص إنجليزي وتطبيق
نفس التقنيات عليه،

127
00:08:07,420 --> 00:08:13,980
والحصول على تضمينات للكلمات الحقيقية من
النص الإنجليزي، ونال هذا إعجاب الناس كثيرًا.

128
00:08:13,980 --> 00:08:18,682
>> أعتقد أننا كنّا نتحدث مؤخرًا كثيرًا حول كيف تقود
أجهزة الكمبيوتر السريعة مثل وحدات معالجة الرسومات

129
00:08:18,682 --> 00:08:21,750
وأجهزة الكمبيوتر الفائقة
التعلم العميق.

130
00:08:21,750 --> 00:08:26,376
لم أكن ألاحظ ذلك مسبقًا بين 1986
وبداية التسعينات، يبدو أن

131
00:08:26,376 --> 00:08:29,570
بدايات هذا الاتجاه
كانت بينك أنت وبينغيو.

132
00:08:30,600 --> 00:08:32,630
>> نعم، فقد كان تطورًا كبيرًا.

133
00:08:32,630 --> 00:08:41,440
في 1986، كنت أستخدم آلة القائمة
والذي كان أقل من عُشر ميجافلوب.

134
00:08:41,440 --> 00:08:47,720
وبحلول عام 1993 تقريبًا،
كان الأشخاص يمكنهم رؤية عشرة ميجافلوب.

135
00:08:47,720 --> 00:08:49,600
>> أفهم ذلك.
>> إذًا، كان هناك عامل قدره 100،

136
00:08:49,600 --> 00:08:51,770
وهذه المرحلة التي كان
الاستخدام خلالها سهلاً،

137
00:08:51,770 --> 00:08:53,580
لأن أجهزة الكمبيوتر
قد بدأت حينها تصبح أسرع.

138
00:08:53,580 --> 00:08:56,960
>> خلال العقود العديدة الماضية،
تمكّنت من ابتكار

139
00:08:56,960 --> 00:08:59,970
العديد من الأجزاء المتعلقة
بالشبكات العصبية والتعلم العميق.

140
00:08:59,970 --> 00:09:02,670
وأنا أشعر بالفضول بالفعل،
لكل هذه الأشياء التي ابتكرتها،

141
00:09:02,670 --> 00:09:05,050
أي من هذه الأشياء ما زلت
متحمسًا بشدة له؟

142
00:09:06,940 --> 00:09:09,590
>> أعتقد أن الشيء الأفضل
كان العمل مع

143
00:09:09,590 --> 00:09:12,620
تيري سيجنوسكي وآلات بولتزمان.

144
00:09:12,620 --> 00:09:14,500
فقد اكتشفنا أن هناك،

145
00:09:14,500 --> 00:09:18,830
خوارزمية التعلم البسيطة هذه
التي تم تطبيقها على

146
00:09:18,830 --> 00:09:23,550
الشبكات الكبيرة المتصلة بكثافة حيث
يمكنك فقط رؤية بعض العقد.

147
00:09:23,550 --> 00:09:27,730
وبالتالي ستتعلم التمثيلات المخفية
وكانت خوارزمية بسيطة للغاية.

148
00:09:27,730 --> 00:09:31,130
وكانت تبدو كالشيء الذي
يجب عليك التمكّن من استيعابه في العقل لأن

149
00:09:31,130 --> 00:09:34,210
كل تشابك لا يحتاج إلا إلى معرفة
سلوك الخليتين العصبيتين

150
00:09:34,210 --> 00:09:35,940
اللتين كان مرتبطًا بهما مباشرة.

151
00:09:37,010 --> 00:09:41,230
والمعلومات التي تم
نشرها كانت مماثلة.

152
00:09:41,230 --> 00:09:45,160
كانت هناك مرحلتان مختلفتان،
وقد أطلقنا عليهما الاستيقاظ والنوم.

153
00:09:45,160 --> 00:09:46,820
ولكن في المرحلتين المختلفتين،

154
00:09:46,820 --> 00:09:48,760
تقوم بنشر المعلومات
بنفس الطريقة تمامًا.

155
00:09:48,760 --> 00:09:52,360
بينما في شيء مثل الانتشار الخلفي،
هناك مسار أمامي

156
00:09:52,360 --> 00:09:54,820
ومسار خلفي
ويعملان بصورة مختلفة.

157
00:09:54,820 --> 00:09:56,379
فهما يرسلان أنواعًا
مختلفة من الإشارات.

158
00:09:58,100 --> 00:10:01,190
لذلك أنا أعتقد أن هذا
هو الشيء الأفضل.

159
00:10:01,190 --> 00:10:03,730
ولسنوات عديدة، بدا الأمر
وكأنه فضول،

160
00:10:03,730 --> 00:10:05,090
لأنه بدا وكأنه
بطيء للغاية.

161
00:10:06,210 --> 00:10:10,420
ولكن بعد ذلك، تخلصت من
القليل من هذه الميزة، وبدأت تجعلني

162
00:10:10,420 --> 00:10:13,730
أشعر بالاستقرار وأكتفي باستخدام تكرار واحد
في شبكة أبسط إلى حد ما.

163
00:10:13,730 --> 00:10:16,570
وهذا منحني
آلات بولتزمان المقيدة،

164
00:10:16,570 --> 00:10:19,430
والتي نجحت في العمل
بفعالية خلال الممارسة.

165
00:10:19,430 --> 00:10:21,586
وفي مسابقة Netflix،
على سبيل المثال،

166
00:10:21,586 --> 00:10:26,170
كانت آلات بولتزمان المقيدة واحدة
من العناصر الخاصة بالعمل الفائز.

167
00:10:26,170 --> 00:10:30,210
>> وفي الواقع، كان جزء كبير من النهضة
الحديثة في الشبكة العصبية

168
00:10:30,210 --> 00:10:34,790
والتعلم العميق، والذي بدأ منذ 2007 تقريبًا،
يرجع إلى عمل آلة بولتزمان المقيدة،

169
00:10:34,790 --> 00:10:37,710
وآلة بولتزمان غير المقيدة
الذي أنجزه المعمل لديكم.

170
00:10:38,940 --> 00:10:42,130
>> نعم، وهذا جزء آخر من العمل
الذي أشعر بسعادة كبيرة بشأنه،

171
00:10:42,130 --> 00:10:46,290
وفكرة ذلك هو أنه يمكنك تدريب
آلة بولتزمان المقيدة لديك،

172
00:10:46,290 --> 00:10:51,120
والتي تحتوي على طبقة واحدة فحسب من
السمات المخفية ويمكنك تعلّم طبقة واحدة من السمات.

173
00:10:51,120 --> 00:10:54,850
وبعد ذلك يمكنك التعامل مع هذه
السمات كبيانات وفعل نفس الأمر مرة أخرى

174
00:10:54,850 --> 00:10:57,953
وحينها يمكنك التعامل مع السمات الجديدة
التي تعلمتها كبيانات وتكرار نفس الأمر مرة أخرى،

175
00:10:57,953 --> 00:10:59,570
بأكبر قدر تريده.

176
00:10:59,570 --> 00:11:03,060
فقد كان هذا الأمر لطيفًا، ونجح عند تطبيقه عمليًا.

177
00:11:03,060 --> 00:11:08,709
وأدركت UY Tay أنه يمكن التعامل مع
الأمر برمته كنموذج واحد،

178
00:11:08,709 --> 00:11:11,110
ولكنه كان نوعًا غريبًا من النموذج.

179
00:11:11,110 --> 00:11:15,946
فقد كان نموذجًا لديك بالأعلى
آلة بولتزمان المقيدة،

180
00:11:15,946 --> 00:11:20,626
ولكن بالأسفل لديك شبكة
الاعتقاد السينية والتي كانت شيئًا

181
00:11:20,626 --> 00:11:23,060
تم اختراعه منذ سنوات كثيرة.

182
00:11:23,060 --> 00:11:24,620
لذلك فقد كان نموذجًا موجهًا

183
00:11:24,620 --> 00:11:28,651
وما تمكّنا من التوصل إليه من خلال
تدريب آلات بولتزمان المقيدة هذه

184
00:11:28,651 --> 00:11:32,760
كان طريقة فعالة للقيام
بالاستنتاجات في شبكات الاعتقاد السينية.

185
00:11:33,830 --> 00:11:36,870
لذا، في ذلك الوقت،

186
00:11:36,870 --> 00:11:41,270
كان هناك أشخاص يدرسون الشبكات العصبية،
وقد كانوا يستخدمون الشبكات المتصلة بكثافة، ولكن

187
00:11:41,270 --> 00:11:45,500
لم تكن لديهم أي وسائل جيدة لترك
بصمات احتمالية بشأنها.

188
00:11:45,500 --> 00:11:50,050
ولديكم أشخاص يقومون بنماذج رسومية،
بخلاف أطفالي،

189
00:11:50,050 --> 00:11:55,603
الذين يمكنهم القيام بالاستنتاج بصورة صحيحة، ولكن
فقط في الشبكات المتصلة بصورة متناثرة.

190
00:11:55,603 --> 00:12:01,140
وما تمكّنا من إظهاره هو
طريقة تعلم شبكات الاعتقاد العميقة هذه

191
00:12:01,140 --> 00:12:06,280
لذلك فهناك نموذج تقريبي
للاستنتاج يتميز بسرعة كبيرة،

192
00:12:06,280 --> 00:12:10,578
فهم يعمل على تسليم مسار أمامي واحد فحسب
وكانت هذه نتيجة رائعة جدًا.

193
00:12:10,578 --> 00:12:14,890
ويمكنك ضمان أنه في كل مرة
تتعلم خلالها هذه الطبقة الإضافية من السمات

194
00:12:16,010 --> 00:12:19,980
فإن هناك نطاقًا، وكل مرة تتعلم خلالها
طبقة جديدة، تحصل على نطاق جديد

195
00:12:19,980 --> 00:12:22,700
وكان النطاق الجديد دومًا
أفضل من النطاق القديم.

196
00:12:22,700 --> 00:12:25,810
>> ويتم إظهار النطاقات المتغيرة
حينما تضيفون الطبقات.

197
00:12:25,810 --> 00:12:26,970
نعم، أتذكر هذا الفيديو.

198
00:12:26,970 --> 00:12:29,680
>> فقد كان هذا هو الشيء الثاني
الذي كنت متحمسًا بشأنه.

199
00:12:29,680 --> 00:12:35,600
وأعتقد أن الشيء الثالث كان العمل
الذي أنجزته من خلال الطرق المتغيرة.

200
00:12:35,600 --> 00:12:40,750
وتبيّن أن الأشخاص العاملين في الإحصاء
قد قاموا بعمل مشابه من قبل،

201
00:12:40,750 --> 00:12:43,100
ولكننا لم نكن على علم بذلك.

202
00:12:44,610 --> 00:12:47,260
فقد تمكّنا من جعل

203
00:12:47,260 --> 00:12:50,250
عمل EN أفضل تمامًا من خلال توضيح
أنك لست بحاجة لتنفيذ خطوة E مثالية.

204
00:12:50,250 --> 00:12:52,800
بل يمكنك تنفيذ خطوة E تقريبية.

205
00:12:52,800 --> 00:12:55,320
وكانت EN خوارزمية كبيرة في الإحصاء.

206
00:12:55,320 --> 00:12:58,380
وتمكّنا من إظهار
تعميم كبير لها.

207
00:12:58,380 --> 00:13:02,490
وخاصة في 1993،
أعتقد مع فان كامب.

208
00:13:02,490 --> 00:13:07,040
قمت بإجراء بحث، من خلال
أول أبحاث بايز المتغيرة،

209
00:13:07,040 --> 00:13:12,090
والتي أظهرنا خلاله أنه يمكنك
إعداد نسخة من التعلم البايزي

210
00:13:12,090 --> 00:13:17,950
والتي كانت أكثر مرونة، من خلال
تقريب الجزء الخلفي من خلال غاوس.

211
00:13:17,950 --> 00:13:20,320
ويمكنك فعل ذلك في شبكة عصبية.

212
00:13:20,320 --> 00:13:22,600
وكنت متحمسًا بشدة لهذا الأمر.

213
00:13:22,600 --> 00:13:23,680
>> أرى ذلك.
رائع،

214
00:13:23,680 --> 00:13:26,670
أعتقد أنني أتذكر
كل هذه الأبحاث.

215
00:13:26,670 --> 00:13:32,630
قضيت أنت وهينتون، في البحث التقريبي،
ساعات كثيرة في قراءة هذا.

216
00:13:32,630 --> 00:13:36,070
وأعتقد أن بعضًا من
الخوارزميات التي تستخدمها اليوم

217
00:13:36,070 --> 00:13:41,110
أو بعضًا من الخوارزميات التي يستخدمها
الكثير من الأشخاص يوميًا تقريبًا،

218
00:13:41,110 --> 00:13:46,570
هي أشياء مثل dropouts (الحذف العشوائي) أو
أعتقد حالات التنشيط الآتية من مجموعتك؟

219
00:13:46,570 --> 00:13:47,390
>> نعم ولا.

220
00:13:47,390 --> 00:13:51,470
فكّر الآخرون في
الوحدات الخطية المعدلة.

221
00:13:51,470 --> 00:13:56,860
وقد قمنا بالفعل ببعض العمل المتعلق
بآلات بولتزمان المقيدة

222
00:13:56,860 --> 00:14:02,880
والذي يظهر أن ReLU كانت مكافئة تقريبًا
لمجموعة كاملة من الوحدات اللوجستية.

223
00:14:02,880 --> 00:14:05,190
وكانت هذه واحدة من الأشياء
التي ساعدت وحدات ReLU في الانتشار.

224
00:14:05,190 --> 00:14:07,440
>> كنت فضوليًا بخصوص هذا الأمر.

225
00:14:07,440 --> 00:14:12,570
كان البحث القيّم يحتوي على الكثير من الأمور
المتعلقة بالرياضيات التي توضح أن هذه الدالة

226
00:14:12,570 --> 00:14:15,530
يمكن تقريبها بواسطة هذه
الصيغة المعقدة تمامًا.

227
00:14:15,530 --> 00:14:19,140
هل قمت بهذه الحسابات حتى يتم
قبول بحثك كمرجع أكاديمي،

228
00:14:19,140 --> 00:14:24,840
أو أن إجراء كل هذه الحسابات قد أثر حقًا
في تطور الحد الأقصى لـ 0 وx؟

229
00:14:26,450 --> 00:14:30,440
>> كانت هذه واحدة من الحالات
التي كانت الرياضيات خلالها مهمة

230
00:14:30,440 --> 00:14:32,350
فيما يتعلق بتطور الفكرة.

231
00:14:32,350 --> 00:14:35,262
لذا فقد عرفت الوحدات الخطية المعدلة،
وعرفت بوضوح

232
00:14:35,262 --> 00:14:36,821
الوحدات اللوجستية.

233
00:14:36,821 --> 00:14:39,250
ونظرًا للعمل
في آلات بولتزمان،

234
00:14:39,250 --> 00:14:42,720
فقد تم إجراء كل العمل الأساسي
باستخدام الوحدات اللوجستية.

235
00:14:42,720 --> 00:14:45,120
لذا فإن السؤال كان،

236
00:14:45,120 --> 00:14:49,070
هل تعمل خوارزمية التعلم
مع الوحدات الخطية المعدلة؟

237
00:14:49,070 --> 00:14:54,400
ومن خلال إظهار أن الوحدات الخطية المعدلة
كانت مكافئة تمامًا لمجموعة

238
00:14:54,400 --> 00:15:00,350
من الوحدات اللوجستية، فقد أظهرنا أنها
قد تنجح مع كل ما يتعلق بالرياضيات.

239
00:15:00,350 --> 00:15:01,508
>> صحيح.

240
00:15:01,508 --> 00:15:05,890
وقد قدمت الإلهام اليوم،
حيث يستخدم الكثير من الأشخاص ReLU

241
00:15:05,890 --> 00:15:08,000
فهي تنجح بدون-
>> نعم.

242
00:15:08,000 --> 00:15:12,130
>> بدون الحاجة الضرورية
لفهم نفس الدافع.

243
00:15:13,150 --> 00:15:16,850
>> نعم، فقد لاحظت شيئًا
مؤخرًا عندما ذهبت إلى Google.

244
00:15:16,850 --> 00:15:22,796
أعتقد في 2014، قدمت محاضرة
في Google حول استخدام وحدات ReLU

245
00:15:22,796 --> 00:15:26,660
والبدء من خلال مصفوفة الهوية.

246
00:15:26,660 --> 00:15:30,300
لأن الشيء الرائع حول وحدات ReLU
هو أنه إذا واصلت تكرار

247
00:15:30,300 --> 00:15:32,667
الطبقات المخفية
وقمت بالبدء من خلال الهوية،

248
00:15:32,667 --> 00:15:35,050
فإنها ستنسخ النمط
في الطبقة أدناه.

249
00:15:36,140 --> 00:15:40,120
وبالتالي كنت أوضح أنه يمكنك
تدريب الشبكات من خلال 300 طبقة مخفية

250
00:15:40,120 --> 00:15:44,760
ويمكنك تدريبها بكفاءة كبيرة
إذا بدأت من خلال هويتها.

251
00:15:44,760 --> 00:15:48,065
ولكنني لم أواصل هذا الأمر
وأنا نادم حقًا على عدم مواصلته.

252
00:15:48,065 --> 00:15:52,507
نشرنا بحثًا مع kwok lee يوضح أنه
يمكنك بدء

253
00:15:52,507 --> 00:15:55,565
يوضح أنه يمكنك بدء
شبكات متكررة مثل هذه.

254
00:15:55,565 --> 00:16:00,370
ولكن كان يجب علي مواصلة
هذا الأمر أكثر لأنه لاحقًا

255
00:16:00,370 --> 00:16:03,572
ستكون هذه الشبكات المتبقية بمثابة شيء مهم.

256
00:16:03,572 --> 00:16:06,660
>> على مدار سنوات، لقد سمعتك
تتحدث كثيرًا عن العقل.

257
00:16:06,660 --> 00:16:09,447
لقد سمعتك تتحدث عن العلاقة
بين الانتشار الخلفي والعقل.

258
00:16:09,447 --> 00:16:13,720
ما أفكارك الحالية حول هذا الأمر؟

259
00:16:13,720 --> 00:16:16,910
>> أعمل حاليًا على
بحث حول هذا الأمر.

260
00:16:18,250 --> 00:16:21,160
وأعتقد أن فكرتي الأساسية تنطوي على،

261
00:16:21,160 --> 00:16:25,570
أنه إذا تبيّن أن الانتشار الخلفي يمثل
خوارزمية جيدة بالفعل للتعلم.

262
00:16:26,620 --> 00:16:31,610
فبالتأكيد كان بإمكان التطور
اكتشاف كيفية منع ذلك.

263
00:16:32,730 --> 00:16:37,270
أعني أنه لديك خلايا قد
تصبح بمثابة مقل للعيون أو أسنان.

264
00:16:37,270 --> 00:16:42,440
والآن، إذا كان بإمكان الخلايا فعل ذلك،
فبالتأكيد يمكنها تنفيذ الانتشار الخلفي

265
00:16:42,440 --> 00:16:45,860
ومن المحتمل هذا
الضغط الانتقائي الكبير من أجله.

266
00:16:45,860 --> 00:16:50,490
لذلك أعتقد أن فكرة علماء الأعصاب أن هذا
لا يبدو قابلاً للتصديق، وأنه مجرد شيء سخيف.

267
00:16:50,490 --> 00:16:52,890
قد يكون هناك
إمكانية تطبيق دقيق للأمر.

268
00:16:52,890 --> 00:16:56,000
وأعتقد أن العقل ربما لديه
شيء قد لا يكون الانتشار الخلفي

269
00:16:56,000 --> 00:16:58,620
بالتحديد، ولكنه
قريب جدًا منه.

270
00:16:58,620 --> 00:17:02,566
وعلى مدار السنين، قد توصّلت إلى
مجموعة من الأفكار حول كيف قد يعمل هذا الأمر.

271
00:17:02,566 --> 00:17:06,994
ففي عام 1987، وبالتعاون مع جيمس مكليلاند،

272
00:17:06,994 --> 00:17:11,202
توصلت إلى
خوارزمية إعادة التوزيع،

273
00:17:11,202 --> 00:17:16,090
حيث تكمن الفكرة في قيامك بإرسال
معلومات حول تكرار حلقي.

274
00:17:17,470 --> 00:17:18,686
وتحاول تنفيذ ذلك بحيث

275
00:17:18,686 --> 00:17:22,206
لا تتغير الأمور بينما
تنتقل المعلومات في هذا التكرار الحلقي.

276
00:17:22,206 --> 00:17:26,490
وبالتالي فإن الإصدار الأبسط يكون من خلال وجود
وحدات إدخال ووحدات مخفية لديك،

277
00:17:26,490 --> 00:17:31,046
وترسل المعلومات من وحدات الإدخال إلى
الوحدات المخفية، ثم تعود إلى الإدخال

278
00:17:31,046 --> 00:17:34,388
وبعدها تعود إلى المخفية،
ثم إلى الإدخال وهكذا.

279
00:17:34,388 --> 00:17:38,001
وما تريده هو،
أنك تريد تدريب autoencoder،

280
00:17:38,001 --> 00:17:42,300
ولكنك تريد تدريبه بدون
الحاجة للقيام بالانتشار الخلفي.

281
00:17:42,300 --> 00:17:47,250
لذلك فإنك تكتفي بتدريبه للمحاولة
والتخلص من كل الاختلافات في الأنشطة.

282
00:17:47,250 --> 00:17:51,922
فالفكرة أن قاعدة التعلم

283
00:17:51,922 --> 00:17:57,930
للتشابك هو تغيير نسبة الأوزان
للإدخال قبل المشبكي

284
00:17:57,930 --> 00:18:01,780
وبما يتناسب مع معدل
التغيير في الإدخال بعد المشبكي.

285
00:18:01,780 --> 00:18:04,060
ولكن في إعادة التوزيع، فإنك تحاول
أن تجعل الإدخال بعد المشبكي،

286
00:18:04,060 --> 00:18:08,330
تحاول جعل الوحدات القديمة
جيدة والوحدات الجديدة سيئة،

287
00:18:08,330 --> 00:18:09,620
لذا فإنك تقوم بالتغيير في هذا الاتجاه.

288
00:18:11,010 --> 00:18:14,472
وقد ابتكرنا هذه الخوارزمية قبل
توصل علماء الأعصاب إلى

289
00:18:14,472 --> 00:18:16,521
spike-timing-dependent plasticity "اللدونة الدماغية المعتمدة على توقيت الحسكة"

290
00:18:16,521 --> 00:18:20,700
وتعد Spike-timing-dependent plasticity
نفس الخوارزمية ولكن بالعكس،

291
00:18:20,700 --> 00:18:26,220
حيث يكون الشيء الجديد جيدًا
والقديم سيئًا في قاعدة التعلم.

292
00:18:26,220 --> 00:18:30,010
لذلك، فإنك تغيّر نسب الوزن
للنشاط قبل المشبكي

293
00:18:30,010 --> 00:18:35,690
مضروبًا في النشاط بعد
المشبكي الجديد مطروحًا منه القديم.

294
00:18:37,060 --> 00:18:42,020
وبعد ذلك، أدركت في 2007،
أنه إذا أخذت مجموعة من

295
00:18:42,020 --> 00:18:47,830
آلات بولتزمان المقيدة
وقمت بتدريبها.

296
00:18:47,830 --> 00:18:52,620
بعد تدريبها، ستكون لديك
الشروط المناسبة تمامًا

297
00:18:52,620 --> 00:18:56,450
لتنفيذ الانتشار الخلفي
من خلال محاولة إعادة البناء.

298
00:18:56,450 --> 00:19:01,124
إذا نظرت إلى خطأ إعادة البناء،
فإن خطأ إعادة البناء هذا

299
00:19:01,124 --> 00:19:05,728
يوضح لك بالفعل مشتقة
الأداء التمييزي.

300
00:19:05,728 --> 00:19:12,079
وفي أول ورشة عمل حول التعلم العميق
في مؤتمر NIPS في 2007، قدمت محاضرة حول ذلك.

301
00:19:12,079 --> 00:19:16,454
وهو ما تم تجاهله تمامًا.

302
00:19:16,454 --> 00:19:19,799
بعد ذلك، أخذ
يوشوا بينغيو الفكرة

303
00:19:19,799 --> 00:19:24,340
وقام بالكثير من
العمل في هذا الأمر.

304
00:19:24,340 --> 00:19:26,490
أكثر مما قمت بنفسي
من العمل في هذا الأمر.

305
00:19:26,490 --> 00:19:33,280
وأعتقد أن هذه الفكرة تنطوي على أنه إذا كان لديك
مجموعة من شبكات autoencoders، فحينها يمكنك

306
00:19:33,280 --> 00:19:38,440
الحصول على المشتقات من خلال إرسال الأنشطة
للخلف وتحديد موضع أخطاء إعادة البناء،

307
00:19:38,440 --> 00:19:42,520
وهي فكرة مثيرة حقًا
وقد تكون جيدة من خلال كيفية تنفيذ العقل لها.

308
00:19:42,520 --> 00:19:47,520
>> هناك موضوع آخر أعلم أنك تفكر فيه كثيرًا
وسمعت أنك ما زلت

309
00:19:47,520 --> 00:19:51,930
تعمل عليه هو كيفية التعامل مع
المقاييس متعددة التوقيتات في التعلم العميق؟

310
00:19:51,930 --> 00:19:54,468
هل يمكنك مشاركة أفكارك حول هذا الأمر؟

311
00:19:54,468 --> 00:19:58,910
>> نعم، في الواقع، يعود هذا الأمر إلى
سنواتي الأولى كطالب في الدراسات العليا.

312
00:19:58,910 --> 00:20:04,040
فقد كانت أول محاضرة ألقيتها حول
استخدام ما أطلقت عليه الأوزان السريعة.

313
00:20:04,040 --> 00:20:07,560
وأعني الأوزان التي تتكيف سريعًا،
ولكنها تتدهور سريعًا.

314
00:20:07,560 --> 00:20:08,832
وبالتالي يمكنها أن تحمل الذاكرة قصيرة الأمد.

315
00:20:08,832 --> 00:20:13,496
وأوضحت من خلال نظام بسيط
للغاية في 1973 أنه يمكنك

316
00:20:13,496 --> 00:20:16,590
القيام بارتداد حقيقي
من خلال هذه الأوزان.

317
00:20:16,590 --> 00:20:23,010
وما أعنيه بالارتداد الحقيقي
هو أنه يتم إعادة استخدام الخلايا العصبية المستخدمة

318
00:20:23,010 --> 00:20:28,470
في تمثيل الأشياء مجددًا
لتمثيل الأشياء في النواة التكرارية.

319
00:20:30,210 --> 00:20:31,750
ويتم إعادة استخدام الأوزان المستخدمة

320
00:20:31,750 --> 00:20:34,388
في تقديم المعرفة مجددًا
في النواة التكرارية.

321
00:20:34,388 --> 00:20:39,170
ويقودنا هذا إلى السؤال
عندما تُخرج النواة التكرارية،

322
00:20:39,170 --> 00:20:41,600
كيف تتذكر ما الشيء الذي
كنت في خضم القيام به؟

323
00:20:41,600 --> 00:20:42,970
أين هذه الذاكرة؟

324
00:20:42,970 --> 00:20:45,015
لأنك استخدمت الخلايا العصبية
للنواة التكرارية.

325
00:20:46,080 --> 00:20:49,240
والإجابة هي أنه يمكنك وضع هذه
الذاكرة في الأوزان السريعة

326
00:20:49,240 --> 00:20:53,940
ويمكنك استرجاع الخلايا العصبية
للأنشطة من هذه الأوزان السريعة.

327
00:20:53,940 --> 00:20:56,151
ومن خلال التعاون حديثًا مع جيمي با،

328
00:20:56,151 --> 00:21:00,141
تمكّنا من إجراء بحث في مؤتمر NIPS حول هذا الأمر
باستخدام الأوزان السريعة للتكرار مثل هذا.

329
00:21:00,141 --> 00:21:00,898
>> صحيح.

330
00:21:00,898 --> 00:21:04,145
>> فقد كانت هذه فجوة كبيرة جدًا.

331
00:21:04,145 --> 00:21:08,746
فقد كان النموذج الأول
الذي لم يتم نشره في 1973

332
00:21:08,746 --> 00:21:14,966
وبعد ذلك كان نموذج جيمي با في 2015،
أعتقد أو 2016.

333
00:21:14,966 --> 00:21:16,469
وبالتالي فهو بعده بحوالي 40 عامًا.

334
00:21:16,469 --> 00:21:22,840
>> وأعتقد أنه من الأفكار التي سمعتك
تتحدث عنها قبل بضع سنوات الآن،

335
00:21:22,840 --> 00:21:29,350
أعتقد منذ أكثر من خمس سنوات، الكبسولات،
إلى أين وصلت؟

336
00:21:29,350 --> 00:21:34,150
>> حسنًا، لقد عدت إلى
الوضع الذي اعتدت على أن أكون عليه.

337
00:21:34,150 --> 00:21:39,320
حيث توجد لدي هذه الفكرة والتي
أؤمن بها تمامًا ولكن لا يؤمن بها أي شخص آخر.

338
00:21:39,320 --> 00:21:42,120
وقدّمت أبحاث حول هذا الأمر
وتم رفضها.

339
00:21:42,120 --> 00:21:45,938
ولكنني أؤمن حقًا بهذه الفكرة
وسأواصل دعمها.

340
00:21:45,938 --> 00:21:53,880
وهي تعتمد على،
بعض الأفكار الرئيسية.

341
00:21:53,880 --> 00:22:00,000
إحداها تدور حول كيف يمكنك
تمثيل الكيانات متعددة الأبعاد

342
00:22:00,000 --> 00:22:05,070
ويمكنك تمثيل الكيانات متعددة الأبعاد
من خلال متجه من الأنشطة.

343
00:22:05,070 --> 00:22:07,630
وكما تعرف
هناك أي منها.

344
00:22:07,630 --> 00:22:12,150
لذا فالفكرة تنطوي على أنه في كل منطقة
بالصورة، ستفترض أن هناك بحد أقصى،

345
00:22:12,150 --> 00:22:14,000
واحدة من أنواع السمات الخاصة.

346
00:22:15,200 --> 00:22:18,020
وحينها ستستخدم مجموعة
من الخلايا العصبية

347
00:22:18,020 --> 00:22:23,190
وستمثل أنشطتها الجوانب
المختلفة لهذه السمة،

348
00:22:24,230 --> 00:22:27,270
مثل، ما إحداثيات x وy
ضمن هذه المنطقة تحديدًا؟

349
00:22:27,270 --> 00:22:28,780
ما اتجاه هذه الصورة؟

350
00:22:28,780 --> 00:22:29,930
ما مدى سرعة تحركها؟

351
00:22:29,930 --> 00:22:30,630
ما لونها؟

352
00:22:30,630 --> 00:22:31,270
ما مدى سطوعها؟

353
00:22:31,270 --> 00:22:32,590
وأشياء من هذا القبيل.

354
00:22:32,590 --> 00:22:36,350
لذا، يمكنك استخدام مجموعة كاملة من
الخلايا العصبية لتمثيل أبعاد مختلف

355
00:22:36,350 --> 00:22:37,710
للشيء نفسه.

356
00:22:37,710 --> 00:22:39,410
شريطة وجود واحد منها فقط.

357
00:22:40,490 --> 00:22:46,110
وهذه طريقة مختلفة
تمامًا للقيام بالتمثيل

358
00:22:46,110 --> 00:22:48,155
عما اعتدنا على استخدامه
عادة في الشبكات العصبية.

359
00:22:48,155 --> 00:22:49,820
عادة في الشبكات العصبية،
لدينا طبقة كبيرة للغاية،

360
00:22:49,820 --> 00:22:52,080
وكل الوحدات تنطلق
وتفعل أيًا كان ما تفعله.

361
00:22:52,080 --> 00:22:55,770
ولكنك لا تفكر في تجميعها
في مجموعات أصغر تمثل

362
00:22:55,770 --> 00:22:57,310
إحداثيات مختلفة لنفس الشيء.

363
00:22:58,660 --> 00:23:02,080
لذا أعتقد أنها ينبغي أن
تكون هذه البنية الإضافية.

364
00:23:02,080 --> 00:23:05,020
والفكرة الأخرى
التي تتماشى مع ذلك.

365
00:23:05,020 --> 00:23:07,410
>> يعني هذا التمثيل
الموزع،

366
00:23:07,410 --> 00:23:09,280
أنك تقوم بتقسيم التمثيل.

367
00:23:09,280 --> 00:23:11,270
>> نعم.
>> إلى مجموعات فرعية مختلفة.

368
00:23:11,270 --> 00:23:13,900
>> نعم.
>> لتمثيل، بدلاً من

369
00:23:13,900 --> 00:23:15,600
>> أطلق على كل مجموعة من هذه المجموعات الفرعية الكبسولة.

370
00:23:15,600 --> 00:23:16,180
>> صحيح.

371
00:23:16,180 --> 00:23:21,078
>> والفكرة في أن الكبسولة بإمكانها
تمثيل نموذج للسمة، ولكن

372
00:23:21,078 --> 00:23:21,794
واحد فقط.

373
00:23:21,794 --> 00:23:27,130
وتمثل كل الخصائص
المختلفة لهذه السمة.

374
00:23:27,130 --> 00:23:29,880
فهي سمة لديها الكثير
من الخصائص على عكس

375
00:23:29,880 --> 00:23:34,530
الخلية العصبية العادية،
والشبكة العصبية التي لديها مقياس واحد للخصائص.

376
00:23:34,530 --> 00:23:36,240
>> نعم، أفهم ذلك.

377
00:23:36,240 --> 00:23:41,423
>> وبعد ذلك ما الذي يمكنك فعله إذا حصلت
على ذلك، هو أنه يمكنك القيام بشيء تعد

378
00:23:41,423 --> 00:23:48,980
الشبكات العصبية العادية سيئة جدًا فيه، وهو قدرتك
على القيام بما أطلق عليه التوجيه بموجب اتفاق.

379
00:23:48,980 --> 00:23:52,960
دعونا نفترض أنك
تريد إجراء تقسيم

380
00:23:52,960 --> 00:23:56,660
وأن لديك شيئًا قد يكون الفم
ولديك شيئًا آخر قد تكون الأنف.

381
00:23:57,910 --> 00:24:02,179
وتريد معرفة ما إذا كان يجب عليك
وضعهما معًا لتكوين شيء واحد.

382
00:24:02,179 --> 00:24:03,879
لذا فإن الفكرة يجب أن تحتوي على كبسولة

383
00:24:03,879 --> 00:24:06,040
.للفم تحتوي على
معلمات الفم

384
00:24:06,040 --> 00:24:10,582
وأن تكون لديك كبسولة للأنف
تكون لديها معلمات الأنف.

385
00:24:10,582 --> 00:24:13,797
ولكي تتمكن من اتخاذ قرار 
وضعهما معًا أم لا

386
00:24:13,797 --> 00:24:18,670
فإنك تحصل على كل منهم للتصويت على
ما المعلمات التي يجب أن تكون موجودة للوجه.

387
00:24:19,930 --> 00:24:23,718
والآن إذا كان الفم والأنف في
العلاقة المكانية المناسبة،

388
00:24:23,718 --> 00:24:24,725
فإنهما سيتفقان.

389
00:24:24,725 --> 00:24:28,888
عندما تكون لديك كبسولتان في مستوى واحد
ومن خلال التصويت لنفس مجموعة المعلمات

390
00:24:28,888 --> 00:24:32,106
في المستوى التالي، يمكنك
افتراض أنها من المحتمل أن تكون صحيحة،

391
00:24:32,106 --> 00:24:35,350
لأن الاتفاق في حيز ذي
أبعاد كبيرة أمر غير مرجح.

392
00:24:36,950 --> 00:24:42,109
وهذه طريقة مختلفة
تمامًا للقيام بالتصفية،

393
00:24:42,109 --> 00:24:46,130
عما نستخدمه عادة في الشبكات العصبية.

394
00:24:46,130 --> 00:24:50,708
لذا، فإنني أعتقد أن هذا التوجيه بموجب اتفاق
سيكون شديد الأهمية

395
00:24:50,708 --> 00:24:56,700
للحصول على الشبكات العصبية لتعميمها
بصورة أفضل من البيانات المحدودة.

396
00:24:56,700 --> 00:24:59,797
أعتقد أن ذلك سيكون أمرًا جيدًا للغاية
فيما يتعلق بإجراء التغييرات في وجهة النظر،

397
00:24:59,797 --> 00:25:01,500
وسيكون جيدًا للغاية في إجراء التقسيم.

398
00:25:01,500 --> 00:25:04,794
وآمل أن يكون أكثر كفاءة
من الناحية الإحصائية

399
00:25:04,794 --> 00:25:06,147
عما نفعله حاليًا في الشبكات العصبية.

400
00:25:06,147 --> 00:25:08,575
إذا كنت تريد التعامل
مع التغييرات في وجهة النظر،

401
00:25:08,575 --> 00:25:12,000
فما عليك إلا تقديم مجموعة كاملة من التغييرات
في وجهة النظر إلى جانب التدريب عليها جميعًا.

402
00:25:12,000 --> 00:25:16,460
>> أفهم ذلك، لذا بدلاً من
التعلم الخاضع للإشراف،

403
00:25:16,460 --> 00:25:19,120
يمكنك تعلم ذلك بطريقة مختلفة.

404
00:25:20,220 --> 00:25:24,120
>> حسنًا، ما زلت أخطط للقيام بذلك
من خلال التعلم الخاضع للإشراف، ولكن

405
00:25:24,120 --> 00:25:27,720
آليات المسارات الأمامية
تكون مختلفة تمامًا.

406
00:25:27,720 --> 00:25:32,010
فهو ليس مسارًا أماميًا خالصًا بمعنى
أن هناك أجزاءً قليلة للتكرار

407
00:25:32,010 --> 00:25:36,550
حيث تعتقد إنك وجدت الفم
وتعتقد أيضًا إنك وجدت الأنف.

408
00:25:36,550 --> 00:25:39,127
واستخدام القليل
من التكرار لتحديد

409
00:25:39,127 --> 00:25:42,530
ما إذا كان يجب تجميعهما معًا
لتكوين الوجه أم لا.

410
00:25:42,530 --> 00:25:46,352
ويمكنك القيام بالانتشار الخلفي
من هذا التكرار.

411
00:25:46,352 --> 00:25:50,286
لذا يمكنك المحاولة
والقيام بالأمر بشكل مميز قليلاً،

412
00:25:50,286 --> 00:25:54,417
ونعمل على ذلك الأمر
الآن في مجموعتي في تورنتو.

413
00:25:54,417 --> 00:26:00,260
فلدي الآن فريق Google صغير
في تورنتو، جزء من فريق العقل.

414
00:26:00,260 --> 00:26:02,127
وهذا ما يثير حماسي حاليًا.

415
00:26:02,127 --> 00:26:02,891
>> نعم، رائع.

416
00:26:02,891 --> 00:26:05,366
نتطلع إلى هذا البحث
حينما يظهر.

417
00:26:05,366 --> 00:26:10,750
>> نعم، إذا ظهر [ضحك].

418
00:26:10,750 --> 00:26:13,040
>> لقد عملت في التعلم العميق
لعقود عديدة.

419
00:26:13,040 --> 00:26:15,330
أنا أشعر بالفضول حقًا،
كيف تغيّر تفكيرك،

420
00:26:15,330 --> 00:26:18,760
وفهمك للذكاء الاصطناعي
على مدار هذه السنوات؟

421
00:26:20,380 --> 00:26:27,678
>> أعتقد أن الكثير من تاريخي
الفكري كان يدور حول الانتشار الخلفي،

422
00:26:27,678 --> 00:26:33,531
وكيفية استخدام الانتشار الخلفي،
وكيفية الاستفادة من قوته.

423
00:26:33,531 --> 00:26:36,966
لذا للبدء في هذا، في منتصف الثمانينات،
كنا نستخدمه من أجل

424
00:26:36,966 --> 00:26:40,203
التعلم التمييزي
وكان يعمل بصورة جيدة.

425
00:26:40,203 --> 00:26:42,405
وبعد ذلك قررت في مطلع التسعينات،

426
00:26:42,405 --> 00:26:46,749
أن معظم التعلم البشري كان
سيكون من خلال التعلم الخاضع للإشراف.

427
00:26:46,749 --> 00:26:50,138
وكنت متحمسًا بشدة
بخصوص التعلم الخاضع للإشراف

428
00:26:50,138 --> 00:26:54,300
وكان هذا عندما عملت في أشياء
مثل خوارزمية wake-sleep.

429
00:26:54,300 --> 00:26:58,306
>> وقد أثرت تعليقاتك في هذا الوقت
تمامًا في تفكيري أيضًا.

430
00:26:58,306 --> 00:27:03,010
عندما كنت أقود مشروع Google Brain،
مشروعنا الأول، بذلت الكثير

431
00:27:03,010 --> 00:27:07,900
من العمل في التعلم الخاضع للإشراف
بسبب تأثيرك.

432
00:27:07,900 --> 00:27:09,740
>> حسنًا، وربما تسببت في تضليلك.

433
00:27:09,740 --> 00:27:11,470
لأنه على المدى الطويل،

434
00:27:11,470 --> 00:27:13,840
أعتقد أن التعلم الخاضع للإشراف
سيكون شديد الأهمية.

435
00:27:15,160 --> 00:27:19,376
ولكن يتعين عليك مواجهة الواقع.

436
00:27:19,376 --> 00:27:24,107
والذي نجح على مدار السنوات العشر الماضية
أو نحو ذلك هو التعلم الخاضع للإشراف.

437
00:27:24,107 --> 00:27:27,179
التدريب التمييزي،
حيث تكون لديك تسميات أو

438
00:27:27,179 --> 00:27:31,810
تحاول توقع الشيء التالي
في السلسلة، لذا فهذا يكون بمثابة التسمية.

439
00:27:31,810 --> 00:27:33,769
ونجح هذا بصورة لا تصدق.

440
00:27:37,528 --> 00:27:42,266
ما زلت أعتقد أن التعلم الخاضع للإشراف
سيكون شديد الأهمية، وأن الأمور

441
00:27:42,266 --> 00:27:47,145
ستنجح بصورة لا تصدق وأفضل مما هي عليه الآن،
عندما ننفذ هذا العمل بصورة صحيحة، ولكن

442
00:27:47,145 --> 00:27:48,200
لم ننفذه جيدًا حتى الآن.

443
00:27:49,990 --> 00:27:53,225
>> نعم، أعتقد أن الكثير من
كبار الشخصيات في التعلم العميق،

444
00:27:53,225 --> 00:27:56,074
بما في ذلك أنا،
نبقى متحمسين للغاية حول ذلك.

445
00:27:56,074 --> 00:28:01,513
ولكن ليس لدى أحد منّا أي فكرة
تقريبًا عن كيفية تنفيذ الأمر حتى الآن.

446
00:28:01,513 --> 00:28:04,983
ربما لديك فكرة، ولكن لا أعتقد أن لدي أي فكرة.

447
00:28:04,983 --> 00:28:08,160
>> تعتبر autoencoders المتغيرة هي الموضع
الذي استخدمت خلاله الحيل الخاصة بإعادة وضع المعلمات.

448
00:28:08,160 --> 00:28:10,120
وقد بدت لي كفكرة رائعة.

449
00:28:10,120 --> 00:28:15,260
وبدت لي كذلك خوارزميات generative
adversarial nets بمثابة فكرة جيدة حقًا.

450
00:28:15,260 --> 00:28:18,645
وأعتقد أن خوارزميات generative
adversarial nets هي واحدة

451
00:28:18,645 --> 00:28:23,430
من أكبر الأفكار في
التعلم العميق التي تعد جديدة حقًا.

452
00:28:23,430 --> 00:28:26,363
آمل أن أتمكن من وضع
كبسولات ناجحة، ولكن

453
00:28:26,363 --> 00:28:31,740
حتى الآن أعتقد أن generative
adversarial nets كانت بمثابة طفرة كبيرة.

454
00:28:31,740 --> 00:28:34,439
>> ماذا حدث لسمات
البطء والتضاؤل،

455
00:28:34,439 --> 00:28:38,806
حيث كانتا اثنتين من المبادئ الأخرى
لبناء النماذج الخاضعة للإشراف؟

456
00:28:41,556 --> 00:28:47,788
لم أكن أبدًا متحمسًا بشأن
التضاؤل كما كنت، يا صديقي.

457
00:28:47,788 --> 00:28:52,672
ولكن بالنسبة لسمات البطء، أعتقد أنها تمثل خطأ.

458
00:28:52,672 --> 00:28:53,660
يجب ألا تقول بطيئة.

459
00:28:53,660 --> 00:28:57,880
الفكرة الأساسية صحيحة، ولكن يجب ألا
تختار سمات لا تتغير،

460
00:28:57,880 --> 00:29:00,660
يجب أن تختار
السمات التي تتغير بطرق متوقعة.

461
00:29:01,680 --> 00:29:07,060
فإليك أحد المبادئ الأساسية
حول كيف تصوغ أي شيء.

462
00:29:08,620 --> 00:29:13,391
تأخذ القياسات الخاصة بك
وتعمل على تطبيق التحولات

463
00:29:13,391 --> 00:29:17,612
غير الخطية على
القياسات حتى تصل إلى

464
00:29:17,612 --> 00:29:22,672
تمثيل كمتجه ثابت
يكون في الواقع خطيًا.

465
00:29:22,672 --> 00:29:26,103
لذا، فإنك لا تتظاهر بأنه خطي فحسب
مثلما تفعل مع مرشحات كالمان.

466
00:29:26,103 --> 00:29:29,625
ولكنك تجد بالفعل تحولاً
من الملاحظات إلى

467
00:29:29,625 --> 00:29:32,616
المتغيرات الأساسية
حيث تقوم العمليات الخطية،

468
00:29:32,616 --> 00:29:37,480
مثل مضاعفات المصفوفة في
المتغيرات الأساسية، بتنفيذ العمل.

469
00:29:37,480 --> 00:29:39,700
لذا على سبيل المثال،
إذا أردت تغيير وجهات النظر.

470
00:29:39,700 --> 00:29:42,890
إذا أردت إنتاج الصورة
من وجهة نظر أخرى،

471
00:29:42,890 --> 00:29:46,900
ما يجب عليك فعله هو الانتقال من
وحدات البكسل إلى الإحداثيات.

472
00:29:47,950 --> 00:29:50,686
وبمجرد وصولك إلى
تمثيل الإحداثيات،

473
00:29:50,686 --> 00:29:54,120
وهو شيء آمل
أن تجده الكبسولات.

474
00:29:54,120 --> 00:29:57,350
يمكنك حينها تنفيذ مضاعفة المصفوفة
لتغيير وجهة النظر

475
00:29:57,350 --> 00:29:59,210
ثم يمكنك ربطها مرة أخرى بوحدات البكسل.

476
00:29:59,210 --> 00:29:59,893
>> حسنًا، هذا هو السبب الذي دفعك للقيام بكل هذا.

477
00:29:59,893 --> 00:30:02,170
>> أعتقد أن هذا
مبدأ عام للغاية.

478
00:30:02,170 --> 00:30:04,773
>> لهذا السبب قمت بكل هذا العمل في تجميع الوجه، أليس كذلك؟

479
00:30:04,773 --> 00:30:09,355
حيث تأخذ الوجه وتضغطه
إلى متجه ذي أبعاد منخفضة للغاية، وبالتالي

480
00:30:09,355 --> 00:30:12,450
يمكنك معالجة هذا الأمر
واسترجاع وجوه أخرى.

481
00:30:12,450 --> 00:30:15,950
>> كان لدي طالب عمل في هذا الأمر،
ولكن لم أقم بالكثير من العمل في هذا الأمر بنفسي.

482
00:30:17,100 --> 00:30:19,180
>> الآن أنا متأكد من أنك ما زلت تتلقى الأسئلة طوال الوقت،

483
00:30:19,180 --> 00:30:23,920
إذا كان شخص يريد بدء العمل في التعلم
العميق، فما الذي يجب عليه فعله؟

484
00:30:23,920 --> 00:30:25,040
وما النصائح التي ستقدمها؟

485
00:30:25,040 --> 00:30:28,938
أنا متأكد من أنك قدمت نصائح كثيرة إلى
الأشخاص في سياقات مباشرة، ولكن

486
00:30:28,938 --> 00:30:31,550
الجمهور العالمي من الناس
يشاهد هذا الفيديو.

487
00:30:31,550 --> 00:30:35,999
ما النصيحة التي تود توجيهها
لهم للبدء في التعلم العميق؟

488
00:30:35,999 --> 00:30:42,171
>> حسنًا، نصيحتي هي أنه يجب عليهم قراءة
المؤلفات، ولكن لا تبالغوا في مرحلة القراءة.

489
00:30:42,171 --> 00:30:48,030
فهذه هي النصيحة التي حصلت عليها من الموجه الخاص بي،
وهو على عكس ما يقوله معظم الناس.

490
00:30:48,030 --> 00:30:52,474
يقول معظم الناس إنه يجب عليك قضاء
سنوات عديدة في قراءة المؤلفات

491
00:30:52,474 --> 00:30:55,421
وبعد ذلك، يجب أن تبدأ
العمل معتمدًا على أفكارك الخاصة.

492
00:30:55,421 --> 00:31:00,295
وقد يكون هذا صحيحًا لبعض الباحثين
ولكن بالنسبة للباحثين المبدعين أعتقد

493
00:31:00,295 --> 00:31:03,803
أن ما يجب عليك فعله هو قراءة
القليل من المؤلفات.

494
00:31:03,803 --> 00:31:07,792
ولاحظ شيئًا تعتقد أن
الجميع يفعله بصورة خاطئة،

495
00:31:07,792 --> 00:31:10,340
أنا ضد هذا المنطلق.

496
00:31:10,340 --> 00:31:13,568
يمكنك النظر في الأمر
ولا يبدو صحيحًا.

497
00:31:13,568 --> 00:31:15,660
ثم تتوصل بعد ذلك إلى طريقة القيام بالأمر بصورة صحيحة.

498
00:31:16,890 --> 00:31:22,476
وعندما يقول لك الناس
هذا ليس جيدًا، فما عليك إلا مواصلة فعل الأمر.

499
00:31:22,476 --> 00:31:26,339
ولدي مبدأ مهم جدًا لمساعدة
الأشخاص في مواصلة الأمر،

500
00:31:26,339 --> 00:31:29,996
حيث تكون أفكارك
إما جيدة أو غير ذلك.

501
00:31:29,996 --> 00:31:32,030
إذا كانت أفكارك جيدة،
فيجب عليك اتباعها

502
00:31:32,030 --> 00:31:34,060
وستكون ناجحًا في النهاية.

503
00:31:34,060 --> 00:31:36,478
وإذا لم تكن أفكارك جيدة،
فلا يهم ما تفعله.

504
00:31:36,478 --> 00:31:40,329
>> صحيح [ضحك].

505
00:31:40,329 --> 00:31:43,420
نصيحة ملهمة، ربما أعمل بها أيضًا.

506
00:31:43,420 --> 00:31:45,410
>> قد تثق
في أفكارك أيضًا.

507
00:31:45,410 --> 00:31:47,847
لا يوجد معنى لعدم ثقتك فيها.

508
00:31:47,847 --> 00:31:49,420
>> صحيح، نعم.

509
00:31:49,420 --> 00:31:55,193
عادة أنصح الناس بعدم القراءة فحسب،
بل بمحاكاة الأبحاث المنشورة.

510
00:31:55,193 --> 00:31:58,161
وربما يضع هذا محددًا طبيعيًا
حول المقدار الذي يمكنك إنجازه،

511
00:31:58,161 --> 00:32:00,800
لأن نتائج المحاكاة
مستهلكة للوقت بشدة.

512
00:32:01,910 --> 00:32:05,312
نعم، هذا صحيح فعندما
تحاول محاكاة بحث منشور

513
00:32:05,312 --> 00:32:08,100
تتمكّن من استكشاف كل الحيل
البسيطة اللازمة لإنجاح الأمر.

514
00:32:08,100 --> 00:32:11,938
النصيحة الأخرى لدي هي،
لا تتوقف أبدًا عن البرمجة.

515
00:32:11,938 --> 00:32:15,577
لأنه إذا أعطيت طالبًا
شيئًا للقيام به، وكان طالبًا سيئًا،

516
00:32:15,577 --> 00:32:18,550
فسيعود ويقول لك، لم ينجح الأمر.

517
00:32:18,550 --> 00:32:22,030
وسبب عدم نجاحه قد يكون
بعض القرارات البسيطة التي اتخذها،

518
00:32:22,030 --> 00:32:25,100
والتي لم يدرك أنها شديدة الأهمية.

519
00:32:25,100 --> 00:32:28,850
بينما إذا أعطيته لطالب جيد،
مثل UY-Tay على سبيل المثال.

520
00:32:28,850 --> 00:32:31,120
يمكنك منحه أي شيء
وسيعود لك ويقول، لقد نجح الأمر.

521
00:32:32,670 --> 00:32:36,420
أتذكر فعل هذا مرة واحدة،
وقلت حينها، انتظر دقيقة UY.

522
00:32:36,420 --> 00:32:37,330
منذ تحدثنا في المرة الأخيرة،

523
00:32:37,330 --> 00:32:40,380
أدركت أنه لا يمكن أن يعمل
للسبب التالي.

524
00:32:40,380 --> 00:32:43,586
وقال UY، نعم، أدركت ذلك
فورًا، لذلك فإنني افترضت أنك لم تقصد ذلك.

525
00:32:43,586 --> 00:32:47,627
>> [ضحك] صحيح، نعم،
هذا رائع.

526
00:32:47,627 --> 00:32:51,575
دعونا نرى، هل هناك أي نصيحة أخرى

527
00:32:51,575 --> 00:32:57,782
للأشخاص الذين يريدون بدء دخول
الذكاء الاصطناعي والتعلم العميق؟

528
00:32:57,782 --> 00:33:02,000
>> أعتقد بالأساس، أنه يجب عليك القراءة بما يكفي
حتى تبدأ في تطوير الأفكار.

529
00:33:02,000 --> 00:33:05,811
وبعدها، ثق في أفكارك
وحاول تحقيقها،

530
00:33:05,811 --> 00:33:10,783
لا تشعر بالقلق إذا قال لك الجميع
إنها ليست لها معنى.

531
00:33:10,783 --> 00:33:14,352
>> وأعتقد أنه لا توجد أي طريقة
لتعلم من خلالها ما إذا كان الآخرون على حق أم خطأ

532
00:33:14,352 --> 00:33:19,950
عندما يقولون إنها ليست ذات معنى، ولكن يجب عليك
تحقيقها واكتشاف الأمر حينها.

533
00:33:19,950 --> 00:33:24,350
>> حسنًا، ولكن هناك شيئًا واحدًا، والذي
، إذا فكرت في إنها فكرة جيدة حقًا،

534
00:33:24,350 --> 00:33:27,201
وقال لك الآخرون
إنها ليست لها معنى تمامًا،

535
00:33:27,201 --> 00:33:29,761
فحينها تعرف
أنك تخطط لشيء.

536
00:33:29,761 --> 00:33:33,960
فمثال على ذلك عندما
وتوصلت أولاً إلى الأساليب المتغيرة.

537
00:33:35,420 --> 00:33:40,690
أرسلت رسالة بريد إلى
طالب سابق لي اسمه بيتر براون،

538
00:33:40,690 --> 00:33:42,560
ونعلم الكثير حوله.

539
00:33:43,570 --> 00:33:46,967
وقد عرضها على الأشخاص
الذين عملوا معه،

540
00:33:46,967 --> 00:33:51,253
ويُعرفون باسم الأشقاء،
فقد كانوا توأمين.

541
00:33:51,253 --> 00:33:55,914
وقد أخبرني لاحقًا ماذا قالوا،
وقد قالوا،

542
00:33:55,914 --> 00:34:00,277
إما أن هذا الشخص سكير
أو مجرد شخص غبي،

543
00:34:00,277 --> 00:34:04,260
فقد كانوا يظنون
بالفعل إنه هراء.

544
00:34:04,260 --> 00:34:06,460
الآن، كان من الممكن جزئيًا
أن تكون الطريقة التي أوضحتها،

545
00:34:06,460 --> 00:34:08,043
لأنني أوضحتها فيما يتعلق بالأفكار.

546
00:34:09,150 --> 00:34:13,100
ولكن عندما تكون لديك
ما تعتقد أنها فكرة جيدة

547
00:34:13,100 --> 00:34:16,810
ويعتقد الآخرون أنها هراء تام،
فهذه علامة الفكرة الجيدة في الواقع.

548
00:34:18,026 --> 00:34:21,555
>> صحيح، ومواضيع الأبحاث،

549
00:34:21,555 --> 00:34:26,183
يجب أن يعمل طلاب الدراسات العليا
الجدد على الكبسولات

550
00:34:26,183 --> 00:34:30,707
وربما التعلم غير الخاضع للإشراف، هل هناك شيء آخر؟

551
00:34:30,707 --> 00:34:34,078
>> من النصائح الجيدة
لطلاب الدراسات العليا الجدد هو،

552
00:34:34,078 --> 00:34:38,344
يجب عليك معرفة ما إذا كان لديك مستشار
لديه نفس معتقدات مشابهة لتلك الخاصة بكم.

553
00:34:38,344 --> 00:34:42,637
لأنه إذا كنت تعمل في أشياء
يشعر مستشارك بإحساس عميق تجاهها،

554
00:34:42,637 --> 00:34:47,170
فإنك ستحظى بالكثير من النصائح الجيدة
والوقت من مستشارك.

555
00:34:47,170 --> 00:34:50,590
إذا كنت تعمل في أشياء
لا يعد المستشار مهتمًا بها،

556
00:34:50,590 --> 00:34:55,262
فكل ما ستحصل عليه، هو بعض النصائح،
ولكنها لن تكون مفيدة للغاية.

557
00:34:55,262 --> 00:34:58,386
>> نعم، 
وآخر شيء حول النصيحة للمتعلمين،

558
00:34:58,386 --> 00:35:02,440
كيف تشعر بخصوص الأشخاص
الذين يدخلون برنامج دكتوراه؟

559
00:35:02,440 --> 00:35:09,687
بالمقارنة مع الانضمام إلى شركة كبيرة،
أو مجموعة أبحاث مرموقة؟

560
00:35:09,687 --> 00:35:13,890
>> نعم، إنه أمر معقد،
أفكر الآن في ما يجري،

561
00:35:13,890 --> 00:35:18,727
لا يوجد عدد كافٍ من الأكاديميين المدربين
في التعلم العميق لتثقيف كل الناس

562
00:35:18,727 --> 00:35:21,125
الذين نحتاج إلى تثقيفهم في الجامعات.

563
00:35:21,125 --> 00:35:25,011
لا يوجد النطاق الترددي
لأعضاء هيئة التدريس، ولكن

564
00:35:25,011 --> 00:35:27,780
أعتقد أن هذا سيكون مؤقتًا.

565
00:35:27,780 --> 00:35:32,410
أعتقد أن ما حدث هو أن
معظم الأقسام كانت بطيئة جدًا في

566
00:35:32,410 --> 00:35:34,890
فهم نوع التطور
الذي يجري.

567
00:35:34,890 --> 00:35:38,720
أوافقك الرأي إلى حد ما، هذا
ليس تطورًا صناعيًا ثانيًا، ولكنه

568
00:35:38,720 --> 00:35:41,000
شيء بهذا الحجم تقريبًا.

569
00:35:41,000 --> 00:35:43,691
وهنا تغيير كبير للغاية يحدث في وجهات النظر،

570
00:35:43,691 --> 00:35:47,980
بشكل أساسي لأن علاقتنا
مع أجهزة الكمبيوتر قد تغيرت.

571
00:35:47,980 --> 00:35:53,920
بدلاً من برمجتها،
نحن الآن نوضح لها، وهي تكتشف الأمر.

572
00:35:53,920 --> 00:35:56,570
وهذه طريقة مختلفة تمامًا
في استخدام أجهزة الكمبيوتر

573
00:35:56,570 --> 00:36:01,210
وقد تم تصميم أقسام علوم الكمبيوتر
حول فكرة برمجة أجهزة الكمبيوتر.

574
00:36:01,210 --> 00:36:03,480
وهي لا تفهم هذه النوعية،

575
00:36:05,000 --> 00:36:09,330
أجهزة كمبيوتر العرض هذه ستكون
كبيرة بحجم أجهزة كمبيوتر البرمجة.

576
00:36:09,330 --> 00:36:13,940
باستثناء عدم فهمها أن نصف الأشخاص
في الأقسام يجب أن يكونوا أشخاصًا

577
00:36:13,940 --> 00:36:16,510
يحضرون أجهزة الكمبيوتر لتنفيذ
الأمور من خلال عرضها.

578
00:36:16,510 --> 00:36:22,183
ويرفض قسمي الإقرار
بضرورة وجود الكثير

579
00:36:22,183 --> 00:36:24,790
من الأشخاص الذين يفعلون هذا الأمر.

580
00:36:24,790 --> 00:36:28,730
فهم يعتقدون أنه يمكنك توفير مجموعة،
ربما أكثر قليلاً، ولكن ليس كثيرًا للغاية.

581
00:36:31,260 --> 00:36:32,452
وفي هذه الحالة

582
00:36:32,452 --> 00:36:36,510
يجب عليك تذكير الشركات الكبيرة
للقيام بالكثير من التدريب.

583
00:36:36,510 --> 00:36:40,335
إن Google يدرب الناس الآن،
وهو ما نطلق عليه موطن العقل،

584
00:36:40,335 --> 00:36:43,792
أعتقد أن الجامعات
في النهاية ستواكب الأمر.

585
00:36:43,792 --> 00:36:48,360
>> نعم، في الواقع، ربما
اكتشف الكثير من الطلاب هذا.

586
00:36:48,360 --> 00:36:53,131
ترغب الكثير من البرامج المدرجة في أول
50 برنامجًا، أكثر من نصف المتقدمين بالفعل

587
00:36:53,131 --> 00:36:57,079
في العمل على العرض
بدلاً من البرمجة.

588
00:36:57,079 --> 00:37:00,720
نعم، رائع، في الواقع،
لإعطاء الفضل لمن يستحقه،

589
00:37:00,720 --> 00:37:04,930
حيث يقوم الذكاء الاصطناعي للتعلم العميق
بإنشاء تخصص التعلم العميق.

590
00:37:04,930 --> 00:37:09,239
إلى حد علمي، فإن أول دورة تدريبية هائلة مفتوحة عبر
الإنترنت في التعلم العميق كانت تلك التي قمت بتدريسها

591
00:37:09,239 --> 00:37:11,752
على كورسيرا، وتعود لعام 2012، أيضًا.

592
00:37:12,828 --> 00:37:14,430
وبطريقة غريبة إلى حد ما،

593
00:37:14,430 --> 00:37:18,900
حدث هذا عندما نشرت خوارزمية RMS
لأول مرة، وهو أمر صعب.

594
00:37:20,240 --> 00:37:25,910
>> حسنًا، نعم، كما تعلم، كان هذا لأنك دعوتني
لدراسة دورة تدريبية هائلة مفتوحة عبر الإنترنت.

595
00:37:25,910 --> 00:37:30,239
وعندما كنت غير متيقن بخصوص
التنفيذ، فإنك واصلت تشجيعي للقيام بالأمر،

596
00:37:30,239 --> 00:37:34,340
لذا فهذا عمل رائع مني، على الرغم
من أنه كان ينطوي على الكثير من العمل.

597
00:37:34,340 --> 00:37:37,409
>> نعم، وشكرًا لك على فعل ذلك،
أتذكر أنك قدمت الشكوى لي،

598
00:37:37,409 --> 00:37:38,351
ما مقدار العمل المبذول.

599
00:37:38,351 --> 00:37:42,413
وأنت تبقى لوقت متأخر في الليل،
ولكنني أعتقد أن الكثير من المتعلمين

600
00:37:42,413 --> 00:37:47,330
قد استفادوا من أول دورة تدريبية هائلة مفتوحة
عبر الإنترنت، وبالتالي فأنا ممتن جدًا لك نظير ذلك.

601
00:37:47,330 --> 00:37:49,260
>> هذا جيد، نعم
>> نعم، على مدار السنين،

602
00:37:49,260 --> 00:37:53,290
رأيتك مشتركًا في مناقشات حول
أمثلة للذكاء الاصطناعية

603
00:37:53,290 --> 00:37:57,030
وما إذا كان هناك تحول في
المثال للذكاء الاصطناعي.

604
00:37:57,030 --> 00:37:59,984
ما،
هل يمكنك مشاركة أفكارك حول هذا الأمر؟

605
00:37:59,984 --> 00:38:05,157
>> نعم، بكل سعادة، أعتقد أنه في
الأيام الأولى، منذ الخمسينات،

606
00:38:05,157 --> 00:38:10,335
الأشخاص مثل فون نيومان
ولم يؤمنوا بالذكاء الاصطناعي الرمزي،

607
00:38:10,335 --> 00:38:14,220
حصلوا على الإلهام من قِبل العقل.

608
00:38:14,220 --> 00:38:20,127
لسوء الحظ، توفى كلاهما بسن صغير جدًا
ولم يكن صوتهما مسموعًا.

609
00:38:20,127 --> 00:38:21,806
وفي الأيام الأولى من الذكاء الاصطناعي،

610
00:38:21,806 --> 00:38:26,259
اقتنع الناس تمامًا
أن التمثيلات التي تحتاج إليها

611
00:38:26,259 --> 00:38:30,500
للذكاء كانت التعبيرات
الرمزية إلى حد ما.

612
00:38:30,500 --> 00:38:35,509
أحد أشكال المنطق النظيف،
والذي يمكنك خلاله أداء الأشياء وليس

613
00:38:35,509 --> 00:38:41,143
المنطق بصورة مطلقة، ولكنه شيء أشبه بالمنطق،
وجوهر الذكاء كان الاستدلال.

614
00:38:41,143 --> 00:38:45,662
ما يحدث الآن هو
أن هناك وجهة نظر مختلفة تمامًا،

615
00:38:45,662 --> 00:38:50,984
وهي أن الفكرة عبارة عن
متجه كبير رائع للنشاط العصبي،

616
00:38:50,984 --> 00:38:55,200
على النقيض من ذلك،
الفكرة التي تعد تعبيرًا رمزيًا.

617
00:38:55,200 --> 00:38:59,087
وأعتقد أن الأشخاص الذين اعتقدوا أن
الأفكار كانت عبارة عن تعبيرات رمزية

618
00:38:59,087 --> 00:39:00,140
قد ارتكبوا خطأ كبيرًا.

619
00:39:01,210 --> 00:39:07,030
فما يأتي عبارة عن سلسلة كلمات،
وما يخرج عبارة عن سلسلة كلمات.

620
00:39:08,140 --> 00:39:12,580
ونظرًا لذلك، فإن سلاسل الكلمات
هي الطريقة الواضحة لتمثيل الأشياء.

621
00:39:12,580 --> 00:39:15,710
وبالتالي فقد اعتقدوا أن ما يجب أن يكون في الوسط
كان سلسلة كلمات أو

622
00:39:15,710 --> 00:39:18,360
شيئًا مثل سلسة كلمات.

623
00:39:18,360 --> 00:39:21,310
وأعتقد أن ما يأتي في الوسط
ليس شيئًا مثل سلسلة كلمات.

624
00:39:21,310 --> 00:39:26,060
أعتقد أن الفكرة في أن الأفكار يتعين أن تكون
بلغة ما هي فكرة سخيفة

625
00:39:26,060 --> 00:39:30,980
مثل الفكرة التي تفيد بأن فهم
التخطيط في مشهد مكاني

626
00:39:30,980 --> 00:39:34,280
يتعين أن يكون بالبكسل.

627
00:39:34,280 --> 00:39:37,930
وإذا كانت لدينا طابعة
مصفوفة نقطية مرتبطة بنا،

628
00:39:37,930 --> 00:39:41,929
فيتعين أن تخرج وحدات البكسل ولكن
ما بين ذلك ليس بكسل.

629
00:39:43,210 --> 00:39:46,620
لذلك أعتقد أن الأفكار هي
مجرد متجهات كبيرة رائعة

630
00:39:46,620 --> 00:39:48,460
وأن هذه المتجهات الكبيرة لديها قوى سببية.

631
00:39:48,460 --> 00:39:50,490
فهي تتسبب في متجهات كبيرة أخرى،

632
00:39:50,490 --> 00:39:56,100
وهذا مخالف تمامًا لوجهة نظر الذكاء الاصطناعي
القياسي بأن الأفكار هي تعبيرات رمزية.

633
00:39:56,100 --> 00:39:56,700
>> نعم، جيد،

634
00:39:57,740 --> 00:40:01,560
أعتقد أن الذكاء الاصطناعي بالتأكيد سيأتي
إلى وجهة النظر الجديدة هذه في الأيام الحالية.

635
00:40:01,560 --> 00:40:02,660
>> بعض ذلك،

636
00:40:02,660 --> 00:40:08,230
أعتقد أن الكثير من الناس في الذكاء الاصطناعي ما زالوا
يعتقدون أن الأفكار يجب أن تكون تعبيرات رمزية.

637
00:40:08,230 --> 00:40:09,780
>> شكرًا كثيرًا لك
على إجراء هذه المقابلة.

638
00:40:09,780 --> 00:40:12,970
كان من الرائع أن نعرف كيف تطور
التعلم العميق على مر السنين،

639
00:40:12,970 --> 00:40:17,680
وكذلك كيف تكونوا ما زلتم تساعدون في توجيهه
نحو المستقبل، إذًا شكرًا لك، جيف.

640
00:40:17,680 --> 00:40:19,038
>> حسنًا، شكرًا لك على
منحي هذه الفرصة.

641
00:40:19,038 --> 00:40:20,147
>> شكرًا.