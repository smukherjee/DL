В попередньому відео ти бачив/ла модель логістичної регресії (ЛР). Щоб натренувати параметри w і b моделі ЛР, нам потрібно визначити функцію Витрат. Давай розглянемо функцію Витрат, яку ми можемо 
використовувати для тренування ЛР. Згадаємо з попереднього слайду що нам треба було знайти. Тож, наша вихідна ŷ= сигмоїді від wᵀx+b, а сигмоїда від z визначається ось так. Тож, щоб навчити параметри нашої моделі, нам дано тренувальний набір з m тренувальних зразків і, природно, що ми хочемо знайти параметри w і b, такі, щоб хоча б для тренувального набору, вивід або передбачення, які ми маємо для тренувального набору, які ми записуємо справа як ŷ⁽ⁱ⁾, були наближеними до емпіричних позначок y⁽ⁱ⁾, які ми маємо в тренувальному наборі. Тож, щоб більш детально описати рівняння вгорі, ми мусимо сказати, що ŷ=, 
як визначено вгорі для тренувального зразка x і, очевидно, 
для кожного тренувального зразка, ми використовуємо ось такі верхні індекси в дужках, щоб позначати і відрізняти тренувальні зразки. Наше передбачення для тренувального зразка ⁽ⁱ⁾, 
тобто ŷ, буде отримане застосуванням сигмоїди до wᵀx⁽ⁱ⁾ (вхідні дані тренувального зразка) +b. 
z⁽ⁱ⁾ можна також визначити наступним чином: z⁽ⁱ⁾=wᵀx⁽ⁱ⁾+b. Тож, протягом цього курсу ми будемо використовувати оцю нотативну конвенцію, згідно якої, верхній індекс ⁽ⁱ⁾ відсилає до даних x або y, або z, чи інших, пов'язаних з i-тим тренувальним зразком або i-тим зразком. Ось що означає верхній індекс в дужках. Тепер давай розглянемо функцію Втрати або функцію Похибки, яку ми можемо використовувати щоб оцінити 
наскільки добре працює наш алгоритм. Одне з того, що можна зробити, 
це обчислити втрату між тим, що видає алгоритм ŷ і справжньою міткою як, скажімо, 
квадратичну похибку або половину квадратичної похибки. Виявляється, що зробити це можна, але для ЛР, це, як правило, не використовується. Тому, що перед навчанням параметрів, виявляється, що проблема оптимізації 
(про яку ми поговоримо пізніше) стає неопуклою. Тож, в кінцевому підсумку, проблема оптимізації 
буде мати багато локальних оптимумів. А Градієнтний спуск може не знайти глобального оптимуму. Якщо ти не зрозумів/ла кілька останніх коментарів, не переймайся, ми повернемось до цього пізніше. Все, що необхідно запам'ятати, - це, що ця функція L, що називається функцією Втрати, - це функція, яка буде необхідна для оцінки наскільки точною є наша вихідна ŷ 
відносно справжньої мітки y. І що квадратична похибка, схоже, - виправданий вибір, якщо вона не впливає негативно на роботу Градієнтного спуску. Тож, в ЛР ми, насправді, будемо визначати дещо іншу функцію Втрати, що виконує роль схожу до квадратичної функції, але яка дасть нам опуклий результат оптимізації і, як ми побачимо пізніше, яку буде набагато легше оптимізувати. Тож, те, що ми використовуємо в ЛР, є, насправді, функція Втрати, яку я зараз тут запишу: -y*log(ŷ)+(1-y)* log(1-ŷ) Пролиємо трохи світла на зміст цієї функції Втрати. Пам'ятай, що коли ми використовуємо квадратичну похибку, то хочемо, 
щоб вона була настільки малою, наскільки це можливо. І з цією функцією Втрати ЛР те саме - ми теж хочемо, 
щоб вона була настільки малою, наскільки це можливо. Щоб зрозуміти чому це важливо, давай розглянемо такі 2 випадки. В першому випадку скажімо y=1, тоді функція Втрати L(ŷ, y) = першому доданку. тобто =-log(ŷ), а y=1. Тому що, якщо y=1, то другий доданок, де ми маємо (1-y), =0. Тож звідси випливає, що якщо y=1, 
нам треба, щоб log(ŷ) був якомога більший. Значить, потрібно, щоб log(ŷ) був великим, якомога більшим, що значить, 
що потрібно щоб ŷ був великим. Але через те, що ŷ, як відомо, це - сигмоїда, яка ніколи не може буде >1. Скажімо так: коли y=1 потрібно щоб ŷ був настільки великим, 
наскільки це можливо. Проте, він ніколи не може бути >1, 
то потрібно щоб він був якомога ближчим до 1. Інший приклад - коли y=0. Якщо y=0, тоді перший доданок функції Втрати =0, тому що y=0. І тоді другий доданок визначає функцію Втрати. Тож Втрата буде =-log(1-ŷ). Тож якщо, застосовуючи навчання, 
ми намагаємося зробити функцію Втрати маленькою, це значить, що ми хочемо, щоб log(1-ŷ) був великим. А через цей знак мінус і з тої ж причини ми можемо дійти висновку, що ця функція Втрати намагається зробити ŷ якомога меншим. І знову ж, через те, що ŷ мусить бути між 0 і 1, ми маємо, що, якщо y=0, то наша функція Втрати підбиратиме параметри так, 
щоб зробити ŷ якомога ближче до 0. Тепер. Існує багато функцій з подібним ефектом - якщо y=1, то ми намагаємось зробити ŷ великим, 
а якщо y=0, то ми намагаємось зробити ŷ малим. Тут ми даємо лише (те, що зеленим) поверхневе обґрунтування цієї конкретної функції Втрати. Ми надамо пізніше необов'язкове відео з більш повним обґрунтуванням чому ми хочемо використовувати в ЛР 
саме цю конкретну формулу. Отож, функція Втрати була визначена для одного тренувального зразка. Вона вимірює наскільки добре ми справляємось 
з одним тренувальним зразком. Зараз я збираюсь визначити те, що називається функцією Витрат, яка вимірює наскільки добре ми справляємось 
з усім тренувальним набором. Тож функція Витрат J, що застосовується до наших параметрів w і b, буде середнім, себто 1/m, від суми функцій Втрати 
застосованих до кожного тренувального зразка по черзі. Де ŷ - звичайно, передбачення виведене нашим алгоритмом ЛР, 
що використовує, як відомо, певний набір параметрів w і b. Тепер просто розпишемо цю формулу. =-1/m, сума від 1 до m визначених функцій Втрати. Тобто, y(i)*log(ŷ(i)) +(1-y(i))*log(1-ŷ(i)). Думаю, я можу дописати тут квадратні дужки. І винести за них мінус. Тож, термінологія, яку я використовуватиму наступна: функція Втрати застосовується до одного тренувального зразка (ось так), а функція Витрат - це витрати параметрів. Тож, тренуючи свою модель ЛР, ми будемо намагатись знайти такі параметри w і b, що мінімізують загальну функцію Витрат J, записану внизу. Отже, ти щойно побачив/ла побудову алгоритму ЛР, функцію Втрати для тренувального зразка і загальну функцію Витрат для параметрів твого алгоритму. Виявляється, що ЛР може розглядатись 
як дуже маленька нейронна мережа (НМ). В наступному відео ми про це поговоримо, тож ти почнеш розуміти що роблять НМ. Тож давай перейдемо до наступного відео про те, як розглянути ЛР як дуже маленьку НМ.