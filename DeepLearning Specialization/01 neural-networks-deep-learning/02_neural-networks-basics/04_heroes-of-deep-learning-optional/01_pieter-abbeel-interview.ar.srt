1
00:00:02,420 --> 00:00:04,575
إذًا، شكرًا جزيلاً لك يا بيتر

2
00:00:04,575 --> 00:00:06,690
على الانضمام إليّ اليوم.

3
00:00:06,690 --> 00:00:08,560
أعتقد أن الكثير من الناس يعرفون أنك

4
00:00:08,560 --> 00:00:12,150
باحث معروف في مجال التعلم الآلي والتعلم العميق والروبوتات.

5
00:00:12,150 --> 00:00:15,550
أود أن يسمع الناس قليلاً عن قصتك.

6
00:00:15,550 --> 00:00:18,220
كيف انتهى بك المطاف إلى القيام بالعمل الذي تمارسه؟

7
00:00:18,220 --> 00:00:22,300
هذا سؤال جيد، وفي الواقع لو كنت سألتني بينما أبلغ من العمر 14 عامًا،

8
00:00:22,300 --> 00:00:24,775
عما كنت أطمح إلى عمله،

9
00:00:24,775 --> 00:00:26,775
فإنه على الأرجح لن يكون ذلك.

10
00:00:26,775 --> 00:00:28,285
في الواقع، في ذلك الوقت،

11
00:00:28,285 --> 00:00:32,565
اعتقدت أن كوني لاعب كرة سلة محترف قد يكون الطريق الصحيح نحو المستقبل.

12
00:00:32,565 --> 00:00:34,680
لا أعتقد أنني كنت قادرًا على تحقيق ذلك.

13
00:00:34,680 --> 00:00:36,430
أشعر أن الحظ قد حالفك مع التعلم الآلي،

14
00:00:36,430 --> 00:00:38,250
بينما لم يفلح الأمر مع كرة السلة.

15
00:00:38,250 --> 00:00:39,510
نعم، هذا لم ينجح.

16
00:00:39,510 --> 00:00:41,890
كان هناك الكثير من المرح في لعب كرة السلة لكن الأمر لم ينجح

17
00:00:41,890 --> 00:00:44,885
في محاولة تحويل ذلك إلى مهنة.

18
00:00:44,885 --> 00:00:48,530
إذًا، ما أعجبني بالفعل في المدرسة الفيزياء والرياضيات.

19
00:00:48,530 --> 00:00:50,005
وهكذا، من تلك النقطة،

20
00:00:50,005 --> 00:00:52,120
بدا من الطبيعي دراسة الهندسة التي

21
00:00:52,120 --> 00:00:55,735
تستخدم الفيزياء والرياضيات في العالم الحقيقي.

22
00:00:55,735 --> 00:00:58,150
وفي الواقع، بعد أن كنت طالبًا في الهندسة الكهربائية،

23
00:00:58,150 --> 00:01:00,355
لم أكن متأكدًا حقًا مما يجب أن أفعله لأنه،

24
00:01:00,355 --> 00:01:03,981
حرفيًا، بدا أي شيء هندسي مثيرًا للاهتمام بالنسبة لي.

25
00:01:03,981 --> 00:01:07,680
إن فهم كيفية عمل أي شيء يبدو مثيرًا للاهتمام.

26
00:01:07,680 --> 00:01:09,595
محاولة بناء أي شيء أمر مثير للاهتمام.

27
00:01:09,595 --> 00:01:11,470
وبشكل ما،

28
00:01:11,470 --> 00:01:13,690
تفوّق الذكاء الاصطناعي لأنه بدا وكأنه

29
00:01:13,690 --> 00:01:18,280
يستطيع أن يساعد جميع التخصصات بطريقة ما.

30
00:01:18,280 --> 00:01:22,370
وأيضًا، بدا أنه أكثر من ذلك بقليل في صميم كل شيء.

31
00:01:22,370 --> 00:01:24,575
أنت تفكر في الطريقة التي يمكن للآلة أن تفكر بها،

32
00:01:24,575 --> 00:01:30,160
ثم ربما يكون ذلك جوهر كل شيء آخر أكثر من اختيار أي تخصص معين.

33
00:01:30,160 --> 00:01:33,260
لقد قلتُ أن الذكاء الاصطناعي هو الكهرباء الجديدة،

34
00:01:33,260 --> 00:01:35,020
تبدو وكأنها نسختك التي تبلغ من العمر 15 عامًا؛

35
00:01:35,020 --> 00:01:37,923
كانت نسخة سابقة من ذلك حتى.

36
00:01:37,923 --> 00:01:44,465
أنت تعلم، في السنوات القليلة الماضية، قمتَ بالكثير من العمل في التعلم المعزز العميق.

37
00:01:44,465 --> 00:01:49,315
ماذا يحدث؟ لماذا يتطور التعلم المعزز العميق فجأة؟

38
00:01:49,315 --> 00:01:51,030
قبل أن أعمل في مجال التعلم المعزز العميق،

39
00:01:51,030 --> 00:01:52,765
عملت كثيرًا في التعلم المعزز؛

40
00:01:52,765 --> 00:01:56,115
في الواقع معك ومع ديورانت في ستانفورد، بالطبع.

41
00:01:56,115 --> 00:01:59,863
وهكذا، عملنا على رحلة طائرة مروحية ذاتية الحكم،

42
00:01:59,863 --> 00:02:02,440
ثم في وقت لاحق في بيركلي مع بعض طلابي الذين عملوا

43
00:02:02,440 --> 00:02:05,440
على تصميم روبوت يتعلم طيّ الملابس المغسولة.

44
00:02:05,440 --> 00:02:09,340
وما ميّز العمل بشكل ما كان الجمع

45
00:02:09,340 --> 00:02:13,015
بين التعلم الذي ساهم في تمكين الأشياء التي لم تكن لتكون ممكنة بدون التعلم،

46
00:02:13,015 --> 00:02:18,120
مع الكثير من الخبرات في المجال جنبًا إلى جنب مع تعلم كيفية جعل هذا الشيء يعمل.

47
00:02:18,120 --> 00:02:20,975
وقد كان هذا

48
00:02:20,975 --> 00:02:22,600
مثيرًا للاهتمام لأنك كنت بحاجة إلى خبرة في المجال كان

49
00:02:22,600 --> 00:02:24,310
من الممتع اكتسابها، ولكن في الوقت نفسه،

50
00:02:24,310 --> 00:02:28,234
كانت تستهلك الكثير جدًا من الوقت لكل تطبيق جديد تريد النجاح فيه؛

51
00:02:28,234 --> 00:02:31,060
لقد كنت بحاجة إلى خبرة في المجال بالإضافة إلى خبرة في التعلم الآلي.

52
00:02:31,060 --> 00:02:34,240
وبالنسبة لي، كان ذلك في عام 2012 مع

53
00:02:34,240 --> 00:02:39,910
نتائج الطفرة التي حققتها ImageNet من مجموعة جيف هينتون في تورنتو،

54
00:02:39,910 --> 00:02:42,880
وأظهرت AlexNet أن التعلم تحت الإشراف، بشكل مفاجئ،

55
00:02:42,880 --> 00:02:48,220
يمكن أن يتم مع هندسة أقل بكثير بالنسبة للمجال المطروح.

56
00:02:48,220 --> 00:02:50,410
كان هناك القليل جدًا من الرؤية الهندسية في AlexNet.

57
00:02:50,410 --> 00:02:53,075
لقد جعلني أعتقد أننا يجب حقًا أن نعيد التفكير

58
00:02:53,075 --> 00:02:57,610
في التعلم المعزز في ظل نفس وجهة النظر ونرى ما إذا كان

59
00:02:57,610 --> 00:03:01,075
بإمكاننا الحصول على النسخة العميقة من التعلم المعزز للعمل وتنفيذ

60
00:03:01,075 --> 00:03:05,950
أشياء مثيرة للاهتمام بنفس القدر كما حدث في التعلم العميق تحت الإشراف.

61
00:03:05,950 --> 00:03:08,565
يبدو أنك قد رأيت قبل

62
00:03:08,565 --> 00:03:12,250
معظم الناس إمكانات التعلم المعزز العميق.

63
00:03:12,250 --> 00:03:14,365
إذًا، بالنظر الآن إلى المستقبل،

64
00:03:14,365 --> 00:03:16,180
ماذا ترى بعد ذلك؟

65
00:03:16,180 --> 00:03:17,260
ما توقعاتك بالنسبة

66
00:03:17,260 --> 00:03:20,440
للطرق العديدة التالية المتوقع ظهورها في التعلم المعزز العميق؟

67
00:03:20,440 --> 00:03:23,270
إذًا، أعتقد أن المثير للاهتمام حول التعلم المعزز العميق هو أنه،

68
00:03:23,270 --> 00:03:26,795
بشكل ما، هناك العديد من الأسئلة أكثر من الموجودة في التعلم تحت الإشراف.

69
00:03:26,795 --> 00:03:29,817
في التعلم تحت الإشراف، يتعلق الأمر بتعلم رسم تخطيط للمخرجات/المدخلات.

70
00:03:29,817 --> 00:03:34,505
في التعلم المعزز هناك مفهوم يدور حول: من أين تأتي البيانات؟

71
00:03:34,505 --> 00:03:36,580
إذًا، هذه مشكلة التنقيب.

72
00:03:36,580 --> 00:03:38,470
عندما تكون لديك بيانات، كيف تقوم بتحديد نقاط التحسّن؟

73
00:03:38,470 --> 00:03:43,315
كيف يمكنك فهم الإجراءات التي اتخذتها في وقت مبكر وأتت ثمارها لاحقًا؟

74
00:03:43,315 --> 00:03:44,830
ثم، هناك مشكلات السلامة.

75
00:03:44,830 --> 00:03:47,335
عندما يكون لديك نظام يجمع البيانات بشكل مستقل،

76
00:03:47,335 --> 00:03:50,140
فهو في الواقع أمر خطير في معظم الحالات.

77
00:03:50,140 --> 00:03:51,880
تخيّل شركة سيارات ذاتية القيادة تعلن

78
00:03:51,880 --> 00:03:53,825
أنها ستقوم بتشغيل التعلم المعزز العميق.

79
00:03:53,825 --> 00:03:55,690
من المرجح أن تتعرض السيارة للكثير من

80
00:03:55,690 --> 00:03:57,985
الحوادث قبل أن تفعل أي شيء مفيد.

81
00:03:57,985 --> 00:03:59,650
لقدكنتَ بحاجة إلى أمثلة سلبية من ذلك، أليس كذلك؟

82
00:03:59,650 --> 00:04:02,000
أنت بحاجة إلى بعض الأمثلة السلبية بطريقة ما، نعم؛

83
00:04:02,000 --> 00:04:04,930
وكذلك أمثلة إيجابية لتمنحك الأمل.

84
00:04:04,930 --> 00:04:07,540
إذًا، أعتقد أنه لا يزال هناك الكثير من التحديات في

85
00:04:07,540 --> 00:04:09,760
التعلم المعزز العميق من حيث

86
00:04:09,760 --> 00:04:12,635
وضع بعض التفاصيل حول كيفية جعل هذه الأشياء تعمل.

87
00:04:12,635 --> 00:04:14,520
إذًا، فالجزء العميق هو التمثيل،

88
00:04:14,520 --> 00:04:18,455
ولكن التعلم المعزز نفسه لا يزال به الكثير من الأسئلة.

89
00:04:18,455 --> 00:04:20,485
وما أشعر به هو أنه،

90
00:04:20,485 --> 00:04:22,810
مع التقدم في التعلم العميق،

91
00:04:22,810 --> 00:04:27,430
تم التعامل بشكل كبير مع جزء من الغموض في التعلم المعزز بشكل ما،

92
00:04:27,430 --> 00:04:29,075
وهو جزء التمثيل.

93
00:04:29,075 --> 00:04:31,540
لذا، إذا كان هناك نمط، يمكننا

94
00:04:31,540 --> 00:04:34,795
تمثيله على الأرجح مع شبكة عميقة والتعامل مع هذا النمط.

95
00:04:34,795 --> 00:04:39,400
ولا تزال كيفية تفكيك النمط تشكل تحديًا كبيرًا في التعلم المعزز.

96
00:04:39,400 --> 00:04:41,740
لذا أعتقد أن التحديات الكبيرة تتمثل في

97
00:04:41,740 --> 00:04:45,695
كيفية جعل الأنظمة منطقية على آفاق زمنية طويلة.

98
00:04:45,695 --> 00:04:47,770
إذًا، في الوقت الحالي، هناك الكثير من النجاحات

99
00:04:47,770 --> 00:04:50,650
في التعلم المعزز العميق ذات أفق قصير جدًا.

100
00:04:50,650 --> 00:04:52,000
هناك مشكلات تتمثل في أنه

101
00:04:52,000 --> 00:04:54,445
إذا كنت تتصرف بشكل جيد على مدى خمس ثوانٍ،

102
00:04:54,445 --> 00:04:57,815
فإنك تتصرف بشكل جيد على مدى المسألة برمتها.

103
00:04:57,815 --> 00:05:02,599
إذًا، مقياس خمس ثوانٍ يختلف كثيرًا عن مقياس يوم،

104
00:05:02,599 --> 00:05:06,930
أو القدرة على عيش حياة كروبوت أو وكيل برمجي.

105
00:05:06,930 --> 00:05:09,240
إذًا، أعتقد أن هناك الكثير من التحديات هناك.

106
00:05:09,240 --> 00:05:12,790
أعتقد أن السلامة تواجه الكثير من التحديات من حيث،

107
00:05:12,790 --> 00:05:14,920
كيف تتعلم بأمان، وكيف يمكنك أيضًا

108
00:05:14,920 --> 00:05:17,785
الاستمرار في التعلم بمجرد أن تكون جيدًا بالفعل؟

109
00:05:17,785 --> 00:05:20,305
إذًا، لضرب مثال مرة أخرى أن

110
00:05:20,305 --> 00:05:23,070
الكثير من الناس قد يكونون على دراية بالسيارات ذاتية القيادة،

111
00:05:23,070 --> 00:05:26,375
وأن السيارة ذاتية القيادة قد تكون أفضل من سائق بشري،

112
00:05:26,375 --> 00:05:31,990
في حال تعرض السائقين البشر لحوادث سيئة كل ثلاثة ملايين ميل أو نحو ذلك.

113
00:05:31,990 --> 00:05:35,763
وهكذا، يستغرق ذلك وقتًا طويلاً لمشاهدة البيانات السلبية؛

114
00:05:35,763 --> 00:05:37,510
بمجرد أن تكون ماهرًا كسائق بشري.

115
00:05:37,510 --> 00:05:40,835
لكنك تريد أن تكون سيارتك ذاتية القيادة أفضل من السائق البشري.

116
00:05:40,835 --> 00:05:43,930
وهكذا، يصبح جمع البيانات في هذه المرحلة أمرًا غير سهل على الإطلاق للحصول

117
00:05:43,930 --> 00:05:48,175
على تلك البيانات المثيرة للاهتمام التي تجعل نظامك يتحسن.

118
00:05:48,175 --> 00:05:52,420
إذًا، هناك الكثير من التحديات المتعلقة بالتنقيب، والتي لا تنفك عنه.

119
00:05:52,420 --> 00:05:57,190
ولكن أحد الأشياء التي أثارت حماستي حقًا في الوقت الحالي هي معرفة

120
00:05:57,190 --> 00:06:02,720
ما إذا كان بإمكاننا في الواقع الرجوع خطوة إلى الوراء وتعلم خوارزمية التعلم المعزز أيضًا.

121
00:06:02,720 --> 00:06:05,030
إذًا، فإن التعزيز معقد للغاية،

122
00:06:05,030 --> 00:06:07,450
وتحديد نقاط التحسّن معقد للغاية، والتنقيب معقد للغاية.

123
00:06:07,450 --> 00:06:08,905
وهكذا، تمامًا مثلما كان

124
00:06:08,905 --> 00:06:13,795
التعلّم العميق للتعلّم تحت الإشراف قادرًا على استبدال الكثير من خبرات المجال،

125
00:06:13,795 --> 00:06:17,320
ربما يمكن أن تكون لدينا برامج مُتعلّمة،

126
00:06:17,320 --> 00:06:20,140
وهي برامج تعلّم معزز تقوم بكل هذا،

127
00:06:20,140 --> 00:06:22,510
بدلاً من أن نقوم نحن بتصميم التفاصيل.

128
00:06:22,510 --> 00:06:25,560
خلال دالة المكافأة أو خلال البرنامج بأكمله؟

129
00:06:25,560 --> 00:06:28,150
إذًا، فإن هذا سيكون تعلم برنامج التعلم المعزز بأكمله.

130
00:06:28,150 --> 00:06:30,430
إذًا، لك أن تتخيل أن

131
00:06:30,430 --> 00:06:34,255
لديك برنامجًا للتعلم المعزز، أيًا كان نوعه،

132
00:06:34,255 --> 00:06:38,320
وأنك تضعه في قلب مشكلة ما، ثم ترى الوقت الذي يستغرقه للتعلم.

133
00:06:38,320 --> 00:06:41,020
ومن ثم تقول، حسنًا، هذا استغرق بعض الوقت.

134
00:06:41,020 --> 00:06:44,950
الآن، دع برنامجًا آخر يقوم بتعديل برنامج التعلم المعزز هذا.

135
00:06:44,950 --> 00:06:48,045
بعد التعديل، ترى مدى السرعة التي يتعلم بها.

136
00:06:48,045 --> 00:06:49,641
إذا كان يتعلم بسرعة أكبر،

137
00:06:49,641 --> 00:06:54,380
فهذا يعني أنه تعديل جيد وربما تحتفظ به وتبدأ التحسين من هناك.

138
00:06:54,380 --> 00:06:57,630
حسنًا، فهمت، صحيح. إنه استثمار في الاتجاه.

139
00:06:57,630 --> 00:06:59,290
أعتقد أن هناك الكثير للقيام به مع، ربما،

140
00:06:59,290 --> 00:07:01,510
مقدار الحوسبة التي أصبحت متاحة.

141
00:07:01,510 --> 00:07:05,860
لذا، فإن هذا قد يكون تشغيل التعلم المعزز في الحلقة الداخلية.

142
00:07:05,860 --> 00:07:08,975
بالنسبة لنا في الوقت الحالي، نحن نمارس التعلم المعزز باعتباره آخر شيء.

143
00:07:08,975 --> 00:07:11,260
وهكذا، كلما حصلنا على المزيد من الحوسبة،

144
00:07:11,260 --> 00:07:14,545
زادت إمكانية تشغيل شيء من هذا القبيل

145
00:07:14,545 --> 00:07:19,160
مثل التعلم المعزز في الحلقة الداخلية لخوارزمية أكبر.

146
00:07:19,160 --> 00:07:22,080
منذ كان عمرك 14 سنة،

147
00:07:22,080 --> 00:07:25,355
عملتَ في مجال الذكاء الاصطناعي لأكثر من 20 سنة حتى الآن.

148
00:07:25,355 --> 00:07:32,795
إذًا، أخبرني قليلاً عن كيفية تطور فهمك للذكاء الاصطناعي خلال هذه الفترة.

149
00:07:32,795 --> 00:07:35,280
عندما بدأت البحث في الذكاء الاصطناعي،

150
00:07:35,280 --> 00:07:38,230
كان الأمر مثيرًا للاهتمام للغاية لأنه حقًا

151
00:07:38,230 --> 00:07:41,445
تزامن مع مجيئي إلى ستانفورد لتحضير رسالة الماجستير هناك،

152
00:07:41,445 --> 00:07:46,998
وكانت هناك بعض الرموز مثل جون مكارثي الذي تحدثت معه،

153
00:07:46,998 --> 00:07:49,300
وقد كان له نهج مختلف تمامًا،

154
00:07:49,300 --> 00:07:50,460
في عام 2000،

155
00:07:50,460 --> 00:07:52,115
عما كان معظم الناس يقومون به في ذلك الوقت.

156
00:07:52,115 --> 00:07:54,958
وتحدثت أيضًا مع دافني كولر.

157
00:07:54,958 --> 00:07:59,320
وأعتقد أن الكثير من تفكيري الأولي في الذكاء الاصطناعي قد تشكّل بفضل تفكير دافني.

158
00:07:59,320 --> 00:08:04,300
إن صفها الدراسي عن الذكاء الاصطناعي، وصفها عن نماذج الرسوم الاحتمالية،

159
00:08:04,300 --> 00:08:06,820
والافتتان حقًا بشكل ما

160
00:08:06,820 --> 00:08:11,450
بمدى سهولة توزيع متغيراتها العشوائية المتعددة، ثم القدرة على البناء

161
00:08:11,450 --> 00:08:14,950
على بعض المتغيرات الفرعية والاستفادة من الاستنتاجات حول الآخرين قد

162
00:08:14,950 --> 00:08:19,015
يعطيك في الواقع الكثير إذا كنت تستطيع بطريقة ما جعل الأمر جذابًا بطريقة حاسوبية،

163
00:08:19,015 --> 00:08:23,170
مما شكّل بالتأكيد تحديًا لجعله قابلاً للحوسبة.

164
00:08:23,170 --> 00:08:25,090
ثم من هناك،

165
00:08:25,090 --> 00:08:28,335
عندما بدأتُ رسالة الدكتوراة، وأنت وصلتَ إلى جامعة ستانفورد،

166
00:08:28,335 --> 00:08:30,910
وأعتقد أنك تمنحني اختبارًا جيدًا حقًا للواقع،

167
00:08:30,910 --> 00:08:35,350
بأن هذا ليس المقياس الصحيح لتقييم عملك،

168
00:08:35,350 --> 00:08:38,470
وأن تحاول حقًا أن ترى العلاقة بين ما

169
00:08:38,470 --> 00:08:41,710
تعمل عليه مقابل تأثيره في الواقع،

170
00:08:41,710 --> 00:08:46,660
وما التغيير الذي يمكن أن يُحدِثه بدلاً من النظر إلى المسائل الرياضية في عملك.

171
00:08:46,660 --> 00:08:48,425
صحيح، هذا رائع.

172
00:08:48,425 --> 00:08:50,685
لم أكن أدرك ذلك، لقد نسيته.

173
00:08:50,685 --> 00:08:54,267
نعم، إنه في الواقع من الأشياء المهمة، وفي معظم الأحيان حين يسألني الناس

174
00:08:54,267 --> 00:09:01,090
عن الاستشهاد بشيء واحد فقط ما زال عالقًا في ذهني من نصيحة أندرو،

175
00:09:01,090 --> 00:09:05,995
أقول إنه التأكد من إمكانية رؤية العلاقة بين عملي والنتيجة المتوقعة منه.

176
00:09:05,995 --> 00:09:11,332
كانت لديك - ولا تزال - مسيرة مهنية رائعة في مجال الذكاء الاصطناعي.

177
00:09:11,332 --> 00:09:14,750
لذا، بالنسبة لبعض الأشخاص الذين يستمعون إليك من خلال الفيديو الآن،

178
00:09:14,750 --> 00:09:18,815
إذا كانوا يريدون أيضًا دخول مجال الذكاء الاصطناعي أو السعي وراء حياة مهنية فيه،

179
00:09:18,815 --> 00:09:20,985
فما النصيحة التي تقدمها لهم؟

180
00:09:20,985 --> 00:09:25,185
أعتقد أنه وقت جيد حقًا لدخول مجال الذكاء الاصطناعي.

181
00:09:25,185 --> 00:09:28,965
إذا نظرت إلى إقبال الناس، تجده مرتفعًا للغاية،

182
00:09:28,965 --> 00:09:30,741
فهناك الكثير من فرص العمل،

183
00:09:30,741 --> 00:09:32,365
والكثير من الأشياء التي يمكنك القيام بها، مثل البحث العلمي،

184
00:09:32,365 --> 00:09:34,735
وإنشاء شركات جديدة وما إلى ذلك.

185
00:09:34,735 --> 00:09:39,240
لذا، أود أن أقول نعم، إنه قرار ذكي بالتأكيد من حيث البدء الفعلي.

186
00:09:39,240 --> 00:09:41,140
الكثير منه، يمكنك بدء الدراسة الذاتية،

187
00:09:41,140 --> 00:09:42,635
سواء كنت في المدرسة أم لا.

188
00:09:42,635 --> 00:09:44,150
هناك الكثير من الدورات التدريبية على الإنترنت، على سبيل المثال،

189
00:09:44,150 --> 00:09:45,585
الدورة التدريبية التي تقدمها عن التعلم الآلي،

190
00:09:45,585 --> 00:09:48,400
وهناك أيضًا، على سبيل المثال،

191
00:09:48,400 --> 00:09:52,030
الدورة التدريبية التي يقدمها أندريه كارباثي عن التعلم العميق والتي تتضمن مقاطع فيديو عبر الإنترنت،

192
00:09:52,030 --> 00:09:54,280
وهي طريقة رائعة للبدء،

193
00:09:54,280 --> 00:09:57,460
وبيركلي الذي لديه دورة تدريبية عن التعلم المعزز العميق

194
00:09:57,460 --> 00:09:59,260
والتي بها كل المحاضرات على الإنترنت.

195
00:09:59,260 --> 00:10:01,235
إذًا، فهذه كلها أماكن جيدة للبدء.

196
00:10:01,235 --> 00:10:06,470
أعتقد أن جزءًا كبيرًا من الأهمية يتوقف على التأكد من تجربة الأشياء بنفسك.

197
00:10:06,470 --> 00:10:10,055
لذلك، لا تكتفِ بقراءة الأشياء أو مشاهدة مقاطع الفيديو فقط، ولكن جرِّب الأشياء.

198
00:10:10,055 --> 00:10:14,347
مع إطارات عمل مثل TensorFlow

199
00:10:14,347 --> 00:10:16,040
وChainer وTheano وPyTorch وما إلى ذلك،

200
00:10:16,040 --> 00:10:17,350
أعني أيًا كان المفضل لديك،

201
00:10:17,350 --> 00:10:21,980
من السهل جدًا البدء وتصميم شيء ما وتشغيله بسرعة كبيرة.

202
00:10:21,980 --> 00:10:24,669
لتدريب نفسك، أليس كذلك؟

203
00:10:24,669 --> 00:10:27,105
مع التنفيذ ومعرفة ما يعمل ومعرفة ما لا يعمل.

204
00:10:27,105 --> 00:10:29,360
إذًا، في الأسبوع الماضي، كان هناك مقال في

205
00:10:29,360 --> 00:10:31,715
ماشابل حول شخص في المملكة المتحدة يبلغ 16 عامًا،

206
00:10:31,715 --> 00:10:34,580
يعد واحدًا من الروّاد في منافسات Kaggle.

207
00:10:34,580 --> 00:10:36,690
ويُقال أنه قد

208
00:10:36,690 --> 00:10:39,290
اعتمد على نفسه وتعلم الأشياء،

209
00:10:39,290 --> 00:10:41,510
وعثر على الأشياء عبر الإنترنت وتعلم كل شيء بنفسه

210
00:10:41,510 --> 00:10:44,915
وأبدًا لم يأخذ أي دورة تدريبية رسمية في حد ذاتها.

211
00:10:44,915 --> 00:10:49,180
إذًا، هناك من يبلغ من العمر 16 عامًا يتمتع بقدرة تنافسية عالية في منافسة Kaggle،

212
00:10:49,180 --> 00:10:50,990
فمن المؤكد أن هذا ممكن.

213
00:10:50,990 --> 00:10:53,120
نحن نُعاصر أوقاتًا جيدة،

214
00:10:53,120 --> 00:10:54,560
إذا أراد الناس التعلم.

215
00:10:54,560 --> 00:10:55,940
بالتأكيد.

216
00:10:55,940 --> 00:10:57,980
هناك سؤال أراهن أنه يُطرح عليك في بعض الأحيان

217
00:10:57,980 --> 00:11:00,160
وهو إذا كان هناك شخص ما يريد أن يدخل مجالي التعلم الآلي والتعلم العميق في الذكاء الاصطناعي،

218
00:11:00,160 --> 00:11:06,885
إذا تقدم بطلب للحصول على برنامج دكتوراة أو للحصول على وظيفة في شركة كبيرة؟

219
00:11:06,885 --> 00:11:12,395
أعتقد أن الكثير منه يتعلق بمقدار التوجيه الذي يمكنك الحصول عليه.

220
00:11:12,395 --> 00:11:14,780
إذًا، في برنامج دكتوراة،

221
00:11:14,780 --> 00:11:16,400
هذا الحق مكفول لك،

222
00:11:16,400 --> 00:11:17,787
فمهمة البروفيسور،

223
00:11:17,787 --> 00:11:18,830
الذي هو مستشارك،

224
00:11:18,830 --> 00:11:20,800
هي الاعتناء بك.

225
00:11:20,800 --> 00:11:21,950
إنه يحاول أن يفعل كل ما في وسعه،

226
00:11:21,950 --> 00:11:23,565
يُشكِّلك بطريقة ما،

227
00:11:23,565 --> 00:11:28,720
ويساعدك على تحسين مستواك في كل ما تريد القيام به، على سبيل المثال، الذكاء الاصطناعي.

228
00:11:28,720 --> 00:11:32,060
وهكذا، يكون هناك شخص متفانٍ للغاية، وأحيانًا يكون لديك مستشاران.

229
00:11:32,060 --> 00:11:34,955
وحرفيًا، هذه وظيفتهم وهذا هو السبب في أنهم أساتذة،

230
00:11:34,955 --> 00:11:37,755
ومعظم ما يعجبهم في كونهم أساتذة هو غالبًا المساعدة في

231
00:11:37,755 --> 00:11:41,200
تشكيل الطلاب ليصبحوا أكثر قدرةً على فعل الأشياء.

232
00:11:41,200 --> 00:11:43,250
الآن، هذا لا يعني أنه ليس ممكنًا في الشركات،

233
00:11:43,250 --> 00:11:46,730
فالعديد من الشركات لديها بالفعل مرشدون جيدون ولديها أشخاص يحبون

234
00:11:46,730 --> 00:11:51,110
المساعدة في تثقيف الموظفين الجُدد وتعزيز مهاراتهم، وما إلى ذلك.

235
00:11:51,110 --> 00:11:55,515
إنه مجرد، قد لا يكون ضمانًا وأمرًا قطعيًا،

236
00:11:55,515 --> 00:12:00,540
مقارنةً بالتسجيل الفعلي في برنامج دكتوراة أو أنه من المؤكد

237
00:12:00,540 --> 00:12:06,020
في البرنامج هو أنك سوف تتعلم وأن هناك شخصًا ما لمساعدتك في التعلم.

238
00:12:06,020 --> 00:12:09,675
إذًا، يعتمد الأمر حقًا على الشركة ويعتمد على برنامج الدكتوراة.

239
00:12:09,675 --> 00:12:14,130
بكل تأكيد، نعم. ولكن أعتقد أنه من المهم أن تتعلم الكثير بنفسك.

240
00:12:14,130 --> 00:12:17,910
ولكني أعتقد أنه يمكنك أن تتعلم بسرعة أكبر إذا كان لديك شخص أكثر خبرة

241
00:12:17,910 --> 00:12:20,469
يأخذ على عاتقه حقًا

242
00:12:20,469 --> 00:12:24,945
مسؤولية قضاء بعض الوقت معك والمساعدة في تسريع تقدمك.

243
00:12:24,945 --> 00:12:28,780
إذًا، لقد كنتَ واحدًا من أبرز القادة في مجال التعلم المعزز العميق.

244
00:12:28,780 --> 00:12:30,720
إذًا، ما الأشياء التي

245
00:12:30,720 --> 00:12:32,930
يعمل عليها بالفعل التعلم المعزز العميق بشكل جيد؟

246
00:12:32,930 --> 00:12:37,450
أعتقد أنه إذا نظرت إلى بعض نجاحات التعلم المعزز العميق،

247
00:12:37,450 --> 00:12:39,000
فستجدها مثيرة للاهتمام للغاية.

248
00:12:39,000 --> 00:12:42,810
على سبيل المثال، تعلم لعب ألعاب آتاري من البكسلات،

249
00:12:42,810 --> 00:12:45,540
فمعالجة هذه البكسلات التي هي مجرد أرقام تتم

250
00:12:45,540 --> 00:12:49,150
معالجتها بطريقة ما وتحويلها إلى إجراءات لعصا التحكم.

251
00:12:49,150 --> 00:12:52,605
ثم، على سبيل المثال، بعض العمل الذي أنجزناه في بيركلي،

252
00:12:52,605 --> 00:12:57,105
فقد كان لدينا روبوت محاكاة يخترع المشي والمكافأة،

253
00:12:57,105 --> 00:12:59,340
وذلك بإعطائه بعض المعطيات البسيطة، مثل أنه كلما ذهب إلى الشمال،

254
00:12:59,340 --> 00:13:02,170
كان أفضل بالنسبة له وقلت الصعوبة التي يواجهها على الأرضية.

255
00:13:02,170 --> 00:13:06,949
وبطريقة ما يقرر ما إذا كان المشي أو الجري هو الشيء الذي يجب أن يخترعه،

256
00:13:06,949 --> 00:13:10,095
بينما لم يُعلّمه أحد كيف يكون المشي أو الجري.

257
00:13:10,095 --> 00:13:14,220
أو روبوت يلعب بدُمى الأطفال ويتعلم كيفية تجميعها بطريقة ما،

258
00:13:14,220 --> 00:13:16,935
ووضع قطعة في فتحة المطابقة، وما إلى ذلك.

259
00:13:16,935 --> 00:13:20,280
وهكذا، أعتقد أنه من المثير للاهتمام حقًا أنه في كل هذه الأمور، من الممكن التعلم

260
00:13:20,280 --> 00:13:24,510
من المدخلات الحسية الأولية بدايةً إلى عناصر التحكم الأولية انتهاءً،

261
00:13:24,510 --> 00:13:27,990
على سبيل المثال، عزم الدوران في المحركات.

262
00:13:27,990 --> 00:13:29,225
ولكن في الوقت ذاته.

263
00:13:29,225 --> 00:13:32,460
لذلك من المثير للاهتمام للغاية أنه يمكن أن تكون لديك خوارزمية واحدة.

264
00:13:32,460 --> 00:13:35,310
على سبيل المثال، أنت تعرف أن الاندفاع عفويّ ويمكنك أن تتعلم،

265
00:13:35,310 --> 00:13:36,745
يمكنك جعل الروبوت يتعلم الجري،

266
00:13:36,745 --> 00:13:38,135
ويمكنك جعل الروبوت يتعلم الوقوف،

267
00:13:38,135 --> 00:13:40,395
ويمكنك بدلاً من تصميم روبوت برجلين

268
00:13:40,395 --> 00:13:42,445
مبادلته بروبوت له أربعة أرجل الآن.

269
00:13:42,445 --> 00:13:46,465
إنك تقوم بتشغيل خوارزمية التعزيز ذاتها وتواصل بدورها تعلّم العمل.

270
00:13:46,465 --> 00:13:49,280
وهكذا، لا يوجد أي تغيير في خوارزمية التعزيز.

271
00:13:49,280 --> 00:13:51,615
إنها عامة جدًا. ينطبق الأمر نفسه على ألعاب أتاري.

272
00:13:51,615 --> 00:13:54,565
كان DQN واحدًا لكل لعبة من الألعاب.

273
00:13:54,565 --> 00:13:56,640
ولكن عندما يبدأ فعليًا في الوصول

274
00:13:56,640 --> 00:14:00,060
إلى حدود ما لم يكن ممكنًا بعد،

275
00:14:00,060 --> 00:14:03,490
فمن الجيد أن يتعلم من الصفر لكل مهمة من

276
00:14:03,490 --> 00:14:07,405
هذه المهام، بل سيكون أفضل إذا استطاع إعادة استخدام الأشياء التي تعلمها في الماضي؛

277
00:14:07,405 --> 00:14:09,640
للتعلم بسرعة أكبر من أجل المهمة القادمة.

278
00:14:09,640 --> 00:14:13,100
وهذا شيء ما زال صعب المنال وليس ممكنًا بعد.

279
00:14:13,100 --> 00:14:16,490
إنه يبدأ دائمًا من الصفر، في الأساس.

280
00:14:16,490 --> 00:14:19,390
في رأيك، ما مدى السرعة التي ترى أن التعلم

281
00:14:19,390 --> 00:14:22,420
المعزز العميق ينتشر بها في الروبوتات من حولنا،

282
00:14:22,420 --> 00:14:25,935
الروبوتات التي تنتشر في العالم اليوم؟

283
00:14:25,935 --> 00:14:29,380
أعتقد من الناحية العملية أن السيناريو الواقعي هو الذي

284
00:14:29,380 --> 00:14:32,770
يبدأ بالتعلم تحت الإشراف،

285
00:14:32,770 --> 00:14:35,960
والاستنساخ السلوكي؛ والبشر يقومون بهذا العمل.

286
00:14:35,960 --> 00:14:38,530
وأعتقد أن الكثير من الشركات سوف يتم بناؤها

287
00:14:38,530 --> 00:14:41,790
على هذا النحو حيث يكون الإنسان وراء الكواليس يقوم بالكثير من العمل.

288
00:14:41,790 --> 00:14:44,980
تخيّل مساعد فيسبوك ماسنجر،

289
00:14:44,980 --> 00:14:47,980
مساعد مثل هذا يمكن تصميمه مع إنسان خلف

290
00:14:47,980 --> 00:14:51,310
الكواليس يقوم بالكثير من العمل؛ التعلم الآلي

291
00:14:51,310 --> 00:14:54,380
يتطابق مع ما يفعله الإنسان ويبدأ في تقديم اقتراحات

292
00:14:54,380 --> 00:14:58,130
للإنسان حتى يكون لدى البشر عدد صغير من الخيارات التي يمكننا النقر عليها وتحديدها.

293
00:14:58,130 --> 00:14:59,640
ثم بمرور الوقت،

294
00:14:59,640 --> 00:15:01,130
عندما تصبح الأمور جيدة،

295
00:15:01,130 --> 00:15:04,465
تبدأ أنت في دمج بعض التعلم المعزز حيث تعطيه أهدافًا فعلية،

296
00:15:04,465 --> 00:15:06,565
وليس مجرد مطابقة الإنسان خلف الكواليس

297
00:15:06,565 --> 00:15:09,040
ولكن تحديد أهداف الإنجاز مثل،

298
00:15:09,040 --> 00:15:14,110
ربما، ما مدى سرعة تمكّن هذين الشخصين من تخطيط اجتماعهما؟

299
00:15:14,110 --> 00:15:16,385
أو ما مدى سرعة تمكّنهما من حجز رحلتهما؟

300
00:15:16,385 --> 00:15:18,340
أو أشياء من هذا القبيل؛ كم من الوقت يستغرق ذلك؟

301
00:15:18,340 --> 00:15:20,065
ما مدى رضاهم عن ذلك؟

302
00:15:20,065 --> 00:15:22,815
ولكن من المحتمل أن يكون هذا الأمر بمثابة تمهيد للكثير

303
00:15:22,815 --> 00:15:27,605
من الاستنساخ السلوكي لدى البشر، وهو إظهار كيف يمكن القيام بذلك.

304
00:15:27,605 --> 00:15:30,690
إذًا، يبدو أن الاستنساخ السلوكي هو مجرد الإشراف على التعلم

305
00:15:30,690 --> 00:15:33,580
لتقليد كل ما يفعله الشخص، وبعد ذلك تدريجيًا في وقت لاحق،

306
00:15:33,580 --> 00:15:37,434
تعزيز التعلم لجعله يفكر في آفاق زمنية أطول؟

307
00:15:37,434 --> 00:15:38,500
هل هذا ملخص شافٍ وافٍ؟

308
00:15:38,500 --> 00:15:39,715
يمكنني قول ذلك، نعم.

309
00:15:39,715 --> 00:15:43,540
فقط لأن التعلم المعزز المباشر من الصفر أمر ممتع حقًا يستحق التجربة.

310
00:15:43,540 --> 00:15:46,780
إنه أمر مثير للاهتمام للغاية، وهناك عدد قليل جدًا من الأشياء التي تستحق المشاهدة

311
00:15:46,780 --> 00:15:50,440
أكثر من روبوت يستخدم التعلم المعزز، بدءًا من لا شيء حتى اختراع الأشياء.

312
00:15:50,440 --> 00:15:54,280
ولكنها تستغرق وقتًا طويلاً وليست آمنة دائمًا.

313
00:15:54,280 --> 00:15:56,200
شكرًا جزيلاً. كان هذا رائعًا.

314
00:15:56,200 --> 00:15:58,005
أنا سعيد حقًا أن كانت لدينا فرصة للدردشة.

315
00:15:58,005 --> 00:16:02,670
حسنًا يا أندرو، أشكرك على استضافتي. أقدّر ذلك كثيرًا.