<html xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w10="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/omml/2004/12/core" xmlns:ve="http://schemas.openxmlformats.org/markup-compatibility/2006" xmlns:o12="http://schemas.microsoft.com/office/2004/7/core" xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships" xmlns:v="urn:schemas-microsoft-com:vml" xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/3/wordprocessingDrawing" xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/3/main" xmlns="http://www.w3.org/TR/REC-html40">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <head>
    <style>style</style>
  </head>
  <body>
    <div class="Section1">
      <p>
        <b>
          <u>
            <span style="font-size:20.0pt">Explanation of logistic regression cost function (optional)</span>
          </u>
        </b>
      </p>
      <p>
(DESCRIPTION)        <br/>
Text, basics of neural network programming. Explanation of logistic regression cost function. Optional        <br/>
      </p>
      <p>
(SPEECH)        <br/>
In an earlier video, I've written down a form for the cost function for logistical regression.        <br/>
      </p>
      <p>
In this optional video, I want to give you a quick justification for why we like to use that cost function for logistic regression.        <br/>
      </p>
      <p>
To        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Text, logistic regression cost function        <br/>
      </p>
      <p>
(SPEECH)        <br/>
quickly recap, in logistic regression, we have that the prediction y hat is sigmoid of w transpose x + b, where sigmoid is this familiar function.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
W transpose x plus b, all passed to the sigmoid function. Sigmoid of z equals the reciprocal of 1 plus e to the negative z        <br/>
      </p>
      <p>
(SPEECH)        <br/>
And we said that we want to interpret y hat as the p( y = 1 | x).        <br/>
      </p>
      <p>
So we want our algorithm to output y hat as the chance that y = 1 for a given set of input features x.        <br/>
      </p>
      <p>
So another way to say this is that if y is equal to 1 then the chance of y given x is equal to y hat.        <br/>
      </p>
      <p>
And conversely if y is equal to 0 then the chance that y was 0 was 1- y hat, right?        <br/>
      </p>
      <p>
So if y hat was a chance, that y = 1, then 1- y hat is the chance that y = 0.        <br/>
      </p>
      <p>
So, let mer take these last two equations and just copy them to the next slide.        <br/>
      </p>
      <p>
So what I'm going to do is take these two equations which basically define p(y|x) for the two cases of y = 0 or y = 1.        <br/>
      </p>
      <p>
And then take these two equations and summarize them into a single equation.        <br/>
      </p>
      <p>
And        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Seeking overall formula for p of y given x        <br/>
      </p>
      <p>
(SPEECH)        <br/>
just to point out y has to be either 0 or 1 because when binary cost equations, so y = 0 or 1 are the only two possible cases, all right.        <br/>
      </p>
      <p>
When someone take these two equations and summarize them as follows.        <br/>
      </p>
      <p>
Let me just write out what it looks like, then we'll explain why it looks like that.        <br/>
      </p>
      <p>
So (1 – y hat) to the power of (1 – y).        <br/>
      </p>
      <p>
So        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Two exponentiations multiplied together. In the first one, base is y hat, exponent is y. In the second one, base is 1 minus y hat, exponent is 1 minus y        <br/>
      </p>
      <p>
(SPEECH)        <br/>
it turns out this one line summarizes the two equations on top.        <br/>
      </p>
      <p>
Let me explain why.        <br/>
      </p>
      <p>
So in the first case, suppose y = 1,        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
First factor        <br/>
      </p>
      <p>
(SPEECH)        <br/>
right?        <br/>
      </p>
      <p>
So if y = 1 then this term ends up being y hat, because that's y hat to the power of 1.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Second factor        <br/>
      </p>
      <p>
(SPEECH)        <br/>
This term ends up being 1- y hat to the power of 1- 1, so that's the power of 0.        <br/>
      </p>
      <p>
But, anything to the power of 0 is equal to 1, so that goes away.        <br/>
      </p>
      <p>
And so, this equation, just as p(y|x) = y hat, when y = 1.        <br/>
      </p>
      <p>
So that's exactly what we wanted.        <br/>
      </p>
      <p>
Now how about the second case, what if y = 0?        <br/>
      </p>
      <p>
If y = 0, then this equation above is p(y|x) = y hat to the 0, but anything to the power of 0 is equal to 1, so that's just equal to 1 times 1- y hat to the power of 1- y.        <br/>
      </p>
      <p>
So 1- y is 1- 0, so this is just 1.        <br/>
      </p>
      <p>
And so this is equal to 1 times (1- y hat) = 1- y hat.        <br/>
      </p>
      <p>
And so here we have that the y = 0, p (y|x) = 1- y hat, which is exactly what we wanted above.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
The formula multiplying two exponentiations        <br/>
      </p>
      <p>
(SPEECH)        <br/>
So what we've just shown is that this equation is a correct definition for p(ylx).        <br/>
      </p>
      <p>
Now, finally because the law of function is a strictly monotonically increasing function, you're maximizing should give you is optimizing p(y|x) and it you compute log of p(y|x), that's equal to log of y hat r of y 1- y at sub par of 1- y.        <br/>
      </p>
      <p>
And so that simplifies to y log y hat + 1- y times log 1- y hat, right?        <br/>
      </p>
      <p>
And so this is actually negative of the loss function that we had to find previously.        <br/>
      </p>
      <p>
And there's a negative sign there because usually if you're training a learning algorithm, you want to make probabilities large whereas in logistic regression we're expressing this.        <br/>
      </p>
      <p>
We want to minimize the loss function.        <br/>
      </p>
      <p>
So minimizing the loss corresponds to maximizing the log of the probability.        <br/>
      </p>
      <p>
So this is what the loss function on a single example looks like.        <br/>
      </p>
      <p>
How about the cost function, the overall cost function on the entire training set on m examples?        <br/>
      </p>
      <p>
Let's figure that out.        <br/>
      </p>
      <p>
So, the probability of all the labels In the training set.        <br/>
      </p>
      <p>
Writing this a little bit informally.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
P function on the phrase, labels in training set        <br/>
      </p>
      <p>
(SPEECH)        <br/>
If you assume that the training examples I've drawn independently or drawn IID, identically independently distributed, then the probability of the example is the product of probabilities.        <br/>
      </p>
      <p>
The product from i = 1 through m p(y(i) ) given x(i).        <br/>
      </p>
      <p>
And so if you want to carry out maximum likelihood estimation, right, then you want to maximize the, find the parameters that maximizes the chance of your observations and training set.        <br/>
      </p>
      <p>
But maximizing this is the same as maximizing the log, so we just put logs on both sides.        <br/>
      </p>
      <p>
So log of the probability of the labels in the training set is equal to, log of a product is the sum of the log.        <br/>
      </p>
      <p>
So that's sum from i=1 through m of log p(y(i)) given x(i).        <br/>
      </p>
      <p>
And we have previously figured out on the previous slide that this is negative L of y hat i, y i.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Indicating the indexed summation term        <br/>
      </p>
      <p>
(SPEECH)        <br/>
And so in statistics, there's a principle called the principle of maximum likelihood estimation, which just means to choose the parameters that maximizes this thing.        <br/>
      </p>
      <p>
Or in other words, that maximizes this thing.        <br/>
      </p>
      <p>
Negative sum from i = 1 through m L(y hat {i},y{i}) and just move the negative sign outside the summation.        <br/>
      </p>
      <p>
So this justifies the cost we had for logistic regression which is J(w,b) of this.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
L of y hat i, y i, summed from i equals 1 to m        <br/>
      </p>
      <p>
(SPEECH)        <br/>
And because we now want to minimize the cost instead of maximizing likelihood, we've got to rid of the minus sign.        <br/>
      </p>
      <p>
And then finally for convenience, we make sure that our quantities are better scale, we just add a 1 over m extra scaling factor there.        <br/>
      </p>
      <p>
But        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
1 over m as coefficient of the whole sum        <br/>
      </p>
      <p>
(SPEECH)        <br/>
so to summarize, by minimizing this cost function J(w,b) we're really carrying out maximum likelihood estimation with the logistic regression model.        <br/>
      </p>
      <p>
Under the assumption that our training examples were IID, or identically independently distributed.        <br/>
      </p>
      <p>
So thank you for watching this video, even though this is optional.        <br/>
      </p>
      <p>
I hope this gives you a sense of why we use the cost function we do for logistic regression.        <br/>
      </p>
      <p>
And with that, I hope you go on to the exercises, the pro exercise and the quiz questions of this week.        <br/>
      </p>
      <p>
And best of luck with both the quizzes, and the following exercise        <br/>
      </p>
    </div>
  </body>
</html>
