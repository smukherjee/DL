مرحبا بكم في الأسبوع الرابع من هذه الدورة التدريبية. قد تعلمتم الآن الانتشار
الأمامي والانتشار الخلفي فيما يتعلق بالشبكة العصبية مع طبقة واحدة
مخفية، بالإضافة إلى الانحدار اللوجستي وقد تعرفتم على الطريقة المتجهية و متى يكون من الضروري
تهيئة الأوزان عشوائيًا. وإذا قمتم بأداء الواجب المنزلي
للأسبوعين السابقين، فقد طبقتم ورأيتم بعض هذه
الأفكار بأنفسكم. فالآن لقد رأيتم فعليا معظم الأفكار التي
تحتاجونها لتطبيق شبكة عصبية عميقة. وما سنفعله هذا الأسبوع هو أننا
سنأخذ هذه الأفكار ونجمعها معًا كي تتمكنوا من تطبيق
شبكتكم العصبية العميقة. لأن تمرين البرمجة لهذا الأسبوع أطول، ويتضمن بذل مجهود أكثر
وسأجعل مقاطع الفيديو لهذا الأسبوع أقصر كي تتمكنوا
من مشاهدتها بسرعة ومن ثم سيكون لديكم وقت
أطول للعمل على التمرين الذي آمل أن يترككم مع معلومات عميقة عن الشبكة
العصبية تفخرون بها. إذن ما هي الشبكة العصبية العميقة؟ رأيتم هذه الصورة
في الانحدار اللوجستي ورأيتم أيضًا شبكات عصبية
بطبقة مخفية واحدة. لذا إليكم مثال عن شبكة
عصبية بطبقتين مخفيتين وشبكة عصبية بخمس طبقات مخفية. نعرِّف الانحدار اللوجستي
كنموذج "سطحي" للغاية. بينما هذا النموذج
هنا أكثر عمقًا، والتضاد بين السطحي والعميق
أمر يعتمد على الدرجة. إذن شبكة عصبية
بطبقة مخفية واحدة. وستكون هذه شبكة عصبية بطبقتين. تذكروا أنه عندما نعد الطبقات في
شبكة عصبية ما فلا نعد طبقة الإدخال. بل نعد فقط الطبقات المخفية
بالإضافة إلى طبقة الإخراج. إذن ما زالت هذه الشبكة العصبية
ذات الطبقتين سطحية إلى حد ما. لكن ليست بسطحية الانحدار اللوجستي. تقنيًا الانحدار اللوجستي هو
شبكة عصبية بطبقة واحدة. لكن خلال الأعوام السابقة
أدرك الذكاء الاصطناعي بمجتمع التعلم الآلي
 أن هناك دالات تستطيع الشبكات العصبية العميقة تعلمها
بينما تفشل النماذج الأكثر سطحية عن ذلك. على الرغم من أنه يصعب في
أي تمرين التنبؤ مسبقًا إلى أي مقدار تحتاج للتعمق في شبكتك. لذا سيكون من الأفضل تجربة
الانحدار اللوجستي، شبكة بطبقة واحدة، ثم طبقتين وتحديد
عدد الطبقات المخفية كمتغير مفرط آخر يمكنك
تجربة عدة قيم له وتقييم كل ما يتوافق مع بيانات
التحقق من الصحة أو على مالخاصة بكجموعة التطوير . وسنتكلم عن ذلك أكثر لاحقًا. لنتكلم الآن عن الترميز الذي استخدمناه
لوصف الشبكات العصبية العميقة. هذه شبكة عصبية مكونة
من واحد، اثنان، ثلاث، أربع طبقات. مع ثلاث طبقات مخفية وأظن
أن عدد الوحدات في هذه الطبقات المخفية هو 5، 5، 3، ثم
1 لوحدة الإخراج. لذا الترميز الذي سنستخدمه هو سنستخدم L كابيتال
للتعبير عن عدد الطبقات في الشبكة. إذن في هذه الحالة
L = 4 وكذلك عدد الطبقات وسنستخدم N أس [l]
للتعبير عن عدد العقد أو عدد الوحدات في حالة
حرف l الصغير للطبقات. إذا أشرنا لهذا إذن،
فسنعطي للإدخال الرقم "0". وهذه هي الطبقة رقم 1 وهذه
رقم 2 وهذه رقم 3 وهذه رقم 4. ثم سيكون لدينا على سبيل
المثال، n[1] أي هذا، أول طبقة وستساوي 5
لأن لدينا 5 طبقات مخفية. أما لهذه فلدينا n[2] أي عدد الوحدات في
الطبقة المخفية الثانية والذي يساوي أيضًا 5، وn[3] = 3 و[n[4] = n[L هذا رقم
وحدات الإخراج وهو 1، لأن حرف L كابيتال يساوي أربعة. وسيكون لدينا هنا لطبقة الإدخال n[0] = nx = 3. إذن هذا هو الترميز الذي سنستخدمه
لوصف عدد العقد التي لدينا في الطبقات المختلفة. لكل L طبقة، سنستخدم أيضًا a[l] للتعبير عن المنشطات في الطبقة l. سنرى لاحقًا أنه في الانتشار الأمامي سننتهي بحساب a[l]
كالمنشط g(z[l]) وربما المنشط مرفوع
بالأس l للطبقة أيضًا، ثم سنستخدم W[l]
للتعبير عن الأوزان لاحتساب القيمة z[l] في الطبقة l وبنفس الطريقة تستخدم b[l] لاحتساب z [l]. وأخيرًا لتلخيص الترميز،
تسمى سمات الإدخال x، لكن x أيضًا هي المنشطات
للطبقة صفر. إذن a[0] = x والمنشط للطبقة الأخيرة
هو a[L] = y-hat. إذن a[L] تساوي الإخراج المتوقع
للتوقع y-hat للشبكة العصبية. الآن تعرفون كيف يبدو
شكل الشبكة العصبية العميقة. وأيضًا الترميز المستخدم لوصف
الشبكات العميقة لإجراء العمليات الحسابية بداخلها. أعرف أننا شرحنا الكثير من الرموز
في هذا الفيديو، لكن إذا نسيتم يومًا ما الذي تعنيه بعض الرموز، فقد نشرناها
على موقع الدورة التدريبية في ورقة للترميز أو دليل ترميز يمكنكم استخدامه
للبحث عما تعنيه هذه الرموز المختلفة. أما تاليًا، فأود شرح كيف يبدو
الانتشار الأمامي في هذا النوع من الشبكات. لننتقل إلى الفيديو التالي.