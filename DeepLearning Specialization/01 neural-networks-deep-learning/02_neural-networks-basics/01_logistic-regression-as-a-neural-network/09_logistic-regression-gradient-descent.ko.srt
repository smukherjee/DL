1
00:00:00,000 --> 00:00:02,250
다시 온 걸 환영합니다. 이번 강의에서는,

2
00:00:02,250 --> 00:00:04,980
환영합니다. 이비디오에서는 여러분이 로지스틱 회귄분석을 위한 기울기 강하를

3
00:00:04,980 --> 00:00:08,330
도입하기 위해서 derivative를 산출하는 방법에대해 이야기하겠습니다.

4
00:00:08,330 --> 00:00:11,040
여기서 가장 중요한 부분은 어떤 것을 도입하느냐 입니다.

5
00:00:11,040 --> 00:00:13,230
즉, 로지스틱 회귀분석을 위한 기울기 강하를

6
00:00:13,230 --> 00:00:17,725
도입하기 위한 중요 공식들에 대한 부분입니다.

7
00:00:17,725 --> 00:00:22,185
이번 비디오에서는, 산출 그래프를 이용해서 이런 계산을 해보겠습니다. 

8
00:00:22,185 --> 00:00:25,320
인정해야하는 부분이지만, 로지스틱 회귀분석의 기울기 강하를

9
00:00:25,320 --> 00:00:29,342
갖기 위해 산출 그래프를 이용하는 것은 조금 오버이기는 합니다.

10
00:00:29,342 --> 00:00:31,183
하지만 이러한 아이디어들에 대해 여러분이 

11
00:00:31,183 --> 00:00:33,975
익숙해지게 하기 위한 목적으로 이런 방법을 통해 설명해보겠습니다.

12
00:00:33,975 --> 00:00:38,370
바라건대, full-fledged 신경망을 이야기할때 조금 더 이해가 되시길 바랍니다.

13
00:00:38,370 --> 00:00:44,235
그러면 이제 로지스틱 회귀분석을 위한 기울기 강하에 대해 알아보겠습니다.

14
00:00:44,235 --> 00:00:49,070
복습하자면 이전에 로지스틱 회귀분석을 이렇게 설정했었는데요, 

15
00:00:49,070 --> 00:00:53,220
예측 값 ŷ은 이렇게 정의되었는데요, 

16
00:00:53,220 --> 00:00:56,490
z는 이것이구요, 

17
00:00:56,490 --> 00:01:01,800
일단 1가지 example에 초점을 맞추면, loss는

18
00:01:01,800 --> 00:01:03,630
여기 example에 대해서는

19
00:01:03,630 --> 00:01:05,190
이렇게 정의됩니다.

20
00:01:05,190 --> 00:01:07,855
A가 로지스틱 회귀분석의 결과값이고

21
00:01:07,855 --> 00:01:10,535
Y는 ground truth 레이블입니다.

22
00:01:10,535 --> 00:01:15,735
이제 산출 그래프 형식으로 적어보겠습니다. 여기 예제에서는

23
00:01:15,735 --> 00:01:20,520
x1, x2와 같은 2개의 특성만 있다고 해보겠습니다.

24
00:01:20,520 --> 00:01:22,860
z를 산출하기 위해서는, 

25
00:01:22,860 --> 00:01:27,030
w1, w1, 그리고 b를 입력해서 하는데요, 

26
00:01:27,030 --> 00:01:31,130
x1, x2의 특성에 부가적으로 말이죠.

27
00:01:31,130 --> 00:01:33,705
산출 그래프에서 이런 것들은, 

28
00:01:33,705 --> 00:01:36,910
z를 산출하는데 쓰이는데요, w1, 

29
00:01:36,910 --> 00:01:41,588
x1 + w2 x2+b입니다.

30
00:01:41,588 --> 00:01:45,380
여기 직사각형으로 둘러서 표시하겠습니다.

31
00:01:45,380 --> 00:01:48,555
그러면 저희는 ŷ의 값을 구하거나

32
00:01:48,555 --> 00:01:52,244
A= z의 시그마를 구합니다.

33
00:01:52,244 --> 00:01:55,740
이것이 산출그래프에서의 다음 단계인데요, 그 이후에 마지막으로 

34
00:01:55,740 --> 00:01:58,725
L, AY를 구합니다.

35
00:01:58,725 --> 00:02:01,840
여기서는 이제 공식을 다시 복사하지는 않겠습니다.

36
00:02:01,840 --> 00:02:06,900
로지스틱 회귀분석에서는, w와 b의 파라미터를 변형시킬 것입니다.

37
00:02:06,900 --> 00:02:12,830
여기 loss 값을 줄이기 위해서 말이죠. 

38
00:02:12,830 --> 00:02:15,870
저희는 하나의 트레이닝 example에서 전 방향전파 step을

39
00:02:15,870 --> 00:02:19,280
이용해서 loss를 계산하는 방법을 배웠는데요, 

40
00:02:19,280 --> 00:02:23,940
이제는 거꾸로 derivative를 산출하는 방법에 대해 이야기 해보겠습니다.

41
00:02:23,940 --> 00:02:26,025
여기 깔끔한 버전의 다이아그램입니다.

42
00:02:26,025 --> 00:02:30,690
이제 loss에 대한 derivative를 계산하고 싶은 것이기 때문에, 

43
00:02:30,690 --> 00:02:33,570
첫번째로 해야할 것은, 뒤로 가는 경우에 말이죠, 

44
00:02:33,570 --> 00:02:38,010
loss의 derivative를, 여기는 script가 있는데요, 

45
00:02:38,010 --> 00:02:41,940
여기 A변수에 대해서 산출해야 합니다. 

46
00:02:41,940 --> 00:02:43,570
그렇기 때문에 여기 코드에서

47
00:02:43,570 --> 00:02:49,000
DA를 이용해 변수를 표기하는데요, 

48
00:02:49,000 --> 00:02:52,725
만약 여러분이 미적분학과 익숙하면

49
00:02:52,725 --> 00:03:02,004
이것이 -y 나누기 a 더하기 (1 빼기 y) 나누기 (1 빼기 알파)라는 것을 보여줄 수 있습니다.

50
00:03:02,004 --> 00:03:06,185
이것을 하는 방법은 loss에 대한 공식을 가지고 하는 것인데요, 

51
00:03:06,185 --> 00:03:07,535
미적분학에 익숙하면 

52
00:03:07,535 --> 00:03:10,515
여기 소문자 a 변수에 대한 derivative을

53
00:03:10,515 --> 00:03:12,792
계산하는 것입니다. 그렇게 하면 여기 이 공식이 나오게 됩니다.

54
00:03:12,792 --> 00:03:15,280
만약 여러분이 미적분학에 익숙하지 않은 경우라면, 걱정하지 마십시요. 

55
00:03:15,280 --> 00:03:17,960
derivative 공식을 제공하겠습니다.

56
00:03:17,960 --> 00:03:20,100
여러분이 코스에서 필요한 분에 대해서 말이죠. 

57
00:03:20,100 --> 00:03:21,185
여러분이 미적분학에 능숙한 경우헨, 

58
00:03:21,185 --> 00:03:24,590
이번 슬라이드의 loss 공식을 보도록 

59
00:03:24,590 --> 00:03:29,504
권장드립니다. 이 공식을 보고, 미적분을 이용해 a에 대한 derivative를 구해보십시요.

60
00:03:29,504 --> 00:03:32,635
만약 여러분이 미적분학에 익숙하지 않으시면, 걱정하지 마십시요. 

61
00:03:32,635 --> 00:03:35,491
그러면 이제 DA의 양을 계산했는데요, 

62
00:03:35,491 --> 00:03:38,825
그리고 마지막 변수 알파를 A에 대해서 derivative값도 구했습니다.

63
00:03:38,825 --> 00:03:40,715
그러면 이제 거꾸로 갈 수 있는데요, 

64
00:03:40,715 --> 00:03:45,525
이제 여러분은 DZ를 보여줄 수 있는데요, 

65
00:03:45,525 --> 00:03:47,648
이 부분은 파이썬 코드의 변수이름인데요, 

66
00:03:47,648 --> 00:03:51,200
여기는 이제 loss의 derivative가 될 것입니다. 

67
00:03:51,200 --> 00:03:53,618
z 나 l 에 대해서 말이죠. 

68
00:03:53,618 --> 00:03:59,850
아니면 A와 Y가 포함된 파라미터를 이용하여 loss를 나타낼 수 있습니다. 맞죠?

69
00:03:59,850 --> 00:04:04,230
둘 중의 아무 표기 방식이나 상관 없습니다.

70
00:04:04,230 --> 00:04:09,605
그러면 이것이 a-y라는 것을 보여줄 수 있습니다.

71
00:04:09,605 --> 00:04:14,685
미적분학에 능숙한 분들을 위해서만 몇가지 말씀드리겠습니다.

72
00:04:14,685 --> 00:04:16,795
익숙치 않으시면 신경 안 쓰셔도 됩니다.

73
00:04:16,795 --> 00:04:20,320
여기 DL 과 DZ는 보면, 

74
00:04:20,320 --> 00:04:27,850
여기는 DL_DA_곱하기_DA_DZ로 나타낼 수 있습니다.

75
00:04:27,850 --> 00:04:29,940
그리고 여기 da / dz는 

76
00:04:29,940 --> 00:04:33,755
a 곱하기 1 빼기 a인데요, 

77
00:04:33,755 --> 00:04:37,800
그리고 dl da는 이전에 계산했지만, 

78
00:04:37,800 --> 00:04:41,530
여기 2값을 보면, dl / da와

79
00:04:41,530 --> 00:04:43,846
여기 이 항이죠, 그리고 da /dz 는

80
00:04:43,846 --> 00:04:47,165
여기 이 항이죠, 그리고 여기 2개의 것들을 가지고 곱해줍니다.

81
00:04:47,165 --> 00:04:51,915
그렇게 되면 이 공식들은 a 빼기 y로 간략해지죠.

82
00:04:51,915 --> 00:04:53,220
이렇게 공식을 만드는 것입니다.

83
00:04:53,220 --> 00:04:57,390
이것은 이전에 간략히 이야기 했던 chain rule이기도 한데요, 

84
00:04:57,390 --> 00:05:02,770
얼마든지 미적분학에 익숙하신 분이라고 하면 이 계산을 한번 더 해보십시요, 

85
00:05:02,770 --> 00:05:05,345
만약 익숙치 않은 경우, 오로지 아셔야하는 부분은

86
00:05:05,345 --> 00:05:09,365
DZ를 a 빼기 y로 계산할 수 있다는 것입니다. 계산은 이미 저희가 다 해놨기 때문이죠. 

87
00:05:09,365 --> 00:05:13,010
그러면 이 산출법에서 마지막 단계는 

88
00:05:13,010 --> 00:05:17,480
w와 b를 얼마나 바꿔야 하는지 계싼하는 부분입니다.

89
00:05:17,480 --> 00:05:24,610
특히, w1에 대한 derivative가 x1 곱하기 dz라는 것을 보여줄 수 있는데요, 코딩에서는 

90
00:05:24,610 --> 00:05:31,810
이것을 dw1이라고 합니다.

91
00:05:31,810 --> 00:05:36,485
그리고 비슷한 방법으로, dw2, 즉 w2를 얼마나 바꿔야하는지 

92
00:05:36,485 --> 00:05:39,455
알려주는 수치는 x2 곱하기 dz 와 b입니다.

93
00:05:39,455 --> 00:05:42,585
아 죄송합니다. b가 아니라 db죠, 이 값은 dz와 동일합니다.

94
00:05:42,585 --> 00:05:47,375
여러분이 만약 1가지 example에 대한 기울기 강하를 원할 경우, 

95
00:05:47,375 --> 00:05:49,280
이렇게 하면 됩니다.

96
00:05:49,280 --> 00:05:52,640
여기 공식을 사용해서 dz를 계산합니다.

97
00:05:52,640 --> 00:05:56,707
그리고 여기 이 공식들을 사용해서 dw1, dw2, 

98
00:05:56,707 --> 00:06:01,170
db 그리고 여기 update를 실행합니다.

99
00:06:01,170 --> 00:06:04,538
w1은 w1 빼기 

100
00:06:04,538 --> 00:06:06,575
러닝속도 알파 곱하기 dw1입니다.

101
00:06:06,575 --> 00:06:09,245
w2도 이와 같이 업데이트 될텐데요, 

102
00:06:09,245 --> 00:06:14,170
그리고 B는 B 빼기 러닝속도 곱하기 DB로 설정됩니다.

103
00:06:14,170 --> 00:06:18,860
그러면 1개의 example의 경우를 보여주는 단계입니다.

104
00:06:18,860 --> 00:06:22,130
여러분은 방금 1개의 트레이닝 example에 대해서 

105
00:06:22,130 --> 00:06:27,200
로지스틱 회귀분석을 위한 기울기 강하 도입법을 배웠는데요, derivative를 산출해서 
구하는 방법을 배웠습니다.

106
00:06:27,200 --> 00:06:28,987
하지만 로지스틱 회귀분석모델을 트레이닝 하는 경우, 

107
00:06:28,987 --> 00:06:34,700
1개의 트레이닝 샘플만 있는 것이 아니라 M세트의 트레이닝 샘플이 있습니다.

108
00:06:34,700 --> 00:06:36,120
다음 비디오에서는

109
00:06:36,120 --> 00:06:39,350
이러한 아이디어를 가지고 러닝에 어떻게 적용시키는지

110
00:06:39,350 --> 00:06:40,760
한가지 샘플이 아닌 

111
00:06:40,760 --> 00:06:42,400
전체 트레이닝 세트에서의 환경에서 살펴보겠습니다.