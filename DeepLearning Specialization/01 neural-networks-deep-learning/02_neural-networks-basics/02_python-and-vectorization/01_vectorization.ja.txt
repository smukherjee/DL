戻ってきましたね
ベクトル化は for loop をコードに
書かないようにする技術です 深層学習時代や
深層学習の実践では 比較的巨大なデータセットを
学習に使うことがあります このような状況でこそ
深層学習のアルゴリズムが輝くからです コードの実行速度が
速いことが重要です さもないと
巨大なデータの時には 学習時に
コードの実行に長時間かかり 結果がでるまでに
非常に長い時間待つことになります このため深層学習時代には ベクトル化するスキルが
鍵のひとつになりました 例を見る事から始めよう。 ではベクトル化とは
何でしょうか ロジステック回帰では
Z=Wの転置かけるX+bを計算する必要があります Wは列のベクトルで
Xもまたベクトルです 多くの特徴量があるときは
非常に大きなベクトルになるでしょう WもXも
RのnX次元のベクトルです Wの転置かけるXの計算には 万がいち
ベクトル化せずに実装する場合には こんな風にするでしょう
まずZ=0 と書き for i in range(nX) と書き i は１からnXになり Z+=W[i]*X[i]と書き Z+=b を最後に書くでしょう これがベクトル化しない場合の
実装です これだと本当に遅いことが
分かるでしょう 対照的にベクトル化した実装だと
Wの転置かけるXを直接計算します Python やnumpy では Z=np.dot(W,X)のコマンドを使います これでWの転置かけるXが
計算できます これにb を
足せばよいだけです この方法のほうが
かなり速いことが分かります 実際の例をデモで
例示します この私のJupyter Notebook に
Python のコードを書きます まずnumpy のライブラリを
np としてインポートします 例えば a をこのように
array として作ります print(a)
してみましょう こんな風にコードを書いて shift+enter を押すと コードが実行されます array a を作り
結果を出力します ベクトル化のデモをしましょう time ライブラリを
インポートします これを使い 異なる演算の実行時間を
測ります array a を作ります random.rand で 乱数値の格納された
百万の長さのarray を作ります b = np.random.rand で もう１つarrayを作ります tic = time.time() として
今の時刻を取得します c = np.dot(a,b) と書き toc = time.time() と書き print を使用して ベクトル化版を表すように vectorize version: と書きます 実行最終時刻のtoc から tic を引いた (toc-tic)かける1,000を行い ミリ秒単位で
表現するようにします ms がミリ秒です shift+enter を押します コードの実行時間は
約３ミリ秒か1.5ミリ秒でした 時により1.5ミリ秒か
3.5ミリ秒くらいかかります 少し実行時間に差が出ますが 平均で1.5ミリ秒か２ミリ秒くらいが 実行時間です こんにちは ここにコードを追加していきます ベクトル化していないコードを
実装しましょう c = 0 と書き tic = time.time()と書き for loop を実装します for i in range(1000000)と書き 私は０を正しく書けましたかね C += a[i] * b[i]と書き toc = time.time()と書き 最後にfor loop を
print します 経過時間は1,000*(toc -tic ) + msで ミリ秒なのを
表します もう１つ追加しましょう 計算したc の値を表示して 両方の方法で同じ値か
確認できるようにします shift+enter を押して実行します
確認しましょう ベクトル化版でも 非ベクトル化版でも
同じ値が計算されました 250286.99...と続く値です ベクトル化版は
1.5ミリ秒で for loop を使った非ベクトル版では
約400から500ミリ秒を超えそうな時間です 非ベクトル版は約300倍ほど ベクトル版よりも
長い時間がかかりました この例でみるように
ベクトル化することさえ忘れなければ コードは300倍以上も速く
動作します もう１度実行しましょう 実行しました ベクトル化版は1.5ミリ秒で
for loop 版は 481ミリ秒かかりました ここでもfor loop は
300分の１の速度でした 300倍遅い場合には 実行が１分で完了するか ５時間かかるかの違いが
コードに出てきます 深層学習のアルゴリズムを
実装する場合には 結果がより速く
返ってきます ベクトル化すると
かなり速く実行されます 多くの拡張可能な深層学習の実装が GPU(画像処理ユニット)で行われてると
聞いたことがあるかもしれません ここで今実行したJupyter Notebook でのデモは
CPU で実行しました 実はGPU もCPU も両方とも
並行処理命令があります SIMD 命令と呼ばれます Single Instruction Multiple Data の
頭文字です これが意味するのは np.dot 関数や
他の関数のような for loop を
使わなくて済む組み込み関数を使うと Python のnumpy が 計算処理を迅速に行うための
並行処理をかなり有効に利用することができます これはCPU での計算処理でも
GPU での計算処理でも当てはまります ただGPU は驚くほどSIMD 計算を 効率的に行えるだけで
CPU の計算も実はそれほど悪くありません GPU ほどは
良くないだけです ベクトル化すると
コードの速度をかなり上げられるのを見てきました 覚えておくべき経験則からの教訓は for loop を
使わないようにすることです 次のビデオに進んで
さらにベクトル化の例を見て ロジステック回帰を
ベクトル化しましょう