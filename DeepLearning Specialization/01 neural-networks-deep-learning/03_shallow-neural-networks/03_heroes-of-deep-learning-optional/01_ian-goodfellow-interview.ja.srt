1
00:00:02,550 --> 00:00:05,830
イアン 今日は来てくれて
どうもありがとう

2
00:00:05,830 --> 00:00:06,860
ご招待ありがとうございます

3
00:00:06,860 --> 00:00:08,775
アンドリュー
来れて嬉しいです

4
00:00:08,775 --> 00:00:11,920
あなたは最も目立っている深層学習の研究者の１人です

5
00:00:11,920 --> 00:00:14,450
個人的な物語を
少し共有していただけませんか

6
00:00:14,450 --> 00:00:16,810
今しているこの研究を
どんな経緯でするようになったか

7
00:00:16,810 --> 00:00:19,150
はい
是非やりましょう

8
00:00:19,150 --> 00:00:24,287
実のところあなたに最初に会う直前に
機械学習に興味をもちました

9
00:00:24,287 --> 00:00:29,705
以前は神経科学の研究をしていたのですが
スタンフォードで

10
00:00:29,705 --> 00:00:34,600
学部生の顧問をしていたジェリー・ケインが
「イントロ・トゥ・AI」クラスを取るように勧めてくれました

11
00:00:34,600 --> 00:00:35,790
あれ それは知りませんでした

12
00:00:35,790 --> 00:00:39,885
それまでAI は良い考えだと思っていましたが

13
00:00:39,885 --> 00:00:42,590
実践では主に起こっていたのは

14
00:00:42,590 --> 00:00:44,483
ゲームAI というようなものでした

15
00:00:44,483 --> 00:00:47,375
人間のプレイヤーでないゲームのキャラクターが

16
00:00:47,375 --> 00:00:49,700
ハードコードされたルールで

17
00:00:49,700 --> 00:00:52,085
異なる時に異なる既に書かれたセリフを
言うよう使われ方でした

18
00:00:52,085 --> 00:00:56,750
その後 あなたの「イントロ・トゥ・AI」の授業を
受けた時には

19
00:00:56,750 --> 00:01:02,815
線形回帰や線形回帰の
予測誤差のバイアス・バリアンスの分解のような話題を扱っていました

20
00:01:02,815 --> 00:01:06,665
これが本当の科学で
神経科学ではなくAI で

21
00:01:06,665 --> 00:01:10,970
科学者の道を歩めると確信し始めました

22
00:01:10,970 --> 00:01:12,730
なるほど
そしてどうなったのですか

23
00:01:12,730 --> 00:01:15,290
コースを受け終わって
後にTA として戻ってきました

24
00:01:15,290 --> 00:01:17,815
なるほど
１TAとしてね

25
00:01:17,815 --> 00:01:22,595
大きな転換点は
コースのTA をしていた時に

26
00:01:22,595 --> 00:01:23,720
学生の１人で友達の

27
00:01:23,720 --> 00:01:25,310
イーサン・ドライファスが

28
00:01:25,310 --> 00:01:28,689
ジェフリー・ヒントンの信念ネットワーク(DBN)の論文に
興味持って

29
00:01:28,689 --> 00:01:29,022
I see.

30
00:01:29,022 --> 00:01:35,660
スタンフォードでボルツマン・マシンを
実行するための初期のGPU CUDA を使ったマシンを

31
00:01:35,660 --> 00:01:43,280
冬休みの余った時間を使って
２人で作ってしまいました

32
00:01:43,280 --> 00:01:43,817
I see.

33
00:01:43,817 --> 00:01:46,295
このころには

34
00:01:46,295 --> 00:01:50,720
深層学習が将来の方向性だという
強い直感を持つようになりました

35
00:01:50,720 --> 00:01:53,660
私が使っていたサポートベクターマシーンのような

36
00:01:53,660 --> 00:01:56,285
他のアルゴリズムの多くは

37
00:01:56,285 --> 00:01:58,845
適切な漸近解析を備えているとは
思えませんでした

38
00:01:58,845 --> 00:02:01,400
より多くの学習データを与えると
速度が低下していましたし

39
00:02:01,400 --> 00:02:03,476
同じ量の学習データでも

40
00:02:03,476 --> 00:02:08,240
設定を変更することによっても
大きく性能を上げることは難しいです

41
00:02:08,240 --> 00:02:13,065
これに気付いた頃から
可能な限り深層学習に集中するようにしました

42
00:02:13,065 --> 00:02:18,595
リチャード レイナの
とても古いGPU の論文で

43
00:02:18,595 --> 00:02:21,585
あなたの初期の多くの研究を
認めていたのを覚えています

44
00:02:21,585 --> 00:02:25,850
そうなんです
私たちが作ったマシンを使ってあの論文は書かれています

45
00:02:25,850 --> 00:02:26,656
なるほど。

46
00:02:26,656 --> 00:02:30,755
最初のマシンは
イーサンのお母さんの家で自分たちのお金を使って

47
00:02:30,755 --> 00:02:35,120
作っただけのような物でした

48
00:02:35,120 --> 00:02:39,835
その後は 研究所のお金を使って
スタンフォードの研究所用の最初の２、３台を作りました

49
00:02:39,835 --> 00:02:42,965
すごいですね
この物語は全く知りませんでした  よかったです

50
00:02:42,965 --> 00:02:45,830
そして今日では

51
00:02:45,830 --> 00:02:48,365
深層学習の世界に起こった旋風は

52
00:02:48,365 --> 00:02:51,645
あなたがGAN を
発明したことです

53
00:02:51,645 --> 00:02:54,085
どうやって思いついたのですか

54
00:02:54,085 --> 00:02:56,885
生成モデルを
長い間研究していました

55
00:02:56,885 --> 00:02:59,000
GANは
生成モデルの１つの方法でした

56
00:02:59,000 --> 00:03:02,570
生成では多くの学習データがある時に

57
00:03:02,570 --> 00:03:08,420
学習させて学習データに似たデータを作ることを目指していますが
想像上のものでした

58
00:03:08,420 --> 00:03:13,265
以前はそのような形のものは
見られませんでいした

59
00:03:13,265 --> 00:03:16,220
わたしがGAN を思いつく前にも
他のいくつかの方法を使う生成モデルがあり

60
00:03:16,220 --> 00:03:19,780
数年は人気でした

61
00:03:19,780 --> 00:03:24,860
博士号の期間のほとんどを
他の方法を使った研究をしていたので

62
00:03:24,860 --> 00:03:29,000
ボルツマン・マシンや
スパース符号化などや

63
00:03:29,000 --> 00:03:32,630
何年にも渡って人気な他の方法の
利点や欠点を

64
00:03:32,630 --> 00:03:35,955
知っていました

65
00:03:35,955 --> 00:03:40,265
これらの欠点のすべてを
避けられるなにかをずっと探していました

66
00:03:40,265 --> 00:03:44,110
そして最後にバーで
友達と生成モデルについて議論していた時に

67
00:03:44,110 --> 00:03:45,845
何かのスイッチが入って

68
00:03:45,845 --> 00:03:47,540
こんな風に話し始めました
これをして

69
00:03:47,540 --> 00:03:49,510
これとこれをすれば
絶対に上手くいくさと言いました

70
00:03:49,510 --> 00:03:52,890
友達はうまくいくとは
信じませんでした

71
00:03:52,890 --> 00:03:55,410
その時は深層学習のテキストを
書かなければいけなかったのですが

72
00:03:55,410 --> 00:03:55,790
I see.

73
00:03:55,790 --> 00:03:57,620
この方法が動作するという
強い確信があったので

74
00:03:57,620 --> 00:03:59,870
家に帰って コーディングを書き上げて
きちんと動作しました

75
00:03:59,870 --> 00:04:02,920
では 最初のGAN は
たった一晩で実装したのですね

76
00:04:02,920 --> 00:04:06,050
友達のさよならパーティーがあったバーから

77
00:04:06,050 --> 00:04:09,530
家に帰ってから
深夜に実装しました

78
00:04:09,530 --> 00:04:10,086
I see.

79
00:04:10,086 --> 00:04:11,784
最初に作ったバージョンが
きちんと動きました

80
00:04:11,784 --> 00:04:13,275
これはとても幸運でした

81
00:04:13,275 --> 00:04:15,825
ハイパーパラメーターや他の方法を
探す必要がありませんでした

82
00:04:15,825 --> 00:04:17,840
こんな話をどこかで読みました

83
00:04:17,840 --> 00:04:21,851
あなたは死にかける経験をして
そのことでAI に献身していることを再確認した話を読みました

84
00:04:21,851 --> 00:04:24,160
この話を聞かせてください

85
00:04:24,160 --> 00:04:30,215
そう 実は死にかけたわけではなかったのですが
そうなったのだと思った瞬間がありました

86
00:04:30,215 --> 00:04:33,170
非常にひどい頭痛を経験して

87
00:04:33,170 --> 00:04:37,571
医師の中に脳内出血しているかもしれないと
考えた人がいました

88
00:04:37,571 --> 00:04:39,740
この時私は

89
00:04:39,740 --> 00:04:43,180
脳内出血があるかどうか確認するMRI を
待っていました

90
00:04:43,180 --> 00:04:47,810
この時に考えていたことのほとんどは
どうすれば他の人たちによって

91
00:04:47,810 --> 00:04:49,910
その当時研究として考えていたことを

92
00:04:49,910 --> 00:04:52,750
結果的に確実に実行できるか
と気が付きました

93
00:04:52,750 --> 00:04:53,224
I see. I see.

94
00:04:53,224 --> 00:04:55,820
振り返ると
とても馬鹿げた研究の考えでしたが

95
00:04:55,820 --> 00:04:56,553
I see.

96
00:04:56,553 --> 00:04:58,700
その時点では

97
00:04:58,700 --> 00:05:02,325
機械学習の研究を実施していくことが

98
00:05:02,325 --> 00:05:05,780
実際に人生で最も優先することだと
実感しました

99
00:05:05,780 --> 00:05:07,910
なるほど
それは素晴らしいです

100
00:05:07,910 --> 00:05:10,055
もうすぐ死ぬかもと思った時でさえ

101
00:05:10,055 --> 00:05:12,265
研究を完了してもらうことだけを
考えていたのですね

102
00:05:12,265 --> 00:05:12,649
なるほど。

103
00:05:12,649 --> 00:05:15,690
それは献身ですね

104
00:05:15,690 --> 00:05:17,850
なるほど。

105
00:05:17,850 --> 00:05:21,808
現在でも GAN の多くの動きの中心にいますね

106
00:05:21,808 --> 00:05:24,560
敵対的生成ネットワークのです

107
00:05:24,560 --> 00:05:27,710
GAN は今後どうなっていくと考えているのか
教えてもらえますか

108
00:05:27,710 --> 00:05:32,930
現在は GAN は
色々な用途に使われています

109
00:05:32,930 --> 00:05:39,185
半教師あり学習であったり 他のモデルのために学習データを生成したり
科学実験をシミュレーションすることにまで使われています

110
00:05:39,185 --> 00:05:43,850
原理的には これらの用途は
他の種類の生成モデルで実現することもできます

111
00:05:43,850 --> 00:05:47,695
このため GANは
重要な岐路に立っています

112
00:05:47,695 --> 00:05:50,210
今は 上手く効果がでるときもありますが

113
00:05:50,210 --> 00:05:55,890
GAN で性能を上げるのは
科学というよりは芸術になっています

114
00:05:55,890 --> 00:05:59,870
人々が10年前に深層学習に感じていたのと
多かれ少なかれ同じようなものです

115
00:05:59,870 --> 00:06:01,430
当時は

116
00:06:01,430 --> 00:06:05,330
ボルツマン・マシンを部品として
信念ネットワーク(DBN)が使われていました

117
00:06:05,330 --> 00:06:07,420
DBN は
とても繊細でした

118
00:06:07,420 --> 00:06:11,945
時が経つと Rectified Linear Units や
バッチ正規化に乗り換えて

119
00:06:11,945 --> 00:06:14,635
そして深層学習が
かなり頼れるものになりました

120
00:06:14,635 --> 00:06:18,470
GAN を深層学習と同じように
頼れるものにできたら

121
00:06:18,470 --> 00:06:20,840
現在使われているところで
GAN が使われているのを

122
00:06:20,840 --> 00:06:24,110
ずっと目にするでしょうが
より大きく成功しているでしょう

123
00:06:24,110 --> 00:06:29,060
GAN を安定させる方法を
見つけることができなかったとしたら

124
00:06:29,060 --> 00:06:32,960
深層学習の歴史に貢献した主なものは

125
00:06:32,960 --> 00:06:35,060
生成モデルで行う作業の

126
00:06:35,060 --> 00:06:37,590
行い方を示したことになるでしょう

127
00:06:37,590 --> 00:06:41,505
最終的には GAN は
他の形の生成モデルで置き換えられるでしょう

128
00:06:41,505 --> 00:06:47,870
なので 私はおよそ40%を
GANを安定させるために使っています

129
00:06:47,870 --> 00:06:50,780
ではあなたのように約10年前に

130
00:06:50,780 --> 00:06:53,765
深層学習を始めた人たちが
気付けば先駆者になっていたというような

131
00:06:53,765 --> 00:06:54,963
ことのように

132
00:06:54,963 --> 00:06:57,360
今 GAN を始めた人たちが

133
00:06:57,360 --> 00:07:00,120
上手く制御できたら
初期の先駆者になることもあるでしょう

134
00:07:00,120 --> 00:07:04,220
そうです 既に多くの人が
初期の先駆者です

135
00:07:04,220 --> 00:07:09,105
GAN のこれまでの歴史を
語るとしたら

136
00:07:09,105 --> 00:07:12,740
Indico、フェイスブック、バークレー校などの

137
00:07:12,740 --> 00:07:17,280
様々なことを成し遂げた他のグループを
挙げる必要があります

138
00:07:17,280 --> 00:07:19,735
あなたはあなたの研究以外にも

139
00:07:19,735 --> 00:07:24,300
深層学習の本も共著してます
これはどういう経緯だったのですか

140
00:07:24,300 --> 00:07:26,897
ヨシュア・ベンジオ、アーロン・カービルとの共著です

141
00:07:26,897 --> 00:07:29,900
彼らは私の博士課程での
共同アドバイザーでした

142
00:07:29,900 --> 00:07:35,465
現代版の深層学習についての
最初のテキストを書きました

143
00:07:35,465 --> 00:07:38,615
英語版と

144
00:07:38,615 --> 00:07:42,920
中国語版のどちらでも
とても人気です

145
00:07:42,920 --> 00:07:48,915
この２言語版で約７万部を
売り上げています

146
00:07:48,915 --> 00:07:54,730
この本から多くのことを学んだと
学生からの感想を多く聞いています

147
00:07:54,730 --> 00:07:58,940
他の本と少し異なるやり方を
したことの１つは

148
00:07:58,940 --> 00:08:03,905
深層学習に必要な種類の数学を
最初に焦点を当てて紹介している点です

149
00:08:03,905 --> 00:08:07,670
あなたのスタンフォード大学でのコースで
分かったことの１つは

150
00:08:07,670 --> 00:08:11,570
線形代数と確率が
非常に重要な一方で

151
00:08:11,570 --> 00:08:15,230
人々は機械学習のアルゴリズムに夢中になっていることです

152
00:08:15,230 --> 00:08:18,500
しかし優秀な実践者になりたければ

153
00:08:18,500 --> 00:08:26,055
最初から全てで使う方法の基礎となる基本的な数学を
習得しておく必要があります

154
00:08:26,055 --> 00:08:27,290
このため
目指したのは

155
00:08:27,290 --> 00:08:31,345
本の最初で数学の基礎に焦点を当てた例示を
しているということです

156
00:08:31,345 --> 00:08:34,153
この方法なら
線形代数の全てを学ぶ必要はなく

157
00:08:34,153 --> 00:08:35,900
深層学習で

158
00:08:35,900 --> 00:08:37,770
最も役に立つ
線形代数を

159
00:08:37,770 --> 00:08:40,540
短期集中で見ることができます

160
00:08:40,540 --> 00:08:44,660
数学が少しあやふやだったり
数年間見てなかったりした人には

161
00:08:44,660 --> 00:08:47,000
本の最初から始めれば
数学の背景を知り

162
00:08:47,000 --> 00:08:49,790
深層学習を
学び始められるのですね

163
00:08:49,790 --> 00:08:52,175
知る必要がある事実は
本に入っています

164
00:08:52,175 --> 00:08:59,520
利用できるように集中して
努力することが絶対に必要です

165
00:08:59,520 --> 00:08:59,684
なるほど。 なるほど。 立派なことです。

166
00:08:59,684 --> 00:09:01,370
もし数学がすごく苦手だと

167
00:09:01,370 --> 00:09:03,700
少し苦痛を伴う経験ではあるでしょうが

168
00:09:03,700 --> 00:09:08,323
学習の経験の覚悟があって
習得できると信じていれば

169
00:09:08,323 --> 00:09:11,360
必要なツールは
全て含んでいます

170
00:09:11,360 --> 00:09:15,470
私は深層学習の研究を
長くしてきた１人として

171
00:09:15,470 --> 00:09:18,710
興味があります
もし過去を振り返ったとして

172
00:09:18,710 --> 00:09:21,050
AI や深層学習が
何年かを経て

173
00:09:21,050 --> 00:09:24,650
進化してきたことについて
どう考えているか教えてください

174
00:09:24,650 --> 00:09:28,595
10年前には
コミュニティとしての

175
00:09:28,595 --> 00:09:31,580
深層学習の最も大きな課題は

176
00:09:31,580 --> 00:09:34,715
AI に関連するような作業について
一体どうすれば効果を持つかということでした

177
00:09:34,715 --> 00:09:39,440
単純な作業については
とても良いツールがありました

178
00:09:39,440 --> 00:09:44,555
手作業で抽出した特徴でのパターンを認識させたいときは

179
00:09:44,555 --> 00:09:47,000
人の設計者が多くの調整をして

180
00:09:47,000 --> 00:09:51,965
特徴を創り出して
コンピューターに手渡していました

181
00:09:51,965 --> 00:09:54,170
この方法は様々なことで
効果を上げていました

182
00:09:54,170 --> 00:09:56,750
例えば どの広告をユーザーが
クリックするか予測したり

183
00:09:56,750 --> 00:10:01,895
他の様々な基礎的な科学分析にはよかったですが

184
00:10:01,895 --> 00:10:07,505
大変苦労していたものは
画像の数百万のピクセルに関するものや

185
00:10:07,505 --> 00:10:10,150
音のウェイブ形式のファイルに関するものでした

186
00:10:10,150 --> 00:10:13,950
何もないところから
システムは理解を築く必要がありました

187
00:10:13,950 --> 00:10:18,880
５年ほど前に これらの障壁を
やっと越えることができました

188
00:10:18,880 --> 00:10:22,180
現在は
非常に多くの道があり

189
00:10:22,180 --> 00:10:26,268
もしAI に関することがしたい人にとって

190
00:10:26,268 --> 00:10:31,060
どの道を進むのかを
選ぶことが最も難しい問題かもしれません

191
00:10:31,060 --> 00:10:35,500
教師あり学習が効果があるのと同じように
強化学習をうまく動くようにするのか

192
00:10:35,500 --> 00:10:40,410
教師あり学習のように
教師なし学習を動作するようにするのか

193
00:10:40,410 --> 00:10:44,333
機械学習のアルゴリズムが
公平で避けたい偏見を

194
00:10:44,333 --> 00:10:48,460
反映させないことを目指すのか

195
00:10:48,460 --> 00:10:54,565
AI を取り巻く社会的問題が
うまく行くようにして

196
00:10:54,565 --> 00:10:58,535
AI が社会の激変や失業の問題を起こすのではなく

197
00:10:58,535 --> 00:11:03,440
みんなに恩恵をもたらすことを
確実にすることを目指すのか

198
00:11:03,440 --> 00:11:04,600
現代は

199
00:11:04,600 --> 00:11:08,025
驚くべきほどの種類のことを
行うことができます

200
00:11:08,025 --> 00:11:11,380
AI の影の部分を防ぐためのことだったり

201
00:11:11,380 --> 00:11:14,965
AI がもたらす利点の全てを
さらに引き出すこともできます

202
00:11:14,965 --> 00:11:19,800
現在は 非常に多くの人が
AI に関わることをしたがっています

203
00:11:19,800 --> 00:11:23,285
こういう人たちへは
どんな助言はありますか

204
00:11:23,285 --> 00:11:26,950
AI の道に入りたい人たちの多くが

205
00:11:26,950 --> 00:11:32,200
博士号や同様の資格が
絶対に必要だと考え始めるようですが

206
00:11:32,200 --> 00:11:35,155
実はもう必須ではなくなってきたと思います

207
00:11:35,155 --> 00:11:40,285
多くの注目を集める方法の１つとしては
良いコードを書いてGitHub に上げることがあります

208
00:11:40,285 --> 00:11:43,380
最上級で働く人が

209
00:11:43,380 --> 00:11:47,320
解決しようとしている問題を
解決する面白いプロジェクトをあなたが行っていて

210
00:11:47,320 --> 00:11:49,840
あなたのGitHub のリポジトリを
見つけたらすぐに

211
00:11:49,840 --> 00:11:53,450
あなたを見つけられますし
働かないかと誘われるでしょう

212
00:11:53,450 --> 00:11:56,140
私がOpenAI や

213
00:11:56,140 --> 00:12:00,010
グーグルで採用したり募集した人の多くは

214
00:12:00,010 --> 00:12:02,755
インターネットのオープンソースのフォーラムで

215
00:12:02,755 --> 00:12:06,895
その人たちが貢献したものを見て
そこから興味を持ったからです

216
00:12:06,895 --> 00:12:11,275
論文を書いてArchive に載せることも
良いことではあるのですが

217
00:12:11,275 --> 00:12:12,745
多くの場合に

218
00:12:12,745 --> 00:12:16,750
科学的機関誌に新たに学問的に発行されるほどに

219
00:12:16,750 --> 00:12:20,860
何かを洗練された形にするのは
非常に困難ですが

220
00:12:20,860 --> 00:12:27,885
役に立つソフトウェアの形にするのは
かなり早期に到達することができます

221
00:12:27,885 --> 00:12:30,022
あなたの本を読んで

222
00:12:30,022 --> 00:12:33,930
資料で練習しGitHub に公開し
できればArchive に公開ですね

223
00:12:33,930 --> 00:12:36,100
本を読むことで学んだ場合には

224
00:12:36,100 --> 00:12:39,454
同時にプロジェクトで
作業することが本当に大切です

225
00:12:39,454 --> 00:12:42,730
既に興味を持っていた領域へ

226
00:12:42,730 --> 00:12:46,555
機械学習を適用する方法模索するのもこの１つです

227
00:12:46,555 --> 00:12:50,500
例えば 野外生物学者で
深層学習を始めたいなら

228
00:12:50,500 --> 00:12:53,255
鳥を識別するために使うかもしれません

229
00:12:53,255 --> 00:12:56,905
もしくは 人生でどこに機械学習を使うのか
考えつかない場合でもこれももう１つの方法です

230
00:12:56,905 --> 00:13:01,600
ストリートビューを使った住所の表記の分類機を作るようなものを
選んでもいいかもしれません

231
00:13:01,600 --> 00:13:05,580
この問題ならデータセットが準備されていて
使いやすい状態になっています

232
00:13:05,580 --> 00:13:07,330
この方法なら

233
00:13:07,330 --> 00:13:09,700
本を読んだり Coursera で見て

234
00:13:09,700 --> 00:13:14,105
その中で説明されている概念の全ての基本的なスキルを
実行することができるでしょう

235
00:13:14,105 --> 00:13:15,670
過去数年で

236
00:13:15,670 --> 00:13:20,045
敵対的攻撃の防御の先例の研究を
ますます行われているのを見てきました

237
00:13:20,045 --> 00:13:21,535
これを少し教えていただけますか

238
00:13:21,535 --> 00:13:24,490
ええ 敵対的攻撃の防御例は

239
00:13:24,490 --> 00:13:29,835
機械学習へのセキュリティという
新しい領域の始まりです

240
00:13:29,835 --> 00:13:33,250
過去には
コンピューターのセキュリティ問題というのは

241
00:13:33,250 --> 00:13:38,275
攻撃者がコンピューターを騙し
悪いコードを実行するものでした

242
00:13:38,275 --> 00:13:40,890
これはアプリケーションレベルでの
セキュリティーと呼ばれています

243
00:13:40,890 --> 00:13:46,300
また身元を偽って送られてきたメッセージを

244
00:13:46,300 --> 00:13:52,545
正しい人から送られてきたと
コンピューターに信じさせる攻撃もあります

245
00:13:52,545 --> 00:13:55,025
これはネットワークレベルでの
セキュリティーと呼ばれています

246
00:13:55,025 --> 00:13:57,230
現在では 機械学習アルゴリズムを騙して

247
00:13:57,230 --> 00:13:59,920
行うべきでない想定のことを
実行させるものも出てきました

248
00:13:59,920 --> 00:14:06,010
機械学習アルゴリズムを実行しているマシンは
正しいコードを実行しているにも関わらずです

249
00:14:06,010 --> 00:14:07,960
同時に機械学習アルゴリズムを

250
00:14:07,960 --> 00:14:10,025
実行しているプログラムには

251
00:14:10,025 --> 00:14:13,605
ネットーワークのどこからメッセージが来たのか
分かっているにも関わらずです

252
00:14:13,605 --> 00:14:17,050
進化の始まりのうちに
新しい技術に

253
00:14:17,050 --> 00:14:20,830
セキュリティーを組み込むのが
重要と考えます

254
00:14:20,830 --> 00:14:27,065
動作するシステムをまず作ったあとで
セキュリティーを追加するのは非常に困難だと気付きました

255
00:14:27,065 --> 00:14:30,640
とても楽しみにしています

256
00:14:30,640 --> 00:14:34,705
この時点でこの領域に飛び込み
機械学習のセキュリティー問題を予測し始めるなら

257
00:14:34,705 --> 00:14:37,600
何年後かに
遡って直すのではなく

258
00:14:37,600 --> 00:14:41,650
初期の段階から
アルゴリズムが守られるようにできます

259
00:14:41,650 --> 00:14:43,111
ありがとうございます
素晴らしかったです

260
00:14:43,111 --> 00:14:46,090
あなた自身に関する魅力的な話が
たくさんありました

261
00:14:46,090 --> 00:14:47,470
何年もあなたを知っていましたが

262
00:14:47,470 --> 00:14:49,935
実は知らなかったです
色々と共有いただいてありがとうございます

263
00:14:49,935 --> 00:14:53,090
どういたしまして
お招きありがとうございます 楽しく話せました

264
00:14:53,090 --> 00:14:53,630
この線の勾配になります。この導関数項はこの線の勾配となります。しかしこの
ありがとうございます

265
00:14:53,630 --> 00:14:55,010
どういたしまして