Bu haftanın önceki videolarında da son birkaç haftadaki videolarda olduğu gibi, temel yapı taşlarını gördünüz, ileri ve geri yayılım algoritmalarının bir derin sinir ağını uygulamanız için gereken anahtar bileşenleri Derin bir ağ oluşturmak için bu bileşenleri nasıl bir araya getirebileceğinizi görelim. İşte birkaç katmandan oluşan bir ağ. Hadi bir katman seçin ve şimdilik sadece bu katman üzerindeki hesaplamalara odaklanın. L katmanı için WL ve BL parametrelerine sahipsiniz ve ileri yayılım için bir önceki katmanın AL-1 etkilenimlerini girdi olarak alacaksınız ve çıktı olarak AL üretileceksiniz. Bu daha önce yaptığımızda şu şekilde yapmıştık: siz ZL = WL x AL - 1 + BL'i hesaplamıştınız daha sonra da AL=G_of_ZL'i hesaplamıştınız değil mi? İşte böyle AL-1 girdisinden AL çıkışına gidersiniz. Ve o daha sonra kullanılmak üzere çıkıyor ZL değerini de ön belleğe almak yararlı olacaktır. Bu ön belleği de dahil edeyim çünkü ZL değerini saklamak geriye doğrular için faydalı olacaktır daha sonra geriye yayılım adımı için faydalı olacaktır ve daha sonra geriye doğru adımı için, geriye yayılım adımı için, tekrar, L katmanı için hesaplamalara odaklanarak, DAL'yi girdisi alan ve DAL-1 çıktısını veren fonksiyonu uygulayacaksınız. Sadece detayları ortaya çıkarmak için girdi aslında DAL'di hem de ön bellektir, bu yüzden sizin hesapladığınız ZL değeri de senin elinde kullanılabilir durumda ve sonra DAL-1 çıktısına ek olarak siz istediğiniz eğimlerin çıktılarını da üreteceksiniz öğrenme için eğim inişini uygulamak amacıyla. İleriye doğru adımın nasıl uyguladığının temel yapısı budur. ben onu ileriye doğru fonksiyonu olarak adlandıracağım aynı zamanda geriye doğru adımı da geriye doğru fonksiyonu olarak adlandırmalıyız. sadece özetlemek gerekirse L katmanında siz ileriye doğru adıma ya da ileriye doğru yayılıma ya da ileriye doğru fonksiyonuna sahip olacaksınız. girdisi AL-1 ve çıktısı AL ve bu hesaplamayı yapmak amacıyla WL ve BL değerlerini kullanmanız gerekecek Ayrıca ZL değerini içeren bir önbellek çıktısı verir ve sonra geriye doğru fonksiyonu geriye doğru yayılımı kullanarak DAL i girdi olarak alan ve çıktı olarak DAL-1 üreten başka bir fonksiyon olacak Bu size söyler ki, bu etkilenimlere göre türevler verildiğinde, ki o da DAL'dir. Türevler nelerdir? Ne kadar AL-1 değişikliği istiyorum? Önceki katmanın etkilenimlerine göre türevleri hesapla Bu kutu içerisinde WL ve BL değerlerini kullanmalısınız ve yol boyunca ortaya çıktı ki DZL değerini hesaplamayla neticelendi. ve sonra bu kutu Bu geriye doğru fonksiyonu ayrıca DWL ve DBL çıktılarını üretir. Bazı zamanlar ben geriye doğru hesaplamaları belirtmek için kırmızı oku kullanırım. Siz de tercih ederseniz bu okları kırmızı ile doldurabiliriz. Eğer bu iki fonksiyonu uygularsanız, sinir ağının temel hesaplaması aşağıdaki gibi olacaktır. Sen A0 girdi özniteliğini alacaksın Bunun ile besle, ve bu ilk katmanın aktivasyonlarını hesaplayacaktır Hadi bunu A1 olarak adlandıralım. Bunu yapmak için sizin W1 ve B1 değerine ihtiyacınız vardı. ve sonra Z1 değerini saklayacağız. Şimdi bunu yaparken bunun ile ikinci katmanı besledin ve sonra W2 ve B2 değerini kullanarak Sonraki katmanın aktivasyonlarını yani A2 değerini hesap edeceksiniz, ve AL çıktısınız üretene kadar bu böyle devam eder. Bu da Y^ eşittir. Tüm bu yol boyunca biz tüm Z değerlerini sakladık, sonuç olarak bu işlem ileri yayılım adımıdır. Şimdi geri yayılım adımı için, Yapacağımız şey, geriye doğru gideceğimiz ve eğimleri hesaplayacağımız bir geri dönüş dizisi olacaktır. O buradan beslenecek, DAL, ve sonra bu kutu bize DAL-1 değerini verecek, ve bu böyle biz DA2, DA1 değerine ulaşana kadar devam eder. Aslında DA0 değerini hesaplamak için bir tane daha çıktı alabilirsiniz. fakat senin girdi özniteliklerine göre bu türevi almak en azından bu gözetimli sinir ağlarının ağırlıklarının eğitimi için hiç faydalı değil. Sonuç olarak bu noktada durabilirsin. Yol boyunca geriye yayılım ayrıca DWL, DBL çıktıları üretmiştir. sadece WL ve BL parametrelerini kullanalım bu DW3, DB3 üretecek ve böyle devam eder. Böylece ihtiyacın olan tüm türevleri hesaplamış olacaksınız. Sadece belki bunun yapısını biraz daha doldurmak amacıyla bu kutular da bu parametreleri kullanır, WL, BL, sonra göreceğimiz gibi bu kutuların içinde de biz DZ değerlerini hesaplayacağız. Bir sinir ağının eğitimin ilk yenilemesi A0 ile başlamayı içerir, ki o da X değeridir. ve ileri yayılım geçimi şu şekildedir, Y^ değerini hesaplama ve sonra bu değeri kullanarak bunu hesaplama ve sonra geri yayılım, bunu yapmak suretiyle Şimdi siz tüm türev değişkenlerine sahipsiniz. Ve böylece her bir katman için W değeri, W eksi öğrenme oranı çarpı dw olarak güncellenecektir ve benzer şekilde B için de Şimdi geri yayılımı hesapla ve tüm türevlere sahip ol. Bu işte sizin sinir ağınızın tek bir yinelemesidir. Devam etmeden önce, sadece bir tane daha uygulama detayı Kavramsal olarak, ön belleği burada Z değerlerini geriye doğru fonksiyonu için saklamak olarak düşünmek yararlı olur fakat sen bunu uyguladığın zaman, ve bunu önceki programlama egzersizlerinde de görüyorsun, biz bunu uyguluyoruz. W1, B1 parametrelerinin bu değerinin de geriye doğru fonksiyona getirilmesi için saklamanın uygun bir yol olduğunu görürsünüz. Eski alıştırmalar da, siz aslında Z değerini kendi ön belliğinizde sakladınız, aynı şekilde W ve B değerlerini de, sonuç olarak sadece Z2, W2, B2 değerlerini depola. Bir uygulama açısından bakıldığında Sadece kopyalanan parametreleri almanın uygun bir yolunu buldum Geri yayılımı hesaplarken bunları daha sonra kullanmanız gerekir. Bu sadece programlama alıştırmasını yaptığınızda gördüğünüz uygulama detayıdır. Artık derin bir sinir ağını uygulamak için gerekli temel yapı taşlarından birini gördünüz. Her bir katman için, bir ileri yayılım adımı var, ve buna karşılık gelen bir geri yayılım adımı var ve bilgileri birinden diğerine aktarmak için bir önbellek var. Bir sonraki videoda, Bu yapı taşlarını gerçekte nasıl uygulayacağınız hakkında konuşacağız. Hadi bir sonrakine gidelim.