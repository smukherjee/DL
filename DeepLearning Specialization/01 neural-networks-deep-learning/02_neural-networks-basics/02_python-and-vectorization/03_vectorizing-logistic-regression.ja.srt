1
00:00:00,860 --> 00:00:05,760
これまではベクトル化によって
コードの実行速度をかなり速くできることを見てきました

2
00:00:05,760 --> 00:00:08,160
このビデオではロジステック回帰で

3
00:00:08,160 --> 00:00:10,545
ベクトル化する方法を話します

4
00:00:10,545 --> 00:00:12,960
トレーニングデータ全体を
処理できるようにします

5
00:00:12,960 --> 00:00:15,930
ここでは１つもfor loop を書かずに

6
00:00:15,930 --> 00:00:22,330
トレーニングデータ全体での勾配降下法の実行を
１度の実行で完了できるように実装します

7
00:00:22,330 --> 00:00:24,039
このテクニックや

8
00:00:24,039 --> 00:00:26,670
１つのfor loop さえも
使っていないような

9
00:00:26,670 --> 00:00:30,050
ニューラルネットワークを語るのは
すごく興奮します

10
00:00:30,050 --> 00:00:35,965
では始めましょう
ロジステック回帰の誤差順伝播を検討しましょう

11
00:00:35,965 --> 00:00:37,860
m のトレーニングデータがあるとして

12
00:00:37,860 --> 00:00:40,605
１つ目のデータで予測するために

13
00:00:40,605 --> 00:00:42,105
この計算が必要です

14
00:00:42,105 --> 00:00:45,480
この馴染みの式を使って
z を計算します

15
00:00:45,480 --> 00:00:47,370
次に活性化を計算します

16
00:00:47,370 --> 00:00:49,485
１つ目のデータで
yハットを計算します

17
00:00:49,485 --> 00:00:52,705
次に２つ目のデータで
予測するために

18
00:00:52,705 --> 00:00:54,405
この計算が必要です

19
00:00:54,405 --> 00:00:57,085
３つ目のデータでの予測には

20
00:00:57,085 --> 00:00:59,045
これが必要で
どんどん続きます

21
00:00:59,045 --> 00:01:01,020
m 個のデータがあれば

22
00:01:01,020 --> 00:01:03,855
これをm 回実行する必要があります

23
00:01:03,855 --> 00:01:08,250
誤差順伝播法を実行するためには

24
00:01:08,250 --> 00:01:13,435
m 個のトレーニングデータの予測を
計算する必要があります

25
00:01:13,435 --> 00:01:14,865
for loop なしで

26
00:01:14,865 --> 00:01:17,925
行う方法があります

27
00:01:17,925 --> 00:01:20,450
どうするか見てみましょう

28
00:01:20,450 --> 00:01:26,455
最初に行列X を定義して
トレーニングデータの入力を

29
00:01:26,455 --> 00:01:30,895
別々の列に
このように積み重ねます

30
00:01:30,895 --> 00:01:33,810
これは行列です

31
00:01:33,810 --> 00:01:38,425
nxとm の行列です

32
00:01:38,425 --> 00:01:41,885
Python numpy での
shape の形で書いていますが

33
00:01:41,885 --> 00:01:50,350
これはXはnxとmの次元を持つ列を
意味しているだけです

34
00:01:50,350 --> 00:01:54,670
まず最初に実行するのは
z(1)、z(2)、z(3)を

35
00:01:54,670 --> 00:01:56,512
どう１回で

36
00:01:56,512 --> 00:01:58,665
計算するかです

37
00:01:58,665 --> 00:02:01,195
実際 １行のコードでです

38
00:02:01,195 --> 00:02:06,930
まず1 と m の行列を作ります

39
00:02:06,930 --> 00:02:13,100
これは列ベクトルでz(1)、z(2)などと

40
00:02:13,100 --> 00:02:15,405
z(m)まで

41
00:02:15,405 --> 00:02:18,480
ずっと計算します

42
00:02:18,480 --> 00:02:22,175
実はこれは

43
00:02:22,175 --> 00:02:29,225
wの転置に行列Xと
ベクトルbを足したものです

44
00:02:29,225 --> 00:02:31,040
bが続きます

45
00:02:31,040 --> 00:02:33,315
この続いていくもの

46
00:02:33,315 --> 00:02:34,480
このb、b、b、b、b は

47
00:02:34,480 --> 00:02:38,980
1 とm のベクトルまたは

48
00:02:38,980 --> 00:02:46,725
1 とm の行列
m要素の行ベクトルです

49
00:02:46,725 --> 00:02:50,495
みなさんの行列積の詳しさによりますが

50
00:02:50,495 --> 00:02:56,300
wの転置には
x(1)、x(2)から

51
00:02:56,300 --> 00:02:58,760
x(m)までありますよね

52
00:02:58,760 --> 00:03:05,755
wの転置したものは
列ベクトルになります

53
00:03:05,755 --> 00:03:10,655
こんな列ベクトルになります

54
00:03:10,655 --> 00:03:18,614
この最初の項を評価すると
wの転置にx(1)をかけ

55
00:03:18,614 --> 00:03:22,970
wの転置にx(2)をかけ
これが続いて

56
00:03:22,970 --> 00:03:29,840
wの転置にx(m)となります
次の項のb を

57
00:03:29,840 --> 00:03:30,960
続けると

58
00:03:30,960 --> 00:03:33,565
b を全要素に
足すことになります

59
00:03:33,565 --> 00:03:37,650
さらにもう１つの
1とmのベクトルができることになります

60
00:03:37,650 --> 00:03:38,955
１つ目の要素がこれで

61
00:03:38,955 --> 00:03:40,590
２つ目の要素がこれで
これが続いて

62
00:03:40,590 --> 00:03:42,810
m 個目の要素まで行きます

63
00:03:42,810 --> 00:03:45,605
この定義を見ると

64
00:03:45,605 --> 00:03:51,250
この１つ目の要素は
z(1)の定義と全く同一です

65
00:03:51,250 --> 00:03:57,305
２つ目の要素そして次も
同じ定義が続きます

66
00:03:57,305 --> 00:04:00,035
X が得られるのと同じで

67
00:04:00,035 --> 00:04:02,870
トレーニングデータを使って

68
00:04:02,870 --> 00:04:07,400
次々に水平に重ねていくと

69
00:04:07,400 --> 00:04:11,069
Z をこのように
定義することになります

70
00:04:11,069 --> 00:04:16,385
小文字のz を使って
水平に重ねます

71
00:04:16,385 --> 00:04:21,080
小文字のx を別のトレーニングデータに
水平に重ねると

72
00:04:21,080 --> 00:04:24,350
大文字の変数X が得られます

73
00:04:24,350 --> 00:04:27,420
これと同じように
小文字のz の変数を

74
00:04:27,420 --> 00:04:28,805
水平に重ねていくと

75
00:04:28,805 --> 00:04:34,050
大文字の先に出てきた変数 Zになります

76
00:04:34,050 --> 00:04:37,400
実は この部分を実装するには

77
00:04:37,400 --> 00:04:45,773
numpy の命令は
Z=np.dot(w.T,X)+bです

78
00:04:45,773 --> 00:04:51,095
wの転置とXで
これにb を加えます

79
00:04:51,095 --> 00:04:53,645
Python には
見えにくい点があり

80
00:04:53,645 --> 00:04:59,405
b は実数で
1と1の行列です

81
00:04:59,405 --> 00:05:01,330
普通の実数ですが

82
00:05:01,330 --> 00:05:06,230
このベクトルに実数を足すと

83
00:05:06,230 --> 00:05:13,235
Python は自動で
実数b を1 x m の列ベクトルに拡張します

84
00:05:13,235 --> 00:05:16,490
この演算が
ちょっと神秘的に見えた場合には

85
00:05:16,490 --> 00:05:20,120
これはブロードキャストと
呼ばれています

86
00:05:20,120 --> 00:05:22,210
今は これは気にしないでください

87
00:05:22,210 --> 00:05:25,760
次のビデオで
もっと解説します

88
00:05:25,760 --> 00:05:29,180
ここで覚えてもらいたいのは
このたった１行のコードです

89
00:05:29,180 --> 00:05:33,290
大文字のZ を計算でき

90
00:05:33,290 --> 00:05:37,698
大文字のZ は1 x m の行列になっています
小文字のz をすべて含んでいます

91
00:05:37,698 --> 00:05:41,200
z(1)からz(m)までです

92
00:05:41,200 --> 00:05:46,255
これが大文字のZ です
ではa たちの値はどうでしょうか

93
00:05:46,255 --> 00:05:48,260
次に行うのは

94
00:05:48,260 --> 00:05:52,685
a(1)からa(2)
そしてa(m)までを

95
00:05:52,685 --> 00:05:57,220
１度で計算を実行するような方法を

96
00:05:57,220 --> 00:05:58,700
探します

97
00:05:58,700 --> 00:06:03,350
小文字のx を水平に重ねることで

98
00:06:03,350 --> 00:06:08,870
大文字のX になったのと同じように

99
00:06:08,870 --> 00:06:10,810
小文字のa を重ねていくと

100
00:06:10,810 --> 00:06:12,470
新しい変数の大文字Aを

101
00:06:12,470 --> 00:06:15,200
定義することになります

102
00:06:15,200 --> 00:06:18,075
この後のプログラムアサインメントでは

103
00:06:18,075 --> 00:06:22,790
ベクトルになったシグモイド関数を
実装する方法が出てきます

104
00:06:22,790 --> 00:06:24,480
シグモイド関数とは

105
00:06:24,480 --> 00:06:32,380
この大文字のZ を入力とし
非常に効率的に大文字のA を出力するものです

106
00:06:32,380 --> 00:06:36,620
プログラムアサインメントで
詳しく紹介しています

107
00:06:36,620 --> 00:06:38,110
まとめると

108
00:06:38,110 --> 00:06:42,655
このスライドで見てきたのは
トレーニングデータのm に対して

109
00:06:42,655 --> 00:06:47,515
小文字のz と小文字のa を
１つずつ計算するためのループが必要になる替わりに

110
00:06:47,515 --> 00:06:52,090
この１行のコードを実装することで

111
00:06:52,090 --> 00:06:54,290
全てのz を
一度で計算できます

112
00:06:54,290 --> 00:06:57,100
さらにこの１行のコードで

113
00:06:57,100 --> 00:06:59,260
小文字のシグマを

114
00:06:59,260 --> 00:07:04,115
計算する適切な実装で
小文字のa 全てを１度で計算します

115
00:07:04,115 --> 00:07:05,965
これがベクトル化実装で

116
00:07:05,965 --> 00:07:07,948
全ての

117
00:07:07,948 --> 00:07:11,560
トレーニングデータm に対して
誤差順伝播法行う方法です

118
00:07:11,560 --> 00:07:13,985
まとめると
ここでは

119
00:07:13,985 --> 00:07:18,100
ベクトル化して
活性化関数の小文字のa を

120
00:07:18,100 --> 00:07:21,700
非常に効率的に
計算する方法を見てきました

121
00:07:21,700 --> 00:07:24,860
次は勾配を計算し
誤差逆伝播法を

122
00:07:24,860 --> 00:07:27,910
非常に効率的に計算する方法を

123
00:07:27,910 --> 00:07:29,650
使えるようになります

124
00:07:29,650 --> 00:07:32,000
どうするのか
次のビデオで見てみましょう