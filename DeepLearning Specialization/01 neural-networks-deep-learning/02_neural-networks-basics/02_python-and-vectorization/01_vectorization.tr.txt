Hoş geldiniz.Vektörleştirme temelde Kodunuzdaki açık klasörlerden kurtulma. Uygulamada derin öğrenme döneminde güvenliği büyük veri setleri üzerinde kendimiz eğitiyoruz çünkü derin öğrenme algoritmaları parlama eğiliminde Böylece kodunuzun çok hızlı çalışır aksi halde, eğer big data seti üzerinde çalışıyorsa kodunuz çalışmak için uzun zaman alabilir. Sonucu almak için uzun süredir bekliyorum. Derin öğrenme döneminde Vectorization(Vektörleştirme) gerçekleştirme önemli bir beceri haline geldi. Bir örnek ile başlayalım. Vectorization(Vektörleştirme) nedir? Lojistik regresyon hesablamada Z=w^T(x)+b W ve X sütun vektörü oldular. Çok fazla özelliğe sahipseniz çok büyük vektörler olabilir. W ve X nx boyutlu vektörlerdir. W transpoz x hesaplanırken Vektörleştirmeme(non-vectorized) uygulaması varsa Z=0 olur Değerler i ile (n-x) aralığında olacaktır. İ=1,2,NX olabilir Z^+=w[i]**[i] Sonrasında Z+=b yapabiliriz belki. Bu bir vektörsüzleştirme uygulaması Bunun gerçekten yavaş olacağını görüyorsun. Tam tersi Vektörleştirme uygulandığında W transpoz X'i doğrudan hesaplanır. Python veya bir numpy kullanacağımız Z=np.W W transpoz x'e eşittir. B'yi doğrudan ekleyebilirsiniz. Bunun daha hızlı olduğunu Küçük bir demo ile örnekleyelim. Jupiter Python kodlarını yazdığım bir platform. İlk önce numpy kütüphanesini dahil edelim. Örneğin, Bir A dizisi tanımlıyorum A'yı yazdırıyoruz. Şimdi kod parçasının çıktısı için shift enter'a bastık sonrasında kodu çalıştırır. Böylece oluşturduğumuz A dizisinin çıktısını verir Şimdi ise Vectorization(Vektörleştirme) demo'su oluşturalım Zaman kütüphanelerini de ekliyorum, onu kullanmamızın amacı farklı operasyonların ne kadar sürdüğünü zamanlamak için. Bir A dizi oluşturabilir miyiz? Rastgele kümesi içinde bu rastgele değerlerle 1 milyon boyutlu bir dizi oluşturduk. b=np.random.rand Başka bir milyon boyutlu dizi. tic=time.time şimdiki zamanı tutar. c=np.dot(a,b) toc=time.time. Yazdırıyoruz Bu vektörleştirme sürümüdür. Vektörleştirme sürümüdür. Çıktı alacağız. Geçen zamana bakalım geçen zaman (toc-tic)*1000 bunu milisaniye cinsinde ifade edebiliriz ms milisaniyedir. Shift Enter'a basıyoruz. Bu kod 3 ms yada 1.5 ms aldı belki 1.5 yada 3.5 ms de olabilir. Çalışırken değerler biraz değişir fakat ortalama 1.5 ms gibi gözüküyor Bu çalıştığında 2 ms alabilir. ortak çalışmaya dayalı şekilde 
katılmaya isteklendiren, Koda eklemeler yapalım. Vektörsüzleştirme(non-vectorize) sürümü uygulanamadı. c=0, tic=time.time. Şimdi klasöre uygulayalım. I aralığı 1 milyon , Doğru sıfırı seçiyorum. C += (a,i) x (b,i) ve toc=time.time. Son olarak, döngüden daha fazlasını yazdır. Alınan süre 1000*(toc-tic) ms bunu milisaniye cinsiden yapar. Bir tane daha yapalım. C değerini de yazdıralım Her iki durumda da aynı değere sahip olduğundan emin olun Çalıştırıyorum ve çıktıyı kontrol ediyorum. Her iki durumda da vektörleştirme sürümü ve vektörsüzleştirme(non-vectorize) sürümü aynı değerleri hesaplar. Bildiğiniz gibi 2.55 den 6.99 olduğunu görüyoruz. Vektörleştirme sürümü 1.5 milisaniye sürdü. For döngüsü ve vektörsüzleştirme(non-vectorized) sürümü 400 ms neredeyse 500 ms sürdü. Vektörsüzleştirme(non-vectorize) sürümü 300 ms vektörleştirme sürümünden daha uzun süreler. Vektörleştirme kodunuzda Kodunuz aslında 300 kat daha hızlı çalışır. Tekrar çalıştıralım. Tekrar çalıştıralım. Vektörleştirme sürümü ve 4 döngü 1.5 ms sürdü Yani yine 481 ms oldu 4 döngü için 300ms daha yavaş. Eğer x yavaşlarsa Aralarındaki fark kodunuzun 5 dakika sürmesine karşın 1 dakika sürmesidir. Derin öğrenme algoritmalarını uygularken gerçekten hızlı sonuçlar alırsınız. Kodunuzu vektörleştirirseniz daha hızlı olur. Bazılarınız bunu duymuş olabilirsiniz ölçeklenebilir derin öğrenme uygulamaları GPU(Graphics Processing Unit) üzerinde yapılır. Fakat Jüpiterde yazdığım bütün demolar CPU(Central Processing Unit) üzerinde. Hem GPU hem CPU paralelleştirme talimatlarına sahipler. Bazen SIMD(Single instruction multiple data ) talimatlar olarak adlandırılırlar. Tek bir komut çoklu veri anlamına gelir. Fakat temel anlamı ise np.function gibi bir fonksiyon veya başka fonksiyonlar for döngüsünü açıkça uygulamanızı gerektirmez. Python Pi'nin almasını sağlar hesaplarınızı daha hızlı yapmak için paralellikten çok daha iyi bir avantaj. Hem CPU'daki hesaplamalar hemde GPU'daki hesaplamalar için geçerlidir. GPU'ların GPU'larda SIMD hesaplamaları üzerinde oldukça iyi ancak CPU' da bu konuda çok da kötü değil. GPU'lar kadar iyi olmayabilir. Vektörleştirmenin kodunuzu önemli ölçüde hızlandırdığını görüyorsunuz. Unutulmaması gereken ana kural mümkün oldukça 4 açık döngüyü kullanmaktan kaçınmak. Gelecek videoda daha fazla vektörleştirme örnekleri inceleyeceğiz ve lojistik regresyon vektörleştirmeye başlayacağız.