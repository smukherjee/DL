1
00:00:00,920 --> 00:00:02,860
안녕하세요. 다시 오신 것을 환영합니다.

2
00:00:02,860 --> 00:00:08,860
이번 주에는 신경망 프로그래밍의 기초에 대해 알아보도록 하겠습니다.

3
00:00:08,860 --> 00:00:11,990
신경망을 구현할 때에는

4
00:00:11,990 --> 00:00:16,260
매우 중요한 몇 가지 기술이 있습니다.

5
00:00:16,260 --> 00:00:21,150
예를 들어, m개의 학습 표본을 가진 학습 세트가 있으면,

6
00:00:21,150 --> 00:00:25,110
m개의 학습 표본에 대해서 for문을 돌리면서

7
00:00:25,110 --> 00:00:28,240
하나씩 학습 세트를 처리 해 왔을 것입니다.

8
00:00:28,240 --> 00:00:31,260
하지만 신경망을 구현할 때는

9
00:00:31,260 --> 00:00:34,540
전체 학습 세트를 돌리는데

10
00:00:34,540 --> 00:00:39,040
for문을 사용하지 않고 처리하고자 합니다.

11
00:00:39,040 --> 00:00:42,940
따라서, 이를 어떻게 하는지 강의를 통해 알아보도록 합시다.

12
00:00:42,940 --> 00:00:47,700
또다른 아이디어에는, 신경망으로 계산을 할 때 보통

13
00:00:47,700 --> 00:00:51,670
순방향경로 혹은 순전파, 그 다음엔

14
00:00:51,670 --> 00:00:56,100
역방향경로 혹은 역전파 계산법을 사용합니다.

15
00:00:56,100 --> 00:01:00,010
따라서, 이번 주 강의에서 신경망을 학습시킬 때 왜

16
00:01:00,010 --> 00:01:04,830
순전파와 역전파를 이용하여 계산을 하는지

17
00:01:04,830 --> 00:01:08,010
소개하도록 하겠습니다.

18
00:01:09,100 --> 00:01:12,620
이 강의에서 저는 이해를 돕고자

19
00:01:12,620 --> 00:01:16,170
로지스틱 회귀를 통해 아이디어를 전달하려 합니다.

20
00:01:16,170 --> 00:01:19,970
하지만 예전에 로지스틱 회귀에 대해서 들어보셨을지라도,

21
00:01:19,970 --> 00:01:23,845
이 강의에서 얻을 수 있는 새롭고 흥미로운 아이디어가 있을 것이라 생각합니다.

22
00:01:23,845 --> 00:01:25,815
그럼 시작해보도록 합시다.

23
00:01:25,815 --> 00:01:30,605
로지스틱 회귀는 이진 분류를 위한 알고리즘입니다.

24
00:01:30,605 --> 00:01:33,145
문제를 통해 이야기해 보도록 합시다.

25
00:01:33,145 --> 00:01:36,925
여기 예로 이진 분류 문제가 하나 있습니다.

26
00:01:36,925 --> 00:01:41,545
여기와 같이 입력 이미지가 있습니다.

27
00:01:41,545 --> 00:01:47,260
이미지를 인식하기 위해서 고양이일 때에는 1로,

28
00:01:47,260 --> 00:01:52,140
고양이가 아닐 때는 0으로 레이블을 출력하려 합니다.

29
00:01:52,140 --> 00:01:57,740
그리고 출력 레이블을 나타내기 위해 y를 사용하도록 하겠습니다.

30
00:01:57,740 --> 00:02:01,550
이미지는 컴퓨터에서 어떻게 표현되는지 살펴보도록 하겠습니다.

31
00:02:01,550 --> 00:02:05,680
이미지를 저장하기 위해서 컴퓨터는 각각 빨간색, 녹색, 파란색 채널에 대응하는

32
00:02:05,680 --> 00:02:09,890
세 개로 분리된 행렬을 사용합니다.

33
00:02:10,990 --> 00:02:15,900
그래서 입력 이미지가 64x64 픽셀이라면

34
00:02:15,900 --> 00:02:21,700
빨간색, 녹색, 파란색 픽셀의 채도에 해당하는

35
00:02:21,700 --> 00:02:27,230
값을 가진 3개의 64x64 행렬을 있을 것입니다.

36
00:02:27,230 --> 00:02:31,290
좁은 슬라이드에 표현하다 보니깐 최대한 작게 그렸는데,

37
00:02:31,290 --> 00:02:35,320
여기에는 64x64 대신에 5x4 행렬이 사용 되었습니다.

38
00:02:35,320 --> 00:02:41,640
이 픽셀들의 채도값을 특징벡터로 바꾸기 위해

39
00:02:41,640 --> 00:02:48,000
여기 픽셀값 모두를 하나의 입력 특징벡터 x에 펼쳐 보았습니다.

40
00:02:48,000 --> 00:02:53,782
모든 픽셀 채도값을 특징벡터에 나열하기 위해서

41
00:02:53,782 --> 00:02:59,580
이미지에 해당하는 특징벡터를 다음과 같이 정의해 봅시다.

42
00:02:59,580 --> 00:03:03,960
255, 231, ...

43
00:03:03,960 --> 00:03:10,827
255, 231, ... 이런식으로 빨간색 픽셀값 모두를 나열합시다.

44
00:03:10,827 --> 00:03:15,737
다음엔 255, 134, ...

45
00:03:15,737 --> 00:03:20,952
255, 134, ... 여기 이미지에 있는 빨간색, 녹색, 파란색 픽셀 채도를 모두

46
00:03:20,952 --> 00:03:25,570
여기 기다란 특징벡터에 나열해봅시다.

47
00:03:25,570 --> 00:03:31,043
그래서 이미지가 64x64 이미지라면, 이 특징벡터 x의

48
00:03:31,043 --> 00:03:36,401
전체 차원은 64x64x3이 될 것입니다. 이는

49
00:03:36,401 --> 00:03:41,320
여기 세 개의 행렬 안에 있는 모든 값들의 수이기 때문입니다.

50
00:03:41,320 --> 00:03:44,097
이 경우에는 12,288이 되겠고

51
00:03:44,097 --> 00:03:47,330
여기 모든 숫자를 곱하면 얻을 수가 있습니다.

52
00:03:47,330 --> 00:03:51,870
그래서 입력 특징 x의 차원을

53
00:03:51,870 --> 00:03:55,080
nx = 12,288로 표현하겠습니다.

54
00:03:55,080 --> 00:03:59,280
가끔 간결하게, 입력 특징벡터의 차원을

55
00:03:59,280 --> 00:04:02,720
소문자 n으로 쓰겠습니다.

56
00:04:02,720 --> 00:04:07,510
따라서 이진 분류에서, 우리의 목표는 입력 벡터 x로 표현된 이미지를

57
00:04:07,510 --> 00:04:10,760
입력으로 주어 분류자를 학습시키고,

58
00:04:10,760 --> 00:04:15,460
출력 레이블 y가 1인지 0인지 예측하려 합니다.

59
00:04:15,460 --> 00:04:19,000
즉, 고양이인지 고양이가 아닌지 예측합니다.

60
00:04:19,000 --> 00:04:21,560
앞으로 이 강의에서 사용하게 될

61
00:04:21,560 --> 00:04:23,820
몇 가지 표기법을 정리하도록 하겠습니다.

62
00:04:23,820 --> 00:04:29,453
하나의 학습 표본은 순서쌍 (x,y)로 표기됩니다.

63
00:04:29,453 --> 00:04:34,446
여기서 x는 x차원을 가진 특징벡터이고,

64
00:04:34,446 --> 00:04:39,320
y는 0 혹은 1중에 하나의 값을 가지는 레이블입니다.

65
00:04:39,320 --> 00:04:44,550
학습 세트는 m개의 학습 표본으로 구성되어 있습니다.

66
00:04:44,550 --> 00:04:50,320
그리고 학습 세트는 첫번째 학습 표본의 입력값과

67
00:04:50,320 --> 00:04:55,370
출력값 (x(1),y(1)), 두번째 학습 표본 (x(2),y(2))에서

68
00:04:55,370 --> 00:05:01,980
마지막 학습 표본 (x(m), y(m))으로 적을 수가 있습니다.

69
00:05:01,980 --> 00:05:05,650
그래서 이것들이 모두 합쳐진 것이 전체 학습 세트입니다.

70
00:05:05,650 --> 00:05:10,170
학습 표본의 수를 나타내기 위해 소문자 m을 사용하도록 하겠습니다.

71
00:05:10,170 --> 00:05:14,418
그리고 가끔 학습 표본의 수라는 것을 강조하기 위해

72
00:05:14,418 --> 00:05:16,437
이것을 m=m_train으로 적도록 하겠습니다.

73
00:05:16,437 --> 00:05:18,692
그리고 테스트 세트를 말할 때는,

74
00:05:18,692 --> 00:05:24,430
m_test로 테스트 표본의 수를 나타내겠습니다.

75
00:05:24,430 --> 00:05:27,430
그래서 이것은 테스트 표본의 수입니다.

76
00:05:27,430 --> 00:05:33,440
마지막으로 모든 학습 표본을 더욱 간결하게 표현하기 위해서

77
00:05:33,440 --> 00:05:36,840
대문자 X로 행렬을 정의하겠습니다.

78
00:05:36,840 --> 00:05:41,592
이 행렬은 학습 세트 입력값들 x(1), x(2), ... 을 가져와서

79
00:05:41,592 --> 00:05:44,568
세로줄로 입력값들을 쌓은 것입니다.

80
00:05:44,568 --> 00:05:49,958
그래서 x(1)을 가져와서 여기 행렬의 첫번째 열에 놓고

81
00:05:49,958 --> 00:05:54,798
x(2)는 두번째 열, 이런식으로 x(m)까지 놓겠습니다.

82
00:05:54,798 --> 00:05:58,000
그러면서 행렬 X가 만들어지겠습니다.

83
00:05:58,000 --> 00:06:03,005
따라서 이 행렬은 학습 표본의 수인 m개의 세로줄

84
00:06:03,005 --> 00:06:08,665
행렬의 높이인 nx개의 가로줄을 가지게 됩니다.

85
00:06:08,665 --> 00:06:14,400
주의할 것이 있는데, 다른 강의에서

86
00:06:14,400 --> 00:06:19,390
가로줄로 학습 표본을 쌓아서 행렬 X를 표현하는 것을 보셨을 겁니다.

87
00:06:19,390 --> 00:06:23,940
x(1) 전치시키고, 아래로 가서 x(m)까지 전치시키고 이런식으로요.

88
00:06:23,940 --> 00:06:27,704
하지만 신경망을 구현할 때

89
00:06:27,704 --> 00:06:32,218
왼쪽에 제가 쓴 표기법이 훨씬 더 쉽다는 것이 알려졌습니다.

90
00:06:32,218 --> 00:06:37,171
그래서 요약하면, X는 nx x m차원을 가진 행렬이고,

91
00:06:37,171 --> 00:06:40,404
파이썬을 코딩할 때 나오는

92
00:06:40,404 --> 00:06:45,362
X.shape()는 행렬의 형태를 알기 위한 명령어이고

93
00:06:45,362 --> 00:06:50,325
(nx, m)을 출력합니다.

94
00:06:50,325 --> 00:06:53,255
따라서 그것은 단순히 nx x m차원의 행렬을 의미합니다.

95
00:06:53,255 --> 00:06:58,785
여기까지 학습 표본의 입력 x를 어떻게 행렬에 묶는지 알아보았습니다.

96
00:06:58,785 --> 00:07:01,315
그렇다면 출력 레이블 Y는 어떻게 할까요?

97
00:07:01,315 --> 00:07:04,815
신경망을 좀 더 쉽게 구현할려면

98
00:07:04,815 --> 00:07:10,030
출력 레이블 Y도 세로줄로 해서 쌓는 것이 더 편리합니다.

99
00:07:10,030 --> 00:07:14,650
따라서 대분자 Y를 이런식으로 y(1), y(2), ...

100
00:07:14,650 --> 00:07:18,580
y(m)와 같아지도록 정의하겠습니다.

101
00:07:18,580 --> 00:07:24,980
그러면 여기 있는 Y는 1 x m 다이멘션얼 매트릭스가 되겠죠.

102
00:07:24,980 --> 00:07:30,530
그리고 다시 Y 모양없이 표기하면, Y는 1, m이 되겠죠.

103
00:07:30,530 --> 00:07:34,810
즉, 이것은 1 x m 매트릭스가 됩니다.

104
00:07:34,810 --> 00:07:39,660
여러분이 차차 새로운 네트워크, mtrain discourse에 영향을 주면서,

105
00:07:39,660 --> 00:07:43,630
다른 트레이닝 example과 연관된 데이터를 적용시키는 것이 
유용하다고 느끼실 것입니다.

106
00:07:43,630 --> 00:07:48,580
여기서 데이터는 x 또는 y또는 나중에 다룰 데이터의 양입니다.

107
00:07:48,580 --> 00:07:49,900
다른 트레이닝 example과 

108
00:07:49,900 --> 00:07:52,990
연관된 데이터를 적용시켜서

109
00:07:52,990 --> 00:07:57,430
마찬가지로 x와 y에서 했던 것처럼 다른 줄에 쌓는 방식으로 
진행합니다.

110
00:07:58,450 --> 00:08:01,380
이것은 회귀를 가르키는데 쓰는 표기방식이구요,

111
00:08:01,380 --> 00:08:04,060
다름 코스에서 다룰 신경망에 대한 표기법입니다. 

112
00:08:04,060 --> 00:08:07,430
여러분이 만약 표기문자가 뜻하는 것을 까먹는 경우,
예를 들어, M이 무엇인지

113
00:08:07,430 --> 00:08:08,300
N이 무엇인지,

114
00:08:08,300 --> 00:08:12,630
다른 어떤 표기 방법은 또 무엇인지, 
이런 내용을 코스 웹사이트 notation guide로

115
00:08:12,630 --> 00:08:17,430
포스팅했기 때문에 여러분이 빠르게 궁금해하는
표기를 확인할 수 있습니다.

116
00:08:17,430 --> 00:08:20,890
자 그럼, 다음 비디오로 넘어가겠습니다.

117
00:08:20,890 --> 00:08:23,190
다음 비디오에서는 이 표기를 사용하여 
선형회귀를 도출하는 법을 다루겠습니다.