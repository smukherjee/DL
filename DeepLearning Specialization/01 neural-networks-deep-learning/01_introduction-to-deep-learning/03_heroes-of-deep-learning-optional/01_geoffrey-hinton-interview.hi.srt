1
00:00:00,620 --> 00:00:03,610
deeplearning.ai द्वारा इस कोर्स के हिस्से के रूप में,

2
00:00:03,610 --> 00:00:07,590
आशा है न केवल आपको पढ़ाना तकनीकी 
विचार डीप लर्निंग के बल्कि

3
00:00:07,590 --> 00:00:11,658
आपका परिचय भी करवाना कुछ लोगों से, 
कुछ नायकों से डीप लर्निंग के.

4
00:00:11,658 --> 00:00:13,160
लोग जिन्होंने आविष्कार किया

5
00:00:13,160 --> 00:00:17,700
बहुत से इन सुझावों का जो आप सीखेंगे 
इस कोर्स में या इस विशेषज्ञता में.

6
00:00:17,700 --> 00:00:21,420
इन वीडियो में, मैं आशा करता हूँ पूछने का 
डीप लर्निंग के इन नेताओं से

7
00:00:21,420 --> 00:00:24,990
देने के लिए आपको कैरियर सलाह कि 
कैसे आप घुस सकते हैं डीप लर्निंग में,

8
00:00:24,990 --> 00:00:27,805
कैसे आप कर सकते हैं अनुसंधान या 
ढूँढ सकते हैं नौकरी डीप लर्निंग में.

9
00:00:27,805 --> 00:00:30,156
इस इंटर्व्यू श्रृंखला के पहले के रूप में,

10
00:00:30,156 --> 00:00:34,228
मुझे ख़ुशी है पेश करते हुए आपको 
एक इंटर्व्यू जेफ़्फ़्री हिंटॉन के साथ.

11
00:00:38,427 --> 00:00:44,150
जेफ़ स्वागत है, और शुक्रिया यह इंटर्व्यू करने के लिए 
deeplearning.ai के साथ.

12
00:00:44,150 --> 00:00:46,550
>> मुझे निमंत्रित करने के लिए धन्यवाद.

13
00:00:46,550 --> 00:00:50,088
>> मुझे लगता है इस पोईँट पर आपने, 
इस ग्रह पर किसी अन्य से ज़्यादा

14
00:00:50,088 --> 00:00:52,835
अविष्कार किए हैं बहुत से विचार/सुझाव डीप लर्निंग के पीछे.

15
00:00:52,835 --> 00:00:57,650
और बहुत से लोग आपको डीप लर्निंग 
का गॉडफादर बुला रहे हैं.

16
00:00:57,650 --> 00:01:01,529
हालांकि यह नहीं था कुछ मिनट पहले तक जब हम 
बातें कर रहे थे, जब मुझे एहसास हुआ

17
00:01:01,529 --> 00:01:05,600
आप सोचते हैं मैं हूँ पहला आपको वह बुलाने वाला, 
जिसे करने से मुझे बहुत ख़ुशी है.

18
00:01:06,780 --> 00:01:11,320
लेकिन मैं जो पूछना चाहता हूँ है कि बहुत से लोग 
जानते हैं आपको एक दिव्य चरित्र के रूप में.

19
00:01:11,320 --> 00:01:15,030
मैं पूछना चाहता हूं आपकी निजी कहानी 
दिव्य चरित्र के पीछे.

20
00:01:15,030 --> 00:01:19,980
तो कैसे आप जुड़े, पीछे वापिस जाते हुए,
 कैसे आप जुड़े AI और

21
00:01:19,980 --> 00:01:21,520
मशीन लर्निंग और न्यूरल नेटवर्क से?

22
00:01:22,730 --> 00:01:26,960
> > तो जब मैं हाई स्कूल में था, 
मेरा एक सहपाठी था जो हमेशा

23
00:01:26,960 --> 00:01:31,220
बेहतर था सभी चीज़ों में, 
वह एक प्रतिभाशाली गणितज्ञ था.

24
00:01:31,220 --> 00:01:37,010
और वह एक दिन स्कूल में आया और बोला
, क्या तुम जानते हो मस्तिष्क होलोग्राम का 
उपयोग करता है?

25
00:01:38,190 --> 00:01:44,161
और मुझे लगता है वह था लगभग 1966 में, 
और मैंने कहा, कुछ क्या होता है एक होलोग्राम?

26
00:01:44,161 --> 00:01:47,390
और उसने बताया कि एक होलोग्राम में आप 
इसे आधा काट कर सकते हैं, और

27
00:01:47,390 --> 00:01:49,730
आपको फिर भी पूरी तस्वीर मिल सकती है.

28
00:01:49,730 --> 00:01:53,466
और कि मस्तिष्क की यादों को पूरे मस्तिष्क में 
वितरित किया जा सकता है.

29
00:01:53,466 --> 00:01:56,022
और इसलिए मुझे लगता है कि उसने लैश्ली के
 प्रयोगों के बारे में पढ़ा था,

30
00:01:56,022 --> 00:01:57,939
जहां आप एक चूहे के मस्तिष्क के टुकड़े काटते हो और

31
00:01:57,939 --> 00:02:01,740
जानते हो कि यह बहुत कठिन है ढूँढना एक टुकड़ा 
जहाँ यह संग्रह करता है एक ख़ास याद.

32
00:02:04,411 --> 00:02:08,920
तो वह था जिसने मेरी रुचि पैदा की कि कैसे 
मस्तिष्क संग्रह करता है यादें.

33
00:02:10,180 --> 00:02:12,220
और फिर जब मैं विश्वविद्यालय गया,

34
00:02:12,220 --> 00:02:15,130
मैंने शुरू किया फिजियोलॉजी और 
भौतिकी के अध्ययन से.

35
00:02:16,400 --> 00:02:17,731
मुझे लगता है कि जब मैं कैंब्रिज में था,

36
00:02:17,731 --> 00:02:20,260
मैं केवल अकेला ग्रैजूएट था फिजियोलॉजी 
और भौतिकी करने वाला.

37
00:02:21,888 --> 00:02:25,270
और फिर मैंने वह छोड़ दिया और

38
00:02:25,270 --> 00:02:29,170
कोशिश की फ़िलासफ़ी करने की, क्योंकि 
मैंने सोचा कि वह शायद मुझे दे अधिक जानकारी.

39
00:02:29,170 --> 00:02:32,780
लेकिन वह मुझे लग रहा था वास्तव में

40
00:02:32,780 --> 00:02:37,130
कुछ कम भेद करने के तरीक़ों में जब 
उन्होंने कुछ झूठ कहा.

41
00:02:37,130 --> 00:02:39,420
और तो फिर मैंने मनोविज्ञान करना शुरू किया.

42
00:02:41,988 --> 00:02:45,920
और मनोविज्ञान में उनके बहुत, बहुत सरल सिद्धांत थे, 
और मुझे ऐसा लग रहा था

43
00:02:45,920 --> 00:02:49,620
यह निराशाजनक रूप से अपर्याप्त है समझाने 
के लिए कि मस्तिष्क क्या कर रहा था.

44
00:02:49,620 --> 00:02:52,737
तो फिर मैंने कुछ अवकाश ले लिया और 
एक बढ़ई बन गया.

45
00:02:52,737 --> 00:02:57,169
और फिर मैंने तय किया कि मैं AI की कोशिश करूंगा, 
और एडिनबर्ग के पास गया,

46
00:02:57,169 --> 00:02:59,580
पढ़ने के लिए AI लैंगर हिगिंज़ के साथ.

47
00:02:59,580 --> 00:03:02,662
और उसने न्यूरल नेटवर्क पर बहुत 
अच्छा काम किया था, और

48
00:03:02,662 --> 00:03:07,830
और उसने हाल ही में त्याग दिये थे न्यूरल नेटवर्क्स, 
और बहुत प्रभावित था विनोगार्ड कि थीसिस से.

49
00:03:07,830 --> 00:03:11,460
तो जब मैं आया उसने सोचा कि मैं एक तरह से 
कर रहा हूँ यह पुराने जमाने का काम, और

50
00:03:11,460 --> 00:03:14,210
मुझे सांकेतिक AI पर शुरू करना चाहिए.

51
00:03:14,210 --> 00:03:18,210
और हमारे बहुत से झगड़े हुए उस बारे में, 
लेकिन मैं सिर्फ़ करता रहा जिसमें मुझे विश्वास था.

52
00:03:18,210 --> 00:03:21,138
>> और फिर क्या?

53
00:03:21,138 --> 00:03:28,033
> > मुझे अंततः PhD मिल गयी AI में, और 
फिर मुझे ब्रिटेन में कोई नौकरी नहीं मिली.

54
00:03:28,033 --> 00:03:30,979
लेकिन मैंने यह बहुत अच्छा विज्ञापन देखा

55
00:03:30,979 --> 00:03:36,070
स्लोन फ़ेलोशिप के लिए कैलिफोर्निया में, 
और कामयाब हुआ पाने में उनमें से एक.

56
00:03:36,070 --> 00:03:40,625
और मैं कैलिफोर्निया चला गया, 
और वहाँ सब कुछ अलग था.

57
00:03:40,625 --> 00:03:46,685
तो ब्रिटेन में, न्यूरल नेट्स माने जाते थे 
एक तरह से मूर्खतापूर्ण,

58
00:03:46,685 --> 00:03:50,272
और कैलिफोर्निया में, डॉन नॉर्मन और

59
00:03:50,272 --> 00:03:56,640
डेविड रूमेलहार्ट बहुत ग्रहणशील थे न्यूरल नेट्स के लिए.

60
00:03:56,640 --> 00:04:00,720
यह पहली बार था जब मैं था कहीं जहाँ सोचना 
कि मस्तिष्क कैसे काम करता है,

61
00:04:00,720 --> 00:04:03,290
और सोचना कि कैसे वह मनोविज्ञान से 
संबंधित हो सकता है,

62
00:04:03,290 --> 00:04:05,650
एक बहुत ही सकारात्मक रूप में देखा जाता था.

63
00:04:05,650 --> 00:04:06,936
और यह वहाँ बहुत आनंददायक था,

64
00:04:06,936 --> 00:04:09,792
ख़ासकर डेविड रूमेलहार्ट के साथ 
मिलकर काम करना शानदार था.

65
00:04:09,792 --> 00:04:12,968
> > अच्छा, बढ़िया.
तो यह था जब आप UCSD में थे, और

66
00:04:12,968 --> 00:04:16,177
आप और रूमेलहार्ट, लगभग कब, 1982,

67
00:04:16,177 --> 00:04:20,182
ने ख़त्म किया लिखना सेमिनल बैकप्रॉप पेपर, सही है?

68
00:04:20,182 --> 00:04:23,292
> > वास्तव में, यह उससे अधिक पेचीदा है.

69
00:04:23,292 --> 00:04:24,796
> > क्या हुआ?

70
00:04:24,796 --> 00:04:28,214
> > मुझे लगता है, 1982 के शुरू में,

71
00:04:28,214 --> 00:04:32,900
डेविड रूमेलहार्ट और मैंने और रॉन विलियम्स ने,

72
00:04:32,900 --> 00:04:37,967
एक साथ बनाया बैकप्रॉप एलगोरिद्म,

73
00:04:37,967 --> 00:04:42,291
यह मुख्य रूप से डेविड रूमेलहार्ट का आइडिया था.

74
00:04:42,291 --> 00:04:46,390
हमें बाद में पता चला कि कई अन्य लोगों ने इसको बनाया था.

75
00:04:46,390 --> 00:04:52,798
डेविड पार्कर ने बनाया था, इसे शायद हमारे बाद, 
लेकिन हमारे प्रकाशित करने से पहले.

76
00:04:52,798 --> 00:04:56,425
पॉल वेरबोस ने प्रकाशित किया था पहले, 
काफ़ी साल पहले, लेकिन

77
00:04:56,425 --> 00:04:58,860
किसी ने उस पर ज़्यादा ध्यान नहीं दिया.

78
00:04:58,860 --> 00:05:01,923
और कई अन्य लोग थे जिन्होंने विकसित किए थे 
बहुत समान एलगोरिद्म्स,

79
00:05:01,923 --> 00:05:04,340
यह स्पष्ट नहीं है कि बैकप्रॉप से क्या तात्पर्य है.

80
00:05:04,340 --> 00:05:08,055
लेकिन इस्तेमाल करना चेन रूल का पाने के लिए 
डेरिवेटिव्स एक नया आइडिया नहीं था.

81
00:05:08,055 --> 00:05:12,484
>> अच्छा, आप क्यों सोचते हैं कि वह 
आपका पेपर था जिसने सहायता की

82
00:05:12,484 --> 00:05:15,940
समुदाय की बहुत अधिक जुड़ने के लिए बैकप्रॉप से?

83
00:05:15,940 --> 00:05:20,540
ऐसा लगता है कि आपके पेपर ने लाया एक 
मोड़ स्वीकृत करने में यह

84
00:05:20,540 --> 00:05:22,934
एल्गोरिद्म, जिसने भी इसे स्वीकार किया.

85
00:05:22,934 --> 00:05:26,675
>> तो हम कर पाए एक पेपर नेचर में 1986 में.

86
00:05:26,675 --> 00:05:30,580
और मैंने काफ़ी राजनीतिक काम किया पेपर 
को स्वीकृत कराने के लिए.

87
00:05:30,580 --> 00:05:34,622
मैंने जाना कि एक रैफ़्री शायद होना था स्टूअर्ट सदरलैंड,

88
00:05:34,622 --> 00:05:36,992
जो ब्रिटेन में एक प्रसिद्ध मनोवैज्ञानिक था.

89
00:05:36,992 --> 00:05:38,815
और मैं गया उससे बात करने लम्बे समय के लिए, और

90
00:05:38,815 --> 00:05:41,480
समझाया उसे सीधे कि क्या चल रहा था.

91
00:05:41,480 --> 00:05:44,140
और वह बहुत प्रभावित हुए इस तथ्य से

92
00:05:44,140 --> 00:05:48,970
कि हमने दिखाया कि बैकप्रॉप सीख सकता था 
शब्दों के निरूपण.

93
00:05:48,970 --> 00:05:52,490
और आप देख सकते थे वे निरूपण, जो हैं छोटे वेक्टर्स,

94
00:05:52,490 --> 00:05:55,950
और आप समझ सकते थे मतलब प्रत्येक फ़ीचर का.

95
00:05:55,950 --> 00:06:01,600
तो हम उसे वास्तव में ट्रेन कर सकते थे फ़ैमिली ट्री 
के शब्दों के छोटे ट्रिपल्स पर,

96
00:06:01,600 --> 00:06:06,420
जैसे मेरी की माँ मदर विक्टोरिया है.

97
00:06:06,420 --> 00:06:11,550
और आप देंगे इसे पहले दो शब्द, और 
इसे प्रिडिक्ट करना होगा आख़िरी शब्द.

98
00:06:11,550 --> 00:06:12,970
और आपके इसे ट्रेन करने के बाद,

99
00:06:12,970 --> 00:06:17,780
आप देख सकते थे सभी प्रकार के फ़ीचर 
निरूपण में अलग-अलग शब्दों के.

100
00:06:17,780 --> 00:06:19,950
जैसे व्यक्ति की राष्ट्रीयता वहाँ,

101
00:06:19,950 --> 00:06:25,180
वे किस पीढ़ी के थे, परिवार के पेड़ की कौन सी 
शाखा में वे थे, और इसी प्रकार आगे.

102
00:06:25,180 --> 00:06:27,680
यही था कि स्टुअर्ट सदरलैंड वास्तव में 
इससे इतना प्रभावित हुआ, और

103
00:06:27,680 --> 00:06:29,666
मुझे लगता है इसीलिए पेपर स्वीकार कर लिया गया.

104
00:06:29,666 --> 00:06:33,905
>> बहुत शुरुआत के शब्द एंबेड्डिंग्स, 
और आप अभी से देख पा रहे हैं सीखे हुए

105
00:06:33,905 --> 00:06:38,390
फ़ीचर्ज़ सिमैनटिक अर्थों के उभरते हुए ट्रेनिंग अल्गोरिद्म से.

106
00:06:38,390 --> 00:06:44,090
> > हां, तो एक मनोवैज्ञानिक के दृष्टिकोण से, 
क्या दिलचस्प था कि इसने एकीकृत किया

107
00:06:44,090 --> 00:06:49,740
दो एकदम भिन्न क़िस्म के विचारों को कि ज्ञान क्या है.

108
00:06:49,740 --> 00:06:53,460
तो वहां था एक पुराने मनोवैज्ञानिक का दृष्टिकोण 
कि एक धारणा है सिर्फ़ एक बड़ा

109
00:06:53,460 --> 00:06:56,810
बंडल फ़ीचर्ज़ का, और उसके लिए बहुत से सबूत हैं.

110
00:06:56,810 --> 00:07:02,180
और फिर वहाँ था AI दृष्टिकोण उस समय का, 
जो है एक नियमानुरूप दृष्टिकोण.

111
00:07:02,180 --> 00:07:06,190
जो था कि एक धारणा है कि यह कैसे अन्य 
धारणायों से सम्बंधित होता है.

112
00:07:06,190 --> 00:07:09,820
और एक धारणा को कैप्चर करने के लिए, आपको कुछ 
करना होगा जैसे एक ग्राफ़ संरचना या

113
00:07:09,820 --> 00:07:11,640
शायद एक सिमैंटिक नेट.

114
00:07:11,640 --> 00:07:15,875
और जो इस बैक प्रॉपगेशन उदाहरण 
ने दिखाया था, आप दे सकते हैं इसे

115
00:07:15,875 --> 00:07:21,070
जानकारी जो जा सकती है एक ग्राफ संरचना में, 
या इस मामले में एक परिवार के पेड़ में.

116
00:07:22,080 --> 00:07:26,920
और यह बदल सकता है उस जानकारी को
 फ़ीचर्ज़ में इस तरह से कि यह तब

117
00:07:26,920 --> 00:07:33,470
इस्तेमाल कर सकता है फ़ीचर्ज़ डिराइव करने के लिए 
नई तर्कयुक्त जानकारी, यानि कि सामान्यीकरण

118
00:07:33,470 --> 00:07:38,438
लेकिन महत्वपूर्ण बात थी कि यह आगे पीछे 
ग्राफ़ संरचना में या

119
00:07:38,438 --> 00:07:43,000
परिवार के पेड़ की ट्री संरचना के निरूपण में, और

120
00:07:43,000 --> 00:07:46,715
एक निरूपण लोगों का एक बड़े फ़ीचर वेक्टर्ज़ में.

121
00:07:46,715 --> 00:07:50,873
और वास्तव में उस ग्राफ़ की तरह की संरचना से 
आप पा सकते थे फ़ीचर्ज़

122
00:07:50,873 --> 00:07:51,469
वेक्टर्स में,

123
00:07:51,469 --> 00:07:54,995
और फ़ीचर वेक्टर्ज़ से, आप पा सकते थे 
और ज्यादा ग्राफ़ की तरह की संरचना.

124
00:07:54,995 --> 00:07:57,730
>> तो यह है 1986?

125
00:07:57,730 --> 00:08:02,430
90 के दशक के शुरू में, बेंजीयो ने दिखाया
 कि आप वास्तव में वास्तविक डेटा ले सकते हैं,

126
00:08:02,430 --> 00:08:07,420
आप ले सकते हैं अंग्रेज़ी टेक्स्ट, 
और अप्लाई कर सकते हैं समान तकनीक वहाँ, और

127
00:08:07,420 --> 00:08:13,980
पा सकते हैं एंबेड्डिंग्स असली शब्दों के लिए अंग्रेज़ी टेक्स्ट से, 
और उससे बहुत लोग प्रभावित हुए.

128
00:08:13,980 --> 00:08:18,682
>> मुझे लगता है हाल ही में हम काफ़ी बात कर रहे हैं कैसे
 द्रुतगामी कम्प्यूटर्स जैसे GPU और

129
00:08:18,682 --> 00:08:21,750
सुपरकम्प्यूटर जो चलायमान कर रहे हैं डीप लर्निंग.

130
00:08:21,750 --> 00:08:26,376
मैंने नहीं सोचा था कि पीछे 1986 और 90 के दशक के 
शुरू में, ऐसा लगता है जैसे बीच में

131
00:08:26,376 --> 00:08:29,570
आपके और बेंजीयो के यह पहले ही शुरुआत थी 
इस प्रवृति की.

132
00:08:30,600 --> 00:08:32,630
> > हां, यह एक बहुत बड़ा बढ़ाव था.

133
00:08:32,630 --> 00:08:41,440
1986 में, मैं इस्तेमाल कर रहा था एक लिस्ट मशीन 
जो कम थी एक दसवें भाग से एक मेगा फ़्लॉप के.

134
00:08:41,440 --> 00:08:47,720
और लगभग 1993 या क़रीब तब तक, 
लोगों को मिल रहे थे दस मेगा फ़्लॉप्स.

135
00:08:47,720 --> 00:08:49,600
>> अच्छा. >> तो वह था एक फ़ैक्टर 100 का,

136
00:08:49,600 --> 00:08:51,770
वह था समय जहाँ प्रयोग में आसान था,

137
00:08:51,770 --> 00:08:53,580
क्योंकि कम्प्यूटर्स अधिक द्रुतगामी हो रहे थे.

138
00:08:53,580 --> 00:08:56,960
>> पिछले कई दशकों में, आपने आविष्कार किया है इतने

139
00:08:56,960 --> 00:08:59,970
सारे न्यूरल नेटवर्क्स और डीप लर्निंग के हिस्सों का.

140
00:08:59,970 --> 00:09:02,670
मैं वास्तव में उत्सुक हूँ, सभी चीज़ों के 
बारे में जिनका अपने अविष्कार किया है,

141
00:09:02,670 --> 00:09:05,050
आप उनमें से किस बारे में सबसे अधिक उत्साहित हैं
 आज?

142
00:09:06,940 --> 00:09:09,590
>> तो मैं सोचता हूँ कि सबसे बढ़िया है काम जो 
मैं करता हूँ

143
00:09:09,590 --> 00:09:12,620
टेरी सेजनोवसकी के साथ बोल्टज़मैन मशीन्स पर.

144
00:09:12,620 --> 00:09:14,500
तो हमने जाना कि वहाँ था यह बहुत ही

145
00:09:14,500 --> 00:09:18,830
सरल लर्निंग अल्गोरिद्म जो 
अप्लाई करने पर बहुत ही

146
00:09:18,830 --> 00:09:23,550
घने रूप से जुड़े नेट्स पर जहाँ आप देख सकते हैं 
कुछ नोड्ज़.

147
00:09:23,550 --> 00:09:27,730
तो यह सीखेगा हिडन रेप्रेज़ेंटेशन्स और यह था
 एक बहुत ही सरल अल्गोरिद्म.

148
00:09:27,730 --> 00:09:31,130
और यह लगता था उस तरह का काम जो 
आप कर सकते हैं मस्तिष्क में क्योंकि

149
00:09:31,130 --> 00:09:34,210
प्रत्येक सिनैप्स को जानने की ज़रूरत है आचरण की दो

150
00:09:34,210 --> 00:09:35,940
न्यूरॉन्स के जिनसे वह सीधे जुड़ा है.

151
00:09:37,010 --> 00:09:41,230
और जो जानकारी प्रचारित की गई थी वह समान थी.

152
00:09:41,230 --> 00:09:45,160
वहाँ दो अलग चरण थे, जिन्हें हमने कहा वेक और स्लीप.

153
00:09:45,160 --> 00:09:46,820
लेकिन दो भिन्न चरणों में,

154
00:09:46,820 --> 00:09:48,760
आप प्रचारित कर रहे थे जानकारी समान ढंग से.

155
00:09:48,760 --> 00:09:52,360
जबकि कुछ बैक प्रॉपगेशन जैसे में, 
वहाँ है एक फ़ॉर्वर्ड पास और

156
00:09:52,360 --> 00:09:54,820
एक बैक्वर्ड पास, और वे काम करते हैं भिन्न ढंग से.

157
00:09:54,820 --> 00:09:56,379
वे भेज रहे हैं भिन्न प्रकार के सिग्नलज़.

158
00:09:58,100 --> 00:10:01,190
तो मैं सोचता हूँ वह है सबसे बढ़िया चीज़.

159
00:10:01,190 --> 00:10:03,730
और बहुत सालों तक, वह लगता था एक कुतूहल जैसे,

160
00:10:03,730 --> 00:10:05,090
क्योंकि ऐसा लगता था जैसे यह बहुत धीमी थी.

161
00:10:06,210 --> 00:10:10,420
लेकिन बाद में, मैंने छोड़ा थोड़ा बहुत सुंदरता को, 
और इसने शुरू किया

162
00:10:10,420 --> 00:10:13,730
मुझे सेटल करना और इस्तेमाल किया केवल एक 
इटरेशन, एक कुछ सरलतर नेट में.

163
00:10:13,730 --> 00:10:16,570
और उससे मिली प्रतिबंधित बोल्ट्ज़मैन मशीन्स,

164
00:10:16,570 --> 00:10:19,430
जिन्होंने वास्तव में व्यवहार में प्रभावी ढंग से काम किया.

165
00:10:19,430 --> 00:10:21,586
तो नेटफ़्लिक्स प्रतियोगिता में, उदाहरण के लिए,

166
00:10:21,586 --> 00:10:26,170
प्रतिबंधित बोल्ट्जमैन मशीने थी एक घटक विजेता प्रविष्टि में.

167
00:10:26,170 --> 00:10:30,210
>> और वास्तव में, हाल के पुनरुत्थान में न्यूरल नेटवर्क के और

168
00:10:30,210 --> 00:10:34,790
डीप लर्निंग के, 2007 में शुरू होते हुए, 
थी प्रतिबंधित / सीमित बोल्ट्ज़मैन मशीन,

169
00:10:34,790 --> 00:10:37,710
और अप्रतिबंधित बोल्ट्जमैन मशीन का काम जो 
आप और आपकी प्रयोगशाला ने किया.

170
00:10:38,940 --> 00:10:42,130
>> वह एक और काम है जिससे मैं बहुत ख़ुश हूँ,

171
00:10:42,130 --> 00:10:46,290
विचार कि आप ट्रेन कर सकते हैं आपकी प्रतिबंधित 
बोल्ट्ज़मैन मशीन, जिसमें सिर्फ़ थी

172
00:10:46,290 --> 00:10:51,120
एक लेयर हिडन फ़ीचर्ज़ की और 
आप सीख सकते थे एक लेयर फ़ीचर्ज़ की.

173
00:10:51,120 --> 00:10:54,850
और फिर आप उन फ़ीचर्ज़ को ले सकते थे डेटा की तरह 
और कर सकते थे इसे दोबारा, और

174
00:10:54,850 --> 00:10:57,953
फिर आप उन फ़ीचर्ज़ को ले सकते थे डेटा की तरह 
और कर सकते थे इसे दोबारा,

175
00:10:57,953 --> 00:10:59,570
उतनी बार जितनी बार आप चाहते थे.

176
00:10:59,570 --> 00:11:03,060
तो वह अच्छा था, उसने व्यवहार में काम किया.

177
00:11:03,060 --> 00:11:08,709
और फिर UY टे को एहसास हुआ कि पूरी चीज़ को 
एक मॉडल के रूप में लिया जा सकता है,

178
00:11:08,709 --> 00:11:11,110
लेकिन यह मॉडल एक अजीब तरह का था.

179
00:11:11,110 --> 00:11:15,946
यह एक मॉडल था जहां शीर्ष पर आपके पास 
एक प्रतिबंधित बोल्ट्जमैन मशीन थी, लेकिन

180
00:11:15,946 --> 00:11:20,626
उसके नीचे आपके पास था एक सिग्मोईड बिलीफ़ नेट 
जो था कुछ जिसका

181
00:11:20,626 --> 00:11:23,060
कई साल पहले आविष्कार हुआ था.

182
00:11:23,060 --> 00:11:24,620
तो यह एक डायरेक्टेड मॉडल था और

183
00:11:24,620 --> 00:11:28,651
जो हम बना पाए थे ट्रेन करके इन प्रतिबंधित बोल्ट्ज़मैन

184
00:11:28,651 --> 00:11:32,760
मशीन्स को था एक कार्यक्षम ढंग इन्फ़र करने का 
सिग्मोईड बिलीफ़ नेट्स में.

185
00:11:33,830 --> 00:11:36,870
तो, उस समय के आसपास,

186
00:11:36,870 --> 00:11:41,270
वहाँ लोग थे काम करते हुए न्यूरल नेट्स पर, 
जो इस्तेमाल कर रहे थे घने रूप से जुड़े नेट्स को लेकिन

187
00:11:41,270 --> 00:11:45,500
उनके पास नहीं था कोई अच्छा ढंग करने का 
प्रोबबिलिसिटिक इमप्रिंट्स का.

188
00:11:45,500 --> 00:11:50,050
और लोग थे जो काम कर रहे थे ग्राफ़ मॉडल्स पर, 
मेरे बच्चों के विपरीत,

189
00:11:50,050 --> 00:11:55,603
जो इन्फ़र कर पा रहे थे सही ढंग से, 
लेकिन केवल विरले रुप से जुड़े नेट्स में.

190
00:11:55,603 --> 00:12:01,140
और हम जो दिखा पाए था तरीक़ा लर्न करने का इन डीप

191
00:12:01,140 --> 00:12:06,280
बिलीफ़ नेट्स को ताकि वहाँ है एक अनुमानित फ़ॉर्म 
इन्फ़्रेन्स की जो बहुत द्रुत है,

192
00:12:06,280 --> 00:12:10,578
और यह देता है सिर्फ़ एक फ़ॉर्वर्ड पास 
और वह था एक बहुत ही सुंदर परिणाम.

193
00:12:10,578 --> 00:12:14,890
और आप गारंटी दे सकते थे कि हर बार जब आप लर्न करते है
 वह अतिरिक्त लेयर फ़ीचर्ज़ की

194
00:12:16,010 --> 00:12:19,980
वहां एक बैंड था, हर बार जब आप एक नई लेयर सीखते हैं, 
आपको मिलता है एक नया बैंड, और

195
00:12:19,980 --> 00:12:22,700
नए बैंड हमेशा पुराने बैंड की तुलना में बेहतर था.

196
00:12:22,700 --> 00:12:25,810
>> भिन्नता बैंड्ज़, दिखाते हुए जैसे आप जोड़ते हैं लेयर्स.

197
00:12:25,810 --> 00:12:26,970
हां, मुझे वह वीडियो याद है.

198
00:12:26,970 --> 00:12:29,680
>> तो वह थी दूसरी चीज़ जिसके बारे में मैं वास्तव में उत्साहित था.

199
00:12:29,680 --> 00:12:35,600
और मुझे लगता है तीसरी चीज़ थी काम जो 
मैंने किया वेरीएशनल विधियों पर.

200
00:12:35,600 --> 00:12:40,750
और ऐसा हुआ कि सांख्यिकीय लोगों ने किया था
 उसी तरह का काम पहले.

201
00:12:40,750 --> 00:12:43,100
लेकिन हमें उसके बारे में पता नहीं था.

202
00:12:44,610 --> 00:12:47,260
तो हम कामयाब रहे बनाने में

203
00:12:47,260 --> 00:12:50,250
EM को बेहतर काम बहुत बेहतर दिखा कर कि 
आपको नहीं करने की आवश्यकता 
एक सटीक E स्टेप.

204
00:12:50,250 --> 00:12:52,800
आप कर सकते हैं एक अनुमानित E स्टेप.

205
00:12:52,800 --> 00:12:55,320
और EM था एक बड़ा अल्गोरिद्म सांख्यिकीय में.

206
00:12:55,320 --> 00:12:58,380
और हमने इसका एक बड़ा सामान्यीकरण दिखाया था.

207
00:12:58,380 --> 00:13:02,490
और विशेष रूप से, 1993 में, शायद वैन कैम्प के साथ.

208
00:13:02,490 --> 00:13:07,040
मैंने लिखा एक पेपर, जो मैं सोचता हूँ, 
था पहला वेरीएशनल बेस पेपर,

209
00:13:07,040 --> 00:13:12,090
जहाँ हमने दिखाया कि आप वास्तव में कर सकते हैं 
बेज़ीयन लर्निंग का एक वर्ज़न

210
00:13:12,090 --> 00:13:17,950
जो था कहीं अधिक सुविधाजनक, 
अनुमानित करके ट्रू पोस्टीरीयर एक गॉशियन से.

211
00:13:17,950 --> 00:13:20,320
और आप कर सकते थे वह एक न्यूरल नेट में.

212
00:13:20,320 --> 00:13:22,600
और मैं उस से बहुत उत्साहित था.

213
00:13:22,600 --> 00:13:23,680
>> ठीक है. वह. सही है.

214
00:13:23,680 --> 00:13:26,670
हाँ, मुझे लगता है मुझे याद हैं वे सब पेपर्स.

215
00:13:26,670 --> 00:13:32,630
नील और हिंटॉन, अप्रोक्सिमेट EM पेपर, 
काफ़ी घंटे व्यतीत किए उसे पढ़ने में.

216
00:13:32,630 --> 00:13:36,070
और मैं सोचता हूँ कुछ उनमें से अल्गोरिद्म्स जो 
इस्तेमाल करते हैं आजकल, या

217
00:13:36,070 --> 00:13:41,110
कुछ उनमें से अल्गोरिद्म्स जो इस्तेमाल करते हैं 
बहुत से लोग लगभग प्रतिदिन, हैं वे

218
00:13:41,110 --> 00:13:46,570
चीज़ें जैसे ड्रॉपआउट्स, मुझे लगता है
 ReLU ऐक्टिवेशनस भी आपके ग्रूप से आए?

219
00:13:46,570 --> 00:13:47,390
>> हां और नहीं.

220
00:13:47,390 --> 00:13:51,470
तो अन्य लोगों ने सोचा है 
रेक्टिफ़ायड लिनीयर यूनिट्स के बारे में.

221
00:13:51,470 --> 00:13:56,860
और हमने वास्तव में किया प्रतिबंधित बोल्ट्ज़मैन 
मशीन्स के साथ, दिखाते हुए

222
00:13:56,860 --> 00:14:02,880
कि एक ReLU था लगभग बिल्कुल समान एक 
लॉजिकल यूनिट्स के एक पूरे स्टैक के जैसे.

223
00:14:02,880 --> 00:14:05,190
और वह थी एक चीज़ जिसने मदद की 
ReLU को ऊपर आने में.

224
00:14:05,190 --> 00:14:07,440
>> मैं उस बारे में बहुत उत्सुक था.

225
00:14:07,440 --> 00:14:12,570
ReLU पेपर में था बहुत सा गणित दिखाते हुए 
कि यह फ़ंक्शन

226
00:14:12,570 --> 00:14:15,530
किया जा सकता है अनुमानित इस 
बहुत जटिल फ़ॉर्म्युला से.

227
00:14:15,530 --> 00:14:19,140
क्या अपने किया वह गणित 
ताकि आपका पेपर स्वीकृत हो 
एक ऐकडेमिक कॉन्फ़्रेन्स में,

228
00:14:19,140 --> 00:14:24,840
यह उस सब गणित ने वास्तव में प्रभावित किया 
विकास मैक्स 0 और x का?

229
00:14:26,450 --> 00:14:30,440
>> वह था एक केस जहाँ वास्तव में गणित था 
महत्वपूर्ण

230
00:14:30,440 --> 00:14:32,350
आइडिया के विकास के लिए.

231
00:14:32,350 --> 00:14:35,262
तो मैं जानता था 
रेक्टिफ़ायड लिनीयर यूनिट्स के बारे में, 
ज़ाहिर है, और

232
00:14:35,262 --> 00:14:36,821
मैं जानता था लॉजिस्टिक यूनिट्स के बारे में.

233
00:14:36,821 --> 00:14:39,250
बोल्टज़मैन मशीन्स पर काम की वजह से,

234
00:14:39,250 --> 00:14:42,720
सारा मूल काम हुआ था लॉजिस्टिक यूनिट्स से.

235
00:14:42,720 --> 00:14:45,120
और इसलिए सवाल था,

236
00:14:45,120 --> 00:14:49,070
क्या लर्निंग अल्गोरिद्म काम कर सकता है
 किसी में रेक्टिफ़ायड लिनीयर यूनिट्स के साथ?

237
00:14:49,070 --> 00:14:54,400
और दिखाने से कि रेक्टिफ़ायड लिनीयर यूनिट्स हैं 
लगभग बिल्कुल समान एक स्टैक के

238
00:14:54,400 --> 00:15:00,350
लॉजिस्टिक यूनिट्स के, हमने दिखाया कि पूरा गणित लगेगा.

239
00:15:00,350 --> 00:15:01,508
>> ठीक है.

240
00:15:01,508 --> 00:15:05,890
और इसने प्रेरणा दी आज के लिए, सैकड़ों लोग 
इस्तेमाल करते हैं ReLU और

241
00:15:05,890 --> 00:15:08,000
और यह काम करता है बिना >> हाँ.

242
00:15:08,000 --> 00:15:12,130
बिना अनिवार्य रूप से समझे वही प्रेरणा.

243
00:15:13,150 --> 00:15:16,850
>> हाँ, एक बात मैंने बाद में नोटिस की
 जब मैं गया गूगल पर.

244
00:15:16,850 --> 00:15:22,796
शायद 2014 में, मैंने दिया एक व्याख्यान गूगल में 
ReLU इस्तेमाल करने पर और

245
00:15:22,796 --> 00:15:26,660
आयडेंटिटी मेट्रिक्स को इनिशियलाइज करने पर.

246
00:15:26,660 --> 00:15:30,300
क्योंकि ReLUs के बारे में अच्छी बात यह है कि 
अगर आप दोहराते रहते हैं हिडन

247
00:15:30,300 --> 00:15:32,667
लेयर्स को और आप इनिशीयलाइज करते हैं 
आयडेंटिटी से,

248
00:15:32,667 --> 00:15:35,050
यह सिर्फ़ कॉपी करता है पैटर्न नीचे की लेयर का.

249
00:15:36,140 --> 00:15:40,120
और इसलिए मैं दिखा रहा था कि
 आप ट्रेन कर सकते हैं 
नेटवर्क्स को 300 हिडन लेयर्स से और

250
00:15:40,120 --> 00:15:44,760
आप उन्हें ट्रेन कर सकते हैं वास्तव में कुशलता से यदि
 आप इनिशियलाइज करते हैं उनकी आयडेंटिटी से.

251
00:15:44,760 --> 00:15:48,065
लेकिन मैंने उस पर और काम नहीं किया और 
मुझे वास्तव में खेद है उसमें न लगे रहने का.

252
00:15:48,065 --> 00:15:52,507
हमने प्रकाशित किया एक पेपर क्वोक ली के साथ 
दिखाते हुए कि आप इनिशियलाइज कर सकते हैं

253
00:15:52,507 --> 00:15:55,565
दिखाते हुए कि आप इनिशियलाइज कर सकते हैं 
 रेकरिंगनेस उस तरह से.

254
00:15:55,565 --> 00:16:00,370
लेकिन मुझे काम करना चाहिए था उस पर 
आगे क्योंकि बाद में ये रेसिडुयल

255
00:16:00,370 --> 00:16:03,572
नेटवर्क्स हैं वास्तव में उस तरह की चीज़.

256
00:16:03,572 --> 00:16:06,660
>> पिछले कुछ वर्षों में मैंने सुना है आप मस्तिष्क के 
बारे में बहुत बात करते हैं.

257
00:16:06,660 --> 00:16:09,447
मैंने सुना है आपको बात करते हुए 
बैकप्रॉप और मस्तिष्क के सम्बंध की.

258
00:16:09,447 --> 00:16:13,720
उस पर अपने वर्तमान विचार क्या हैं?

259
00:16:13,720 --> 00:16:16,910
>> मैं वास्तव में अभी उस पर 
एक पेपर पर काम कर रहा हूं.

260
00:16:18,250 --> 00:16:21,160
मुझे लगता है, मेरा मुख्य विचार है यह.

261
00:16:21,160 --> 00:16:25,570
यदि ऐसा हुआ कि बैकप्रॉप है वास्तव में बढ़िया 
अल्गोरिद्म लर्निंग करने के लिए.

262
00:16:26,620 --> 00:16:31,610
तब यक़ीनन क्रम-विकास समझ सकता है
 कैसे उसे इम्प्लमेंट करना है.

263
00:16:32,730 --> 00:16:37,270
मेरा मतलब है आपके पास कोशिकाएँ हैं 
जो बदल सकती हैं आँखों या दाँतों में.

264
00:16:37,270 --> 00:16:42,440
अब, अगर कोशिकाएँ वह कर सकती हैं, 
वे यकीनन इम्प्लमेंट कर सकते है बैक प्रॉपगेशन और

265
00:16:42,440 --> 00:16:45,860
शायद इसके लिए इस विशाल चयनात्मक दबाव में.

266
00:16:45,860 --> 00:16:50,490
तो मुझे लगता है कि न्यूरो साययंटिस्ट का विचार 
कि यह मुमकिन नहीं लग रहा है सिर्फ़ मूर्खतापूर्ण है.

267
00:16:50,490 --> 00:16:52,890
इसका कुछ सूक्ष्म कार्यान्वयन / इम्प्लमेंटेशन हो सकता है.

268
00:16:52,890 --> 00:16:56,000
और मुझे लगता है कि मस्तिष्क में शायद कुछ है 
जो वास्तव में हो सकता है सटीक न हो

269
00:16:56,000 --> 00:16:58,620
बैक प्रॉपगेशन के, लेकिन यह काफ़ी कुछ इसके जैसा है.

270
00:16:58,620 --> 00:17:02,566
और पिछले कुछ वर्षों में, मैंने कई विचार बनाएँ हैं 
कि यह कैसे काम कर सकता है.

271
00:17:02,566 --> 00:17:06,994
तो 1987 में, जे मैक क्लिलैंड के साथ काम करते हुए,

272
00:17:06,994 --> 00:17:11,202
मैंने बनाया रीसर्क्यलेशन अल्गोरिद्म,

273
00:17:11,202 --> 00:17:16,090
जहां विचार है आप जानकारी भेजें एक लूप में.

274
00:17:17,470 --> 00:17:18,686
और आप इसे बनाने की कोशिश करें ताकि

275
00:17:18,686 --> 00:17:22,206
चीज़ें न बदलें जैसे जानकारी जाती है इस लूप में.

276
00:17:22,206 --> 00:17:26,490
तो सरलतम वर्ज़न होगा कि आपके पास हैं 
इनपुट यूनिट्स और हिडन यूनिट्स, और

277
00:17:26,490 --> 00:17:31,046
भेजते हैं जानकारी इनपुट से हिडन और 
फिर वापिस इनपुट को, और

278
00:17:31,046 --> 00:17:34,388
फिर वापिस हिडन को और 
फिर वापिस इनपुट को और इसी प्रकार आगे.

279
00:17:34,388 --> 00:17:38,001
और क्या आप चाहते हैं, आप ट्रेन चाहते हैं 
एक ऑटोएनकोडर,

280
00:17:38,001 --> 00:17:42,300
लेकिन आप इसे ट्रेन करना चाहते हैं बिना किए 
बैकप्रॉपगेशन.

281
00:17:42,300 --> 00:17:47,250
तो आप सिर्फ़ इसे ट्रेन करते हैं छुटकारा पाने की कोशिश में 
सभी भिन्नताओं से गतिविधियों में.

282
00:17:47,250 --> 00:17:51,922
तो विचार है कि लर्निंग रूल

283
00:17:51,922 --> 00:17:57,930
सिनैप्स का है कि बदलें वेट प्रपॉर्शन 
प्रीसिनैप्टिक इनपुट पर और

284
00:17:57,930 --> 00:18:01,780
पोस्ट सिनैप्टिक इनपुट पर बदलाव की दर के अनुपात में

285
00:18:01,780 --> 00:18:04,060
लेकिन रीसर्क्यलेशन में, आप बनाने की कोशिश कर रहे हैं 
पोस्ट सिनैप्टिक इनपुट,

286
00:18:04,060 --> 00:18:08,330
आप बनाना चाह रहे हैं पुराने को अच्छा 
और नए को ख़राब, तो

287
00:18:08,330 --> 00:18:09,620
आप बदल रहे हैं उस दिशा में.

288
00:18:11,010 --> 00:18:14,472
हमने बनाया यह अल्गोरिद्म न्यूरोसाययंटिस्ट्स के बनाने से पहले

289
00:18:14,472 --> 00:18:16,521
स्पाइक-टाइमिंग-डिपेंडेंट प्लैस्टिसिटी.

290
00:18:16,521 --> 00:18:20,700
स्पाइक-टाइमिंग-डिपेंडेंट प्लैस्टिसिटी है 
वास्तव में वही अल्गोरिद्म लेकिन

291
00:18:20,700 --> 00:18:26,220
विपरीत दिशा में, जहाँ नई चीज़ है अच्छी और 
पुरानी चीज़ है ख़राब लर्निंग रूल में.

292
00:18:26,220 --> 00:18:30,010
तो आप बदल रहे हैं वेट प्रपॉर्शन प्रीसिनैप्टिक ऐक्टिविटी

293
00:18:30,010 --> 00:18:35,690
गुणा नई प्रीसिनैप्टिक ऐक्टिविटी घटा पुरानी पर.

294
00:18:37,060 --> 00:18:42,020
बाद में 2007 में मुझे एहसास हुआ, कि अगर अपने लिया एक स्टैक

295
00:18:42,020 --> 00:18:47,830
प्रतिबंधित बोल्ट्जमैन मशीनों का और आपने उसे ट्रेन किया.

296
00:18:47,830 --> 00:18:52,620
उसे ट्रेन करने के बाद आपके पास थी बिलकुल सही परिस्थितियाँ

297
00:18:52,620 --> 00:18:56,450
इम्प्लमेंट करने के लिए बैकप्रॉपगेशन सिर्फ़ रीकन्स्ट्रक्ट करके.

298
00:18:56,450 --> 00:19:01,124
यदि आप देखते रीकन्स्ट्रक्शन समय, वह रीकन्स्ट्रक्शन समय

299
00:19:01,124 --> 00:19:05,728
वास्तव में आपको बताएगा डेरिवेटिव डिस्क्रमिनेटिव पर्फ़ॉर्मन्स का.

300
00:19:05,728 --> 00:19:12,079
और पहली डीप लर्निंग वर्क्शाप में NIPS में 
2007 में, मैंने दिया एक व्याख्यान उस बारे में.

301
00:19:12,079 --> 00:19:16,454
जिसे लगभग पूरी तरह नजरअंदाज कर दिया गया.

302
00:19:16,454 --> 00:19:19,799
बाद में, जोशुया बेंजीयो, ने लिया वह विचार और

303
00:19:19,799 --> 00:19:24,340
उसने काम किया उस पर वास्तव में और अधिक.

304
00:19:24,340 --> 00:19:26,490
और मैं ख़ुद भी उस पर और काम कर रहा हूँ.

305
00:19:26,490 --> 00:19:33,280
और मैं सोचता हूँ यह विचार कि यदि आपके पास है 
एक स्टैक ऑटोएनकोडर्स का, तब आप

306
00:19:33,280 --> 00:19:38,440
पा सकते हैं डेरिवेटिव्स भेज कर ऐक्टिविटी बैकवर्ड्स 
और पा सकते हैं रीकन्स्ट्रक्शन एरर,

307
00:19:38,440 --> 00:19:42,520
है एक वास्तव में दिलचस्प विचार और शायद 
हो सकता है जैसे मस्तिष्क इसे करता है.

308
00:19:42,520 --> 00:19:47,520
एक अन्य विषय जो मैं जानता हूँ आपने पूरा सोचा है 
और मैंने सुना है आप अभी भी

309
00:19:47,520 --> 00:19:51,930
उस पर काम कर रहे हैं कि कैसे बर्ताव करना है 
मल्टिपल टाइम स्केल्ज़ से डीप लर्निंग में.

310
00:19:51,930 --> 00:19:54,468
तो, क्या आप उस पर अपने विचार 
साँझा करना चाहेंगे?

311
00:19:54,468 --> 00:19:58,910
>> हां, तो वास्तव में, वह मेरे 
पहले साल की बात है ग्रैजूएशन में.

312
00:19:58,910 --> 00:20:04,040
पहला व्याख्यान जो मैंने कभी दिया था वह था 
जिसे मैं कहता हूँ इस्तेमाल करना फ़ास्ट वेट्स 
के बारे में.

313
00:20:04,040 --> 00:20:07,560
तो वेट्स जो अनुरूप बनते हैं तेज़ी से 
लेकिन क्षय होते हैं तेज़ी से.

314
00:20:07,560 --> 00:20:08,832
और इसलिए रख सकते हैं शॉर्ट टर्म मेमरी.

315
00:20:08,832 --> 00:20:13,496
और मैंने दिखाया एक बहुत सरल सिस्टम में 
1973 में कि आप कर सकते हैं

316
00:20:13,496 --> 00:20:16,590
असल रिकर्शन उन वेट्स से.

317
00:20:16,590 --> 00:20:23,010
और असल रिकर्शन से मेरा क्या मतलब है कि 
न्यूरॉन्स जो इस्तेमाल होते हैं

318
00:20:23,010 --> 00:20:28,470
चीज़ों के निरूपण में, दोबारा इस्तेमाल होते हैं 
निरूपण में चीज़ों के रिकर्सिव कोर में.

319
00:20:30,210 --> 00:20:31,750
और वेट्स जो इस्तेमाल होते है

320
00:20:31,750 --> 00:20:34,388
नॉलेज निरूपण में दोबारा इस्तेमाल होते हैं रिकर्सिव कोर में.

321
00:20:34,388 --> 00:20:39,170
और इसलिए वह उठाता है सवाल कि कब आप 
पॉप आउट करते हैं आपका रिकर्सिव कोर,

322
00:20:39,170 --> 00:20:41,600
कैसे आप याद रखते हैं क्या था जब चीज़ों के 
बीच में थे?

323
00:20:41,600 --> 00:20:42,970
कहाँ है वह मेमरी?

324
00:20:42,970 --> 00:20:45,015
क्योंकि आपने इस्तेमाल किए न्यूरॉन्स 
रिकर्सिव कोर के लिए.

325
00:20:46,080 --> 00:20:49,240
और जवाब है कि आप रख सकते हैं 
वह मेमरी फ़ास्ट वेट्स में, और

326
00:20:49,240 --> 00:20:53,940
और आप दोबारा पा सकते हैं 
एक्टिव स्टेट न्यूरॉन्स की उन फ़ास्ट वेट्स से.

327
00:20:53,940 --> 00:20:56,151
और अभी हाल ही में जिमी बा के साथ 
काम करते हुए,

328
00:20:56,151 --> 00:21:00,141
हमने वास्तव में बनाया एक पेपर उस पर इस्तेमाल 
करते हुए फ़ास्ट वेट्स उस तरह के रिकर्शन के लिए.

329
00:21:00,141 --> 00:21:00,898
>> ठीक है.

330
00:21:00,898 --> 00:21:04,145
> > तो वह था काफी बड़ा गैप.

331
00:21:04,145 --> 00:21:08,746
पहला मॉडल 1973 में प्रकाशित किया गया था और

332
00:21:08,746 --> 00:21:14,966
फिर जिमी बा का मॉडल था 2015 में, मुझे लगता है 
या 2016 में.

333
00:21:14,966 --> 00:21:16,469
तो यह लगभग 40 साल बाद है.

334
00:21:16,469 --> 00:21:22,840
>> और, मुझे लगता है, एक और आइडिया जो 
मैं सोचता हूँ, कुछ साल पहले,

335
00:21:22,840 --> 00:21:29,350
पांच साल से अधिक, मुझे लगता है कि कैप्सूल है, 
आप क्या सोचते हैं उसके बारे में?

336
00:21:29,350 --> 00:21:34,150
ठीक है, तो मैं वापिस हूँ उस स्थिति में जिसमें 
मुझे आदत है होने की.

337
00:21:34,150 --> 00:21:39,320
जो है कि मेरे पास है यह आइडिया जिसमें मुझे सच में 
विश्वास है और किसी और को उसमें विश्वास नहीं है.

338
00:21:39,320 --> 00:21:42,120
और मैं प्रस्तुत करता हूँ पेपर उस बारे में और 
उन्हें ख़ारिज कर दिया जाता है.

339
00:21:42,120 --> 00:21:45,938
लेकिन मुझे सच में इस विचार में विश्वास है 
और मैं उस पर ज़ोर देता रहूँगा.

340
00:21:45,938 --> 00:21:53,880
तो यह टिका है, वहाँ कुछ प्रमुख विचार है.

341
00:21:53,880 --> 00:22:00,000
एक है कि कैसे आप दर्शाते हैं मल्टी-डिमेन्शनल 
एंटिटीज़, और आप

342
00:22:00,000 --> 00:22:05,070
दर्शा सकते हैं मल्टी डिमेन्शनल एंटिटीज़ सिर्फ़ 
थोड़ी बैक डोर ऐक्टिविटीज़ से.

343
00:22:05,070 --> 00:22:07,630
जब तक आप जानते हैं वहां उनमें से कोई एक है.

344
00:22:07,630 --> 00:22:12,150
तो आइडिया है कि इमिज के प्रत्येक क्षेत्र में, 
आप मान लेंगे कि वहाँ ज़्यादा से ज़्यादा,

345
00:22:12,150 --> 00:22:14,000
एक तरह का एक ही फ़ीचर है.

346
00:22:15,200 --> 00:22:18,020
और फिर आप इस्तेमाल करेंगे कुछ न्यूरॉन्स समूह, और

347
00:22:18,020 --> 00:22:23,190
उनकी ऐक्टिविटीज़ दर्शाएगीं विभिन्न पहलू 
उस फ़ीचर के,

348
00:22:24,230 --> 00:22:27,270
जैसे कि उस क्षेत्र में क्या हैं वास्तव में 
उसके x और y कोऑर्डिनट्स.

349
00:22:27,270 --> 00:22:28,780
कौन सी ऑरीएंटेशन पर है वह?

350
00:22:28,780 --> 00:22:29,930
कितनी गति से यह चल रहा है?

351
00:22:29,930 --> 00:22:30,630
इसका क्या रंग है?

352
00:22:30,630 --> 00:22:31,270
कितना स्पष्ट है यह?

353
00:22:31,270 --> 00:22:32,590
और उस तरह की चीज़ें.

354
00:22:32,590 --> 00:22:36,350
तो आप इस्तेमाल कर सकते हैं कुछ न्यूरॉन्स 
दर्शाने के लिए विभिन्न आयाम

355
00:22:36,350 --> 00:22:37,710
उसी चीज़ के.

356
00:22:37,710 --> 00:22:39,410
बशर्ते उनमें से केवल एक ही हो.

357
00:22:40,490 --> 00:22:46,110
वह है एक बहुत विभिन्न तरीक़ा दर्शाने का

358
00:22:46,110 --> 00:22:48,155
जो हम आमतौर पर करते हैं न्यूरल नेट्स में.

359
00:22:48,155 --> 00:22:49,820
आमतौर पर न्यूरल नेट्स में, 
हमारे पास होती है एक बहुत बड़ी लेयर,

360
00:22:49,820 --> 00:22:52,080
और सारे यूनिट्स चलते हैं और करते हैं 
जो भी वे करते हैं.

361
00:22:52,080 --> 00:22:55,770
लेकिन आप नहीं सोचते बंडल करने का 
उन्हें छोटे समूहों में जो दर्शाते हैं

362
00:22:55,770 --> 00:22:57,310
विभिन्न आयाम उसी चीज़ के.

363
00:22:58,660 --> 00:23:02,080
तो मुझे लगता है हमारे पास होना चाहिए 
यह अतिरिक्त संरचना.

364
00:23:02,080 --> 00:23:05,020
और अन्य विचार जो इसके साथ आता है.

365
00:23:05,020 --> 00:23:07,410
>> तो इसका मतलब है कि डिस्ट्रिब्यूटेड रेप्रेज़ेंटेशन में,

366
00:23:07,410 --> 00:23:09,280
आप विभाजित करते हैं रेप्रेज़ेंटेशन को.

367
00:23:09,280 --> 00:23:11,270
>> हाँ. 
 >> विभिन्न सबसेट्स में.

368
00:23:11,270 --> 00:23:13,900
>>हाँ. 
>> दर्शाने के लिए, ठीक है, बजाय-

369
00:23:13,900 --> 00:23:15,600
मैं उन प्रत्येक सबसेट्स को कहता हूँ एक कैप्सुल.

370
00:23:15,600 --> 00:23:16,180
>> ठीक है.

371
00:23:16,180 --> 00:23:21,078
>> आइडिया यह है कि एक कैप्सूल दर्शा सकता है 
एक इन्स्टन्स एक फ़ीचर का, लेकिन

372
00:23:21,078 --> 00:23:21,794
केवल एक.

373
00:23:21,794 --> 00:23:27,130
और यह दर्शाता है सभी विभिन्न पहलू 
उस फ़ीचर के,

374
00:23:27,130 --> 00:23:29,880
यह है एक फ़ीचर जिसके है बहुत से पहलु तुलना में

375
00:23:29,880 --> 00:23:34,530
एक आम न्यूरॉन और एक आम न्यूरल नेट के, 
जिसमें है केवल एक स्केलर प्रॉपर्टी.

376
00:23:34,530 --> 00:23:36,240
>> जी हाँ
 हाँ.

377
00:23:36,240 --> 00:23:41,423
>> और फिर आप क्या कर सकते हैं कि यदि 
आपके पास है वह, आप कर सकते हैं जो आम

378
00:23:41,423 --> 00:23:48,980
न्यूरल नेट्स काफ़ी ख़राब करते हैं, जो है कि 
आप कर सकते हैं जिसे मैं कहता हूँ 
रूटिंग बाए एग्रिमेंट.

379
00:23:48,980 --> 00:23:52,960
तो चलिए मान लेते हैं आप सेग्मेंटेशन 
करना चाहते हैं और

380
00:23:52,960 --> 00:23:56,660
और आपके पास है कुछ जो मुँह हो सकता है 
और कुछ और जो शायद नाक हो सकता है.

381
00:23:57,910 --> 00:24:02,179
और आप जानना चाहते हैं कि आपको रखना चाहिए 
उन्हें एक साथ बनाने के लिए एक चीज़.

382
00:24:02,179 --> 00:24:03,879
तो आइडिया में होना चाहिए एक कैप्सूल

383
00:24:03,879 --> 00:24:06,040
एक मुँह जिसमें हैं पैरामीटर्स मुँह के.

384
00:24:06,040 --> 00:24:10,582
और आपके पास है कैप्सूल एक नाक के लिए 
जिसमें है पैरामीटर्स नाक के.

385
00:24:10,582 --> 00:24:13,797
और फिर समझने के लिए कि क्या 
उन्हें एक साथ रखा जाए या

386
00:24:13,797 --> 00:24:18,670
नहीं, आप उनमें से प्रत्येक से वोट करवाते हैं 
कि क्या पैरामीटर्स होने चाहिए एक चेहरे के.

387
00:24:19,930 --> 00:24:23,718
अब अगर मुंह और नाक सही 
स्पेश्यल रिलेशनशिप में हो,

388
00:24:23,718 --> 00:24:24,725
वे सहमत होंगे.

389
00:24:24,725 --> 00:24:28,888
तो जब आपको मिलते हैं दो कैप्सूल एक लेवल में 
जो वोट कर रहे हैं पैरामीटर्स के समान सेट के लिए

390
00:24:28,888 --> 00:24:32,106
ऊपर के अगले लेवल के लिए, आप मान सकते हैं 
कि वे शायद सही हैं,

391
00:24:32,106 --> 00:24:35,350
क्योंकि सहमत होना एक उच्च डिमेन्शनल स्पेस 
में काफ़ी असंभावित है.

392
00:24:36,950 --> 00:24:42,109
वह है एक बहुत विभिन्न तरीक़ा फ़िल्टर करने का,

393
00:24:42,109 --> 00:24:46,130
उससे जो हम आमतौर पर 
न्यूरल नेट्स में इस्तेमाल करते हैं.

394
00:24:46,130 --> 00:24:50,708
तो मुझे लगता है यह रूटिंग बाए एग्रिमेंट 
होगा बहुत महत्वपूर्ण

395
00:24:50,708 --> 00:24:56,700
बेहतर जनरलाइज करवाने के लिए
 न्यूरल नेट्स को सीमित डेटा से.

396
00:24:56,700 --> 00:24:59,797
मुझे लगता है यह बहुत अच्छा करेगा दृष्टिकोण में
 बदलाव आने पर,

397
00:24:59,797 --> 00:25:01,500
सेगमेंटेशन करने में बहुत अच्छा करेगा.

398
00:25:01,500 --> 00:25:04,794
और मैं उम्मीद कर रहा हूँ यह होगा
 सांख्यिकिय रूप से 
अधिक कुशल तुलना में जो हम

399
00:25:04,794 --> 00:25:06,147
वर्तमान में न्यूरल नेट्स में करते हैं.

400
00:25:06,147 --> 00:25:08,575
जो है, यदि आप नियंत्रण करना चाहते है दृष्टिकोण में
 बदलाव पर,

401
00:25:08,575 --> 00:25:12,000
आप सिर्फ़ दें इसे सारे बदलाव दृष्टिकोण में 
और ट्रेनिंग करें उन सभी पर.

402
00:25:12,000 --> 00:25:16,460
>> अच्छा, ठीक है, तो बजाय करने के 
केवल फ़ीड फ़ॉर्वर्ड सूपर्वायज़्ड लर्निंग,

403
00:25:16,460 --> 00:25:19,120
आप लर्न कर सकते हैं इसे किसी भिन्न ढंग से.

404
00:25:20,220 --> 00:25:24,120
>> ठीक है, मेरी अभी भी योजना है इसे करने की 
सूपर्वायज़्ड लर्निंग के साथ, लेकिन

405
00:25:24,120 --> 00:25:27,720
फ़ॉर्वर्ड पास के मेकैनिक्स काफ़ी भिन्न हैं.

406
00:25:27,720 --> 00:25:32,010
यह नहीं है एक शुद्ध फ़ॉर्वर्ड पास उस मायने में कि
 वहाँ थोड़ी बहुत इटरेशन्स

407
00:25:32,010 --> 00:25:36,550
हो रही हैं, जहाँ आप सोचते हैं 
आपको मिला है एक मुँह 
और आप सोचते हैं आपको मिला है एक नाक.

408
00:25:36,550 --> 00:25:39,127
और इस्तेमाल करते हैं थोड़ा इटरेशन का 
तय करने के लिए

409
00:25:39,127 --> 00:25:42,530
क्या उन्हें सच में साथ जाना चाहिए बनाने के 
लिए एक चेहरा.

410
00:25:42,530 --> 00:25:46,352
और आप कर सकते हैं बैक प्रॉप्स उस इटरेशन से.

411
00:25:46,352 --> 00:25:50,286
तो आप यह कर सकते हैं थोड़ा अंतर करने के लिए,

412
00:25:50,286 --> 00:25:54,417
और हम उस पर काम कर रहे हैं 
अब मेरे ग्रूप में टोरोंटो में.

413
00:25:54,417 --> 00:26:00,260
तो अब मेरे पास है एक छोटी गूगल टीम टोरोंटो में,
 ब्रेन टीम का एक हिस्सा.

414
00:26:00,260 --> 00:26:02,127
और वह है जिसके बारे में मैं अब उत्साहित हूँ.

415
00:26:02,127 --> 00:26:02,891
>> अच्छा, बढ़िया, हाँ.

416
00:26:02,891 --> 00:26:05,366
तत्पर हैं उस पेपर के लिए जब वह आएगा.

417
00:26:05,366 --> 00:26:10,750
>> हाँ, यदि यह आता है [हँसी].

418
00:26:10,750 --> 00:26:13,040
>> आपने कई दशकों से डीप लर्निंग में काम किया है.

419
00:26:13,040 --> 00:26:15,330
मैं वास्तव में बहुत उत्सुक हूं, कैसे अपनी सोच,

420
00:26:15,330 --> 00:26:18,760
आपकी समझ AI की बदली इन सालों में?

421
00:26:20,380 --> 00:26:27,678
>> तो मुझे लगता है बहुत सा मेरा बौद्धिक इतिहास है 
बैक प्रॉपगेशन के इर्द गिर्द,

422
00:26:27,678 --> 00:26:33,531
और कैसे इस्तेमाल करना है बैक प्रॉपगेशन, 
कैसे इस्तेमाल करना है इसकी ताक़त का.

423
00:26:33,531 --> 00:26:36,966
तो शुरू में, 80 के दशक के मध्य में, 
हम इसका उपयोग कर रहे थे

424
00:26:36,966 --> 00:26:40,203
डिस्क्रमिनेटिव लर्निंग के लिए और यह
 अच्छा चल रहा था.

425
00:26:40,203 --> 00:26:42,405
मैंने तब तय किया, 90 के दशक के शुरू में,

426
00:26:42,405 --> 00:26:46,749
कि वास्तव में लोगों द्वारा अधिकांश लर्निंग होगी 
अनसूपर्वायज़्ड लर्निंग.

427
00:26:46,749 --> 00:26:50,138
और मुझे बहुत दिलचस्पी पैदा हुई 
अनसुपरवाईज्ड लर्निंग में, और

428
00:26:50,138 --> 00:26:54,300
वह था जब मैंने शुरू किया काम करना 
वेक-स्लीप अल्गोरिद्म जैसी चीज़ों पर.

429
00:26:54,300 --> 00:26:58,306
>> और उस समय आपकी टिप्पणी ने वास्तव में 
प्रभावित किया मेरी सोच को भी.

430
00:26:58,306 --> 00:27:03,010
तो जब मैं अग्रणी था गूगल ब्रेन में,
 हमारे पहले प्रोजेक्ट ने काफ़ी किया

431
00:27:03,010 --> 00:27:07,900
काम अनसूपर्वायज़्ड लर्निंग पर 
आपके प्रभाव की वजह से.

432
00:27:07,900 --> 00:27:09,740
>> ठीक है, और शायद मैंने आपको गुमराह किया हो.

433
00:27:09,740 --> 00:27:11,470
क्योंकि अंतत:,

434
00:27:11,470 --> 00:27:13,840
मैं सोचता हूँ अनसूपर्वायज़्ड लर्निंग होगी 
बहुत महत्वपूर्ण.

435
00:27:15,160 --> 00:27:19,376
लेकिन आपको वास्तविकता का सामना करना है.

436
00:27:19,376 --> 00:27:24,107
और जिसने काम किया पिछले क़रीब 
दस सालों में है सूपर्वायज़्ड लर्निंग.

437
00:27:24,107 --> 00:27:27,179
डिस्क्रिमिनेटिव ट्रेनिंग, जहाँ आपके पास हैं लेबल्स, या

438
00:27:27,179 --> 00:27:31,810
आप प्रिडिक्ट करना चाह रहे हैं 
अगली चीज़ सिरीज़ में, 
तो वह लेबल की तरह काम करती है.

439
00:27:31,810 --> 00:27:33,769
और उसने अविश्वसनीय रूप से अच्छा काम किया है.

440
00:27:37,528 --> 00:27:42,266
मुझे अभी भी विश्वास है कि अनसूपर्वायज़्ड लर्निंग होगा 
महत्वपूर्ण, और चीज़ें

441
00:27:42,266 --> 00:27:47,145
काम करेंगी अविश्वसनीय रूप से ज्यादा बेहतर 
जब हम उससे सहित ढंग से काम करवा पाएँगे, लेकिन

442
00:27:47,145 --> 00:27:48,200
हमने अभी तक नहीं किया है.

443
00:27:49,990 --> 00:27:53,225
>> हाँ, मैं सोचता हूँ बहुत से वरिष्ठ लोग डीप लर्निंग में,

444
00:27:53,225 --> 00:27:56,074
मुझे मिला कर, बहुत उत्साहित रहते हैं इस बारे में.

445
00:27:56,074 --> 00:28:01,513
सिर्फ़ इतना कि हम में से किसी को अभी कोई 
आइडिया नहीं है कि कैसे करना है इसे.

446
00:28:01,513 --> 00:28:04,983
शायद आपको है, मुझे नहीं लगता कि मुझे है.

447
00:28:04,983 --> 00:28:08,160
>> वेरिएशनल ऑटोएनकोडर है जहाँ आप इस्तेमाल
 करते हैं रीपैरामीटराइज़ेशन ट्रिक.

448
00:28:08,160 --> 00:28:10,120
मुझे एक बहुत अच्छे विचार की तरह लगा.

449
00:28:10,120 --> 00:28:15,260
और जैनेरेटिव ऐड्वर्सेरीयल नेट्स भी 
मुझे एक अच्छा विचार लगा.

450
00:28:15,260 --> 00:28:18,645
मुझे लगता है जैनेरेटिव ऐड्वर्सेरीयल नेट्स हैं एक

451
00:28:18,645 --> 00:28:23,430
तरह से सबसे बड़ा आइडिया डीप लर्निंग में 
जो वास्तव में नया है.

452
00:28:23,430 --> 00:28:26,363
मैं उम्मीद कर रहा हूँ कि मैं बना सकूँ कैप्सूल्स 
जो सफल हैं, लेकिन

453
00:28:26,363 --> 00:28:31,740
अभी जैनेरेटिव ऐड्वर्सेरीयल नेट्स, 
मैं सोचता हूँ एक बड़ी सफलता हैं.

454
00:28:31,740 --> 00:28:34,439
>>क्या हुआ स्पार्सिटी और स्लो फ़ीचर्ज़ का,

455
00:28:34,439 --> 00:28:38,806
जो थे दो अन्य सिद्धांत बनाने के लिए 
अनसूपर्वायज़्ड मॉडल्स?

456
00:28:41,556 --> 00:28:47,788
मैंने कभी स्पार्सिटी पर उतना काम नहीं 
किया जितना आपने, दोस्त.

457
00:28:47,788 --> 00:28:52,672
लेकिन स्लो फ़ीचर्ज़, मुझे लगता है, एक गलती है.

458
00:28:52,672 --> 00:28:53,660
आपको नहीं कहना चाहिए स्लो.

459
00:28:53,660 --> 00:28:57,880
मूल विचार सही है, लेकिन आपको नहीं जाना चाहिए 
फ़ीचर्ज़ पर जो बदलते नहीं हैं.

460
00:28:57,880 --> 00:29:00,660
आपको जाना चाहिए फ़ीचर्ज़ पर 
जो बदलते हैं पूर्वकथनीय रूप से.

461
00:29:01,680 --> 00:29:07,060
तो यहाँ है एक तरह से मूल सिद्धांत कि 
कैसे आपको कुछ भी मॉडल करना चाहिए.

462
00:29:08,620 --> 00:29:13,391
आप अपने माप लें, और आप 
अप्लाई कर रहे हैं नॉन-लिनीअर

463
00:29:13,391 --> 00:29:17,612
ट्रैन्स्फ़र्मेशन्स आपके मापों को जब तक 
आपको नहीं मिलता

464
00:29:17,612 --> 00:29:22,672
एक रेप्रेज़ेंटेशन एक स्टेट वेक्टर जैसे 
जहाँ ऐक्शन लिनीअर है.

465
00:29:22,672 --> 00:29:26,103
तो आप सिर्फ़ दिखावा नहीं करते कि यह लिनीअर है
 जैसे आप करते हैं आम फ़िल्टर्ज़ के साथ.

466
00:29:26,103 --> 00:29:29,625
लेकिन आप वास्तव में ढूँढते हैं एक ट्रैन्स्फ़र्मेशन 
दिखने वाले से

467
00:29:29,625 --> 00:29:32,616
अंतर्निहित वेरिएबल्स तक जहाँ लिनीअर ऑपरेशनस,

468
00:29:32,616 --> 00:29:37,480
जैसे मेट्रिक्स गुणक अंतर्निहित वेरिएबल्स पर, 
काम करेंगे.

469
00:29:37,480 --> 00:29:39,700
तो उदाहरण के लिए, यदि आप
 बदलना चाहते हैं दृष्टिकोण,

470
00:29:39,700 --> 00:29:42,890
आप बनाना चाहते हैं इमिज एक अन्य दृष्टिकोण से,

471
00:29:42,890 --> 00:29:46,900
जो आपको करना चाहिए कि जाएँ 
पिक्सल्स से कोऑर्डिनेट्स पर.

472
00:29:47,950 --> 00:29:50,686
और एक बार जब आप पहुँच जाते हैं
 कोऑर्डिनेट रेप्रेज़ेंटेशन पर,

473
00:29:50,686 --> 00:29:54,120
जो है एक तरह का काम जो मैं 
उम्मीद करता हूँ कैप्सूल्स करेंगे.

474
00:29:54,120 --> 00:29:57,350
आप तब कर सकते हैं एक मेट्रिक्स गुणक 
बदलने के लिए दृष्टिकोण, और

475
00:29:57,350 --> 00:29:59,210
फिर आप मैप कर सकते हैं वापिस इसे पिक्सल्स पर.

476
00:29:59,210 --> 00:29:59,893
>> ठीक है, इसलिए आपने वह सब किया.

477
00:29:59,893 --> 00:30:02,170
>> मुझे लगता है कि यह एक बहुत, 
बहुत सामान्य सिद्धांत है.

478
00:30:02,170 --> 00:30:04,773
>> यही कारण है कि आपने चेहरे संश्लेषण 
पर वह सब काम किया है, है न?

479
00:30:04,773 --> 00:30:09,355
जहाँ आप लेते हैं एक चेहरा और कम्प्रेस करते हैं इसे 
एक बहुत छोटी डिमेन्शन के वेक्टर में, और इसलिए

480
00:30:09,355 --> 00:30:12,450
आप छेड़-छाड़ कर सकते हैं उसके साथ और 
पा सकते हैं अन्य चेहरे.

481
00:30:12,450 --> 00:30:15,950
>> मेरा एक छात्र था जिसने उस पर काम किया, 
मैंने ख़ुद उस पर ज़्यादा काम नहीं किया.

482
00:30:17,100 --> 00:30:19,180
>> अब मुझे यकीन है कि आपको अब भी 
हर समय पूछा जाता है,

483
00:30:19,180 --> 00:30:23,920
अगर कोई डीप लर्निंग में जाना चाहता है, 
उन्हें क्या करना चाहिए?

484
00:30:23,920 --> 00:30:25,040
तो आपकी क्या सलाह है?

485
00:30:25,040 --> 00:30:28,938
मुझे यक़ीन है कि आपने दी है बहुत सी सलाह 
लोगों को एक एक करके, लेकिन

486
00:30:28,938 --> 00:30:31,550
सम्पूर्ण विश्व के श्रोताओं को 
जो देख रहे हैं यह वीडियो.

487
00:30:31,550 --> 00:30:35,999
आपकी उनके लिए क्या सलाह है 
डीप लर्निंग में जाने के लिए?

488
00:30:35,999 --> 00:30:42,171
>> ठीक है, तो मेरी सलाह है एक तरह से 
साहित्य पढ़ें, लेकिन बहुत ज्यादा नहीं.

489
00:30:42,171 --> 00:30:48,030
तो यह है सलाह जो मुझे मिली मेरे सलाहकार से, 
जो काफ़ी अलग है जो बहुत लोग कहते हैं.

490
00:30:48,030 --> 00:30:52,474
अधिकांश लोग कहते हैं कि आपको कई साल लगाने 
चाहिए साहित्य पढ़ने में और

491
00:30:52,474 --> 00:30:55,421
फिर आपको शुरू करना चाहिए काम 
आपके अपने आइडिया पर.

492
00:30:55,421 --> 00:31:00,295
और वह कुछ शोधकर्ताओं के लिए सच हो सकता है, 
लेकिन रचनात्मक शोधकर्ताओं के लिए मुझे लगता है

493
00:31:00,295 --> 00:31:03,803
आप क्या करना चाहते हैं कि पढ़ें थोड़ा साहित्य.

494
00:31:03,803 --> 00:31:07,792
और नोटिस कुछ जो आप सोचते हैं 
सब लोग ग़लत कर रहे हैं.

495
00:31:07,792 --> 00:31:10,340
मैं उस अर्थ में विपरीत हूँ.

496
00:31:10,340 --> 00:31:13,568
आप देखते हैं इसे और यह बस सही नहीं लगता.

497
00:31:13,568 --> 00:31:15,660
और फिर समझते हैं कैसे इसे सही करना है.

498
00:31:16,890 --> 00:31:22,476
और फिर लोग आपको कहेंगे कि वह अच्छा नहीं हैं, 
लेकिन आप उसपर बने रहें.

499
00:31:22,476 --> 00:31:26,339
और लोगों को उस पर बनाए रखने के लिए 
मेरे पास एक बढ़िया सिद्धांत है,

500
00:31:26,339 --> 00:31:29,996
जो है कि या आपका अंतर्ज्ञान अच्छा है या नहीं है.

501
00:31:29,996 --> 00:31:32,030
यदि आपका अंतर्ज्ञान अच्छा है 
आपको उस पर चलना चाहिए और

502
00:31:32,030 --> 00:31:34,060
अंतत: आप सफल होंगे.

503
00:31:34,060 --> 00:31:36,478
यदि आपका अंतर्ज्ञान अच्छा नहीं है, कोई फर्क नहीं 
पड़ता कि आप क्या करते हैं.

504
00:31:36,478 --> 00:31:40,329
>> ठीक है [हँसी].

505
00:31:40,329 --> 00:31:43,420
प्रेरणादायक सलाह, निश्चित रूप से लेनी चाहिए.

506
00:31:43,420 --> 00:31:45,410
>> आपको अपने अंतर्ज्ञान पर भरोसा भी करना चाहिए.

507
00:31:45,410 --> 00:31:47,847
उन पर भरोसा न करने में कोई फ़ायदा नहीं है.

508
00:31:47,847 --> 00:31:49,420
>> अच्छा, हाँ.

509
00:31:49,420 --> 00:31:55,193
मैं आमतौर पर लोगों को न केवल 
पढ़ने की सलाह देता हूँ, बल्कि प्रकाशित पेपर्स को 
दोबारा करने को कहता हूँ.

510
00:31:55,193 --> 00:31:58,161
और शायद उससे सीमित हो जाता है कि 
आप कितने कर पाते हैं,

511
00:31:58,161 --> 00:32:00,800
क्योंकि दोबारा उन परिणामों को ला पाने में 
काफ़ी समय लगता है.

512
00:32:01,910 --> 00:32:05,312
हाँ, यह सच है जब आप दोबारा करने की 
कोशिश कर रहे हैं एक प्रकाशित पेपर,

513
00:32:05,312 --> 00:32:08,100
आपको समझ आती है छोटी-छोटी चालें 
इसे काम करवाने के लिए.

514
00:32:08,100 --> 00:32:11,938
अन्य सलाह जो मेरे पास है कि कभी प्रोग्रामिंग 
बंद मत करो.

515
00:32:11,938 --> 00:32:15,577
क्योंकि यदि आप किसी छात्र को कुछ 
करने के लिए देते हैं और वे कमज़ोर छात्र हैं

516
00:32:15,577 --> 00:32:18,550
वे वापिस आएँगे और कहेंगे, यह नहीं चला.

517
00:32:18,550 --> 00:32:22,030
और कारण कि यह नहीं चला होगा एक 
छोटा निर्णय जो उन्होंने लिया,

518
00:32:22,030 --> 00:32:25,100
जो उन्होंने नहीं समझा कि महत्वपूर्ण है.

519
00:32:25,100 --> 00:32:28,850
और यदि आप देते हैं इसे एक अच्छे छात्र को, 
जैसे U Y Tay उदाहरण के लिए,

520
00:32:28,850 --> 00:32:31,120
आप उसे दे सकते हैं कुछ भी और वह वापिस 
आकर कहेगा काम हो गया.

521
00:32:32,670 --> 00:32:36,420
मुझे याद है ऐसा करना एक बार, और मैंने कहा 
रुको एक मिनट UY,

522
00:32:36,420 --> 00:32:37,330
हमारी पिछली बातचीत के बाद,

523
00:32:37,330 --> 00:32:40,380
मुझे समझ आया कि यह काम नहीं करेगा, 
निम्नलिखित कारणों की वजह से.

524
00:32:40,380 --> 00:32:43,586
और उसने कहा, हाँ, मुझे उसी समय समझ आ गया, 
तो मैंने मान लिया कि आपका वह मतलब नहीं था.

525
00:32:43,586 --> 00:32:47,627
>> [हँसी], अच्छा, हाँ, वह बढ़िया है, हाँ.

526
00:32:47,627 --> 00:32:51,575
चलो देखते है, कोई अन्य सलाह

527
00:32:51,575 --> 00:32:57,782
लोगों के लिए जो जाना चाहते हैं 
AI और डीप लर्निंग में.

528
00:32:57,782 --> 00:33:02,000
>> मुझे लगता है कि मूल रूप से आप उतना पढ़े कि 
अंतर्ज्ञान का विकास शुरू कर सकें.

529
00:33:02,000 --> 00:33:05,811
और फिर, अपने अंतर्ज्ञान पर भरोसा करें 
और चले उस पर,

530
00:33:05,811 --> 00:33:10,783
और ज़्यादा चिंता न करें यदि सब लोग 
कहते हैं यह बकवास है.

531
00:33:10,783 --> 00:33:14,352
>> और मुझे लगता है यह जानने का कोई 
तरीक़ा नहीं है कि अन्य लोग सही हैं या

532
00:33:14,352 --> 00:33:19,950
ग़लत जब वे कहते हैं यह बकवास है, 
लेकिन आपको सिर्फ़ उस पर चलना चलना चाहिए 
और फिर जानना चाहिए.

533
00:33:19,950 --> 00:33:24,350
>> लेकिन एक चीज़ है, जो है, 
यदि आप सोचते हैं यह एक बहुत ही बढ़िया विचार है,

534
00:33:24,350 --> 00:33:27,201
और अन्य लोग आपको कहते हैं 
यह बिल्कुल बकवास है,

535
00:33:27,201 --> 00:33:29,761
तब आप जानते हैं आप वाक़ई कुछ कर रहे हैं.

536
00:33:29,761 --> 00:33:33,960
तो एक उदाहरण उसका है कि जब रैम्पार्ट और मैंने 
पहले बनाए वेरीएशनल मेथड,

537
00:33:35,420 --> 00:33:40,690
मैंने भेजी मैल समझाते हुए इसे एक पुराने छात्र को 
जिसका नाम था पीटर ब्राउन,

538
00:33:40,690 --> 00:33:42,560
जिसे EM के बारे में काफ़ी पता था.

539
00:33:43,570 --> 00:33:46,967
और उसने दिखाया इसे लोगों को जो 
उसके साथ काम करते थे,

540
00:33:46,967 --> 00:33:51,253
डेल पीएट्रो भाई, जो जुड़वाँ थे, शायद.

541
00:33:51,253 --> 00:33:55,914
और उसने मुझे बाद में बताया उन्होंने जो कहा, 
और उन्होंने कहा,

542
00:33:55,914 --> 00:34:00,277
या यह आदमी नशे में है, या यह सिर्फ़ मूर्ख है, तो

543
00:34:00,277 --> 00:34:04,260
उन्होंने वास्तव में सोचा कि वह बकवास था.

544
00:34:04,260 --> 00:34:06,460
अब, यह हो सकता है थोड़ा उस वजह से जैसे मैंने समझाया इसे,

545
00:34:06,460 --> 00:34:08,043
क्योकिं मैंने समझाया इसे सहज शब्दों में.

546
00:34:09,150 --> 00:34:13,100
लेकिन जब आपके पास है जो आप सोचते हैं 
एक बढ़िया आइडिया है और

547
00:34:13,100 --> 00:34:16,810
अन्य लोग सोचते हैं उसे एकदम बकवास, 
तब वह संकेत है एक सच में अच्छे आइडिया का.

548
00:34:18,026 --> 00:34:21,555
>> अच्छा, शोध के विषय,

549
00:34:21,555 --> 00:34:26,183
नए ग्रैजूएट छात्रों को कैप्सूल पर 
काम करना चाहिए और

550
00:34:26,183 --> 00:34:30,707
शायद अनसुपरवाईज्ड लर्निंग, कोई अन्य?

551
00:34:30,707 --> 00:34:34,078
>> नए स्नातक छात्रों के लिए एक अच्छी सलाह है,

552
00:34:34,078 --> 00:34:38,344
देखो कि क्या आप ढूँढ सकते हैं एक एडवाईज़र 
जिसके आपके जैसे विचार हैं.

553
00:34:38,344 --> 00:34:42,637
क्योंकि यदि आप काम करते हैं 
जो एडवाईज़र के काफ़ी क़रीब है,

554
00:34:42,637 --> 00:34:47,170
आपको मिलेगी बहुत सी अच्छी सलाह और 
समय आपके एडवाईज़र से.

555
00:34:47,170 --> 00:34:50,590
यदि आप काम करते हैं जिसमें आपके 
एडवाईज़र को कोई रुचि नहीं है,

556
00:34:50,590 --> 00:34:55,262
जो आपको मिलेगा, आपको मिलेगी कुछ सलाह, 
लेकिन वह कुछ ज़्यादा उपयोगी नहीं होगी.

557
00:34:55,262 --> 00:34:58,386
>> ठीक है, आख़िरी सलाह शिक्षार्थियों के लिए,

558
00:34:58,386 --> 00:35:02,440
आपको कैसा लगता है लोगों का 
PhD प्रोग्राम में प्रवेश लेना?

559
00:35:02,440 --> 00:35:09,687
तुलना में जुड़ना एक चोटी की कम्पनी से, 
या एक चोटी के अनुसंधान ग्रूप से?

560
00:35:09,687 --> 00:35:13,890
>> हां, यह जटिल है, मुझे लगता है अभी, क्या हो रहा है,

561
00:35:13,890 --> 00:35:18,727
वहाँ नहीं हैं पर्याप्त शिक्षविद डीप लर्निंग में प्रशिक्षित 
शिक्षित करने के लिए सभी लोगों को

562
00:35:18,727 --> 00:35:21,125
जिन्हें हमें विश्वविद्यालयों में शिक्षित करने की जरूरत है.

563
00:35:21,125 --> 00:35:25,011
वहाँ नहीं है पर्याप्त फ़ैकल्टी, लेकिन

564
00:35:25,011 --> 00:35:27,780
मुझे लगता है कि यह अस्थाई होगा.

565
00:35:27,780 --> 00:35:32,410
मुझे लगता है कि क्या हुआ है, 
ज्यादातर विभाग बहुत धीरे से

566
00:35:32,410 --> 00:35:34,890
समझ पा रहे हैं एक तरह की क्रांति जो चल रही है.

567
00:35:34,890 --> 00:35:38,720
मैं एक तरह से सहमत हूँ आपके साथ
 कि यह कुछ एक दूसरी औद्योगिक क्रांति 
जैसे नहीं है, लेकिन

568
00:35:38,720 --> 00:35:41,000
यह लगभग है उस पैमाने पर कुछ है.

569
00:35:41,000 --> 00:35:43,691
और एक बहुत बड़ा परिवर्तन आ रहा है,

570
00:35:43,691 --> 00:35:47,980
मूलत: इसलिए कि हमारे सम्बंध 
कम्प्यूटर्स के साथ बदल गए हैं.

571
00:35:47,980 --> 00:35:53,920
बजाय उनको प्रोग्राम करने के, हम 
अब उन्हें दिखाते हैं, और वे इसे समझते हैं.

572
00:35:53,920 --> 00:35:56,570
वह है एक बहुत ही भिन्न ढंग इस्तेमाल करने 
का कम्प्यूटर्स को, और

573
00:35:56,570 --> 00:36:01,210
कम्प्यूटर साइयन्स डिपार्टमेंट्स बने हैं कम्प्यूटर्स को 
प्रोग्राम करने के आइडिया पर.

574
00:36:01,210 --> 00:36:03,480
और वे नहीं समझते कि एक तरह से,

575
00:36:05,000 --> 00:36:09,330
यह दिखाना कम्प्यूटर्स को होगा उतना ही बड़ा 
जितना कम्प्यूटर्स को प्रोग्राम करना.

576
00:36:09,330 --> 00:36:13,940
सिवाय कि वे नहीं समझते कि आधे लोग 
डिपार्टमेंट में होने चाहिए लोग

577
00:36:13,940 --> 00:36:16,510
जो करवा पाए कम्प्यूटर्स से काम उनको दिखा कर.

578
00:36:16,510 --> 00:36:22,183
तो मेरा डिपार्टमेंट इस को स्वीकार नहीं करता कि 
इसमें होने चाहिए बहुत से

579
00:36:22,183 --> 00:36:24,790
लोग इसे करते हुए.

580
00:36:24,790 --> 00:36:28,730
वे सोचते हैं उनके पास हैं कुछ, शायद कुछ और, 
लेकिन बहुत ज़्यादा नहीं.

581
00:36:31,260 --> 00:36:32,452
और उस स्थिति में,

582
00:36:32,452 --> 00:36:36,510
आपको याद कराना होगा बड़ी कम्पनी को करने के लिए ट्रेनिंग.

583
00:36:36,510 --> 00:36:40,335
तो गूगल अब ट्रेन करता है लोगों को 
 हम कहते हैं ब्रेन रेज़िडेन्स.

584
00:36:40,335 --> 00:36:43,792
मुझे लगता है विश्वविद्यालय अंततः कर पाएँगे.

585
00:36:43,792 --> 00:36:48,360
>> अच्छा, ठीक है, वास्तव में बहुत से 
छात्रों ने यह समझ लिया है.

586
00:36:48,360 --> 00:36:53,131
चोटी के 50 प्रोग्राम्स में से बहुत से, आधे से ज़्यादा 
आवेदक वास्तव में

587
00:36:53,131 --> 00:36:57,079
चाह रहे है काम करना दिखाने पर बजाय प्रोग्राम करने पर.

588
00:36:57,079 --> 00:37:00,720
हाँ, वास्तव में, श्रेय देने के लिए जहाँ उचित है,

589
00:37:00,720 --> 00:37:04,930
जबकि deeplearning.ai बना रहा है 
एक डीप लर्निंग स्पेशलाइज़ेशन.

590
00:37:04,930 --> 00:37:09,239
जहाँ तक मैं जानता हूँ, उनका पहल डीप लर्निंग 
MOOC था वास्तव में आपका पढ़ाया

591
00:37:09,239 --> 00:37:11,752
कौरसेरा पर, 2012 में, भी.

592
00:37:12,828 --> 00:37:14,430
और कुछ हद तक हैरत की बात है,

593
00:37:14,430 --> 00:37:18,900
वह था जब आपने पहले प्रकाशित किया था RMS अल्गोरिद्म, 
जो है एक रफ़ भी.

594
00:37:20,240 --> 00:37:25,910
>> ठीक है, हाँ, जैसा आप जानते हैं, वह था क्योंकि 
आपने मुझे आमंत्रित किया था MOOC करने के लिए.

595
00:37:25,910 --> 00:37:30,239
और तब जब मुझे संदेह था करने में, आप मुझे 
उत्साहित करते रहे करने के लिए उसे, तो

596
00:37:30,239 --> 00:37:34,340
वह बहुत अच्छा हुआ कि मैंने वह किया, 
हालाँकि बहुत काम करना पड़ा.

597
00:37:34,340 --> 00:37:37,409
>> हाँ, और धन्यवाद वह करने के लिए, 
मुझे याद है आपका मुझे शिकायत करना,

598
00:37:37,409 --> 00:37:38,351
कितना काम था वह.

599
00:37:38,351 --> 00:37:42,413
और आपका रात भर जागना, 
लेकिन मैं सोचता हूँ बहुत से शिक्षार्थियों को

600
00:37:42,413 --> 00:37:47,330
लाभ हुआ आपके पहले MOOC से, 
तो मैं आपका बहुत आभारी हूँ उसके लिए. तो.

601
00:37:47,330 --> 00:37:49,260
वह अच्छा है, हाँ. >> हाँ, कुछ वर्षों में,

602
00:37:49,260 --> 00:37:53,290
मैंने देखा है आपको उलझते हुए 
बहस में AI के पैरडायम्स, और

603
00:37:53,290 --> 00:37:57,030
क्या वहाँ कोई परिवर्तन है AI के पैरडायम्स में.

604
00:37:57,030 --> 00:37:59,984
क्या हैं आपके, क्या आप उस पर अपने
 विचार साँझा कर सकते हैं?

605
00:37:59,984 --> 00:38:05,157
>> हाँ ख़ुशी से, तो मैं सोचता हूँ कि शुरुआती दिनों में, 
50 के दशक में,

606
00:38:05,157 --> 00:38:10,335
लोग जैसे वॉन नियुमन और ट्यूरिंग ने 
नहीं विश्वास किया सिम्बॉलिक AI में,

607
00:38:10,335 --> 00:38:14,220
वे कहीं अधिक प्रेरित थे मस्तिष्क से.

608
00:38:14,220 --> 00:38:20,127
दुर्भाग्य से, उन
 दोनों की बहुत छोटी उम्र में मृत्यु हो गई, 
और उनकी आवाज सुनी नहीं जा सकी.

609
00:38:20,127 --> 00:38:21,806
और AI के शुरुआती दिनों में,

610
00:38:21,806 --> 00:38:26,259
लोग पूरी तरह आश्वस्त थे कि रेप्रेज़ेंटेशनज़ 
जिनकी आपको आवश्यकता है

611
00:38:26,259 --> 00:38:30,500
इंटेलिजेंस के लिए, थे किसी तरह के 
सिम्बॉलिक इक्स्प्रेशन्स.

612
00:38:30,500 --> 00:38:35,509
जैसे कि शुद्ध लॉजिक, जहाँ आप कर सकते थे
 नॉन-मोनोटोनिक चीज़ें, और न बहुत कुछ

613
00:38:35,509 --> 00:38:41,143
लॉजिक, लेकिन कुछ लॉजिक जैसे, 
और कि सार इंटेलिजेन्स का था तर्क.

614
00:38:41,143 --> 00:38:45,662
अब क्या हुआ है, वहां एक पूरी तरह से अलग दृश्य है,

615
00:38:45,662 --> 00:38:50,984
जो है कि एक सोच क्या है, है एक बड़ा 
वेक्टर न्यूरल ऐक्टिविटी का,

616
00:38:50,984 --> 00:38:55,200
तो तुलना करें उसकी एक सोच जो है 
एक सिम्बॉलिक इक्स्प्रेशन.

617
00:38:55,200 --> 00:38:59,087
और मैं सोचता हूँ कि लोग जिन्होंने सोचा कि सोच थे 
सिम्बॉलिक इक्स्प्रेशन्स सिर्फ़

618
00:38:59,087 --> 00:39:00,140
की एक बड़ी ग़लती.

619
00:39:01,210 --> 00:39:07,030
जो अंदर आता है वह है एक स्ट्रिंग शब्दों की, 
और जो बाहर आता है वह है एक स्ट्रिंग शब्दों की.

620
00:39:08,140 --> 00:39:12,580
और उस वजह से, शब्दों की स्ट्रिंग्स हैं प्रकट ढंग 
रेप्रेज़ेंट करने के चीज़ों को.

621
00:39:12,580 --> 00:39:15,710
तो उन्होंने सोचा जो है मध्य में 
वह थी एक स्ट्रिंग शब्दों की, या

622
00:39:15,710 --> 00:39:18,360
कुछ शब्दों की स्ट्रिंग जैसे.

623
00:39:18,360 --> 00:39:21,310
और मैं सोचता हूँ कि जो है मध्य में वह बिल्कुल नहीं थी 
शब्दों की एक स्ट्रिंग जैसे.

624
00:39:21,310 --> 00:39:26,060
मैं सोचता हूँ कि आइडिया कि सोच होनी चाहिए 
किसी तरह की भाषा में उतना मूर्खतापूर्ण है जितना

625
00:39:26,060 --> 00:39:30,980
आइडिया कि समझ कि लेआउट एक 
स्थानिक दृश्य का

626
00:39:30,980 --> 00:39:34,280
होने चाहिए पिक्सल्स में, पिक्सल्स आ जाते हैं.

627
00:39:34,280 --> 00:39:37,930
और अगर हम, अगर हमारे पास होता एक 
डॉट मेट्रिक्स प्रिंटर मशीन से जुड़ा,

628
00:39:37,930 --> 00:39:41,929
तब पिक्सल्स आ जाएँगे, 
लेकिन जो मध्य में है वह नहीं है पिक्सल्स.

629
00:39:43,210 --> 00:39:46,620
और इसलिए मैं सोचता हूँ सोच हैं सिर्फ़ 
ये बड़े वेक्टर्स, और

630
00:39:46,620 --> 00:39:48,460
उन बड़े वैक्टर्स में कॉज़ल शक्ति है.

631
00:39:48,460 --> 00:39:50,490
वे अन्य बड़े वेक्टर्स का कारण बनते हैं, और

632
00:39:50,490 --> 00:39:56,100
वह है बिल्कुल विपरीत मानक AI दृष्टिकोण के 
कि सोच हैं सिम्बॉलिक इक्स्प्रेशन्स.

633
00:39:56,100 --> 00:39:56,700
>> ठीक है, बढ़िया,

634
00:39:57,740 --> 00:40:01,560
मुझे लगता है AI निश्चित रूप से इस नए 
दृष्टिकोण के दौर में आ रही है आजकल.

635
00:40:01,560 --> 00:40:02,660
>>इसमें से कुछ,

636
00:40:02,660 --> 00:40:08,230
मुझे लगता है कि बहुत से लोग अभी भी 
सोचते हैं कि सोच होने चाहिए 
सिम्बॉलिक इक्स्प्रेशन्स.

637
00:40:08,230 --> 00:40:09,780
>> बहुत शुक्रिया यह इंटर्व्यू करने के लिए.

638
00:40:09,780 --> 00:40:12,970
यह बहुत अच्छा था सुनना कैसे 
डीप लर्निंग विकसित हुई है सालों में,

639
00:40:12,970 --> 00:40:17,680
तथा कैसे आप अभी भी इसे भविष्य की ओर 
ले जा रहे हैं, तो धन्यवाद, जेफ़.

640
00:40:17,680 --> 00:40:19,038
ठीक है, आपका धन्यवाद मुझे यह अवसर देने के लिए.

641
00:40:19,038 --> 00:40:20,147
शुक्रिया