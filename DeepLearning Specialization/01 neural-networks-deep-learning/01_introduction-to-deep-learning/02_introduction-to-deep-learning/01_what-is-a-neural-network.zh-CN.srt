1
00:00:01,050 --> 00:00:03,840
深度学习 一般指的是训练神经网络

2
00:00:03,840 --> 00:00:06,050
有时是非常非常大(深)的神经网络

3
00:00:06,050 --> 00:00:08,400
那 什么叫做 神经网络 呢?

4
00:00:08,400 --> 00:00:11,340
这个视频将试图给你一些它的基本知识

5
00:00:12,850 --> 00:00:16,540
让我们从 房价预测 这个例子来开始

6
00:00:16,540 --> 00:00:20,599
让我们假设你有一个
包含六个房子的数据的数据集

7
00:00:20,599 --> 00:00:24,478
所以我们可以知道
房子的大小(多少平方)和对应的价格

8
00:00:24,478 --> 00:00:28,501
我们想要用一个函数
来根据房子的大小来预测价格

9
00:00:28,501 --> 00:00:33,509
所以 如果你熟悉线性回归的话
那你可能会说 好吧

10
00:00:33,509 --> 00:00:38,450
我们用一条直线来拟合这些数据
所以我们就可以得到一条像这样的直线

11
00:00:38,450 --> 00:00:41,850
但是这里有一点有趣的地方
你可能会说 我们知道价格

12
00:00:41,850 --> 00:00:43,770
是不可能是负数的

13
00:00:43,770 --> 00:00:48,050
而如果用直线的话 总会有负数存在

14
00:00:48,050 --> 00:00:49,960
所以我们在这里把直线折一下

15
00:00:49,960 --> 00:00:51,530
让其在这里归零

16
00:00:51,530 --> 00:00:56,770
那么 这根粗的蓝色的线就是你用来

17
00:00:56,770 --> 00:00:59,760
根据房子的大小来
预测房子的价格的函数(图像)

18
00:00:59,760 --> 00:01:03,310
嗯所以 这边是零 而另一边是一条直线

19
00:01:04,408 --> 00:01:08,735
你可以把这个你刚才
根据房价拟合出这个方程

20
00:01:08,735 --> 00:01:11,880
当做一个很简单的神经网络

21
00:01:11,880 --> 00:01:14,230
这个几乎是最简单的神经网络了

22
00:01:14,230 --> 00:01:15,000
让我来把它画在这里

23
00:01:17,220 --> 00:01:22,170
我们用房子的大小 x
作为对神经网络的输入

24
00:01:22,170 --> 00:01:26,791
它进入到这个节点(这个小圈)中

25
00:01:26,791 --> 00:01:30,940
然后这个小圈就输出了房价 我们叫做 y

26
00:01:30,940 --> 00:01:37,183
所以这个小圈
也就是一个神经网络中的一个神经元

27
00:01:37,183 --> 00:01:41,830
就会执行我们刚刚
在左边的图中画出的这个方程

28
00:01:43,350 --> 00:01:48,940
并且所有的神经元都会做同样的事情
以房屋的大小作为输入

29
00:01:48,940 --> 00:01:51,960
计算这个线性方程 结果取max(0, y)
然后输出估计价格

30
00:01:53,190 --> 00:01:58,230
而且在神经网络的文献中
你会经常看到这个函数

31
00:01:58,230 --> 00:02:00,992
这个方程的输出结果前部分是零

32
00:02:00,992 --> 00:02:03,550
后部分是直线

33
00:02:03,550 --> 00:02:09,108
这样的一个方程我们叫做 ReLU 函数

34
00:02:09,108 --> 00:02:17,620
意思是线性整流函数
(Rectified Linerar Unite)

35
00:02:17,620 --> 00:02:18,252
所以 ReLU 以及整流

36
00:02:18,252 --> 00:02:22,520
就意味着取max(0, y) 这也是你
会看到这样一个形状的函数图象的原因

37
00:02:23,640 --> 00:02:25,550
你暂时不需要担心理解 ReLU 函数

38
00:02:25,550 --> 00:02:30,200
我们在之后的课程中还会再看到它

39
00:02:30,200 --> 00:02:33,790
所以如果这个是一个
单一神经元的话 这就是一个

40
00:02:33,790 --> 00:02:38,870
非常非常小的神经网络
而一个很大的神经网络

41
00:02:38,870 --> 00:02:44,520
是由许多这样的单一神经元叠加在一起组成

42
00:02:44,520 --> 00:02:50,700
所以 如果你把这个神经元当做一个乐高积木

43
00:02:50,700 --> 00:02:55,270
你可以通过搭建很多这样的乐高积木
来组成一个较大的神经网络

44
00:02:55,270 --> 00:02:56,110
一起看个例子

45
00:02:57,260 --> 00:03:02,220
假设我们不仅仅
根据房屋大小来预测房屋价格

46
00:03:02,220 --> 00:03:04,330
我们现在有别的特征量(用来预测)

47
00:03:04,330 --> 00:03:08,164
你知道房子的别的一些东西
例如卧室的数量

48
00:03:08,164 --> 00:03:13,630
我写作 #bedroom
而且你可能会觉得

49
00:03:13,630 --> 00:03:18,820
家庭的大小(人口)也会影响房屋价格

50
00:03:18,820 --> 00:03:21,882
所以这个房子能够
容纳你的三口或者四口

51
00:03:21,882 --> 00:03:22,687
甚至五口之家吗

52
00:03:22,687 --> 00:03:26,351
而这个因素(能够容纳的家庭大小)
其实是取决于房屋大小以及

53
00:03:26,351 --> 00:03:28,960
卧室的数量

54
00:03:28,960 --> 00:03:31,462
这两个因素决定了
这个房子是否能够容纳你的家庭

55
00:03:31,462 --> 00:03:34,909
另外你可能知道邮政编码

56
00:03:34,909 --> 00:03:40,520
在不同的州(美国)
它也被称为一个房子的邮政编码

57
00:03:40,520 --> 00:03:48,820
而且邮政编码可能可以
告诉你它步行的便利程度

58
00:03:48,820 --> 00:03:51,434
比如在这里生活是否便利?

59
00:03:51,434 --> 00:03:53,635
像是走到杂货店方便么

60
00:03:53,635 --> 00:03:54,194
能走到学校吗

61
00:03:54,194 --> 00:03:55,250
你是否需要开车?

62
00:03:55,250 --> 00:03:57,870
而且有些人可能偏爱步行比较便利的街区

63
00:03:57,870 --> 00:04:06,145
接下来 邮政编码以及(街区)富裕程度

64
00:04:06,145 --> 00:04:09,200
在美国和其他国家都是这样的

65
00:04:09,200 --> 00:04:13,590
(这个可以)告诉你(附近)学校的质量好坏

66
00:04:13,590 --> 00:04:17,820
所以我画的每一个小圆圈
都可以是这些 ReLU 函数

67
00:04:17,820 --> 00:04:22,670
线性整流函数或者一些
别的非线性函数中的一个

68
00:04:22,670 --> 00:04:24,936
所以基于房间的大小 卧室数目

69
00:04:24,936 --> 00:04:28,420
你可以估计出家庭的大小
(根据)他们的邮政编码 估计步行便利性

70
00:04:28,420 --> 00:04:32,050
基于邮政编码和富裕程度
可以估计(周围的)学校质量

71
00:04:32,050 --> 00:04:35,660
最后你估计察觉到了
人们判断他们究竟要为了

72
00:04:35,660 --> 00:04:38,880
房子花多少钱 是取决于他们究竟看重哪些东西

73
00:04:38,880 --> 00:04:43,060
在这个案例中 (他们看重的是)
房屋大小 步行便利性以及学校质量

74
00:04:43,060 --> 00:04:45,210
(这些)都能帮助你去预测房价

75
00:04:46,330 --> 00:04:51,740
所以在这个例子中 x 表示所有这四个输入
(房屋大小 卧室数量 邮政编码 富裕程度)

76
00:04:53,470 --> 00:04:56,460
而y就是你试图去预测的价格

77
00:04:57,960 --> 00:05:03,350
所以通过堆叠一些
单一神经元 或者说我们之前的

78
00:05:03,350 --> 00:05:07,360
ppt 中的简单预测器
我们可以得到一个稍微大些的神经网络

79
00:05:07,360 --> 00:05:10,850
你如何管理神经网络呢?
就是说当你实现(搭建)它的时候

80
00:05:10,850 --> 00:05:15,860
你只需要给它你
训练集中的大量的例子

81
00:05:15,860 --> 00:05:20,740
的输入 x 以及对应的输出 y 

82
00:05:20,740 --> 00:05:23,580
而所有这些在中间的东西
他们(神经网络)将会自己搞清楚

83
00:05:25,435 --> 00:05:29,225
所以你实际需要做的是这个

84
00:05:29,225 --> 00:05:32,055
这里 你有一个有四个输入的神经网络

85
00:05:32,055 --> 00:05:35,455
所以输入特征可能是
房屋大小 卧室数量

86
00:05:35,455 --> 00:05:40,365
邮政编码以及居住地的富裕程度

87
00:05:40,365 --> 00:05:44,805
所以给定这些输入参数

88
00:05:44,805 --> 00:05:50,200
神经网络的工作就是预测价格 y

89
00:05:50,200 --> 00:05:55,942
注意 这里的每个小圆圈
都叫做神经网络中的 隐藏神经元

90
00:05:55,942 --> 00:06:02,310
其中的每一个神经元
都将所有的四个特征当作输入

91
00:06:02,310 --> 00:06:08,139
所以 举例来说
与其说第一个节点代表家庭人数

92
00:06:08,139 --> 00:06:12,056
而家庭人数仅仅
依赖于特征 x1 和 x2

93
00:06:12,056 --> 00:06:15,302
不如说 在神经网络中

94
00:06:15,302 --> 00:06:18,200
神经网络自己来决定
这些网络节点是什么

95
00:06:18,200 --> 00:06:21,070
我们将会给你所有的四个特征
来完成你想要的任务

96
00:06:21,070 --> 00:06:26,170
所以我们称这一层为输入层

97
00:06:26,170 --> 00:06:28,960
在中间的这一层是全连接的

98
00:06:28,960 --> 00:06:31,740
因为每一个输入特征(参数)都会连接

99
00:06:31,740 --> 00:06:33,980
中间层的每一个节点

100
00:06:33,980 --> 00:06:38,630
而神经网络最重要的一点就是
只要给定足够多的

101
00:06:38,630 --> 00:06:43,290
训练示例 x 和 y

102
00:06:43,290 --> 00:06:47,450
神经网络就能很好地拟合出一个
函数来建立 x 和 y 之间的映射关系

103
00:06:48,990 --> 00:06:51,680
所以 这就是最基本的神经网络

104
00:06:51,680 --> 00:06:54,290
实际上当你建造了
你自己的神经网络之后

105
00:06:54,290 --> 00:06:57,130
你可能发现他们在监督学习中
是最有用 最强大的

106
00:06:57,130 --> 00:07:01,620
所谓监督学习 就是需要把
一个输入 x 和一个输出 y 相对应起来

107
00:07:01,620 --> 00:07:06,980
就像我们刚才看到的房屋价格预测示例

108
00:07:06,980 --> 00:07:11,490
在下一个视频中 让我们一起
看更多的关于监督学习的例子

109
00:07:11,490 --> 00:07:15,670
针对其中的一些例子
你可能会发现神经网络

110
00:07:15,670 --> 00:07:16,670
对你的应用将会特别有帮助