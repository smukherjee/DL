<html xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w10="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/omml/2004/12/core" xmlns:ve="http://schemas.openxmlformats.org/markup-compatibility/2006" xmlns:o12="http://schemas.microsoft.com/office/2004/7/core" xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships" xmlns:v="urn:schemas-microsoft-com:vml" xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/3/wordprocessingDrawing" xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/3/main" xmlns="http://www.w3.org/TR/REC-html40">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <head>
    <style>style</style>
  </head>
  <body>
    <div class="Section1">
      <p>
        <b>
          <u>
            <span style="font-size:20.0pt">Vectorization</span>
          </u>
        </b>
      </p>
      <p>
(SPEECH)        <br/>
&gt;&gt;        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Text, Basics of Neural Network Programming. Vectorization. Website, deep learning, dot, A.I.        <br/>
      </p>
      <p>
(SPEECH)        <br/>
Welcome back. Vectorization is basically the art of getting rid of explicit folders in your code.        <br/>
      </p>
      <p>
In the deep learning era safety in deep learning in practice, you often find yourself training on relatively large data sets, because that's when deep learning algorithms tend to shine.        <br/>
      </p>
      <p>
And so, it's important that your code very quickly because otherwise, if it's running on a big data set, your code might take a long time to run then you just find yourself waiting a very long time to get the result.        <br/>
      </p>
      <p>
So in the deep learning era, I think the ability to perform vectorization has become a key skill.        <br/>
      </p>
      <p>
Let's start with an        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
New slide, What is vectorization?        <br/>
      </p>
      <p>
(SPEECH)        <br/>
example.        <br/>
      </p>
      <p>
So, what is Vectorization?        <br/>
      </p>
      <p>
In logistic regression you need to compute Z equals W transpose X plus B, where W was this column vector and X is also this vector.        <br/>
      </p>
      <p>
Maybe there are very large vectors if you have a lot of features.        <br/>
      </p>
      <p>
So, W and X were both these R and no R, NX dimensional vectors.        <br/>
      </p>
      <p>
So, to compute W transpose X, if you had a non-vectorized implementation, you would do something like Z equals zero.        <br/>
      </p>
      <p>
And then for I in range of X.        <br/>
      </p>
      <p>
So, for I equals 1, 2 NX, Z plus equals W I times XI.        <br/>
      </p>
      <p>
And then maybe you do Z plus equal B at the end.        <br/>
      </p>
      <p>
So, that's a non-vectorized implementation.        <br/>
      </p>
      <p>
Then you find that that's going to be really slow.        <br/>
      </p>
      <p>
In contrast, a vectorized implementation would just compute W transpose X directly.        <br/>
      </p>
      <p>
In Python or a numpy, the command you use for that is Z equals np.W, X, so this computes W transpose X.        <br/>
      </p>
      <p>
And you can also just add B to that directly.        <br/>
      </p>
      <p>
And you find that this is much faster.        <br/>
      </p>
      <p>
Let's actually illustrate this with a little        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Jupiter is opened. The file is Vectorization demo.        <br/>
      </p>
      <p>
(SPEECH)        <br/>
demo.        <br/>
      </p>
      <p>
So, here's my Jupiter notebook in which I'm going to write some Python code.        <br/>
      </p>
      <p>
So, first, let me import the numpy library to import.        <br/>
      </p>
      <p>
Send P. And so, for example, I can create A as an array as follows.        <br/>
      </p>
      <p>
Let's say print A.        <br/>
      </p>
      <p>
Now, having written this chunk of code, if I hit shift enter, then it executes the code.        <br/>
      </p>
      <p>
So, it created the array A and it prints it out.        <br/>
      </p>
      <p>
Now, let's do the Vectorization demo.        <br/>
      </p>
      <p>
I'm going to import the time libraries, since we use that, in order to time how long different operations take.        <br/>
      </p>
      <p>
Can they create an array A?        <br/>
      </p>
      <p>
Those random thought round.        <br/>
      </p>
      <p>
This creates a million dimensional array with random values.        <br/>
      </p>
      <p>
b = np.random.rand.        <br/>
      </p>
      <p>
Another million dimensional array.        <br/>
      </p>
      <p>
And, now, tic=time.time, so this measure the current time, c = np.dot (a, b).        <br/>
      </p>
      <p>
toc = time.time.        <br/>
      </p>
      <p>
And this print, it is the vectorized version.        <br/>
      </p>
      <p>
It's a vectorize version.        <br/>
      </p>
      <p>
And so, let's print out.        <br/>
      </p>
      <p>
Let's see the last time, so there's toc - tic x 1000, so that we can express this in milliseconds.        <br/>
      </p>
      <p>
So, ms is milliseconds.        <br/>
      </p>
      <p>
I'm going to hit Shift Enter.        <br/>
      </p>
      <p>
So, that code took about three milliseconds or this time 1.5, maybe about 1.5 or 3.5 milliseconds at a time.        <br/>
      </p>
      <p>
It varies a little bit as I run it, but looks like maybe on average it's taking like 1.5 milliseconds, maybe two milliseconds as I run this.        <br/>
      </p>
      <p>
All right.        <br/>
      </p>
      <p>
Let's keep adding to this block of code.        <br/>
      </p>
      <p>
That's not implementing non-vectorize version.        <br/>
      </p>
      <p>
Let's see, c = 0, then tic = time.time.        <br/>
      </p>
      <p>
Now, let's implement a folder.        <br/>
      </p>
      <p>
For I in range of 1 million, I'll pick out the number of zeros right.        <br/>
      </p>
      <p>
C += (a,i) x (b, i), and then toc = time.time.        <br/>
      </p>
      <p>
Finally, print more than explicit full loop.        <br/>
      </p>
      <p>
The time it takes is this 1000 x toc - tic + "ms" to know that we're doing this in milliseconds.        <br/>
      </p>
      <p>
Let's do one more thing.        <br/>
      </p>
      <p>
Let's just print out the value of C we compute it to make sure that it's the same value in both cases.        <br/>
      </p>
      <p>
I'm going to hit shift enter to run this and check that out.        <br/>
      </p>
      <p>
In both cases, the vectorize version and the non-vectorize version computed the same values, as you know, 2.50 to 6.99, so on.        <br/>
      </p>
      <p>
The vectorize version took 1.5 milliseconds.        <br/>
      </p>
      <p>
The explicit for loop and non-vectorize version took about 400, almost 500 milliseconds.        <br/>
      </p>
      <p>
The non-vectorize version took something like 300 times longer than the vectorize version.        <br/>
      </p>
      <p>
With this example you see that if only you remember to vectorize your code, your code actually runs over 300 times faster.        <br/>
      </p>
      <p>
Let's just run it again.        <br/>
      </p>
      <p>
Just run it again.        <br/>
      </p>
      <p>
Yeah. Vectorize version 1.5 milliseconds seconds and the four loop.        <br/>
      </p>
      <p>
So 481 milliseconds, again, about 300 times slower to do the explicit four loop.        <br/>
      </p>
      <p>
If the engine x slows down, it's the difference between your code taking maybe one minute to run versus taking say five hours to run.        <br/>
      </p>
      <p>
And when you are implementing deep learning algorithms, you can really get a result back faster.        <br/>
      </p>
      <p>
It will be much faster if you vectorize your code.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
Return to slide What is vectorization?        <br/>
      </p>
      <p>
(SPEECH)        <br/>
Some of you might have heard that a lot of scaleable deep learning implementations are done on a GPU or a graphics processing unit.        <br/>
      </p>
      <p>
But all the demos I did just now in the Jupiter notebook where actually on the CPU.        <br/>
      </p>
      <p>
And it turns out that both GPU and CPU have parallelization instructions.        <br/>
      </p>
      <p>
They're sometimes called SIMD instructions.        <br/>
      </p>
      <p>
This stands for a single instruction multiple data.        <br/>
      </p>
      <p>
But what this basically means is that, if you use built-in functions such as this np.function or other functions that don't require you explicitly implementing a for loop.        <br/>
      </p>
      <p>
It enables Phyton Pi to take much better advantage of parallelism to do your computations much faster.        <br/>
      </p>
      <p>
And this is true both computations on CPUs and computations on GPUs.        <br/>
      </p>
      <p>
It's just that GPUs are remarkably good at these SIMD calculations but CPU is actually also not too bad at that.        <br/>
      </p>
      <p>
Maybe just not as good as GPUs.        <br/>
      </p>
      <p>
You're seeing how vectorization can significantly speed up your code.        <br/>
      </p>
      <p>
The rule of thumb to remember is whenever possible, avoid using explicit four loops.        <br/>
      </p>
      <p>
Let's go onto the next video to see some more examples of vectorization and also start to vectorize logistic regression.        <br/>
      </p>
    </div>
  </body>
</html>
