여러분이 신경망을 효과적으로 발전시키키 위해서는, 파라미터
뿐만 아니라 하이퍼 파라미터 또한 잘 조직화 시켜야합니다. 그러면
하이퍼 파라미터s는 무엇일까요? 한번
살펴보겠습니다. 여러분 모델의 파라미터는 W와 B입니다. 여러분의 알고리즘에게 알려줘야하는 것들이 있는데요, 러닝속도 a 와 같은 것 말이죠. a의 값을 잘 지정해서 결과적으로 이 a값이
여러분의 파라미터가 어떻게 진화하는지 또는 기울기 강하의
iterarion의 수가 필요할 수 있죠, 러닝 알고리즘에서 진행되는 iteration
말이죠 또는 숨겨진 레이어의 개수들을 알려줘야 할 수도 있습니다. 이것을 대문자 L 또는 숨겨진
유닛의 개수라고 하겠습니다. 여기에서처럼 0, 1, 그리고 2 등등 말이죠 또한, activation
function을 어떤 것을 고를지에 대한 선택권도 있습니다. 즉, ReLu 함수를
이용할지, tahn h 또는 시그모이드 함수를 쓸지 말이죠. 특히 숨겨진 레이어에서 말이죠. 이런 모든 것들이 여러분이 러닝 알고리즘에 제공해야 하는 것들인데요. 이런 파라미터들이
ultimate 파라미터인 W와 B를 컨트롤합니다. 그렇기
때문에 여기 밑에있는 모든 것들을 하이퍼 파라미터라고 합니다. 여기 알파와 같은 학습속도, iteration 숫자, 숨겨진 레이어의 수, 등등 이런 파라미터들은 W와 B를 컨트롤합니다. 그러므로 이것들을 하이퍼 파라미터라고 합니다. 이런 하이퍼 파라미터들이 최종적으로 W와 B와 같은 파라미터의 값을 결정짓기 때문에, 딥러닝에서는 여러 개의 다양한 하이퍼 파라미터가 상존하는데요, 나중에서 다루는 코스에서는 모멘텀 요서, 그리고 the 미니 배치 사이즈, 또, 다양한 일반화와
같은 유형의 하이퍼 파라미터를 보도록 하겠습니다. 여기
밑에 있는 용어들이 잘 이해되지 않으시면, 너무 걱정하지 마십시요, 이
내용은 2번째 코스에서 다루도록 하겠습니다. 딥러닝 분야에서는 하이퍼 파라미터의 종류가 머신 러닝 초기 시점과 비교 했을 때, 굉장히 많습니다. 저는
러닝속도인 알파 하이퍼 파라미터를 부르는데 일관되게 하겠습니다. 파라미터 라고 부르지 않고요.
이전에, 머신 러닝 초반부에는 하이퍼 파라미터의 개수가 그리 많지 않았기 때문에 종사자들은 이 내용과 관련해서 조금 천천히 받아들였습니다. 그래서
그냥 파라미터라고 불렀는데요. 엄밀히
이야기하면 알파는 리얼 파라미터가 맞긴 맞습니다. 파라미터를 결정하는 파라미터죠. 알파와 같은 거나, iteration의 수 등등 의 하이퍼 파라미터 말이죠. 그러므로 여러분 개인 어플의 깊은 네트워크를 트레이닝하는 경우에 여러분의 하이퍼 파라미터를 사용할 수 있는 다양한 설정값이 있기 때문에,
단순히 시도를 해봐야 알 수 있습니다.
그렇기 때문에 오늘날의 Applied
Deep Learning 절차는 여러분이 어떤 아이디어가 있으면 예를 들어, 학습
속도에 대한 최적값을 생각하고 있으면, 알파의
값이 0.01이라고 할 수 있겠죠. 이 값을 시도해보고 싶을 수 있습니다. 그러면 도입해서, 시도해보고, 어떻게 작동하는지 볼 수 있습니다. 그리고 그 결과를 바탕으로, 그
값을 바꾸고 싶을 수 있습니다. 학습속도를 0.05로
증가시키고 싶을 수 있겠죠. 만약 러닝 속도를 어떤 값으로 해야 최고일지 잘 모르겠으면, 하나의 알파 값을 시도해보고 j 비용함수가
이렇게 내려가는 것을 직접 본 후에, 조금
더 큰 값의 알파를 러닝 속도로 지정할 수 있겠죠. 그렇게 했는데 비용함수가 폭발적으로 변화를 일으켜 그래프가 갈라지게 되면, 다른 버전을 시도해서 빨리 내려가는 것을 볼 수도 있겠죠. 이 경우 큰 값의 반대이기 때문에 또 다른 버전을 시도해서 지켜봅니다. 비용함수가 이러는 것을 보게 되겠죠. 값을 시도해본 다음에, 여기 이 알파의 값이 꽤 빠른 러닝 속도를 주고, 더 낮은 j 비용함수로
수렴하게 만들어주기 때문에 여기 이 알파 값을 이용할 것 이라고 이야기할 수 있겠죠 이전 슬라이드에서 봤듯이,여러가지 종류의 hybrid 파라미터가 있습니다. 그리고
여러분이 새로운 어플을 시작하는 경우에, 저는 사실 가장 좋은 하이퍼 파라미터 의 값이 어떤 것인지 미리 그 값을 알아내는 것이 매우 어렵다고 생각합니다. 그러므로 어떤 일이 벌어지냐면, 여러분이 다양한 값들을 시도해보는 방법 밖에는 없습니다. 이 동그란 싸이클을 돌면서, 예를
들어, 5개의 숨겨진 레이어를 시도해보고, 이 만큼의 숨겨진 레이어를 시도해보고, 이것을
도입해서 잘 되는지 확인하고, 시도를
반복하는 것입니다.이 슬라이드의 제목은
"apply deep learning is very empirical process" 인데요, empirical process라고 하는 것은 여러 가지 다른 것들을 시도해보고 어떤 것이 잘 작동하는지 확인하는 것을 멋스럽게 표현한 것입니다.제가 추가적으로 본 효과는 오늘날의 딥러닝이 컴퓨터 비전, 음성인식, 자연언어처리와
같은 수 많은 다양한 문제에 적용되고 있다는 점입니다. 또한, 구조적 데이터 어플인 온라인 광고 또는 웹서칭 또는 제품 추천 등등과 같은 것에 적용될 수도 있죠 제가 봤던 것으로 비추어 보았을 때, 한가지 특정 분야의 리서치 연구원들이 다른 분야로 가려고 하는데 가끔은 하이퍼 파라미터에 대한 직관은 이어서 연계되는 경우도 있고, 다른 때에는 안 그런 경우도 있습니다.그러므로 저는 특히 새로운 문제를 시작하는 사람들에게 여러가지 범위의 값들을 먼저 시도해보고 어떤 것이 잘 되는지 확인하라고말씀 드립니다. 다음 코스에서는 시스템적인 방법을 보겠습니다. 여러가지 범위의 값들을 시도하는 시스템적인 방법을 살펴볼 텐데요, 둘째로, 여러분이
한가지 어플에 오랜 기간 작업을 하더라도, 온라인 광고와 같은 분야에서 오랫동안 작업할 수도 있겠죠. 이런
작업을 하면서 가장 최적의 값이 변할 수도 있는데요 러닝속도나, 숨겨진 유닛의 총 개수 등의 값들이 업무를 진행하는 단계에서변할 수도 있습니다. 만약 오늘 가장 최적의 하이퍼 파라미터의 값으로 시스템을 튜닝한다고 하더라도, 가장 최적의 값이 지금으로부터 1년후에는 변할 수도 있습니다. 컴퓨터 인프라가 변해서, 예를
들어, CPU 나 GPU와 같은 것이 완전히 변해서 그럴 수 있습니다. 그러나 한가지 적용할 수 있는 경험의 근거한 규칙은 간간히 몇 개월마다 여러분이 어떤 특정 문제를 장기간 작업한다고 하면, 또는 수년 간 작업하는 경우도 말이죠, 일단 먼저 몇개의 값을 하이퍼 파라미터 값을 시도해보고 더 좋은 값의 하이퍼 파라미터가 있는지도 확인해봅니다. 이렇게
계속 진행을 하다보면 하이퍼 파라미터에 대한 직관적인 이해도가 천천히 늘어나고 어떤 것이 본인 문제에 가장 적합한지 배울 수 있습니다. 저는 이렇게 계속해서 반복적으로 여러가지 하이퍼 파라미터값을 시도해봐야 하는 이런 부분이 매우 불만족스러운 부분일 수도 있다고 생각하는데요, 이 부문은 어쩌면 리서치 부분의 딥러닝에서는 아직도 발전하고 있는 분야이기 때문에 어느 정도 시간이 지나면, 어떤 하이퍼 파라미터가 가장 좋은 값인지 더 나은 가이드를 해줄 수도 있을 것입니다. 하지만 동시에 CPU 와 GPU와 네트워크, 그리고 데이터 세트들이 항상 변하기 때문에 특정 가이드라인이 한동안은 수렴하지 않을 가능성도 있습니다. 그렇기
때문에 계속 다른 값들을 시도해보고 cross-validation set와 같은 것을 통해 평가하고 그렇게 해서 여러분의 문제에 가장 잘 맞는 값을 고르도록 합니다. 이번에 다룬 내용은 하이퍼 파라미터에 관련 내용이 였는데요. 두번째 코스에서는 시스템적으로 어떻게 하이퍼 파라미터의 공간을 탐구하는 방법을 몇 가지 알아보겠습니다. 그렇지만 이제 여러분은 이미 연습문제를 진행하기 위한 충분한 도구를 가지고 있습니다. 연습문제를 진행하기 앞서서 한가지의 아이디어를 더 공유할 텐데요. 바로
딥러닝이 어떻게 인간의 두뇌와 관련 있는지.