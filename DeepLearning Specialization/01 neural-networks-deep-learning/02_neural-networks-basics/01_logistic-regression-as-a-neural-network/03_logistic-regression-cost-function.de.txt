Im vorherigen Video sahen sie das logistische Regressionsmodell. Um die Parameter w und b des logistischen Regressionsmodells zu trainieren, sollten Sie eine Kostenfunktion (= cost function) definieren. Schauen wir uns die Kostenfunktion an, wie wir sie für das Training der logistischen Regression nutzen können. Zur Wiederholung, dies ist was wir aus den vorherigen Folien definiert hatten. Somit wird die Ausgabe "y-Dach" gleich Sigmoid von w transponiert mal x plus b, wobei Sigmoid von z wie hier definiert ist. Um Parameter für ihr Modell zu lernen, seien ihnen ein Trainingsset mit m Trainingsbeispielen gegeben und es erscheint nur natürlich, dass sie daraus die Parameter w und b finden möchten, so dass zumindest für das Trainingsset die erhaltenen Ausgabe - die erhaltenen Vorhersagen aus dem Trainingsset, die wir nur als y-Dach hoch (i) schreiben - nahe bei den zugrundeliegenden Etiketten y hoch (i) aus dem Trainingsset liegen. Um etwas mehr Details in die Gleich oben einzufügen: Wir sagten, dass y-Dach, wie oben definiert, für ein Trainingsbeispiel x definiert ist und selbstverständlich benutzen wir für jedes Trainingsbeispiel in runden Klammern diese hochgestellte Indexierung um die einzelnen Beispiele zu unterscheiden. Ihre Prognose aus dem Trainingsbeispiel (i), es ist y-Dach (i), wird erhalten indem man die Sigmoidfunktion nimmt und sie auf w transponiert mal x hoch (i) - die Eingabe des Trainingsbeispiels - plus b anwendet; zudem kann man z (i) auch wie folgt definieren: z (i) ist gleich w transpose x (i) plus b. So, durch den gesamten Kurs werden wir diese Notationskonvention anwenden, dass das hochgestellte, geklammerte "i" Daten - wie x, y, z oder sonst etwas - referenziert, die mit dem i. Trainingsbeispiels verbunden sind; resp. mit dem i. Beispiel assoziieren. Das also bedeutet das hochgestellte "i" in Klammern. Nun, schauen wir uns an welche Verlustfunktion resp. Fehlerfunktion wir benutzen können, um zu messen wie gut unser Algorithmus ist. Eine Sache, die man tun könnte, wäre den Verlust (L) so zu definieren, dass wenn ihr Algorithmus "y-Dach" ausgibt und die wahre Bezeichnung "y" ist, man daraus möglicherweise den quadratischen oder halben quadratischen Fehler berechnet. Es zeigt sich jedoch, dass man dies tun könnte, aber bezüglich der logistischen Regression Menschen dies in der Regel so nicht tun. Und zwar, wenn man dazu kommt die Parameter lernen zu lassen, findet man heraus, dass das Optimierungsproblem, wir werden später darauf eingehen, nicht konvex wird. Das heißt also: Man gerät in ein Optimierungsproblem, das mehrere lokale Optima aufweist. Damit findet der Gradientenabstieg (= gradient descent) möglicherweise nicht das globale Optimum. Falls Sie die letzten paar Kommentare nicht verstanden haben, machen Sie sich nichts daraus, wir werden in einem späteren Video dazu kommen. Doch die Intuition, die Sie mitnehmen sollten, ist dass Sie diese Funktion "L", genannt "Verlustfunktion" (= loss function), eine Funktion ist, die Sie benötigen um zu messen wie gut ihre Ausgabe "y-Dach" ist, wenn die wahre Bezeichnung "y" beinhaltet. Obwohl die quadratische Fehlerberechnung als eine vernünftige Wahl erscheinen mag, verursacht sie doch, dass der Gradientenabstieg nicht gut funktioniert. Aus diesem Grunde definieren wir für die logistische Regression eine andere Verlustfunktion. Sie spielt eine ähnliche Rolle wie der "quadratische Fehler", ergibt aber ein konvexes Optimierungsproblem. Wie wir in einem späteren Video sehen werden, wird dies viel leichter zu optimieren sein. Was wir daher für die logistische Regression verwenden, ist die nachfolgende Verlustfunktion, die ich gleich an dieser Stelle aufführe: minus ((y mal log y-Dach) plus ((eins minus y) mal log(eins minus y-Dach))). Hier ein paar Intuitionen weshalb diese Verlustfunktion Sinn ergibt: Beachten Sie, dass wenn wir den quadratischen Fehler benutzen, möchte man dass der quadratische Fehler so klein wie möglich ist. Und mit dieser Verlustfunktion für die logistischen Regression wollen wir dies ebenfalls so klein wie möglich. Um zu verstehen weshalb dies sinnvoll ist, wollen wir die beiden Fälle anschauen: Im ersten Fall sagen wir y ist gleich eins, dann ist die Verlustfunktion "y-Dach" Komma "y" einfach nur dieser erste Term, mit diesem negativen Zeichen. Also dieses negative log von "y-Dach"; sofern y gleich 1 ist. Weil, wenn y gleich 1 ist, dann wird der zweite Term 1 minus y gleich 0. Dies besagt also, wenn "y" gleich 1 ist, möchte man negativ log von "y-Dach" so groß wie möglich, so das bedeutet man möchte dass der log von "y-Dach" groß wird, so groß wie möglich und das bedeutet man möchte, dass "y-Dach" groß ist. Aber, weil - wie Sie wissen - "y-Dach" eine Sigmoidfunktion ist, kann dies nie größer als 1 werden. Also, dies besagt, wenn "y" gleich 1 ist, möchte man "y-Dach" so groß wie möglich. Aber, weil dies nie größer als 1 sein kann, sagen wir besser man möchte dass "y-Dach" ebenfalls nahe bei 1 liegt. Im anderen Fall, wenn y gleich 0 ist, Wenn y gleich 0 ist, dann wird dieser erste Term der Verlustfunktion ebenfalls 0; gerade weil y = 0 ist. Folglich definiert der zweite Term die Verlustfunktion. Damit wird die Verlustfunktion negativ log (1 minus "y-Dach") And daher, wenn Sie in ihrem Lernverfahren versuchen die Verlustfunktion klein zu machen, bedeutet dies Sie möchten, dass der log von 1 minus "y-Dach" groß wird und - weil hier ein negatives Zeichen steht - und durch ähnliche Begründungen kann man folgern, dass diese Verlustfunktion versucht "y-Dach" so klein wie möglich zu machen. Und nochmals, weil "y-Dach" zwischen 0 und 1 sein muss, besagt dies, dass wenn y gleich 0 ist, dass ihre Verlustfunktion die Parameter zwingt, "y-Dach" so nahe wie möglich an 0 zu bringen. Nun, es gibt viele Funktionen mit dem Rafidah Effekt, dass wenn y gleich 1 ist, wir versuchen "y-Dach" groß zu machen und wenn y gleich 0 ist, wir versuchen "y-Dach" klein zu machen. Wir haben soeben hier in grün eine etwas informelle Rechtfertigung für diese spezielle Verlustfunktion gegeben. Später werden wir ein optionales Video anbieten, das eine formalere Begründung gibt, weshalb wir in der logistischen Regression gerne die Verlustfunktion in dieser besonderen Form benutzen. Abschließend: Die Verlustfunktion wurde im Hinblick auf ein einzelnes Trainingsbeispiel definiert. Es misst, wie gut man dies bei einem einzelnen Trainingsbeispiel macht. Ich werde jetzt etwas definieren, was man die Kostenfunktion nennt, welche misst wie gut unser Tun in Bezug auf die gesamte Trainingsmenge ist. Die Kostenfunktion J, welche auf ihre Parameter "w" und "b" angewendet wird, wird der Durchschnitt 1 über "m" mal die Summe der Verlustfunktionen, die auf jedes einzelne der Trainingsbeispiele angewendet wurde. Wobei hier "y-Dach" selbstverständlich die ausgegebene Vorhersage durch den Algorithmus der logistischen Regression ist, wobei - wie Sie wissen - eine partikuläre Menge von Parametern w und b benutzt wird. Und, wenn wir dies alles berücksichtigen, wird dies negativ 1 dividiert durch m mal die Summe von "i" gleich "1" bis "m" der Definition der Verlustfunktion; wobei die y(i) log "y-Dach"(i) plus (1 minus y(i) mal log (1 minus "y-Dach"(i))). Ich denke, ich könnte hier eckige Klammern setzen. Man beachte, das Minuszeichen ist hier ausserhalb von allem anderen. Also, die Terminologie, welche ich benutzen werde, ist dass die Verlustfunktion wird nur auf ein einzelnes Trainingsbeispiel angewendet, wie hier und die Kostenfunktion sind die Kosten für Ihre Parameter. Um die Parameter w und b des logistischen Regressionsmodells zu trainieren, werden wir versuchen Parameter w und b so zu finden, dass die Kostenfunktion J über allem, wie unten beschrieben, minimiert wird. Alles in allem, haben Sie nun gesehen wie das Modell der Logistischen Regression, die Verlustfunktion des Trainingsbeispiels und die umfassende Kostenfunktion für die Parameter ihres Algorithmus aussieht. Es stellt sich heraus, dass die Logistische Regression als ein sehr, sehr kleines neuronales Netz betrachtet werden kann. Damit Sie ein Gefühl darüber erhalten können, wie neuronale Netze funktionieren, werden wir im nächsten Video darüber besprechen. Lasst uns zum nächsten Video gehen, das zeigt wie man die logistische Regression als ein sehr kleines neuronales Netzwerk betrachten kann.