1
00:00:03,320 --> 00:00:05,850
ニューラルネットワークは
大げさに表現されているところがあります

2
00:00:05,850 --> 00:00:10,170
ニューラルネットワークが効果的に動作することを考えると
大げさとも言えないものもあります

3
00:00:10,170 --> 00:00:11,220
ただニューラルネットワークで

4
00:00:11,220 --> 00:00:15,710
作られた経済的価値のほとんどは
教師あり学習という種類の

5
00:00:15,710 --> 00:00:18,970
機械学習の手法でもたらされています

6
00:00:18,970 --> 00:00:22,120
教師あり学習とは何なのか
例を見てみましょう

7
00:00:22,120 --> 00:00:26,030
教師あり学習では
入力のx があり

8
00:00:26,030 --> 00:00:30,210
出力のy が割り当たるような関数を求めるものです

9
00:00:30,210 --> 00:00:34,890
例えばここでは住宅価格を
予測するアプリケーションを見たところです

10
00:00:34,890 --> 00:00:40,850
住宅の特徴を入力することで
価格y を出力または予測します

11
00:00:40,850 --> 00:00:45,180
これから紹介する例では
ニューラルネットワークが適用され効果的に

12
00:00:45,180 --> 00:00:46,940
学習しました。

13
00:00:46,940 --> 00:00:51,180
こんにちの深層学習で
最も利益の出る適用例は

14
00:00:51,180 --> 00:00:56,150
最も刺激的ではないかもしれませんが
利益が出るのはオンライン広告です

15
00:00:56,150 --> 00:01:02,770
オンライン広告ではユーザーの情報と

16
00:01:02,770 --> 00:01:07,020
候補の広告の情報を入力することで
ニューラルネットワークは

17
00:01:07,020 --> 00:01:10,700
ユーザーが広告をクリックするかどうかを
かなり正確に予測できるようになりました

18
00:01:10,700 --> 00:01:11,770
そして

19
00:01:11,770 --> 00:01:15,800
ユーザーに最もクリックしそうな広告を表示することは

20
00:01:15,800 --> 00:01:20,830
ある企業群では信じられないほど利益を生む
ニューラルネットワークの適用例となっています

21
00:01:20,830 --> 00:01:24,040
というのも最もクリックしそうな広告を
表示することができることは

22
00:01:24,040 --> 00:01:26,690
オンライン広告を行う巨大企業にとって

23
00:01:26,690 --> 00:01:29,200
収益を左右する直接的な影響があるからです

24
00:01:30,630 --> 00:01:35,150
コンピュータービジョンもまた
その多くが深層学習によって

25
00:01:35,150 --> 00:01:37,050
ここ数年で大きな進歩を遂げました

26
00:01:37,050 --> 00:01:41,140
ここでは画像を入力して
何の画像か示す画像番号を出力します

27
00:01:41,140 --> 00:01:45,290
例えば１から1,000までの番号で
その画像がどの画像が示されます

28
00:01:45,290 --> 00:01:47,300
1,000個の異なる画像のどれかを示します

29
00:01:47,300 --> 00:01:50,500
写真をタグ付けするのにも使えます

30
00:01:50,500 --> 00:01:54,520
音声認識の最近の進歩も
とても刺激的です

31
00:01:54,520 --> 00:01:57,910
ニューラルネットワークに
音声ファイルを入力すると

32
00:01:57,910 --> 00:02:00,930
音声のテキストが出力されます

33
00:02:00,930 --> 00:02:05,400
深層学習のおかげで
機械翻訳も大きな進歩を遂げました

34
00:02:05,400 --> 00:02:09,400
ニューラルネットワークに英語の文を入力すれば
出力として

35
00:02:09,400 --> 00:02:11,010
中国語の文を出せます

36
00:02:11,010 --> 00:02:15,930
自動運転ではレーダー情報や

37
00:02:15,930 --> 00:02:20,600
車の前方の画像を入力することで

38
00:02:20,600 --> 00:02:25,080
周りの車の位置を教えてくれるように
ニューラルネットワークに

39
00:02:25,080 --> 00:02:26,100
学習させることができます

40
00:02:26,100 --> 00:02:30,870
自動運転システムの鍵となる部品となりました

41
00:02:30,870 --> 00:02:35,730
つまり特定の問題に対して
賢明にx とy を選択し

42
00:02:35,730 --> 00:02:39,360
この教師あり学習の部品を

43
00:02:39,360 --> 00:02:45,000
例えば自動運転車のような
より大きなシステムに適合させます

44
00:02:45,000 --> 00:02:48,660
ニューラルネットワークで創造される価値の多くは
このようなところから生じています

45
00:02:48,660 --> 00:02:52,880
様々な適用先に対して
少しずつ異なる種類のニューラルネットワークが

46
00:02:52,880 --> 00:02:54,960
役立つとわかってきました

47
00:02:54,960 --> 00:03:00,100
例えば 先ほどのビデオで見た
不動産の適用例では

48
00:03:00,100 --> 00:03:04,520
普遍的で標準的なニューラルネットワークの
アーキテクチャーを使用しました

49
00:03:04,520 --> 00:03:08,510
不動産でもオンライン広告でも
見てきたように

50
00:03:08,510 --> 00:03:11,620
比較的標準的なニューラルネットワークを使います

51
00:03:13,410 --> 00:03:19,120
画像への適用では
畳みこみニューラルネットワークを使用することが多く

52
00:03:19,120 --> 00:03:20,680
CNN とよく略されます

53
00:03:21,730 --> 00:03:24,000
シーケンスデータでは

54
00:03:24,000 --> 00:03:27,840
例えば音には一時的な側面があります

55
00:03:27,840 --> 00:03:32,990
音は時とともに再生されるもので
ごく必然的に

56
00:03:32,990 --> 00:03:38,110
１次元の時系列データまたは
１次元の一時的なものの連続で表されます

57
00:03:38,110 --> 00:03:42,420
シーケンスデータには
RNNをよく使います

58
00:03:42,420 --> 00:03:45,810
再帰型ニューラルネットワークです

59
00:03:45,810 --> 00:03:50,270
英語や中国語などの言語ではアルファベットか語が
１つずつ使われます

60
00:03:50,270 --> 00:03:54,820
このため言語も必然的にシーケンスデータで表されます

61
00:03:54,820 --> 00:04:00,700
これらの適用例では
より複雑な形態のRNN がよく使われます

62
00:04:00,700 --> 00:04:04,360
自動運転車のように
さらに複雑な適用例では

63
00:04:04,360 --> 00:04:09,200
画像に対してはCNN
畳み込みニューラルネットワークの構造が推奨され

64
00:04:09,200 --> 00:04:12,480
レーダーに対しては全く異なるものが必要です

65
00:04:12,480 --> 00:04:15,360
これには特別に作られた
より複雑で

66
00:04:15,360 --> 00:04:19,880
複合的に組み合わされた
ニューラルネットワーク構造を使うかもしれません

67
00:04:20,880 --> 00:04:26,100
もう少し具体的に
標準的なCNN やRNN の構造を

68
00:04:26,100 --> 00:04:27,950
見てみましょう

69
00:04:27,950 --> 00:04:32,790
書籍などでこんな画像を
見たことがあるでしょうか

70
00:04:32,790 --> 00:04:34,740
これが標準的なニューラルネットです

71
00:04:34,740 --> 00:04:36,800
このような画像をみたかと思います

72
00:04:36,800 --> 00:04:41,830
そしてこれが畳み込みニューラルネットワークの例です

73
00:04:41,830 --> 00:04:45,950
今後のコースで画像が意味するものと
どうやって作るかを学びます

74
00:04:45,950 --> 00:04:51,560
畳み込みネットワークは
画像データによく使われます

75
00:04:51,560 --> 00:04:54,100
この画像も見たことがあるかもしれません

76
00:04:54,100 --> 00:04:57,590
今後のコースで
どう作るのか学びます

77
00:04:57,590 --> 00:05:00,180
再帰型ニューラルネットワークは
時系列的な要素を持つような

78
00:05:00,180 --> 00:05:06,220
１次元のシーケンスデータに特に有効です

79
00:05:06,220 --> 00:05:10,310
機械学習を構造化データと
非構造化データの両方に

80
00:05:10,310 --> 00:05:14,000
適用できると聞いたかもしれません

81
00:05:14,000 --> 00:05:14,960
これがその用語の意味です

82
00:05:14,960 --> 00:05:18,620
構造化データは
基本的にデータベースのデータです

83
00:05:19,910 --> 00:05:25,010
例えば住宅価格の予測では
データベースがあり

84
00:05:25,010 --> 00:05:28,140
列が住宅の面積や寝室の数を示します

85
00:05:28,140 --> 00:05:33,460
これが構造化データです
またユーザーが広告をクリックするかの予測では

86
00:05:33,460 --> 00:05:37,330
年齢などのユーザーの情報や
広告の情報があり

87
00:05:37,330 --> 00:05:41,590
予測しようとするラベルのy があります

88
00:05:41,590 --> 00:05:46,470
これが構造化データで
特徴のそれぞれが十分に定義されています

89
00:05:46,470 --> 00:05:49,740
例えば家の面積や寝室の数や

90
00:05:49,740 --> 00:05:54,530
ユーザーの年齢などです

91
00:05:54,530 --> 00:06:00,520
対照的に 非構造化データが指すのは
音や画像で

92
00:06:00,520 --> 00:06:05,790
画像や文字が何かを認識することが目的になることがあります

93
00:06:05,790 --> 00:06:09,230
この例では画像の画素の値や
文字の一部の語が

94
00:06:09,230 --> 00:06:12,190
特徴量となるでしょう

95
00:06:12,190 --> 00:06:14,330
歴史的にコンピューターにとっては

96
00:06:14,330 --> 00:06:19,480
非構造化データの方が構造化データよりも
理解が困難でした

97
00:06:19,480 --> 00:06:24,270
人類は画像や音の手がかりの理解を
非常に上手くできるように

98
00:06:24,270 --> 00:06:26,270
進化しました

99
00:06:26,270 --> 00:06:28,390
文字はより最近の発明ですが

100
00:06:28,390 --> 00:06:31,760
人類は非構造化データを
非常にうまく理解するのです

101
00:06:31,760 --> 00:06:36,800
深層学習やニューラルネットワークのおかげで
この進化で最も刺激的なもののひとつは

102
00:06:36,800 --> 00:06:41,280
数年前に比べてコンピューターが非構造化データを

103
00:06:41,280 --> 00:06:46,320
かなり上手に理解できるようになったことです

104
00:06:46,320 --> 00:06:51,240
このおかげで多くの刺激的なことに
新たに適用できるようになりました

105
00:06:51,240 --> 00:06:55,220
音声認識、画像認識、文字の自然言語処理などの用途です

106
00:06:56,230 --> 00:07:00,180
ほんの２～３年前と比べても
かなりのことができるようになっています

107
00:07:00,180 --> 00:07:03,940
非構造化データが理解できることには
自然に感情移入してしまうため

108
00:07:03,940 --> 00:07:08,250
メディアでは非構造化データに対する
ニューラルネットワークの成功例をよく聞くかもしれません

109
00:07:08,250 --> 00:07:13,060
ニューラルネットワークが猫を認識できることは
ただただ凄いことだからです

110
00:07:13,060 --> 00:07:15,750
みんなが好ましい進歩だと思いますし
どんな意味を持つかを知っています

111
00:07:15,750 --> 00:07:19,290
しかしニューラルネットワークがもたらす

112
00:07:19,290 --> 00:07:24,270
短期的な経済的価値の創造は
構造化データに関するものが多いです

113
00:07:24,270 --> 00:07:28,690
かなり効率的になった広告システムや
利益を最大化する推薦システムや

114
00:07:28,690 --> 00:07:33,730
多くの企業が正確な予測を行うために持つ
巨大なデータベースを

115
00:07:33,730 --> 00:07:37,290
処理できるような
より強力な能力に関するものです

116
00:07:37,290 --> 00:07:41,230
このコースでは多くの方法を紹介しますが

117
00:07:41,230 --> 00:07:44,690
これは構造化データ
非構造化データの両方に適用できます

118
00:07:44,690 --> 00:07:46,970
アルゴリズムを説明する目的で

119
00:07:46,970 --> 00:07:52,210
非構造化データの例をより多く使いますが

120
00:07:52,210 --> 00:07:56,280
テーマの中でニューラルネットワークの
適用方法を考えるなかで

121
00:07:56,280 --> 00:08:01,360
構造化データ、非構造化データの両方での
使い方を理解してもらいたいです

122
00:08:02,590 --> 00:08:06,390
まとめるとニューラルネットワークによって
教師あり学習は大きく形を変え

123
00:08:06,390 --> 00:08:09,500
膨大な経済的価値が生まれています

124
00:08:09,500 --> 00:08:12,910
しかしニューラルネットワークの裏にある
基本的な技術的考えは

125
00:08:12,910 --> 00:08:16,520
もう何十年も存在しているものです

126
00:08:16,520 --> 00:08:20,980
ではなぜつい最近になってやっと盛り上がり
上手く動作するようになったのでしょうか

127
00:08:20,980 --> 00:08:24,970
次のビデオではなぜ近年になって初めて
ニューラルネットワークが利用可能で

128
00:08:24,970 --> 00:08:28,940
信じられないほど
強力なツールになったのかを紹介します