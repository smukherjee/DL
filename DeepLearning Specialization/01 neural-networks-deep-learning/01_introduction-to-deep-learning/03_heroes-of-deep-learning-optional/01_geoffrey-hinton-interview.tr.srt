1
00:00:00,620 --> 00:00:03,610
deeplearning.ai tarafından verilen bu dersin bir kısmı olarak

2
00:00:03,610 --> 00:00:07,590
sadece derin öğrenmedeki teknik fikirleri öğretmeyi değil
 aynı zamanda

3
00:00:07,590 --> 00:00:11,658
bazı insanları,
 bazı derin öğrenme kahramanlarını tanıtmak.

4
00:00:11,658 --> 00:00:13,160
Tanıttığımız bu insanlar

5
00:00:13,160 --> 00:00:17,700
kurslarda öğrenilen çoğu temel fikri
 icat eden bilim insanlarıdır.

6
00:00:17,700 --> 00:00:21,420
Ayrıca bu videolarda, 
 derin öğrenme öncülerinden

7
00:00:21,420 --> 00:00:24,990
bu alana nasıl giriş yapabileceğinize
 dair kariyer tavsileri isteyeceğim.

8
00:00:24,990 --> 00:00:27,805
Derin öğrenme alanında araştırma yapmak
 ya da iş bulmak için tavsiyeler.

9
00:00:27,805 --> 00:00:30,156
Bu röportaj serisinin ilki olarak

10
00:00:30,156 --> 00:00:34,228
sizlere Geoffrey Hinton röportajını
 sunmaktan mutluluk duyuyorum.

11
00:00:38,427 --> 00:00:44,150
Hoşgeldin Geoff, öncelikle deeplearning.ai ailesiyle
 bu röportajı yaptığın için teşekkür ederim.

12
00:00:44,150 --> 00:00:46,550
Davetiniz için teşekkürler.

13
00:00:46,550 --> 00:00:50,088
Bence bulunduğumuz bu noktada
 derin öğrenme konusu üzerine

14
00:00:50,088 --> 00:00:52,835
gezegendeki herkesten daha fazla
 fikir icat ettiğini söyleyebiliriz.

15
00:00:52,835 --> 00:00:57,650
Öyle ki çok fazla insan seni 
derin öğrenmenin babası olarak anıyor.

16
00:00:57,650 --> 00:01:01,529
Aslında az önceki sohbetimizden sonra 
seni böyle adlandıran ilk kişinin

17
00:01:01,529 --> 00:01:05,600
ben olduğumu farkettim 
ve bunu yaptığım için oldukça mutluyum.

18
00:01:06,780 --> 00:01:11,320
Birçok insan seni efsane olarak biliyor.
 Ben de şöyle bir soruyla başlamak istiyorum:

19
00:01:11,320 --> 00:01:15,030
Bu efsanenin arkasındaki
 kişisel hikaye nedir?

20
00:01:15,030 --> 00:01:19,980
En başa gidecek olursak, 
 yapay zeka araştırmalarına nasıl başladın?

21
00:01:19,980 --> 00:01:21,520
Makine öğrenmesi ve sinir ağları çalışmalarına?

22
00:01:22,730 --> 00:01:26,960
Ben lisedeyken her konuda
 benden iyi olan bir arkadaşım vardı.

23
00:01:26,960 --> 00:01:31,220
Arkadaşım oldukça parlak bir matematikçiydi.

24
00:01:31,220 --> 00:01:37,010
Bir gün okula geldi ve bana
 beyin hologramlar kullanıyor biliyor muydun dedi.

25
00:01:38,190 --> 00:01:44,161
Sanırım bu 1966 yılındaydı ve
 hologram nedir diye karşılık verdim.

26
00:01:44,161 --> 00:01:47,390
Ve o da bir hologramda bulunan objenin
 yarısını kessen bile

27
00:01:47,390 --> 00:01:49,730
resmin bütünlüğünü koruduğunu söyledi.

28
00:01:49,730 --> 00:01:53,466
Ve benzer şekilde beyindeki anılar
 beynin bütününe dağıtılıyor olabilir.

29
00:01:53,466 --> 00:01:56,022
Sanırım arkadaşım Lashley deneylerini okumuştu.

30
00:01:56,022 --> 00:01:57,939
Bu deneylerde
 fare beyninin bir kısmını ayırıyorsunuz

31
00:01:57,939 --> 00:02:01,740
ve sonunda bir anının belli bir noktada depolandığını 
bulmanın çok zor olduğunu görüyorsunuz.

32
00:02:04,411 --> 00:02:08,920
Beynin anıları nasıl depoladığı
 ilk defa burda ilgimi çekmişti.

33
00:02:10,180 --> 00:02:12,220
Daha sonra üniversiteye gittiğimde

34
00:02:12,220 --> 00:02:15,130
ilk olarak fizyoloji ve fizik
 okuyarak başladım.

35
00:02:16,400 --> 00:02:17,731
Sanırım Cambridge'de okurken

36
00:02:17,731 --> 00:02:20,260
fizyoloji ve fiziği birlikte okuyan
 tek kişi bendim.

37
00:02:21,888 --> 00:02:25,270
Ondan sonra bunlardan vazgeçtim

38
00:02:25,270 --> 00:02:29,170
ve felsefe okumayı denedim.
 Çünkü bu daha fazla kavrayış sağlar diye düşündüm.

39
00:02:29,170 --> 00:02:32,780
Orada gördüğüm eksiklik de

40
00:02:32,780 --> 00:02:37,130
yanlış olduğunu söyledikleri bir şeyi
 ayırt etme konusundaydı.

41
00:02:37,130 --> 00:02:39,420
Oradan da psikolojiye geçtim.

42
00:02:41,988 --> 00:02:45,920
Ve psikolojide oldukça çok basit teoriler vardı. Bu da bana

43
00:02:45,920 --> 00:02:49,620
beynin nasıl çalıştığını açıklama konusunda
 çok ama çok yetersiz geldi.

44
00:02:49,620 --> 00:02:52,737
En sonunda biraz ara verdim 
ve bir süre marangozluk yaptım.

45
00:02:52,737 --> 00:02:57,169
Marangozluktan sonra da yapay zekayı denemek için Edinburgh'ya gittim.

46
00:02:57,169 --> 00:02:59,580
Langer Higgins ile yapay zeka çalışmak için

47
00:02:59,580 --> 00:03:02,662
Onun sinir ağları üzerinde çok iyi çalışmaları vardı.

48
00:03:02,662 --> 00:03:07,830
Ama sinir ağlarından umudu kesmek üzereydi. 
Winograd'ın tezinden epey etkilenmişti.

49
00:03:07,830 --> 00:03:11,460
Onunla çalışmaya başladığımda 
benim eski moda şeylerle ilgilendiğimi düşünüyordu.

50
00:03:11,460 --> 00:03:14,210
Ona göre sembolik yapay zeka üzerine eğilmeliydim .

51
00:03:14,210 --> 00:03:18,210
Bu konu üzerine çok kavga ettik
 ama ben inandığım şeyi yapmaya devam ettim.

52
00:03:18,210 --> 00:03:21,138
Peki sonra ne oldu?

53
00:03:21,138 --> 00:03:28,033
Eninde sonunda yapay zeka alanında doktoramı aldım. 
Fakat akabinde Britanya'da iş bulamadım.

54
00:03:28,033 --> 00:03:30,979
Neyse ki Kaliforniya'daki Sloan bursu için

55
00:03:30,979 --> 00:03:36,070
güzel bir reklam gördüm.
 Bursu kazanmayı da başardım.

56
00:03:36,070 --> 00:03:40,625
Ve Kaliforniya'ya gittim.
 Orada her şey farklıydı.

57
00:03:40,625 --> 00:03:46,685
Britanya'da sinir ağları
 saçma olarak algılanıyordu.

58
00:03:46,685 --> 00:03:50,272
Kaliforniya'da ise işler farklıydı.

59
00:03:50,272 --> 00:03:56,640
Don Norman ve David Rumelhart
 sinir ağları hakkındaki fikirlere açıktılar.

60
00:03:56,640 --> 00:04:00,720
İlk defa, bulunduğum bir yerde
 beynin nasıl çalıştığı hakkında düşünmek

61
00:04:00,720 --> 00:04:03,290
ve bunun psikolojiyle 
nasıl ilişkilendirilebileciği hakkında düşünmek

62
00:04:03,290 --> 00:04:05,650
çok pozitif bir şey olarak görülüyordu.

63
00:04:05,650 --> 00:04:06,936
Orada oldukça keyifli bir ortam vardı.

64
00:04:06,936 --> 00:04:09,792
Özellikle,
 David Rumelhart ile birlikte çalışmak harikaydı.

65
00:04:09,792 --> 00:04:12,968
Anlıyorum. 
Yani bu senin USCD günlerin ve

66
00:04:12,968 --> 00:04:16,177
Rumelhart ile birlikte, 1982 civarlarında,

67
00:04:16,177 --> 00:04:20,182
ufuk açıcı "geriyayılım" makalesini
 yazdığınız zamanlar mıydı?

68
00:04:20,182 --> 00:04:23,292
Aslına bakarsan
 olanlar bundan çok daha karmaşıktı.

69
00:04:23,292 --> 00:04:24,796
Neler oldu?

70
00:04:24,796 --> 00:04:28,214
Sanırım 1982'nin başlarıydı,

71
00:04:28,214 --> 00:04:32,900
David Rumelhart, ben ve Ron Williams birlikte

72
00:04:32,900 --> 00:04:37,967
geriyayılım algoritmasını geliştirdik.

73
00:04:37,967 --> 00:04:42,291
Fikir babası David Rumelhart diyebiliriz.

74
00:04:42,291 --> 00:04:46,390
Daha sonra öğrendik ki başka insanlar da
 bizden bağımsız icat etmişler.

75
00:04:46,390 --> 00:04:52,798
David Parker icat etmiş.
 Muhtemelen biz geliştirdikten sonra ama yayımlamadan önce yapmış.

76
00:04:52,798 --> 00:04:56,425
Paul Werbos zaten birkaç yıl önce icat etmiş

77
00:04:56,425 --> 00:04:58,860
ama kimse ilgi göstermemiş.

78
00:04:58,860 --> 00:05:01,923
Ve benzer algoritmalari geliştiren
 başka insanlar da vardı.

79
00:05:01,923 --> 00:05:04,340
Geriyayılım denilince kastedilen de açık değil zaten.

80
00:05:04,340 --> 00:05:08,055
Ama türev almak için zincir kuralını kullanmanın
 orijinal olmadığı kesin.

81
00:05:08,055 --> 00:05:12,484
Anlıyorum.
 Peki, bu algoritmanın yaygınlaşmasında

82
00:05:12,484 --> 00:05:15,940
sizin makale niye bu kadar etkili oldu?

83
00:05:15,940 --> 00:05:20,540
Tabiri caizse
 sizin makale algoritmanın kabul edilmesinde

84
00:05:20,540 --> 00:05:22,934
bir salgın etkisi yarattı.

85
00:05:22,934 --> 00:05:26,675
Biz 1986'da Nature dergisinde
 bir makale yayımlamayı başardık.

86
00:05:26,675 --> 00:05:30,580
Ben de makale yayımlanabilsin diye
 bayağı politika yaptım.

87
00:05:30,580 --> 00:05:34,622
Hakemlerden birinin
 muhtemelen Stuart Sutherland olacağını öğrendim.

88
00:05:34,622 --> 00:05:36,992
Ki kendisi Britanya'da çok bilinen bir psikologtu.

89
00:05:36,992 --> 00:05:38,815
Kendisiyle uzun süren bir konuşma yapmaya gittim.

90
00:05:38,815 --> 00:05:41,480
Ona tam olarak ne yaptığımızı açıkladım.

91
00:05:41,480 --> 00:05:44,140
Ve o da geriyayılımın kelimeler için gösterim

92
00:05:44,140 --> 00:05:48,970
öğrenebildiğini başarmamızdan çok etkilendi.

93
00:05:48,970 --> 00:05:52,490
Ve o gösterimlere baktığınızda
-ki bunlar küçük vektörlerdir-

94
00:05:52,490 --> 00:05:55,950
her bir özniteliğin anlamını görebilirsiniz.

95
00:05:55,950 --> 00:06:01,600
Biz aslında bunu 
akrabalık ilişkileri ile ilgili üçlü kelimelerde eğiterek yaptık. 

96
00:06:01,600 --> 00:06:06,420
Mesela, Mary'nin annesi Victoria'dır.

97
00:06:06,420 --> 00:06:11,550
Ve siz ilk iki kelimeyi verdiğinizde
 program üçüncü kelimeyi tahmin ediyordu.

98
00:06:11,550 --> 00:06:12,970
Modeli eğittikten sonra,

99
00:06:12,970 --> 00:06:17,780
kelimelerin gösterimlerinde
 bütün öznitelikleri görebiliyordunuz.

100
00:06:17,780 --> 00:06:19,950
Mesela kişinin uyruğunu,

101
00:06:19,950 --> 00:06:25,180
hangi nesilden oldukları, 
ne tür akrabalık ilişkisinde oldukları gibi.

102
00:06:25,180 --> 00:06:27,680
Stuart Sutherland'ın çok etkilendiği de buydu.

103
00:06:27,680 --> 00:06:29,666
Bence makale de bu sebepten kabul edildi.

104
00:06:29,666 --> 00:06:33,905
Kelime gömme modellerinin daha çok başında,
 siz kelime anlamlarının

105
00:06:33,905 --> 00:06:38,390
öğrenilmiş özniteliklerini
 eğitim algoritmasında görmeye başladınız.

106
00:06:38,390 --> 00:06:44,090
Evet.
 Psikolojinin perspektifinden bunun önemi

107
00:06:44,090 --> 00:06:49,740
bilginin ne olduğuna dair 
tamamen farklı iki fikri birleştirmesiydi.

108
00:06:49,740 --> 00:06:53,460
Psikolojinin görüşü bir kavramın bir sürü öznitelikten oluştuğuydu.

109
00:06:53,460 --> 00:06:56,810
Bu görüşü destekleyen çok kanıt da var.

110
00:06:56,810 --> 00:07:02,180
O zamanlar bir de yapay zeka camiasının görüşü vardı
ki bu oldukça yapısalcı bir görüştü.

111
00:07:02,180 --> 00:07:06,190
Yapısalcı görüşe göre bir kavram,
 diğer kavramlarla kurduğu ilişkiydi.

112
00:07:06,190 --> 00:07:09,820
Ve bir kavramı yakalamak isterseniz,
 çizge yapısı gibi bir şey yapmak zorundaydınız.

113
00:07:09,820 --> 00:07:11,640
Ya da belki bir anlamsal ağ.

114
00:07:11,640 --> 00:07:15,875
Bizim geriyayılım örneğimiz ise şunu gösterdi:

115
00:07:15,875 --> 00:07:21,070
Çizge yapısına ya da bizim örnekteki gibi 
soy ağacına girecek bilgiyi algoritmaya verirsiniz

116
00:07:22,080 --> 00:07:26,920
ve o da bu bilgiyi özniteliklere çevirir. Algoritma bu öznitelikleri

117
00:07:26,920 --> 00:07:33,470
kullanarak yeni tutarlı bilgi türetir, yani geneller.

118
00:07:33,470 --> 00:07:38,438
Önemli olan şey ise bu ileri geri mekik dokumaydı.

119
00:07:38,438 --> 00:07:43,000
Çizgesel gösterim veya 
soy ağacının yapılandırılmış gösterimi ile

120
00:07:43,000 --> 00:07:46,715
kişilerin büyük öznitelik vektörleri 
olarak gösteriminin arasındaki mekik dokuma.

121
00:07:46,715 --> 00:07:50,873
Ve aslında çizgemsi gösterimlerden
 öznitelik vektörleri elde edebiliyordunuz.

122
00:07:50,873 --> 00:07:51,469
öznitelik vektörleri

123
00:07:51,469 --> 00:07:54,995
Aynı şekilde, öznitelik vektörlerinden de daha fazla çizgemsi gösterimler elde edebiliyordunuz.

124
00:07:54,995 --> 00:07:57,730
Yani bunlar 1986'da oluyor?

125
00:07:57,730 --> 00:08:02,430
90'ların başlarında,
 Bengio gösterdi ki gerçek veriyi alıp

126
00:08:02,430 --> 00:08:07,420
mesela bir İngilizce metni alıp aynı yöntemleri uyguladığınızda

127
00:08:07,420 --> 00:08:13,980
İngilizce metinlerden gerçek kelimeler için 
gömmeler elde edebilirsiniz. Bu insanları çok etkiledi.

128
00:08:13,980 --> 00:08:18,682
Sanırım yakın zamanlarda GPU ve süperbilgisayar 
gibi hızlı bilgisayarların

129
00:08:18,682 --> 00:08:21,750
derin öğrenmeyi nasıl geliştirdiğini çok konuştuk.

130
00:08:21,750 --> 00:08:26,376
Fakat daha 86 ve 90'ların başı arasında bile

131
00:08:26,376 --> 00:08:29,570
Bengio ve senin aranda
 bu trendin başlangıcı varmış zaten.

132
00:08:30,600 --> 00:08:32,630
Evet, bu konuda büyük gelişmeler oldu.

133
00:08:32,630 --> 00:08:41,440
Mesela benim 86'da kullandığım lisp bilgisayarı
 bir megaflopun onda birinden daha yavaştı.

134
00:08:41,440 --> 00:08:47,720
93'e geldiğimizde ise insanlar
 10 megaflop kullanmaya başlamıştı.

135
00:08:47,720 --> 00:08:49,600
-Anlıyorum. 
-100 kat artış oldu yani

136
00:08:49,600 --> 00:08:51,770
ve bu da kolay kullanımın olduğu bir zamandı.

137
00:08:51,770 --> 00:08:53,580
Çünkü bilgisayarlar 
giderek daha hızlı hale geliyordu.

138
00:08:53,580 --> 00:08:56,960
Son birkaç on yılda sinir ağları ve

139
00:08:56,960 --> 00:08:59,970
derin öğrenmenin 
birçok parçasını icat ettiniz.

140
00:08:59,970 --> 00:09:02,670
Şunu merak ediyorum;
 icat ettiğiniz onca şey arasında

141
00:09:02,670 --> 00:09:05,050
hangisiyle ilgili bugün en fazla heyecan duyuyorsunuz?

142
00:09:06,940 --> 00:09:09,590
En güzel işimin Terry Sejnowski ile yaptığımız

143
00:09:09,590 --> 00:09:12,620
Boltzmann makineleri üzerine olduğunu düşünüyorum.

144
00:09:12,620 --> 00:09:14,500
Çok ama çok basit öğrenme algoritması keşfettik.

145
00:09:14,500 --> 00:09:18,830
Bu, sadece birkaç düğümünü görebildiğin 

146
00:09:18,830 --> 00:09:23,550
çok büyük sıkı bağlı ağlara uyguladığın bir algoritma.

147
00:09:23,550 --> 00:09:27,730
Bu şekilde saklı gösterimleri öğreniyordu
 ve çok basit bir algoritmaydı.

148
00:09:27,730 --> 00:09:31,130
Pekala bir beyinde bulunabilecek
 bir şey gibi duruyordu çünkü

149
00:09:31,130 --> 00:09:34,210
her sinaps sadece direk bir şekile bağlı olduğu

150
00:09:34,210 --> 00:09:35,940
iki nöronun davranışlarını bilmesi gerekiyordu.

151
00:09:37,010 --> 00:09:41,230
Ve yayılan bilgi de aynıydı.

152
00:09:41,230 --> 00:09:45,160
Uyanık ve uykuda olarak 
adlandırdığımız iki farklı faz vardı.

153
00:09:45,160 --> 00:09:46,820
Fakat iki farklı fazda da

154
00:09:46,820 --> 00:09:48,760
bilgiyi tamamen aynı şekilde yayıyorsun.

155
00:09:48,760 --> 00:09:52,360
Geriyayılımda ise, farklı olarak,
 ileri geçiş ve geri geçiş

156
00:09:52,360 --> 00:09:54,820
olarak iki süreç var.
 İkisi farklı çalışıyor.

157
00:09:54,820 --> 00:09:56,379
İkisi de farklı tür sinyaller gönderiyorlar.

158
00:09:58,100 --> 00:10:01,190
Yani ben bunun en güzel
 çalışmam olduğunu düşünüyorum.

159
00:10:01,190 --> 00:10:03,730
Yıllar boyunca bu tam anlamıyla
 bir macera olarak kaldı,

160
00:10:03,730 --> 00:10:05,090
çünkü çok yavaş görünüyordu.

161
00:10:06,210 --> 00:10:10,420
Fakat daha sonra, biraz güzellikten fedakarlık ettim.

162
00:10:10,420 --> 00:10:13,730
Bu da sadece bir yineleme kullanılan daha basit bir ağ ile sonuçlandı.

163
00:10:13,730 --> 00:10:16,570
Ve sonucunda
 kısıtlı Boltzmann makineleri ortaya çıktı.

164
00:10:16,570 --> 00:10:19,430
Ki bu da pratik kullanımda efektif çalıştı.

165
00:10:19,430 --> 00:10:21,586
Mesela Netflix'in yarışmasında,

166
00:10:21,586 --> 00:10:26,170
kısıtlı Boltzmann makineleri 
kazanan takımın kullandığı tekniklerden biriydi.

167
00:10:26,170 --> 00:10:30,210
Doğrusu, sinir ağları ve derin öğrenmenin
 yakın zamanda canlanması da

168
00:10:30,210 --> 00:10:34,790
2007 civarlarında sen ve grubunun
 kısıtlı Boltzmann makinesi

169
00:10:34,790 --> 00:10:37,710
ve kısıtlı olmayan Boltzmann makinesi
 çalışmaları diyebiliriz.

170
00:10:38,940 --> 00:10:42,130
Evet, o da beni mutlu eden
 çalışmalarımdan biri,

171
00:10:42,130 --> 00:10:46,290
fikir şöyle; sadece bir katman saklı özniteliği olan

172
00:10:46,290 --> 00:10:51,120
kısıtlı Boltzmann makineni eğitirsin
 ve bir katman öznitelik öğrenebilirsin.

173
00:10:51,120 --> 00:10:54,850
Daha sonra o öznitelikleri veri olarak işler
 ve süreci tekrarlarsın.

174
00:10:54,850 --> 00:10:57,953
Sonra veri olarak öğrendiğin öznitelikleri yeniden işler
 ve aynı işlemi tekrarlarsın,

175
00:10:57,953 --> 00:10:59,570
istediğin kadar yapabilirsin bunu.

176
00:10:59,570 --> 00:11:03,060
Bu güzeldi, pratikte işe yaradı!

177
00:11:03,060 --> 00:11:08,709
Akabinde UY Tay farkına vardı ki 
bütün süreç tek bir model olarak işlenebilirdi.

178
00:11:08,709 --> 00:11:11,110
Fakat bu biraz garip bir modeldi.

179
00:11:11,110 --> 00:11:15,946
Bu modelin en üstünde Boltzmann makinesi vardı,

180
00:11:15,946 --> 00:11:20,626
altında da sigmoid inanç ağı vardı. Yıllar önce

181
00:11:20,626 --> 00:11:23,060
Radford Neal tarafından icat edilmişti.

182
00:11:23,060 --> 00:11:24,620
Bu yönlü bir modeldi ve

183
00:11:24,620 --> 00:11:28,651
kısıtlı Boltzmann makinelerini 
eğiterek elde ettiğimiz sonuç

184
00:11:28,651 --> 00:11:32,760
sigmoid inanç ağları içinde çıkarsama
 yapmanın verimli bir yoluydu.

185
00:11:33,830 --> 00:11:36,870
Aşağı yukarı bu zamanlarda,

186
00:11:36,870 --> 00:11:41,270
sinir ağları üzerinde çalışan insanlar vardı.
Sıkı bağlı ağları kullanıyorlardı ama

187
00:11:41,270 --> 00:11:45,500
bu ağlarda olasılıksal çıkarsama yapma
 konusunda pek iyi değillerdi.

188
00:11:45,500 --> 00:11:50,050
Ve bir de çizgesel modellerle uğraşan insanlar vardı,
 çocuklarımın aksine,

189
00:11:50,050 --> 00:11:55,603
bu insanlar düzgün bir şekilde çıkarsama yapabiliyordu
 ama sadece seyrek bağlı ağlarda.

190
00:11:55,603 --> 00:12:01,140
Bu derin inanç ağlarını öğrenebilen bir yol gösterdik,

191
00:12:01,140 --> 00:12:06,280
öyle ki bu yolla çok hızlı olan 
yaklaşık bir çıkarsama yapılabilir.

192
00:12:06,280 --> 00:12:10,578
Sadece bir tane ileri geçiş iletiyor
 ve sonuç çok güzeldi.

193
00:12:10,578 --> 00:12:14,890
Ekstra öznitelik katmanı öğrendiğin 
her seferinde bir sınır bulman garanti

194
00:12:16,010 --> 00:12:19,980
yeni katman öğrendiğin her seferinde
 yeni bir sınır elde ediyorsun ve

195
00:12:19,980 --> 00:12:22,700
her seferinde yeni sınır 
eskisinden daha iyi oluyor.

196
00:12:22,700 --> 00:12:25,810
Değişimsel sınırlar,
 sen katman ekledikçe gelen.

197
00:12:25,810 --> 00:12:26,970
Evet, o videoyu hatırlıyorum.

198
00:12:26,970 --> 00:12:29,680
Ve bu da beni en çok 
heyecanlandıran ikinci çalışmamdı.

199
00:12:29,680 --> 00:12:35,600
Ve sanırım üçüncü sırada da Niel(?) ile yaptığımız 
değişimsel methodlar geliyor.

200
00:12:35,600 --> 00:12:40,750
Görünen o ki, istatistikçiler
 daha evvel benzer işler yapmışlar.

201
00:12:40,750 --> 00:12:43,100
ama biz bunu bilmiyorduk tabi.

202
00:12:44,610 --> 00:12:47,260
EN(beklenti büyütme) daha iyi çalışmasını

203
00:12:47,260 --> 00:12:50,250
tam E adım yapmak zorunda 
olmadığını göstererek sağladık.

204
00:12:50,250 --> 00:12:52,800
Sadece yaklaşık E adım yaparak da başarılabilir yani.

205
00:12:52,800 --> 00:12:55,320
Ve EN istatistikte büyük bir algoritmaydı.

206
00:12:55,320 --> 00:12:58,380
Bizde onun büyük bir genellemesini yapmış olduk.

207
00:12:58,380 --> 00:13:02,490
Ve özellikle, sanırım 93'te Van Camp ile birllikte

208
00:13:02,490 --> 00:13:07,040
bildiğim kadarıyla ilk değişimsel bayes makalesini yazdık.

209
00:13:07,040 --> 00:13:12,090
Burda da doğru sonsal olasılığı
 gaussian'a yaklaştırarak daha işlenebilir

210
00:13:12,090 --> 00:13:17,950
bir Bayesçi öğrenme yapılabileceğini gösterdik.

211
00:13:17,950 --> 00:13:20,320
Ve bunu bir sinir ağında yapabilirsin.

212
00:13:20,320 --> 00:13:22,600
Bu da beni çok heyecanlandırmıştı.

213
00:13:22,600 --> 00:13:23,680
Anlıyorum. Wow, gerçekten.

214
00:13:23,680 --> 00:13:26,670
Evet, ben bu makalelerin 
hepsini hatırlıyorum!

215
00:13:26,670 --> 00:13:32,630
Neil and Hinton, EN yaklaştırma makalesi.
 Bunu okumak için saatler harcadım.

216
00:13:32,630 --> 00:13:36,070
Ve sanırım bugün kullanılan algoritmalar,

217
00:13:36,070 --> 00:13:41,110
insanların her gün kullandığı
 algoritmaların bazıları da,

218
00:13:41,110 --> 00:13:46,570
mesela dropout ya da ReLU etkilenim
 gibi algoritmalar da sizin grubunuzdan çıktı?

219
00:13:46,570 --> 00:13:47,390
Evet ve hayır.

220
00:13:47,390 --> 00:13:51,470
Diğer insanlar da rectified linear units(ReLU) 
hakkında düşündüler.

221
00:13:51,470 --> 00:13:56,860
Biz aslında kısıtlı Boltzmann makineleri ile çalışarak

222
00:13:56,860 --> 00:14:02,880
ReLU ile logistic ünite yığınlarının neredeyse eşit olduğunu gösterdik.

223
00:14:02,880 --> 00:14:05,190
Ve bu da ReLU'lerin çok 
popüler olmasına yardımcı oldu.

224
00:14:05,190 --> 00:14:07,440
Ben o konuyu epey merak ediyordum.

225
00:14:07,440 --> 00:14:12,570
ReLU makalesinde bu fonksiyonun çok karmaşık bir formül 

226
00:14:12,570 --> 00:14:15,530
tarafından yakınlaştırılabileceğini
 gösteren çok fazla matematik vardı.

227
00:14:15,530 --> 00:14:19,140
O kadar matematiği makaleniz akademik bir konferansa kabul edilsin diye mi yaptın?

228
00:14:19,140 --> 00:14:24,840
Ya da gerçekten 0 ve X'in 
maksimumlarının geliştirilmesinde etkili miydi?

229
00:14:26,450 --> 00:14:30,440
O aslında matematiğin fikrin geliştirilmesinde önemi olan

230
00:14:30,440 --> 00:14:32,350
durumlardan birisiydi.

231
00:14:32,350 --> 00:14:35,262
Ben tabiki rectified linear units hakkında bilgi sahibiydim ve

232
00:14:35,262 --> 00:14:36,821
logist units kısmına da hakimdim.

233
00:14:36,821 --> 00:14:39,250
Ve Boltzmann makinesi üzerine
 olan çalışmalardan dolayı

234
00:14:39,250 --> 00:14:42,720
bütün temel iş logistic units
 kullanılarak yapılmıştı.

235
00:14:42,720 --> 00:14:45,120
Elimizdeki soru şuydu,

236
00:14:45,120 --> 00:14:49,070
öğrenme algoritması ReLU ile birlikte olan
 birşeyle çalışabilir miydi?

237
00:14:49,070 --> 00:14:54,400
Ve rectified linear units ve logistic units yığınının 
neredeyse aynı şeyler olduğunu göstererek,

238
00:14:54,400 --> 00:15:00,350
bu şekilde bütün matematiğin
 geçeceğini gösterdik.

239
00:15:00,350 --> 00:15:01,508
Anladım.

240
00:15:01,508 --> 00:15:05,890
Bu yaptığınız ilham kaynağı oldu, 
günümüzde çok insan ReLU kullanıyor.

241
00:15:05,890 --> 00:15:08,000
-Oldukça iyi çalışıyor
-Evet

242
00:15:08,000 --> 00:15:12,130
-Aynı motivasyonu anlamaya
 ihtiyaç duymadan da işe yarıyor

243
00:15:13,150 --> 00:15:16,850
Evet, daha sonralarda Google'a gittiğimde
 farkettiğim bir şey oldu,

244
00:15:16,850 --> 00:15:22,796
Sanırım 2014'te, Google'da 
kimlik dizeyleri ile başlatılan ReLU

245
00:15:22,796 --> 00:15:26,660
kullanımı üzerine bir konuşma yaptım.

246
00:15:26,660 --> 00:15:30,300
Çünkü ReLU'nun şöyle güzel bir özelliği var;

247
00:15:30,300 --> 00:15:32,667
eğer saklı katmanları sürekli 
çoğaltır ve kimlik ile başlatırsanız,

248
00:15:32,667 --> 00:15:35,050
sadece bir katman alttaki örüntü kopyalanır.

249
00:15:36,140 --> 00:15:40,120
Ve ben de 300 katmanlı ağları eğitebileceğinizi ve

250
00:15:40,120 --> 00:15:44,760
eğer kimlik ile başlatırsanız bu işi
 çok verimli yapabileceğinizi gösteriyordum.

251
00:15:44,760 --> 00:15:48,065
Fakat bu araştırmayı daha ileri taşımadım,
 bu konuda da pişmanım açıkçası.

252
00:15:48,065 --> 00:15:52,507
Sadece -?- ile bir makale yayımladık,
 orada da bir etkin başlatarak

253
00:15:52,507 --> 00:15:55,565
özyineli ağlar başlatılabileceğini gösterdik.

254
00:15:55,565 --> 00:16:00,370
Ama bu konunu üzerine gitmem
 gerekirdi çünkü daha sonra

255
00:16:00,370 --> 00:16:03,572
bu artık ağları önemli bir yer edindi.

256
00:16:03,572 --> 00:16:06,660
Yıllardır beyin hakkında çok konuşmanı dinledim.

257
00:16:06,660 --> 00:16:09,447
Geriyayılım ve beyin arasındaki ilişki hakkında konuşmalarını dinledim.

258
00:16:09,447 --> 00:16:13,720
Bu konu hakkındaki şimdi ne düşünüyorsun?

259
00:16:13,720 --> 00:16:16,910
Aslında şuanda o konuyla ilgili bir makale üzerinde çalışıyorum.

260
00:16:18,250 --> 00:16:21,160
Sanırım ana fikrim şu şekilde,

261
00:16:21,160 --> 00:16:25,570
Eğer geriyayılım öğrenme problemi için 
gerçekten iyi bir algoritma çıkarsa,

262
00:16:26,620 --> 00:16:31,610
o zaman kesinlikle evrim bu algoritmayı
 nasıl uygulayacağını çözmüş olmalıdır.

263
00:16:32,730 --> 00:16:37,270
Yani göz bebeklerine ya da dişlere
 dönüşebilen hücrelerimiz varsa,

264
00:16:37,270 --> 00:16:42,440
bu hücreler bunu yapabiliyorsa, 
eminim geriyayılımı da uygulayabilirler.

265
00:16:42,440 --> 00:16:45,860
Muhtemelen güçlü bir
 seçici baskıdan bahsediyoruz burada.

266
00:16:45,860 --> 00:16:50,490
Bence sinirbilimcilerin 
bunu akla yatkın bulmaması çok saçma.

267
00:16:50,490 --> 00:16:52,890
Geriyayılımın kolay
 farkedilmeyen bir uygulaması olabilir.

268
00:16:52,890 --> 00:16:56,000
Muhtemelen beyin aynısı olmasa
 da geriyayılıma benzer

269
00:16:56,000 --> 00:16:58,620
bir algoritma uyguluyor, epey yakın birşey.

270
00:16:58,620 --> 00:17:02,566
Yıllar süren çalışmalarım sonucunda,
 bunun nasıl çalışıyor olabileceği üzerine bazı fikirlerim var.

271
00:17:02,566 --> 00:17:06,994
87'de, Jay McClelland ile çalışırken,

272
00:17:06,994 --> 00:17:11,202
bir devridaim algoritması geliştirdim.

273
00:17:11,202 --> 00:17:16,090
Bilgiyi yuvarlak bir döngüye gönderdiğin bir fikir.

274
00:17:17,470 --> 00:17:18,686
Ve sen de bilgi bu döngüde iken

275
00:17:18,686 --> 00:17:22,206
bir değişikliğin olmamasını sağlıyorsun.

276
00:17:22,206 --> 00:17:26,490
En basit halinde girdi üniteleri ve
 saklı üniter var diye düşünebilirsin.

277
00:17:26,490 --> 00:17:31,046
Girdiden saklıya bilgiyi gönderiyorsun ve
 sonra da tekrar geri girdiye,

278
00:17:31,046 --> 00:17:34,388
ardından tekrar saklıya ve sonra
 tekrar girdiye diye devam ediyor.

279
00:17:34,388 --> 00:17:38,001
Ve şunu istiyorsun; 
bir otogizyazar(autoencoder) eğitmek istiyorsun,

280
00:17:38,001 --> 00:17:42,300
fakat bunu geriyayılım yapmak zorunda
 kalmadan yapman lazım.

281
00:17:42,300 --> 00:17:47,250
Yani sadece bütün aktivitelerdeki 
değişimden kurtulmak için eğitiyorsun.

282
00:17:47,250 --> 00:17:51,922
Sinaps için öğrenme kuralı şu şekilde;

283
00:17:51,922 --> 00:17:57,930
Presinaptik girdideki ağırlık oranını 

284
00:17:57,930 --> 00:18:01,780
postsinaptik girdideki ağırlık oranının
 değişimine göre güncelle.

285
00:18:01,780 --> 00:18:04,060
Devridaim algoritmasında ise,
 eski olanı dahi yapmaya

286
00:18:04,060 --> 00:18:08,330
ve yeni olanı daha kötü yapmaya çalışıyorsun.

287
00:18:08,330 --> 00:18:09,620
Yani bu sefer diğer taraftan değiştiriyorsun.

288
00:18:11,010 --> 00:18:14,472
Biz bu algoritmayı sinirbilimciler 
spike-timing-dependent plastisite 

289
00:18:14,472 --> 00:18:16,521
fikrini geliştirmeden daha önce icat ettik.

290
00:18:16,521 --> 00:18:20,700
Spike-timing-dependent algoritması aslında aynı şey ama tersten,

291
00:18:20,700 --> 00:18:26,220
yani öğrenme kuralında son hal daha iyiyken
 başlangıç hali daha kötü görülüyor.

292
00:18:26,220 --> 00:18:30,010
Yani ağırlıklandırma oranını şuna göre değiştiriyorsun; 

293
00:18:30,010 --> 00:18:35,690
presinaptik aktivite * (yeni aktivite - eski aktivite)

294
00:18:37,060 --> 00:18:42,020
Daha sonra 2007'de şunu farkettim;

295
00:18:42,020 --> 00:18:47,830
bir kısıtlı Boltzmann makinesi yığını alır ve eğitirsiniz,

296
00:18:47,830 --> 00:18:52,620
ve eğitimden sonra, geriyayılımı uygulamak için tam anlamıyla

297
00:18:52,620 --> 00:18:56,450
doğru koşullara sahip olursunuz,
 sadece yeniden inşa ederek.

298
00:18:56,450 --> 00:19:01,124
Eğer yeniden inşanın hatasına bakarsan, 

299
00:19:01,124 --> 00:19:05,728
aslında bu hata
 ayırt edici performansın türevini gösterir.

300
00:19:05,728 --> 00:19:12,079
2007'de NIPS'teki ilk derin öğrenme atölyesinde
 bununla ilgili bir konuşma yaptım.

301
00:19:12,079 --> 00:19:16,454
Bu tamamen göz ardı edilmişti.

302
00:19:16,454 --> 00:19:19,799
Daha sonra, Yoshua Bengio fikirle ilgilenmeye başladı.

303
00:19:19,799 --> 00:19:24,340
Ve gerçekten benim yaptığıma kıyasla

304
00:19:24,340 --> 00:19:26,490
daha da ileri götürdü diyebiliriz.

305
00:19:26,490 --> 00:19:33,280
Bence bu otogizyazarlar yığınıyla
 aktiviteyi geri göndererek ve

306
00:19:33,280 --> 00:19:38,440
geri çatma hatalarının yerini belirleyerek
 türev elde etme fikri oldukça ilginç.

307
00:19:38,440 --> 00:19:42,520
Ve hatta beyin de böyle yapıyor olabilir.

308
00:19:42,520 --> 00:19:47,520
Geçmişte hep düşündüğün ve hala da 
üzerinde çalıştığını bildiğim bir diğer konu da

309
00:19:47,520 --> 00:19:51,930
derin öğrenmede birden fazla 
zaman ölçeğiyle nasıl baş edilir?

310
00:19:51,930 --> 00:19:54,468
Bu konudaki düşüncelerini de paylaşabilir misin?

311
00:19:54,468 --> 00:19:58,910
Evet, aslında bu benim doktoradaki ilk yılıma kadar gidiyor.

312
00:19:58,910 --> 00:20:04,040
Verdiğim ilk konuşma o zamanlar
 hızlı ağırlıklar dediğim konu üzerineydi.

313
00:20:04,040 --> 00:20:07,560
Hızlı bir şekilde adapte olan
 ama hızlı da sönen ağırlıklar.

314
00:20:07,560 --> 00:20:08,832
Bu yüzden de kısa süreli hafızaya sahip olabiliyor.

315
00:20:08,832 --> 00:20:13,496
Ve 73'te çok basit bir sistem ile bu ağırlıklarla

316
00:20:13,496 --> 00:20:16,590
gerçek özçağrı yapılabileceğini gösterdim.

317
00:20:16,590 --> 00:20:23,010
Gerçek özçağrıdan kastım
 bir şeylerin gösteriminde kullanılan nöronların

318
00:20:23,010 --> 00:20:28,470
özçağrılı çekirdekte başka şeylerin gösteriminde
 tekrar kullanılabilmesi.

319
00:20:30,210 --> 00:20:31,750
Ve bilgiyi göstermek için kullanılan ağırlıklar

320
00:20:31,750 --> 00:20:34,388
özçağrılı çekirdekte tekrardan kullanılıyorlar.

321
00:20:34,388 --> 00:20:39,170
Tabi şöyle bir soru geliyor akla;
 özçağrılı çekirdeğini çıkardığında,

322
00:20:39,170 --> 00:20:41,600
tam olarak ne yapıyor olduğunu
 nasıl hatırlayacaksın?

323
00:20:41,600 --> 00:20:42,970
O bellek nerede?

324
00:20:42,970 --> 00:20:45,015
Çünkü nöronları 
özçağrılı çekirdek için kullandın.

325
00:20:46,080 --> 00:20:49,240
Cevap da şu;
 o belleği hızlı ağırlıkların içine koyabilirsin!

326
00:20:49,240 --> 00:20:53,940
Ve nöronların aktivitelerini de
 o hızlı ağırlıklardan geri kazanabilirsin.

327
00:20:53,940 --> 00:20:56,151
Yakınlardaki Jimmy Ba ile olan çalışmalarımız sonucunda ise

328
00:20:56,151 --> 00:21:00,141
o tarz bir özçağrı için hızlı ağırlıkları kullandığımız
 bir makaleyi NIPS'e kabul ettirdik.

329
00:21:00,141 --> 00:21:00,898
Anladım.

330
00:21:00,898 --> 00:21:04,145
Bu büyük bir açıktı.

331
00:21:04,145 --> 00:21:08,746
İlk anlattığım model 73'te ama yayımlanmadı.

332
00:21:08,746 --> 00:21:14,966
Jimmy Ba'nın modeli de ya 2015
 ya da 2016'da yayımlandı.

333
00:21:14,966 --> 00:21:16,469
Yani 40 yıl sonra !

334
00:21:16,469 --> 00:21:22,840
Ve konuşmak istediğim bir fikir daha var,
 birkaç yıl oldu herhalde

335
00:21:22,840 --> 00:21:29,350
5 yılı geçmiş olabilir.
 Kapsüller konusunda neredesiniz?

336
00:21:29,350 --> 00:21:34,150
Tamam. Yani eskiden olduğum yere geri döndüm.

337
00:21:34,150 --> 00:21:39,320
O da şurası; bir fikrim var,
 sadece ben inanıyorum başka kimse değil!

338
00:21:39,320 --> 00:21:42,120
Makaleleri yolluyorum ama reddedilecekler.

339
00:21:42,120 --> 00:21:45,938
Ama bu fikre gerçekten inanıyorum,
 o yüzden sadece ilerletmeye çalışacağım.

340
00:21:45,938 --> 00:21:53,880
Fikir şöyle;
 birkaç tane önemli kısmı var aslında,

341
00:21:53,880 --> 00:22:00,000
birincisi çok boyutlu varlıkların gösterimin hakkında,

342
00:22:00,000 --> 00:22:05,070
çok boyutlu varlıkları
 küçük perde arkası aktiviteleri olarak gösterebilirsiniz.

343
00:22:05,070 --> 00:22:07,630
Herhangi bir tanesinin
 var olduğunu bilseniz yeter.

344
00:22:07,630 --> 00:22:12,150
Fikir şu; 
görüntünün her bir bölgesinde en fazla 

345
00:22:12,150 --> 00:22:14,000
bir tane spesifik öznitelik
 olduğunu varsayıyorsunuz.

346
00:22:15,200 --> 00:22:18,020
Sonra birkaç nöron kullanacaksınız,

347
00:22:18,020 --> 00:22:23,190
ve nöronların aktiviteleri
 özniteliğin farklı yönlerini gösterecek.

348
00:22:24,230 --> 00:22:27,270
Mesela o bölgenin içindeki
 x ve y tam koordinatları neler?

349
00:22:27,270 --> 00:22:28,780
Ya da hangi yönde?

350
00:22:28,780 --> 00:22:29,930
Ne kadar hızlı hareket ediyor?

351
00:22:29,930 --> 00:22:30,630
Rengi ne?

352
00:22:30,630 --> 00:22:31,270
Ne kadar parlak?

353
00:22:31,270 --> 00:22:32,590
Bu gibi şeyler.

354
00:22:32,590 --> 00:22:36,350
Aynı şeyin farklı boyutlarının
 gösterimini yapmak için

355
00:22:36,350 --> 00:22:37,710
bir sürü nöron kullanabilirsiniz.

356
00:22:37,710 --> 00:22:39,410
Tabi sadece bir tane olduğundan eminseniz.

357
00:22:40,490 --> 00:22:46,110
Bu gösterim yapmanın
 çok farklı bir yolu.

358
00:22:46,110 --> 00:22:48,155
Sinir ağlarında
 normalde yaptıklarımızdan çok farklı.

359
00:22:48,155 --> 00:22:49,820
Normalde, sinir ağlarında
 sadece kocaman bir katmanımız oluyor,

360
00:22:49,820 --> 00:22:52,080
bütün üniteler de
 işleri neyse onu yapıyorlar.

361
00:22:52,080 --> 00:22:55,770
Onları küçük gruplar halinde
 aynı şeyin farklı koordinatlarının

362
00:22:55,770 --> 00:22:57,310
gösterimini yapan paketler
 olarak düşünmüyoruz.

363
00:22:58,660 --> 00:23:02,080
Ben bu ekstra yapı
 olmalı diye düşünüyorum.

364
00:23:02,080 --> 00:23:05,020
Ve bununla beraber olan diğer fikir de...

365
00:23:05,020 --> 00:23:07,410
- Yani gösterim içerisinde gösterimi parçalara

366
00:23:07,410 --> 00:23:09,280
ayırıyorsunuz demek bu?

367
00:23:09,280 --> 00:23:11,270
-Evet
-Farklı alt kümelere ayırıyorsunuz.

368
00:23:11,270 --> 00:23:13,900
-Evet
-...göstermek için, evet...

369
00:23:13,900 --> 00:23:15,600
-Bu alt kümelerin her birini 
kapsül olarak adlandırıyorum.

370
00:23:15,600 --> 00:23:16,180
Anladım.

371
00:23:16,180 --> 00:23:21,078
Ve kapsül bir özniteliğin
 bir örneğinin gösterimini yapabiliyor.

372
00:23:21,078 --> 00:23:21,794
Fakat sadece bir!

373
00:23:21,794 --> 00:23:27,130
Ve o özniteliğin bütün özelliklerinin gösterimin yapabiliyor.

374
00:23:27,130 --> 00:23:29,880
Bir çok özelliği olan bir öznitelik bu.

375
00:23:29,880 --> 00:23:34,530
Normal bir nöron ve sinir ağı ise
 sadece sayıl bir özelliğe sahip.

376
00:23:34,530 --> 00:23:36,240
Evet, anlıyorum.

377
00:23:36,240 --> 00:23:41,423
Bunu yaparak sinir ağlarının
 çok kötü olduğu bir şeyi başarıyorsunuz.

378
00:23:41,423 --> 00:23:48,980
Benim "anlaşmayla yönlendirme"
 dediğim bir şey bu.

379
00:23:48,980 --> 00:23:52,960
Mesela bölütleme yapmak
 istiyorsunuz diyelim,

380
00:23:52,960 --> 00:23:56,660
ve elinizde ağız olabilecek bir şey var
 ve bir de buruna benzeyen bir şey var.

381
00:23:57,910 --> 00:24:02,179
Ve bu ikisini birleştirmeli misiniz acaba,
 bunu bilmek istiyorsunuz.

382
00:24:02,179 --> 00:24:03,879
Şöyle ki, ağız için 

383
00:24:03,879 --> 00:24:06,040
ağız parametleri 
olan bir kapsülünüz var.

384
00:24:06,040 --> 00:24:10,582
Aynı şekilde burun için 
burnun parametreleri olan bir kapsülünüz var.

385
00:24:10,582 --> 00:24:13,797
Sonra bunları bir araya 
getirip getirmemeye karar vermek için

386
00:24:13,797 --> 00:24:18,670
her ikisi de yüz için hangi parametreler
 olması gerekeceğini oyluyor.

387
00:24:19,930 --> 00:24:23,718
Şimdi eğer ağız ve yüz aynı 
uzaysal ilişki içindeyse

388
00:24:23,718 --> 00:24:24,725
bu konuda anlaşıyorlar.

389
00:24:24,725 --> 00:24:28,888
Yani bir seviyedeki iki kapsül 
daha üst seviyede aynı takım parametreler için oyluyorsa

390
00:24:28,888 --> 00:24:32,106
siz de onların muhtemelen
 doğru olduğunu varsayıyorsunuz.

391
00:24:32,106 --> 00:24:35,350
Çünkü yüksek boyutlu uzayda 
anlaşma olasılığı düşüktür.

392
00:24:36,950 --> 00:24:42,109
Bu da bizim normalde 
sinir ağlarında kullandığımızdan

393
00:24:42,109 --> 00:24:46,130
çok farklı bir filtreleme yolu.

394
00:24:46,130 --> 00:24:50,708
Bence bu anlaşma ile yönlendirme yöntemi
 sinir ağlarının 

395
00:24:50,708 --> 00:24:56,700
kısıtlı veriden yola çıkarak
 genellemesi için çok önemli olacak.

396
00:24:56,700 --> 00:24:59,797
Bence bu bakış açısında değişmelerle
 başa çıkmada

397
00:24:59,797 --> 00:25:01,500
ve bölütleme yapmada çok efektif olacak.

398
00:25:01,500 --> 00:25:04,794
Ve umuyorum ki bizim şuanda
 sinir ağlarında yaptığımızdan

399
00:25:04,794 --> 00:25:06,147
çok daha istatistik olarak verimli olacak.

400
00:25:06,147 --> 00:25:08,575
Öyle ki, 
bakış açısındaki değişimlerle uğraşmak istediğinde

401
00:25:08,575 --> 00:25:12,000
sadece bir sürü bakış açısı değişimi vereceksin
 ve hepsinin üzerinde eğiteceksin.

402
00:25:12,000 --> 00:25:16,460
Anlıyorum, tabi. Yani sadece 
ileriye doğru gözetimli öğrenme ile değil,

403
00:25:16,460 --> 00:25:19,120
daha farklı yollarla da öğrenebilirsin.

404
00:25:20,220 --> 00:25:24,120
Şimdi, ben hala gözetimli öğrenme ile yapmayı düşünüyorum, ama

405
00:25:24,120 --> 00:25:27,720
ileri geçişin mekaniği oldukça farklı.

406
00:25:27,720 --> 00:25:32,010
Tam anlamıyla saf ileri geçişten bahsedemiyoruz.
 Çünkü biraz yineleme süreci de var.

407
00:25:32,010 --> 00:25:36,550
Mesela ağız bulduğunu sanıyorsun
 ve burun bulduğunu düşünüyorsun,

408
00:25:36,550 --> 00:25:39,127
Ve biraz yineleme kullanarak bunlar

409
00:25:39,127 --> 00:25:42,530
bir yüz oluşturmalı mı 
oluşturmamalı mı ona karar veriyorsun.

410
00:25:42,530 --> 00:25:46,352
Ve bu yinelemeden
 geriyayılım da yapabilirsin.

411
00:25:46,352 --> 00:25:50,286
Bunu biraz ayırt edici bir şekilde
 yapmayı deneyebilirsin.

412
00:25:50,286 --> 00:25:54,417
Biz şuanda Toronto'daki grubumda
 bunun üzerinde çalışıyoruz.

413
00:25:54,417 --> 00:26:00,260
Ayrıca Beyin Takımının bir parçası olarak
 Toronto'da bir Google ekibim de var.

414
00:26:00,260 --> 00:26:02,127
Şuanda heyecanla çalıştığım konu bu.

415
00:26:02,127 --> 00:26:02,891
Anlıyorum, harika gerçekten.

416
00:26:02,891 --> 00:26:05,366
Makalenin çıkmasını dört gözle bekliyorum.

417
00:26:05,366 --> 00:26:10,750
Evet, çıkarsa görürsün tabi :D

418
00:26:10,750 --> 00:26:13,040
Derin öğrenme konusunda 
on yıllardır çalışıyorsun.

419
00:26:13,040 --> 00:26:15,330
Şunu gerçekten merak ediyorum; 

420
00:26:15,330 --> 00:26:18,760
senin yapay zeka konusundaki fikirlerin
 nasıl değişti bu dönemde?

421
00:26:20,380 --> 00:26:27,678
Sanırım entellektüel geçmişimin çoğu
 geriyayılım

422
00:26:27,678 --> 00:26:33,531
ve geriyayılımın gücünü nasıl kullanabilirizin
 etrafında vuku buldu.

423
00:26:33,531 --> 00:26:36,966
Şöyle başlayabilirim herhalde,
 80'lerin ortalarıydı, biz o zamanlar

424
00:26:36,966 --> 00:26:40,203
ayırt edici öğrenmesi için kullanıyorduk
 ve güzel gidiyordu.

425
00:26:40,203 --> 00:26:42,405
Sonradan 90'ların başında,

426
00:26:42,405 --> 00:26:46,749
insan öğrenmesinin çoğu 
gözetimsiz öğrenme olur diye karar verdim.

427
00:26:46,749 --> 00:26:50,138
Ve gözetimsiz öğrenme konusuna ilgim artarken 
gözetimli olanla ilgilenmemeye başladım.

428
00:26:50,138 --> 00:26:54,300
Tam bu sıralarda da uyku-uyanık algoritmaları
 üstünde çalışmaya başladım.

429
00:26:54,300 --> 00:26:58,306
Ve senin o dönemdeki yorumların
 benim düşünce tarzımı de çok etkiledi.

430
00:26:58,306 --> 00:27:03,010
Ben Google Beyin'i yönetirken ilk projemizde

431
00:27:03,010 --> 00:27:07,900
gözetimsiz öğrenme üzerine çok efor harcadık,
 senin etkin var burada.

432
00:27:07,900 --> 00:27:09,740
Evet, seni yanlış etkilemiş olabilirim :)

433
00:27:09,740 --> 00:27:11,470
Çünkü uzun vadede,

434
00:27:11,470 --> 00:27:13,840
gözetimsiz öğrenmenin mutlak bir önem
 arz edeceğini düşünüyorum.

435
00:27:15,160 --> 00:27:19,376
Ama şu noktada gerçekle yüzleşmek lazım,

436
00:27:19,376 --> 00:27:24,107
aşağı yukarı son 10 senedir 
düzgün çalışan şey gözetimli öğrenme!

437
00:27:24,107 --> 00:27:27,179
Elinde etiketler olan, ayırt edici eğitim.

438
00:27:27,179 --> 00:27:31,810
Ya da serideki bir sonraki şeyi öngöreceksin
 ve o etiket görevinde olacak.

439
00:27:31,810 --> 00:27:33,769
Bunlar inanılmaz iyi bir şekilde çalıştı!

440
00:27:37,528 --> 00:27:42,266
Tabi hala gözetimsiz öğrenmenin 
çok önemli olacağını düşünüyorum.

441
00:27:42,266 --> 00:27:47,145
Bir başardığımızda şuan yaptıklarımızdan
 çok daha iyi çalışacaklar,

442
00:27:47,145 --> 00:27:48,200
ama daha başaramadık!

443
00:27:49,990 --> 00:27:53,225
Evet, derin öğrenme çalışan
 bir süre kıdemli insan-ben dahil-

444
00:27:53,225 --> 00:27:56,074
bu konuda çok heyecanlılar.

445
00:27:56,074 --> 00:28:01,513
Problem kimsenin nasıl yapılacağına dair
 iyi bir fikrinin olmaması.

446
00:28:01,513 --> 00:28:04,983
Belki senin vardır,
 benim yok diye düşünüyorum.

447
00:28:04,983 --> 00:28:08,160
Yeniden parametreleme trikleri kullanılan
 değişimsel otogizyazar kodu.

448
00:28:08,160 --> 00:28:10,120
Bu güzel bir fikir gibi göründü bana.

449
00:28:10,120 --> 00:28:15,260
Ve tabi çekişmeli üretici ağlar da
 çok güzel bir fikir bence.

450
00:28:15,260 --> 00:28:18,645
Sanırım çekişmeli üretici ağlar için

451
00:28:18,645 --> 00:28:23,430
derin öğrenmede gerçekten yeni olan
 en büyük fikir diyebiliriz.

452
00:28:23,430 --> 00:28:26,363
Umuyorum kapsülleri de bu kadar başarılı yapabilirim.

453
00:28:26,363 --> 00:28:31,740
Ama şuan için çekişmeli üretici ağların
 büyük bir buluş olduğunu söyleyebiliriz.

454
00:28:31,740 --> 00:28:34,439
Peki seyreklik ve yavaş özniteliklere ne oldu?

455
00:28:34,439 --> 00:28:38,806
Bunlar da gözetimsiz öğrenme
 yapmak için iki farklı prensipti?

456
00:28:41,556 --> 00:28:47,788
Ben seyreklik konusunda hiçbir zaman
 senin kadar heveslı değildim dostum :)

457
00:28:47,788 --> 00:28:52,672
Ben yavaş özniteliklerin
 bir hata olduğunu düşünüyorum.

458
00:28:52,672 --> 00:28:53,660
Yavaş olarak adlandırmamak lazım.

459
00:28:53,660 --> 00:28:57,880
Temel fikir doğru ama
 değişmeyen öznitelikler amacımız olmamalı.

460
00:28:57,880 --> 00:29:00,660
Öngörülebilir bir şekilde değişen özniteliklerin
 hedef olması lazım.

461
00:29:01,680 --> 00:29:07,060
Herhangi bir şeyin nasıl
 modelleneceğine dair temel prensip;

462
00:29:08,620 --> 00:29:13,391
Önce ölçüm yaparsın, bu ölçümlerinin üzerine

463
00:29:13,391 --> 00:29:17,612
eylemin doğrusal olduğu durum vektörü olan gösterimi
 elde edene kadar

464
00:29:17,612 --> 00:29:22,672
doğrusal olmayan dönüşümleri uygularsın.

465
00:29:22,672 --> 00:29:26,103
Yani Kalman filtresinde yaptığın gibi
 sanki doğrusalmış gibi davranmazsın,

466
00:29:26,103 --> 00:29:29,625
gözlenebilir olanları temel değişkenlere çeviren
 bir dönüşüm bulursun.

467
00:29:29,625 --> 00:29:32,616
Bu temel değişkenlerin üzerinde
 yapacağın doğrusal işlemler de,

468
00:29:32,616 --> 00:29:37,480
mesela dizey çarpanları gibi,
 işi hallederler.

469
00:29:37,480 --> 00:29:39,700
Örnek olarak; diyelim ki bakış açısını 
değiştirmek istiyorsunuz,

470
00:29:39,700 --> 00:29:42,890
görüntüyü başka bir bakış açısından
 üretmek istiyorsunuz,

471
00:29:42,890 --> 00:29:46,900
yapmanız gereken şey
 piksellerden koordinatlara gitmek.

472
00:29:47,950 --> 00:29:50,686
Ve koordinat gösterimlerini elde ettiğinizde,

473
00:29:50,686 --> 00:29:54,120
-ki kapsüllerin bunu yapabileceğini umuyorum-

474
00:29:54,120 --> 00:29:57,350
ardından dizey çarpımı yaparak
 bakış açısını değiştirebilirsiniz.

475
00:29:57,350 --> 00:29:59,210
Sonra bunu tekrar piksellere eşleyebilirsiniz.

476
00:29:59,210 --> 00:29:59,893
-Evet, bütün her şeyi de bunun için yaptın zaten.

477
00:29:59,893 --> 00:30:02,170
-Ben bunun çok ama çok 
genel bir prensip olduğunu düşünüyorum.

478
00:30:02,170 --> 00:30:04,773
-Tam olarak bu yüzden bütün o 
yüz sentezi çalışmalarını yaptınız değil mi?

479
00:30:04,773 --> 00:30:09,355
Bir yüzü alıp
 onu çok düşük boyutlu bir vektöre sıkıştırıp

480
00:30:09,355 --> 00:30:12,450
oradan da oynamalarla
 tekrar başka yüzler elde ettiniz.

481
00:30:12,450 --> 00:30:15,950
Bir öğrencim vardı onun üzerinde çalışan
 ama ben çok fazla çalışmadım.

482
00:30:17,100 --> 00:30:19,180
Eminim bu soru sana çok soruluyordur,

483
00:30:19,180 --> 00:30:23,920
eğer biri derin öğrenmeye başlamak isterse,
ilk olarak ne yapması gerekir?

484
00:30:23,920 --> 00:30:25,040
Bu konuda nasıl bir tavsiye verebilirsin?

485
00:30:25,040 --> 00:30:28,938
Eminim bire bir konuşmalarda
 çok fazla yardım olmuşsundur insanlara,

486
00:30:28,938 --> 00:30:31,550
ama bu videoyu izleyen
 küresel seyirciler için de sorayım.

487
00:30:31,550 --> 00:30:35,999
Bu insanlara derin öğrenmeye girişle
 ilgili nasıl bir tavsiye verirsin?

488
00:30:35,999 --> 00:30:42,171
Tamam, benim tavsiyem şöyle; 
literatürü okuyun ama içinde boğulmamaya çalışın!

489
00:30:42,171 --> 00:30:48,030
Çoğu insanın söylemeyeceği bu tavsiyeyi
 ben de danışmanımdan aldım.

490
00:30:48,030 --> 00:30:52,474
Çoğu insan literatürü okumak için
 birkaç yıl harcamanız gerektiğini söyler.

491
00:30:52,474 --> 00:30:55,421
Daha sonra kendi fikirleriniz üzerinde
 çalışmaya başlayın derler.

492
00:30:55,421 --> 00:31:00,295
Bu bazı araştırmacılar için doğru olabilir
 ama yaratıcı insanlar için durum farklı,

493
00:31:00,295 --> 00:31:03,803
bu kişiler biraz literatür okuyup

494
00:31:03,803 --> 00:31:07,792
daha sonra herkesin yanlış yaptığını
 düşündükleri bir şeyi ararlar.

495
00:31:07,792 --> 00:31:10,340
Tavsiyem bu manada farklı yani.

496
00:31:10,340 --> 00:31:13,568
Çalışmalara bakarsınız ve
 doğru gitmeyen bir şeyler sezersiniz.

497
00:31:13,568 --> 00:31:15,660
Ve sonra da bunu düzeltmeye çalışırsınız.

498
00:31:16,890 --> 00:31:22,476
İnsanlar size yaptığınızın iyi olmadığını söylese de
 yılmadan devam edin.

499
00:31:22,476 --> 00:31:26,339
İnsanların yılmadan devam etmesine
 yardım edecek bir prensibim de var.

500
00:31:26,339 --> 00:31:29,996
Sezgileriniz ya iyidir
 ya da değildir!

501
00:31:29,996 --> 00:31:32,030
Eğer sezgileriniz iyiyse 
onları takip etmeniz gerekir.

502
00:31:32,030 --> 00:31:34,060
Eninde sonunda başarılı olursunuz.

503
00:31:34,060 --> 00:31:36,478
Eğer sezgileriniz kötüyse,
 ne yaptığınızın da bir önemi yok

504
00:31:36,478 --> 00:31:40,329
Anlıyorum :D

505
00:31:40,329 --> 00:31:43,420
İlham verici bir tavsiye, dinlemek lazım :)

506
00:31:43,420 --> 00:31:45,410
Sezgilerinize güvenmeniz lazım.

507
00:31:45,410 --> 00:31:47,847
Güvenmemeniz için hiçbir sebep yok.

508
00:31:47,847 --> 00:31:49,420
Anlıyorum, evet.

509
00:31:49,420 --> 00:31:55,193
Ben genellikle insanlara makaleleri sadece okumalarını değil 
onları tekrarlamalarını da tavsiye ediyorum.

510
00:31:55,193 --> 00:31:58,161
Belki bu, doğal olarak, okuyabileceğin
 sayıyı da sınırlıyordur tabi,

511
00:31:58,161 --> 00:32:00,800
çünkü sonuçları tekrarlamak
 çok zaman alıyor.

512
00:32:01,910 --> 00:32:05,312
Evet bu doğru. 
Yayımlanmış bir makaleyi tekrarlamaya çalışırken

513
00:32:05,312 --> 00:32:08,100
işi başarılı kılan bütün
 küçük taktikleri de keşfediyorsunuz

514
00:32:08,100 --> 00:32:11,938
Diğer bir tavsiyem ise
 durmadan programlama yapın!

515
00:32:11,938 --> 00:32:15,577
Çünkü bir öğrenciye 
yapması için bir şey verdiğinizde,

516
00:32:15,577 --> 00:32:18,550
eğer kötü öğrencilerse, 
geri gelip olmadı diyecekler.

517
00:32:18,550 --> 00:32:22,030
Ve olmamasının sebebi
 verdikleri küçük bir kararın

518
00:32:22,030 --> 00:32:25,100
ne kadar önemli olduğunu
 anlamamış olmaları.

519
00:32:25,100 --> 00:32:28,850
Ama iyi bir öğrenciye verirseniz, UY Tay mesela,

520
00:32:28,850 --> 00:32:31,120
ona herhangi bir şeyi verebilirsiniz
 çünkü gerip gelip oldu diyecektir.

521
00:32:32,670 --> 00:32:36,420
Bir defasında şöyle oldu, bir dur bakalım dedim,

522
00:32:36,420 --> 00:32:37,330
en son konuşmamızdan sonra

523
00:32:37,330 --> 00:32:40,380
fark ettim ki, şu sebepten dolayı 
bunun işe yaramaması lazım,

524
00:32:40,380 --> 00:32:43,586
UY da hemen "Oh ben hemen anlamıştım zaten,
 öyle demek istemediğini varsaydım o yüzden!" dedi

525
00:32:43,586 --> 00:32:47,627
-Anladım, evet :D harika gerçekten

526
00:32:47,627 --> 00:32:51,575
Peki yapay zeka ve derin öğrenmeye 

527
00:32:51,575 --> 00:32:57,782
giriş yapmak isteyen insanlara
 başka tavsiyen var mı?

528
00:32:57,782 --> 00:33:02,000
Basitçe şöyle; 
sezgilerinizin gelişeceği kadar okuyun,

529
00:33:02,000 --> 00:33:05,811
daha sonra da sezgilerinize güvenin ve yardırın.

530
00:33:05,811 --> 00:33:10,783
Eğer diğer herkes 
çok saçma olduğunu söylerse de, takmayın.

531
00:33:10,783 --> 00:33:14,352
Sanırım başkaları çok saçma olduğunu söylediğinde

532
00:33:14,352 --> 00:33:19,950
haklılar mı değiller mi bilmenin bir yolu yok,
 o yüzden sonuna kadar gidip öğrenmek zorundasın.

533
00:33:19,950 --> 00:33:24,350
Evet ama şöyle bir şey var, 
eğer gerçekten çok iyi bir fikir olduğunu düşünüyorsanız,

534
00:33:24,350 --> 00:33:27,201
ve diğer insanlar da 
tamamen saçma olduğunu söylüyorsa,

535
00:33:27,201 --> 00:33:29,761
o zaman gerçekten 
ortada bir şey olduğunu bilirsiniz. 

536
00:33:29,761 --> 00:33:33,960
Mesela buna bir örnek olarak,
 Radford ve ben değişimsel methodları geliştirdiğimizde,

537
00:33:35,420 --> 00:33:40,690
EM konusunda çok bilgisi olan
 eski öğrencim Peter Brown'a

538
00:33:40,690 --> 00:33:42,560
fikri açıklayan bir mail gönderdim.

539
00:33:43,570 --> 00:33:46,967
O da bu çalışmayı birlikte çalıştığı

540
00:33:46,967 --> 00:33:51,253
... Pietro(?) kardeşlere göstermiş,
 ikizdiler sanırım.

541
00:33:51,253 --> 00:33:55,914
Sonra da ne düşündüklerini
 söyledi bana,

542
00:33:55,914 --> 00:34:00,277
"bu adam ya sarhoş ya da çok salak" demişler.

543
00:34:00,277 --> 00:34:04,260
Gerçekten çalışmanın
 çok saçma olduğunu düşünmüşler.

544
00:34:04,260 --> 00:34:06,460
Belki de benim anlatma şeklimden
 dolayı böyle düşünmüşlerdir.

545
00:34:06,460 --> 00:34:08,043
Çünkü sezgisel bir şekilde açıklamıştım.

546
00:34:09,150 --> 00:34:13,100
İşin özü, çok güzel olduğunu 
düşündüğünüz bir fikriniz varsa

547
00:34:13,100 --> 00:34:16,810
ve diğer insanlar da tam bir saçmalık diyorsa,
 bu fikrin iyi olduğuna işaret eder.

548
00:34:18,026 --> 00:34:21,555
Anlıyorum, peki araştırma konuları...

549
00:34:21,555 --> 00:34:26,183
Yeni lisansüstü öğrenciler 
hangi konularda çalışmalı?

550
00:34:26,183 --> 00:34:30,707
Kapsüller? Gözetimsiz öğrenme? 
Ya da başka şeyler?

551
00:34:30,707 --> 00:34:34,078
Yeni lisansüstü öğrenciler için güzel bir tavsiye,

552
00:34:34,078 --> 00:34:38,344
kendi düşüncelerine yakın düşünen
 danışman bulmaya çalışsınlar.

553
00:34:38,344 --> 00:34:42,637
Çünkü sizin çalıştığınız şeylerin üzerine
 derinlemesine düşünen

554
00:34:42,637 --> 00:34:47,170
bir danışmanınız varsa, 
size çok vakit ayırıp güzel tavsiyeler verebilir.

555
00:34:47,170 --> 00:34:50,590
Eğer danışmanınızın ilgi duymadığ
ı bir konu üzerinde çalışıyorsanız,

556
00:34:50,590 --> 00:34:55,262
biraz tavsiye alırsınız
 ama çok da faydalı olmaz.

557
00:34:55,262 --> 00:34:58,386
Anlıyorum,
 öğrenciler için son bir soru,

558
00:34:58,386 --> 00:35:02,440
doktora programına başlayan insanlar da var,
 büyük şirketlere ya da 

559
00:35:02,440 --> 00:35:09,687
en iyi araştırma gruplarına katılanlar da,
 bu konuda ne düşünüyorsun?

560
00:35:09,687 --> 00:35:13,890
Evet, bu biraz karmaşık.
 Şuanda bence,

561
00:35:13,890 --> 00:35:18,727
üniversitedeki bu kadar insanı eğitecek, 
derin öğrenme konusunda uzman

562
00:35:18,727 --> 00:35:21,125
yeterince akademisyen yok.

563
00:35:21,125 --> 00:35:25,011
Yeterince hoca yok yani anlayacağın,

564
00:35:25,011 --> 00:35:27,780
ama bu geçici bir durum bence.

565
00:35:27,780 --> 00:35:32,410
Şöyle bir problem yaşandı, 
çoğu departman nasıl bir devrim

566
00:35:32,410 --> 00:35:34,890
gerçekleştiğini anlama
 konusunda yavaş kaldı.

567
00:35:34,890 --> 00:35:38,720
Sana biraz katılıyorum, 
bir ikinci sanayi devrimi diyemeyiz tabi

568
00:35:38,720 --> 00:35:41,000
ama ona yakın ölçekte bir değişim.

569
00:35:41,000 --> 00:35:43,691
Devasa bir değişim yaşanıyor ve

570
00:35:43,691 --> 00:35:47,980
bunun ana sebebi;
 bilgisayarlarla aramızdaki ilişki değişti.

571
00:35:47,980 --> 00:35:53,920
Onları programlamak yerine, ne yapacaklarını gösteriyoruz
 ve onlar da nasıl yapacaklarını çözüyor.

572
00:35:53,920 --> 00:35:56,570
Bu bilgisayarları kullanmanın tamamen farklı bir yolu,

573
00:35:56,570 --> 00:36:01,210
bilgisayar bilimi departmanları ise
 "bilgisayarları programlama" fikri etrafında inşa edilmiş.

574
00:36:01,210 --> 00:36:03,480
Ve şuanda bu bilgisayarları eğitme işinin

575
00:36:05,000 --> 00:36:09,330
onları programlama kadar önemli
 bir şey olacağını anlamıyorlar.

576
00:36:09,330 --> 00:36:13,940
Departmanın yarısı 
bilgisayarı eğitme işiyle uğraşan

577
00:36:13,940 --> 00:36:16,510
kişiler olması lazım, 
bunu anlamıyorlar.

578
00:36:16,510 --> 00:36:22,183
Benim kendi departmanım
 bu işi yapan insanlardan çok ama çok

579
00:36:22,183 --> 00:36:24,790
işe alması gerektiğini reddediyor.

580
00:36:24,790 --> 00:36:28,730
Birkaç tane, hadi belki biraz daha
 fazla olsun yeter diyorlar.

581
00:36:31,260 --> 00:36:32,452
Böyle bir durumda

582
00:36:32,452 --> 00:36:36,510
büyük şirketlere eğitimin bir kısmını
 üstlenmeleri gerektiğini hatırlatmak gerekiyor.

583
00:36:36,510 --> 00:36:40,335
Google mesela, 
beyin evi programı ile insanları eğitiyor.

584
00:36:40,335 --> 00:36:43,792
Üniversitelerin de eninde sonunda
 yetişeceğini düşünüyorum.

585
00:36:43,792 --> 00:36:48,360
Anlıyorum, evet. Aslında bir sürü öğrenci
 de bu meseleyi anlamış görünüyor.

586
00:36:48,360 --> 00:36:53,131
En iyi doktora programlarına
 başvuranların yarısından fazlası

587
00:36:53,131 --> 00:36:57,079
bilgisayarları programlamaktansa,
 onlara öğretmek üzerinde çalışmak istiyor.

588
00:36:57,079 --> 00:37:00,720
Evet. Aslında hakkını vermek lazım,

589
00:37:00,720 --> 00:37:04,930
deeplearning.ai bu uzmanlık
 programını yapıyor ama

590
00:37:04,930 --> 00:37:09,239
bildiğim kadarıyla, derin öğrenme üzerine
 ilk online dersi sen vermiştin.

591
00:37:09,239 --> 00:37:11,752
2012'de yine coursera üzerindeydi.

592
00:37:12,828 --> 00:37:14,430
Ve biraz garip bir şekilde,

593
00:37:14,430 --> 00:37:18,900
RMSProp algoritmasını da
 bu zamanlarda yayımlamıştın .

594
00:37:20,240 --> 00:37:25,910
Evet, tabi öyleydi.
 Sen davet etmiştin online dersi anlatmam için.

595
00:37:25,910 --> 00:37:30,239
Hatta ben ders verme konusunda çok şüpheliyken de 
zorlamıştın yapalım diye.

596
00:37:30,239 --> 00:37:34,340
Çok işçiliği vardı 
ama iyi ki vermişim o dersi.

597
00:37:34,340 --> 00:37:37,409
Evet, verdiğin için teşekkürler. 
Bana ne kadar çok zaman istiyor diye

598
00:37:37,409 --> 00:37:38,351
şikayet ettiğini hatırlıyorum.

599
00:37:38,351 --> 00:37:42,413
Çok gecelerini aldı ama
 bence birçok kişi faydalandı.

600
00:37:42,413 --> 00:37:47,330
Bu konuda da çok müteşekkirim sana.

601
00:37:47,330 --> 00:37:49,260
Evet, evet iyi oldu.

602
00:37:49,260 --> 00:37:53,290
Yıllar boyunca, yapay zeka geliştirme paradigmaları
 üzerine çok tartışmalara girdin.

603
00:37:53,290 --> 00:37:57,030
Ya da bir paradigma değişimi
 var mı yok mu diye.

604
00:37:57,030 --> 00:37:59,984
Bu konudaki düşüncelerini de paylaşabilir misin?

605
00:37:59,984 --> 00:38:05,157
Tabi, paylaşırım. 
İlk zamanlarda, 50'ler gibi yani,

606
00:38:05,157 --> 00:38:10,335
von Neumann ve Turing gibi kişiler
 sembolik yapay zekaya çok inanmadılar.

607
00:38:10,335 --> 00:38:14,220
Asıl büyülendikleri şey beyindi.

608
00:38:14,220 --> 00:38:20,127
Ne yazık ki çok gençken öldüler
 ve sesleri çok duyulmadı.

609
00:38:20,127 --> 00:38:21,806
Yapay zekanın erken günlerinde,

610
00:38:21,806 --> 00:38:26,259
insanlar, zeka için ihtiyaç duyulan gösterimlerin

611
00:38:26,259 --> 00:38:30,500
bir tür sembolik ifadeler
 olduğuna ikna olmuşlardı.

612
00:38:30,500 --> 00:38:35,509
Monotonik olmayan mantık yapabileceğin,
 bir tür toparlanmış mantık diyebiliriz.

613
00:38:35,509 --> 00:38:41,143
Tam mantık değil aslında, mantık gibi bir şey.
 Ve buna göre zekanın özü akıl yürütme idi.

614
00:38:41,143 --> 00:38:45,662
Şuan da olan ise tamamen farklı bir bakış açısı.

615
00:38:45,662 --> 00:38:50,984
Buna göre, düşünce
büyük bir sinirsel aktivite vektörü olarak görülüyor.

616
00:38:50,984 --> 00:38:55,200
Düşüncenin bir sembolik ifade olduğu
 görüşüne zıt olan bir görüş yani.

617
00:38:55,200 --> 00:38:59,087
Ve bence düşüncenin bir sembolik ifade
 olduğuna inanan insanlar

618
00:38:59,087 --> 00:39:00,140
çok büyük bir hata yaptı.

619
00:39:01,210 --> 00:39:07,030
Giren şey bir dizi kelime, 
çıkan şey de bir dizi kelime.

620
00:39:08,140 --> 00:39:12,580
Bu yüzden de gösterim yapmak için
 kelime dizileri en bariz yoldur.

621
00:39:12,580 --> 00:39:15,710
Onlar da arada olan şeylerin de 
kelimeler dizisi olduğunu düşündüler.

622
00:39:15,710 --> 00:39:18,360
Ya da kelimeler dizisine benzer şeyler.

623
00:39:18,360 --> 00:39:21,310
Bence aradaki sürecin
 kelimeler dizisiyle alakası yok.

624
00:39:21,310 --> 00:39:26,060
Bence düşüncelerin
 dil gibi bir şey olduğu fikri

625
00:39:26,060 --> 00:39:30,980
uzaysal bir manzara düzeninin
 pikseller olduğu 

626
00:39:30,980 --> 00:39:34,280
anlayışı kadar saçma bir fikir.

627
00:39:34,280 --> 00:39:37,930
Eğer bize nokta vuruşlu yazıcılar bağlı olsaydı

628
00:39:37,930 --> 00:39:41,929
o zaman pikseller çıkardı dışarı
 ama aradaki süreç pikseller değil işte.

629
00:39:43,210 --> 00:39:46,620
O yüzden bence düşünceler
 sadece harika büyük vektörler,

630
00:39:46,620 --> 00:39:48,460
ve bu büyük vektörlerin nedensel güçleri de var.

631
00:39:48,460 --> 00:39:50,490
Başka büyük vektörlerin oluşmasına neden oluyorlar.

632
00:39:50,490 --> 00:39:56,100
Ve bu görüş, düşüncelerin sembolik ifadeler olduğunu söyleyen
 standart yapay zeka görüşünden tamamen farklı.

633
00:39:56,100 --> 00:39:56,700
Anlıyorum, güzel.

634
00:39:57,740 --> 00:40:01,560
Sanırım bugünlerde yapay zeka
 bu yeni bakış açısına yaklaşıyor diyebiliriz.

635
00:40:01,560 --> 00:40:02,660
Bazısı öyle evet.

636
00:40:02,660 --> 00:40:08,230
Yapay zeka çalışan bir sürü insan hala 
düşüncelerin sembolik ifadeler olduğunu düşünüyor.

637
00:40:08,230 --> 00:40:09,780
Bu röportajı yaptığın için
 çok teşekkür ederim.

638
00:40:09,780 --> 00:40:12,970
Derin öğrenmenin yıllar boyunca
 nasıl evrildiğini duymak büyüleyiciydi.

639
00:40:12,970 --> 00:40:17,680
Bu alanı ilerletmek için şuan yaptıklarını
 dinlemek de öyleydi, çok teşekkürler Geoff.

640
00:40:17,680 --> 00:40:19,038
Bana bu fırsatı verdiğin için
 ben sana teşekkür ederim.

641
00:40:19,038 --> 00:40:20,147
>> Teşekkür ederim.