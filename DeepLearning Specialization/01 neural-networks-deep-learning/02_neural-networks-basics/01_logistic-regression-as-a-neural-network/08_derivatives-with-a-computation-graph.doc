<html xmlns:o="urn:schemas-microsoft-com:office:office" xmlns:w10="urn:schemas-microsoft-com:office:word" xmlns:m="http://schemas.microsoft.com/office/omml/2004/12/core" xmlns:ve="http://schemas.openxmlformats.org/markup-compatibility/2006" xmlns:o12="http://schemas.microsoft.com/office/2004/7/core" xmlns:r="http://schemas.openxmlformats.org/officeDocument/2006/relationships" xmlns:v="urn:schemas-microsoft-com:vml" xmlns:wp="http://schemas.openxmlformats.org/drawingml/2006/3/wordprocessingDrawing" xmlns:w="http://schemas.openxmlformats.org/wordprocessingml/2006/3/main" xmlns="http://www.w3.org/TR/REC-html40">
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <head>
    <style>style</style>
  </head>
  <body>
    <div class="Section1">
      <p>
        <b>
          <u>
            <span style="font-size:20.0pt">Derivatives with a Computation Graph</span>
          </u>
        </b>
      </p>
      <p>
(DESCRIPTION)        <br/>
Text, Basics of Neural Network Programming. Derivatives with a Computation Graph. Website, deep learning, dot, A.I.        <br/>
      </p>
      <p>
(SPEECH)        <br/>
In the last video, we worked through an example of using a computation graph to compute a function J.        <br/>
      </p>
      <p>
Now, let's take a clean diversion of that computation graph.        <br/>
      </p>
      <p>
And show how you can use it to figure out derivative calculations for that function J.        <br/>
      </p>
      <p>
(DESCRIPTION)        <br/>
New slide, Computing derivatives.        <br/>
      </p>
      <p>
(SPEECH)        <br/>
So here's a computation graph.        <br/>
      </p>
      <p>
Let's say you want to compute the derivative of J with respect to v.        <br/>
      </p>
      <p>
So what is that?        <br/>
      </p>
      <p>
Well, this says, if we were to take this value of v and change it a little bit, how would the value of J change?        <br/>
      </p>
      <p>
Well, J is defined as 3 times v.        <br/>
      </p>
      <p>
And right now, v = 11.        <br/>
      </p>
      <p>
So if we're to bump up v by a little bit to 11.001, then J, which is 3v, so currently 33, will get bumped up to 33.003.        <br/>
      </p>
      <p>
So here, we've increased v by 0.001.        <br/>
      </p>
      <p>
And the net result of that is that J goes out 3 times as much.        <br/>
      </p>
      <p>
So the derivative of J with respect to v is equal to 3.        <br/>
      </p>
      <p>
Because the increase in J is 3 times the increase in v.        <br/>
      </p>
      <p>
And in fact, this is very analogous to the example we had in the previous video, where we had f(a) = 3a.        <br/>
      </p>
      <p>
And so we then derived that df/da, which with slightly simplified, a slightly sloppy notation, you can write as df/da = 3.        <br/>
      </p>
      <p>
So instead, here we have J = 3v, and so dJ/dv = 3.        <br/>
      </p>
      <p>
With here, J playing the role of f, and v playing the role of a in this previous example that we had from an earlier video.        <br/>
      </p>
      <p>
So indeed, terminology of backpropagation, what we're seeing is that if you want to compute the derivative of this final output variable, which usually is a variable you care most about, with respect to v, then we've done one step of backpropagation.        <br/>
      </p>
      <p>
So we call it one step backwards in this graph.        <br/>
      </p>
      <p>
Now let's look at another example.        <br/>
      </p>
      <p>
What is dJ/da?        <br/>
      </p>
      <p>
In other words, if we bump up the value of a, how does that affect the value of J?        <br/>
      </p>
      <p>
Well, let's go through the example, where now a = 5.        <br/>
      </p>
      <p>
So let's bump it up to 5.001.        <br/>
      </p>
      <p>
The net impact of that is that v, which was a + u, so that was previously 11.        <br/>
      </p>
      <p>
This would get increased to 11.001.        <br/>
      </p>
      <p>
And then we've already seen as above that J now gets bumped up to 33.003.        <br/>
      </p>
      <p>
So what we're seeing is that if you increase a by 0.001, J increases by 0.003.        <br/>
      </p>
      <p>
And by increase a, I mean, you have to take this value of 5 and just plug in a new value.        <br/>
      </p>
      <p>
Then the change to a will propagate to the right of the computation graph so that J ends up being 33.003.        <br/>
      </p>
      <p>
And so the increase to J is 3 times the increase to a.        <br/>
      </p>
      <p>
So that means this derivative is equal to 3.        <br/>
      </p>
      <p>
And one way to break this down is to say that if you change a, then that will change v.        <br/>
      </p>
      <p>
And through changing v, that would change J.        <br/>
      </p>
      <p>
And so the net change to the value of J when you bump up the value, when you nudge the value of a up a little bit, is that, First, by changing a, you end up increasing v.        <br/>
      </p>
      <p>
Well, how much does v increase?        <br/>
      </p>
      <p>
It is increased by an amount that's determined by dv/da.        <br/>
      </p>
      <p>
And then the change in v will cause the value of J to also increase.        <br/>
      </p>
      <p>
So in calculus, this is actually called the chain rule that if a affects v, affects J, then the amounts that J changes when you nudge a is the product of how much v changes when you nudge a times how much J changes when you nudge v.        <br/>
      </p>
      <p>
So in calculus, again, this is called the chain rule.        <br/>
      </p>
      <p>
And what we saw from this calculation is that if you increase a by 0.001, v changes by the same amount.        <br/>
      </p>
      <p>
So dv/da = 1.        <br/>
      </p>
      <p>
So in fact, if you plug in what we have wrapped up previously, dv/dJ = 3 and dv/da = 1.        <br/>
      </p>
      <p>
So the product of these 3 times 1, that actually gives you the correct value that dJ/da = 3.        <br/>
      </p>
      <p>
So this little illustration shows hows by having computed dJ/dv, that is, derivative with respect to this variable, it can then help you to compute dJ/da.        <br/>
      </p>
      <p>
And so that's another step of this backward calculation.        <br/>
      </p>
      <p>
I just want to introduce one more new notational convention.        <br/>
      </p>
      <p>
Which is that when you're witting codes to implement backpropagation, there will usually be some final output variable that you really care about.        <br/>
      </p>
      <p>
So a final output variable that you really care about or that you want to optimize.        <br/>
      </p>
      <p>
And in this case, this final output variable is J.        <br/>
      </p>
      <p>
It's really the last node in your computation graph.        <br/>
      </p>
      <p>
And so a lot of computations will be trying to compute the derivative of that final output variable.        <br/>
      </p>
      <p>
So d of this final output variable with respect to some other variable.        <br/>
      </p>
      <p>
Then we just call that dvar.        <br/>
      </p>
      <p>
So a lot of the computations you have will be to compute the derivative of the final output variable, J in this case, with various intermediate variables, such as a, b, c, u or v.        <br/>
      </p>
      <p>
And when you implement this in software, what do you call this variable name?        <br/>
      </p>
      <p>
One thing you could do is in Python, you could give us a very long variable name like dFinalOurputVar/dvar.        <br/>
      </p>
      <p>
But that's a very long variable name.        <br/>
      </p>
      <p>
You could call this, I guess, dJdvar.        <br/>
      </p>
      <p>
But because you're always taking derivatives with respect to dJ, with respect to this final output variable, I'm going to introduce a new notation.        <br/>
      </p>
      <p>
Where, in code, when you're computing this thing in the code you write, we're just going to use the variable name dvar in order to represent that quantity.        <br/>
      </p>
      <p>
So dvar in a code you write will represent the derivative of the final output variable you care about such as J.        <br/>
      </p>
      <p>
Well, sometimes, the last l with respect to the various intermediate quantities you're computing in your code.        <br/>
      </p>
      <p>
So this thing here in your code, you use dv to denote this value.        <br/>
      </p>
      <p>
So dv would be equal to 3.        <br/>
      </p>
      <p>
And your code, you represent this as da, which is we also figured out to be equal to 3.        <br/>
      </p>
      <p>
So we've done backpropagation partially through this computation graph.        <br/>
      </p>
      <p>
Let's go through the rest of this example on the next slide.        <br/>
      </p>
      <p>
So let's go to a cleaned up copy of the computation graph.        <br/>
      </p>
      <p>
And just to recap, what we've done so far is go backward here and figured out that dv = 3.        <br/>
      </p>
      <p>
And again, the definition of dv, that's just a variable name, where the code is really dJ/dv.        <br/>
      </p>
      <p>
We've figured out that da = 3.        <br/>
      </p>
      <p>
And again, da is the variable name in your code and that's really the value dJ/da.        <br/>
      </p>
      <p>
And we hand wave how we've gone backwards on these two edges like so.        <br/>
      </p>
      <p>
Now let's keep computing derivatives.        <br/>
      </p>
      <p>
Now let's look at the value u.        <br/>
      </p>
      <p>
So what is dJ/du?        <br/>
      </p>
      <p>
Well, through a similar calculation as what we did before and then we start off with u = 6.        <br/>
      </p>
      <p>
If you bump up u to 6.001, then v, which is previously 11, goes up to 11.001.        <br/>
      </p>
      <p>
And so J goes from 33 to 33.003.        <br/>
      </p>
      <p>
And so the increase in J is 3x, so this is equal.        <br/>
      </p>
      <p>
And the analysis for u is very similar to the analysis we did for a.        <br/>
      </p>
      <p>
This is actually computed as dJ/dv times dv/du, where this we had already figured out was 3.        <br/>
      </p>
      <p>
And this turns out to be equal to 1.        <br/>
      </p>
      <p>
So we've gone up one more step of backpropagation.        <br/>
      </p>
      <p>
We end up computing that du is also equal to 3.        <br/>
      </p>
      <p>
And du is, of course, just this dJ/du.        <br/>
      </p>
      <p>
Now we just step through one last example in detail.        <br/>
      </p>
      <p>
So what is dJ/db?        <br/>
      </p>
      <p>
So here, imagine if you are allowed to change the value of b.        <br/>
      </p>
      <p>
And you want to tweak b a little bit in order to minimize or maximize the value of J.        <br/>
      </p>
      <p>
So what is the derivative or what's the slope of this function J when you change the value of b a little bit?        <br/>
      </p>
      <p>
It turns out that using the chain rule for calculus, this can be written as the product of two things.        <br/>
      </p>
      <p>
This dJ/du times du/db.        <br/>
      </p>
      <p>
And the reasoning is if you change b a little bit, so b = 3 to, say, 3.001.        <br/>
      </p>
      <p>
The way that it will affect J is it will first affect u.        <br/>
      </p>
      <p>
So how much does it affect u?        <br/>
      </p>
      <p>
Well, u is defined as b times c.        <br/>
      </p>
      <p>
So this will go from 6, when b = 3, to now 6.002 because c = 2 in our example here.        <br/>
      </p>
      <p>
And so this tells us that du/db = 2.        <br/>
      </p>
      <p>
Because when you bump up b by 0.001, u increases twice as much.        <br/>
      </p>
      <p>
So du/db, this is equal to 2.        <br/>
      </p>
      <p>
And now, we know that u has gone up twice as much as b has gone up.        <br/>
      </p>
      <p>
Well, what is dJ/du?        <br/>
      </p>
      <p>
We've already figured out that this is equal to 3.        <br/>
      </p>
      <p>
And so by multiplying these two out, we find that dJ/db = 6.        <br/>
      </p>
      <p>
And again, here's the reasoning for the second part of the argument.        <br/>
      </p>
      <p>
Which is we want to know when u goes up by 0.002, how does that affect J?        <br/>
      </p>
      <p>
The fact that dJ/du = 3, that tells us that when u goes up by 0.002, J goes up 3 times as much.        <br/>
      </p>
      <p>
So J should go up by 0.006.        <br/>
      </p>
      <p>
So this comes from the fact that dJ/du = 3.        <br/>
      </p>
      <p>
And if you check the math in detail, you will find that if b becomes 3.001, then u becomes 6.002, v becomes 11.002.        <br/>
      </p>
      <p>
So that's a + u, so that's 5 + u.        <br/>
      </p>
      <p>
And then J, which is equal to 3 times v, that ends up being equal to 33.006.        <br/>
      </p>
      <p>
And so that's how you get that dJ/db = 6.        <br/>
      </p>
      <p>
And to fill that in, this is if we go backwards, so this is db = 6.        <br/>
      </p>
      <p>
And db really is the Python code variable name for dJ/db.        <br/>
      </p>
      <p>
And I won't go through the last example in great detail.        <br/>
      </p>
      <p>
But it turns out that if you also compute out dJ, this turns out to be dJ/du times du.        <br/>
      </p>
      <p>
And this turns out to be 9, this turns out to be 3 times 3.        <br/>
      </p>
      <p>
I won't go through that example in detail.        <br/>
      </p>
      <p>
So through this last step, it is possible to derive that dc is equal to.        <br/>
      </p>
      <p>
So the key takeaway from this video, from this example, is that when computing derivatives and computing all of these derivatives, the most efficient way to do so is through a right to left computation following the direction of the red arrows.        <br/>
      </p>
      <p>
And in particular, we'll first compute the derivative with respect to v.        <br/>
      </p>
      <p>
And then that becomes useful for computing the derivative with respect to a and the derivative with respect to u.        <br/>
      </p>
      <p>
And then the derivative with respect to u, for example, this term over here and this term over here.        <br/>
      </p>
      <p>
Those in turn become useful for computing the derivative with respect to b and the derivative with respect to c.        <br/>
      </p>
      <p>
So that was the computation graph and how does a forward or left to right calculation to compute the cost function such as J that you might want to optimize.        <br/>
      </p>
      <p>
And a backwards or a right to left calculation to compute derivatives.        <br/>
      </p>
      <p>
If you're not familiar with calculus or the chain rule, I know some of those details, but they've gone by really quickly.        <br/>
      </p>
      <p>
But if you didn't follow all the details, don't worry about it.        <br/>
      </p>
      <p>
In the next video, we'll go over this again in the context of logistic regression.        <br/>
      </p>
      <p>
And show you exactly what you need to do in order to implement the computations you need to compute the derivatives of the logistic regression model.        <br/>
      </p>
    </div>
  </body>
</html>
