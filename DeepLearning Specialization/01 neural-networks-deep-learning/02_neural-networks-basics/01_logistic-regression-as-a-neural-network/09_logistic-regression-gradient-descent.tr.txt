Tekrar hoşgeldiniz. Bu videoda Lojistik regresyon için gradyan düşümü (gradient descent) uygulamak amacıyla türev nasıl hesaplanır bahsedeceğiz. uygulamada yapacağınız şeyler bu konuyla ilgili akılda tutmanız gereken şeyler olacaktır. Yani, lojistik regresyon için gradyan düşümü uygulamak için gereken temel denklemler. Bu videoda, hesaplama grafiğini kullanarak bu hesaplamayı yapmak istiyorum. Hesaplama grafiğini kullanarak lojistik regresyon için gradyan düşümü biraz abartılı olduğunu itiraf etmeliyim, Ama bu fikirlere aşina olmak için şunları açıklamak istiyorum, Umarım, ayrıntılı bir şekilde sinir ağlarını konuştuğumuzda biraz daha anlamlı olacaktır. Bunun için, lojistik regreson için gradyan düşümüne giriş yapalım. Tekrarlamak gerekirse, aşağıdaki gibi lojistik regresyon kurmuştuk, Tahminleriniz, ŷ, aşağıdaki gibi tanımlanır, burada z olmasıdır. Şimdilik sadece bir örneğe odaklanırsak, o zaman Loss(Loss Function), ya da bu örneğe nazaran, aşağıdaki gibi tanımlanır, A'nın lojistik regrasyonun çıktısı olduğu yer, ve Y yerdeki gerçek etikettir. Bunu bir hesaplama grafiği olarak yazalım ve bu örnek için Diyelim ki sadece iki tane var, X1 ve X2. Z'yi hesaplamak için, W1'i girmemiz gerekecek W2 ve B, X1, X2 özellik değerlerine ek olarak. Bu şeyler, bir hesaplama grafiğinde, W1 olan Z'yi hesaplamak için kullanılır, X1 + W2 X2 + B, Bunu çerçeve içine alalım Sonra, ŷ hesaplayalım, ya da A =σ(z) hesapla grafiğinde bir sonraki adım, son olarak, L(a,y) hesaplayalım ve formülü tekrar kopyalamayacağım. Lojistik regresyonda, yapmak istediğimiz, parametreleri değiştirmek, W ve B, bu Loss'u basitleştirmek için. Tek bir eğitim örneğinde nasıl hesaplandığını gösteren 4 propagation (yayılım) adımdan bahsettik. Şimdi, türevleri hesaplamak için geriye doğru nasıl gideceğimizi konuşalım. İşte diyagramın temizlenmiş bir versiyonu. Çünkü yapmak istediğimiz şey, bu Loss'la ilgili olarak türevleri hesaplamaktır. Geriye doğru giderken yapmak istediğimiz ilk şey, bu Loss'un türevini hesaplamaktır. Buradaki A değişkenine göre senaryo. Yani, kod da Bu değişkeni göstermek için sadece "da" kullanıyorsunuz. Calculus'a (hesaplama) aşina iseniz, bunun -y/b + 1-y/1-a olduğu sonucuna varabilirdiniz. Ve bunu yapmanın yolu, Loss için formülü alıyorsunuz ve eğer calculus bilgisine aşinaysanız türevi değişkene göre hesaplayabilirsiniz. küçük harf A ve bu formülü elde edersiniz. Ancak, matematik bilgisine aşina değilseniz, endişelenmeyin. Türev formunu ve bu kurs boyunca başka ne ihtiyacınız varsa karşılayacağız. Calculus'ta uzman iseniz, Loss'un formülünü aramanızı tavsiye ederim. önceki slaytları ve hesaplamayı kullanarak A'ya göre türev alma, ama bunu yapmak için yeterli matematik bilmiyorsanız, bunun için endişelenmeyin. Şimdi, bu miktarda da ve türevi veya son alfa değişkeninizi A'ya göre hesapladıktan sonra, daha sonra geriye gidebilirsiniz. dz'yi gösterebiliyorsunuz ki, Bu değişken adı denen kısım, bu Loss'un türevi olacak, Z'ye veya L'ye karşı, A ve Y de dahil olmak üzere Loss'u gerçekten parametre olarak yazabilir ya da yazamazsınız, değil mi? Her iki gösterim de eşit derecede kabul edilebilir. Bunun A-Y'ye eşit olduğunu gösterebiliriz. Calculus uzmanları için sadece birkaç yorum, Eğer calculus'ta uzman değilseniz, bunun için endişelenmeyin. Ama bu, dL dz ortaya çıkıyor Bu dL/da çarpı da/dz olarak ifade edilebilir, ve da/dz ortaya çıkar, Bu a(1-a) olduğu ortaya çıkıyor ve dL/da daha önce burada çalıştık, Bu iki niceliği alırsanız, dL/da Bu terim, da/dz ile birlikte, bu terimle ve sadece bu iki şeyi alıp çarpın. Denklemin A-Y'ye basitleştirdiğini gösterebilirsiniz. Bunun türevini bu şekilde alırsanız, ve bu forma kısaca değinen zincir kuraldır. Calculus'ta bilgili iseniz, bu hesaplamayı kendiniz yapmaktan çekinmeyin, ama eğer bilmiyorsanız, bilmeniz gereken tek şey hesaplayabilirsiniz. A-Y olarak DZ ve biz zaten bu hesabı sizin için yaptık. Daha sonra, bu hesaplamadaki son adım, W ve B'yi ne kadar değiştirmeniz gerektiğini hesaplamak için geri dönmektir. Özellikle, W1 bakımından ve tırnak içinde türevin bu dw1 gerektirdiğini ve bunun X1 kere dz'ye eşit olduğunu gösterebilirsiniz. Sonra, benzer şekilde, W2'yi değiştirmek istediğiniz dW2, X2 çarpı dz ve B, affedersiniz, dB dZ'ye eşittir. Sadece bu bir örneğe göre gradyan düşümü yapmak isterseniz, Yapacağınız şey; dz'yi hesaplamak için bu formülü kullanırdınız, ve sonra dW1, dW2, hesaplamak için bu formülleri kullanın db ve sonra bu güncelleştirmeleri gerçekleştirin. W1, W1 eksi olarak güncellenir, öğrenme oranı alfa, çarpı dW1. W2 benzer şekilde güncellenir, B, B eksi öğrenme oranı çarpı db olarak ayarlanır. Ve böylece, bu tek bir örneğe göre bir derecelik adım olacaktır. Türevleri nasıl hesaplayacağınızı ve nasıl uygulayacağınızı görüyorsunuz. Tek bir eğitim örneğine göre lojistik regresyon için gradyan düşüm. Ancak eğitim lojistik regresyon modeli, M eğitim örneklerinin eğitim setleri verilen sadece bir eğitim örneğiniz yok. Bir sonraki videoda, bu fikirleri nasıl alabileceğinizi ve öğrenmeye nasıl uygulayabileceğinizi görelim. sadece bir örnek değil ama tüm bir eğitim setinden.