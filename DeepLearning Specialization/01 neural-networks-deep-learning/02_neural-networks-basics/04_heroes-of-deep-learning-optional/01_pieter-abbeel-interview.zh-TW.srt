1
00:00:02,420 --> 00:00:04,575
很感謝您, Pieter

2
00:00:04,575 --> 00:00:06,690
今天加入我們的談話

3
00:00:06,690 --> 00:00:08,560
我想很多人知道您是

4
00:00:08,560 --> 00:00:12,150
著名的機器學習和深度學習機器人研究人員

5
00:00:12,150 --> 00:00:15,550
我想讓人們聽一些您自己的故事

6
00:00:15,550 --> 00:00:18,220
您怎麼會從事這項工作？

7
00:00:18,220 --> 00:00:22,300
這是一個好的問題，其實如果你會問我當我 14 歲的時候

8
00:00:22,300 --> 00:00:24,775
我的志願

9
00:00:24,775 --> 00:00:26,775
可能不是這個

10
00:00:26,775 --> 00:00:28,285
事實上, 當時

11
00:00:28,285 --> 00:00:32,565
我想成為一名職業籃球運動員會是正確的路

12
00:00:32,565 --> 00:00:34,680
我想我沒辦法達成

13
00:00:34,680 --> 00:00:36,430
我覺得機器學習很幸運

14
00:00:36,430 --> 00:00:38,250
籃球事情不順利

15
00:00:38,250 --> 00:00:39,510
是的, 那行不通

16
00:00:39,510 --> 00:00:41,890
籃球很好玩但那行不通

17
00:00:41,890 --> 00:00:44,885
如果把它當成是一個職業

18
00:00:44,885 --> 00:00:48,530
所以，在學校我最喜歡的就是物理和數學

19
00:00:48,530 --> 00:00:50,005
所以，從那裡

20
00:00:50,005 --> 00:00:52,120
似乎很自然地學習工程

21
00:00:52,120 --> 00:00:55,735
應用物理和數學在現實世界中

22
00:00:55,735 --> 00:00:58,150
其實 , 後來畢業於電機工程

23
00:00:58,150 --> 00:01:00,355
我其實不確定要做什麼, 因為

24
00:01:00,355 --> 00:01:03,981
真的, 任何工程我都有興趣

25
00:01:03,981 --> 00:01:07,680
瞭解任何東西如何作用我都有興趣

26
00:01:07,680 --> 00:01:09,595
試著建造任何東西都有興趣

27
00:01:09,595 --> 00:01:11,470
在某種意義上

28
00:01:11,470 --> 00:01:13,690
人工智慧勝出因為它似乎

29
00:01:13,690 --> 00:01:18,280
可以某種程度幫助所有學科以某種方式

30
00:01:18,280 --> 00:01:22,370
它似乎是任何東西的核心

31
00:01:22,370 --> 00:01:24,575
想想看機器如何可以思考

32
00:01:24,575 --> 00:01:30,160
也許那遠比選擇一個特定的學科更核心

33
00:01:30,160 --> 00:01:33,260
我一直說 AI 是新的電力

34
00:01:33,260 --> 00:01:35,020
似乎 14歲的您

35
00:01:35,020 --> 00:01:37,923
早已經有了這樣的視野

36
00:01:37,923 --> 00:01:44,465
過去幾年您做了很多工作在深度強化學習

37
00:01:44,465 --> 00:01:49,315
發生了什麼事?為什麼深度強化學習突然起飛?

38
00:01:49,315 --> 00:01:51,030
在我做深度強化學習之前

39
00:01:51,030 --> 00:01:52,765
我做了很多強化學習

40
00:01:52,765 --> 00:01:56,115
實際上是跟您及 Durant 在史丹佛

41
00:01:56,115 --> 00:01:59,863
我們做了無人直升機飛行

42
00:01:59,863 --> 00:02:02,440
後來在柏克萊跟我一些學生

43
00:02:02,440 --> 00:02:05,440
讓機器人學會折疊洗衣

44
00:02:05,440 --> 00:02:09,340
這工作歸類於學習的組合

45
00:02:09,340 --> 00:02:13,015
不使用學習是無法辦到的

46
00:02:13,015 --> 00:02:18,120
同時跟很多專業領域達人結合學習來讓這個可行

47
00:02:18,120 --> 00:02:20,975
而這是很

48
00:02:20,975 --> 00:02:22,600
有趣因為您需要專業領域達人

49
00:02:22,600 --> 00:02:24,310
去尋找他們很有趣, 同時

50
00:02:24,310 --> 00:02:28,234
非常花時間對於每個新的應用要想成功

51
00:02:28,234 --> 00:02:31,060
您需要專業領域達人跟機器學習專家

52
00:02:31,060 --> 00:02:34,240
對我來說是在 2012 年

53
00:02:34,240 --> 00:02:39,910
ImageNet 從 Geoff Hinton多倫多團隊的突破性結果

54
00:02:39,910 --> 00:02:42,880
AlexNet 展示了監督式學習, 突然之間

55
00:02:42,880 --> 00:02:48,220
可以用很少的專業領域工程達人

56
00:02:48,220 --> 00:02:50,410
只有很少的視野工程專家在 AlexNet

57
00:02:50,410 --> 00:02:53,075
這使我想起我們真的應該重新檢視

58
00:02:53,075 --> 00:02:57,610
強化學習在相同的觀點下看看是否我們可以

59
00:02:57,610 --> 00:03:01,075
讓強化學習的轉向的可行性, 做

60
00:03:01,075 --> 00:03:05,950
剛剛發生在深度監督式學習一樣有趣的事

61
00:03:05,950 --> 00:03:08,565
似乎您比大部分的人更早

62
00:03:08,565 --> 00:03:12,250
看到深度強化學習的潛力

63
00:03:12,250 --> 00:03:14,365
現在看未來

64
00:03:14,365 --> 00:03:16,180
您看下一步呢？

65
00:03:16,180 --> 00:03:17,260
您的預測對於

66
00:03:17,260 --> 00:03:20,440
即將來到的深度強化學習的下幾個方向是什麼？

67
00:03:20,440 --> 00:03:23,270
我想深度強化學習的有趣地方是

68
00:03:23,270 --> 00:03:26,795
有比監督式學習更多的問題

69
00:03:26,795 --> 00:03:29,817
在監督式學習, 是有關於輸入輸出的映射

70
00:03:29,817 --> 00:03:34,505
在強化學習裡的概念是: 這些資料從何而來?

71
00:03:34,505 --> 00:03:36,580
所以這是探索的問題

72
00:03:36,580 --> 00:03:38,470
當您有了資料，您如何歸類分配？

73
00:03:38,470 --> 00:03:43,315
您如何理解什麼樣早先的動作會得到以後的獎勵 ？

74
00:03:43,315 --> 00:03:44,830
然後, 還有安全問題

75
00:03:44,830 --> 00:03:47,335
當您有一個系統自動收集資料

76
00:03:47,335 --> 00:03:50,140
這實際上在大部分情況下是十分危險的

77
00:03:50,140 --> 00:03:51,880
想像一下, 自動駕駛公司說

78
00:03:51,880 --> 00:03:53,825
我們來跑深度強化學習

79
00:03:53,825 --> 00:03:55,690
很有可能這車子會弄出很多

80
00:03:55,690 --> 00:03:57,985
意外在他變得有用之前

81
00:03:57,985 --> 00:03:59,650
您需要負面的例子, 對吧 ？

82
00:03:59,650 --> 00:04:02,000
您真的需要一些負的例子

83
00:04:02,000 --> 00:04:04,930
跟希望是正的例子

84
00:04:04,930 --> 00:04:07,540
我想還是有很多挑戰在

85
00:04:07,540 --> 00:04:09,760
深度強化學習在

86
00:04:09,760 --> 00:04:12,635
一些特定的方面讓這些東西可行

87
00:04:12,635 --> 00:04:14,520
深入的部分在於表達方式

88
00:04:14,520 --> 00:04:18,455
但強化學習本身也有很多問題

89
00:04:18,455 --> 00:04:20,485
我的感覺是

90
00:04:20,485 --> 00:04:22,810
因為深度學習的前進

91
00:04:22,810 --> 00:04:27,430
一部分的謎團在強化學習已經被大部分解開

92
00:04:27,430 --> 00:04:29,075
也就是表達部分

93
00:04:29,075 --> 00:04:31,540
如果有一種規律我們

94
00:04:31,540 --> 00:04:34,795
也許可以用深度網路來代表它來捕捉這種規律

95
00:04:34,795 --> 00:04:39,400
如何梳理這些規律在強化學習仍然是一個巨大的挑戰

96
00:04:39,400 --> 00:04:41,740
我想大的挑戰是

97
00:04:41,740 --> 00:04:45,695
如何讓系統合理化經過一段長的時間

98
00:04:45,695 --> 00:04:47,770
所以現在, 很多的成功

99
00:04:47,770 --> 00:04:50,650
在深度強化學習是很短的時間

100
00:04:50,650 --> 00:04:52,000
問題在於

101
00:04:52,000 --> 00:04:54,445
如果您可以在五秒的時間表現很好

102
00:04:54,445 --> 00:04:57,815
您在整個問題會表現得很好嗎？

103
00:04:57,815 --> 00:05:02,599
一個五秒的規模是非常不同於一天的規模

104
00:05:02,599 --> 00:05:06,930
或者一個機器人或者軟體代理人的生命週期

105
00:05:06,930 --> 00:05:09,240
我想有很多的挑戰在那裡

106
00:05:09,240 --> 00:05:12,790
我想安全性有很多的挑戰在於

107
00:05:12,790 --> 00:05:14,920
您如何安全地學習跟如何

108
00:05:14,920 --> 00:05:17,785
持續地學習當您已經很好的時候?

109
00:05:17,785 --> 00:05:20,305
舉個例子

110
00:05:20,305 --> 00:05:23,070
很多人都很熟悉的, 自駕車

111
00:05:23,070 --> 00:05:26,375
要使得自駕車比人類駕駛好

112
00:05:26,375 --> 00:05:31,990
人類駕車也許會碰到糟糕的意外大約每三百萬哩

113
00:05:31,990 --> 00:05:35,763
所以需要很長的時間才能見到負的資料

114
00:05:35,763 --> 00:05:37,510
當您的系統像是很棒的人類駕駛

115
00:05:37,510 --> 00:05:40,835
但如果您想要自駕車表現比人類好

116
00:05:40,835 --> 00:05:43,930
在這一點資料收集變得很難去獲得

117
00:05:43,930 --> 00:05:48,175
有趣的資料來提升您的系統

118
00:05:48,175 --> 00:05:52,420
有很多的挑戰來自於資料探索

119
00:05:52,420 --> 00:05:57,190
我現在最興奮的一件事是看到

120
00:05:57,190 --> 00:06:02,720
如果您可以退一步也學習強化學習演算法

121
00:06:02,720 --> 00:06:05,030
強化是非常複雜的

122
00:06:05,030 --> 00:06:07,450
歸類分配很複雜, 資料探索很複雜

123
00:06:07,450 --> 00:06:08,905
或許, 就像

124
00:06:08,905 --> 00:06:13,795
監督式學習的深度學習能夠取代很多專業領域達人

125
00:06:13,795 --> 00:06:17,320
或許我們可以用程式學習

126
00:06:17,320 --> 00:06:20,140
用強化學習程式做到這一切

127
00:06:20,140 --> 00:06:22,510
而不是由我們設計這些細節

128
00:06:22,510 --> 00:06:25,560
學習獎勵函數或者整個專案

129
00:06:25,560 --> 00:06:28,150
會是學習整個強化學習專案

130
00:06:28,150 --> 00:06:30,430
將會是, 想像

131
00:06:30,430 --> 00:06:34,255
您有強化學習專案, 不管做什麼

132
00:06:34,255 --> 00:06:38,320
您丟給它一些問題然後看它需要學多久

133
00:06:38,320 --> 00:06:41,020
然後您說, 好吧 , 需要一點時間

134
00:06:41,020 --> 00:06:44,950
再讓另一個專案修改這個強化學習專案

135
00:06:44,950 --> 00:06:48,045
經過修改後, 看它可以學習多快

136
00:06:48,045 --> 00:06:49,641
如果它學得比較快

137
00:06:49,641 --> 00:06:54,380
那會是一個好的修改,也許保留它然後繼續改進

138
00:06:54,380 --> 00:06:57,630
我明白了, 這是正確的方向

139
00:06:57,630 --> 00:06:59,290
我想這也許跟

140
00:06:59,290 --> 00:07:01,510
可用的計算量有關

141
00:07:01,510 --> 00:07:05,860
應該是要跑強化學習在內迴圈中

142
00:07:05,860 --> 00:07:08,975
對照現在我們跑強化學習在最後一件事

143
00:07:08,975 --> 00:07:11,260
越多我們可以用的計算能力

144
00:07:11,260 --> 00:07:14,545
越是有可能跑一些

145
00:07:14,545 --> 00:07:19,160
像強化學習在內迴圈在大的演算法中

146
00:07:19,160 --> 00:07:22,080
從 14 歲開始

147
00:07:22,080 --> 00:07:25,355
您在AI 做了將近20幾年

148
00:07:25,355 --> 00:07:32,795
可以告訴我們您覺得AI 在這段期間的演變嗎?

149
00:07:32,795 --> 00:07:35,280
當我開始做 AI

150
00:07:35,280 --> 00:07:38,230
它真的很有趣因為它

151
00:07:38,230 --> 00:07:41,445
恰巧是我來史丹佛做我的碩士學位

152
00:07:41,445 --> 00:07:46,998
有一些偶像像是 John McCarthy 我跟他交談過

153
00:07:46,998 --> 00:07:49,300
但他有很不同的方向

154
00:07:49,300 --> 00:07:50,460
在 2000年時

155
00:07:50,460 --> 00:07:52,115
相對於大部分的人做的

156
00:07:52,115 --> 00:07:54,958
也跟 Daphne Kokker 談過

157
00:07:54,958 --> 00:07:59,320
我想我很多起初AI的想法是Daphne塑造的

158
00:07:59,320 --> 00:08:04,300
她的AI課程, 她的機率圖形模型課程

159
00:08:04,300 --> 00:08:06,820
是真的引起好奇心對於

160
00:08:06,820 --> 00:08:11,450
僅僅是一個她的很多隨機變數的分佈能夠條件於

161
00:08:11,450 --> 00:08:14,950
一些子集合然後得出有關其他相關的結論, 可能

162
00:08:14,950 --> 00:08:19,015
真的給您很多, 如果您可以讓它變得能夠計算

163
00:08:19,015 --> 00:08:23,170
而真正的挑戰在於讓它可計算

164
00:08:23,170 --> 00:08:25,090
而從那裡

165
00:08:25,090 --> 00:08:28,335
我開始我的博士學位而您來到史丹佛

166
00:08:28,335 --> 00:08:30,910
我想您給我很好的現實檢驗

167
00:08:30,910 --> 00:08:35,350
那不是一個好的度量標準來衡量您的工作

168
00:08:35,350 --> 00:08:38,470
真的試著看這連結從

169
00:08:38,470 --> 00:08:41,710
您做什麼, 到這個會產生什麼影響

170
00:08:41,710 --> 00:08:46,660
產生什麼變化而不僅僅只是看數學在您的工作發生了什麼

171
00:08:46,660 --> 00:08:48,425
是的, 真令人驚訝

172
00:08:48,425 --> 00:08:50,685
我沒意識到, 我已經忘了

173
00:08:50,685 --> 00:08:54,267
是的, 那就是這麼一回事, 除了人們經常問

174
00:08:54,267 --> 00:09:01,090
如果您只可以引用一件事您一直記住從 Andrew 得到的建議

175
00:09:01,090 --> 00:09:05,995
就是確定您可以看到它真的可以做一些事情的這些連結

176
00:09:05,995 --> 00:09:11,332
您已經而且持續的有很驚人的 AI 事業

177
00:09:11,332 --> 00:09:14,750
對於一些人看這段影片

178
00:09:14,750 --> 00:09:18,815
如果他們也想進入或者追尋AI 的事業

179
00:09:18,815 --> 00:09:20,985
您會給他們什麼建議?

180
00:09:20,985 --> 00:09:25,185
我想這是好的時間點來進入人工智慧領域

181
00:09:25,185 --> 00:09:28,965
如果您看到對於這類人的需求, 是如此之高

182
00:09:28,965 --> 00:09:30,741
有很多的就業機會

183
00:09:30,741 --> 00:09:32,365
很多您可以做的事, 研究方面

184
00:09:32,365 --> 00:09:34,735
成立一個新的公司等等

185
00:09:34,735 --> 00:09:39,240
我會說, 是的, 這樣做絕對是一個聰明的決定

186
00:09:39,240 --> 00:09:41,140
很多時候,您可以自學

187
00:09:41,140 --> 00:09:42,635
不管您在不在學校

188
00:09:42,635 --> 00:09:44,150
有很多線上課程， 舉例來說

189
00:09:44,150 --> 00:09:45,585
您的機器學習課程

190
00:09:45,585 --> 00:09:48,400
還有, 舉個例子

191
00:09:48,400 --> 00:09:52,030
Andrej Karpathy 深度學習課程也有線上影片

192
00:09:52,030 --> 00:09:54,280
是很棒的方式開始

193
00:09:54,280 --> 00:09:57,460
柏克萊也有深度強化學習課程

194
00:09:57,460 --> 00:09:59,260
讓所有的課程上線

195
00:09:59,260 --> 00:10:01,235
這些是很好開始的地方

196
00:10:01,235 --> 00:10:06,470
我想最重要的是確定您自己試著做這些

197
00:10:06,470 --> 00:10:10,055
不只是讀東西或者看影片而是試著做看看

198
00:10:10,055 --> 00:10:14,347
使用像 TensorFlow

199
00:10:14,347 --> 00:10:16,040
Chainer, Theano, PyTorch 等等框架

200
00:10:16,040 --> 00:10:17,350
用您喜歡用的

201
00:10:17,350 --> 00:10:21,980
真的是很簡單上手跟跑得很快

202
00:10:21,980 --> 00:10:24,669
自己練習, 是吧?

203
00:10:24,669 --> 00:10:27,105
建置完成後來看哪些可行哪些不可行

204
00:10:27,105 --> 00:10:29,360
上個禮拜有一篇文章

205
00:10:29,360 --> 00:10:31,715
在 Mashable 有關一位16歲孩子在英國

206
00:10:31,715 --> 00:10:34,580
是 Kaggle 比賽的領先者之一

207
00:10:34,580 --> 00:10:36,690
這篇文章說

208
00:10:36,690 --> 00:10:39,290
他只是走出來學事情

209
00:10:39,290 --> 00:10:41,510
從線上找東西, 自學且

210
00:10:41,510 --> 00:10:44,915
從未上過任何正式的課程

211
00:10:44,915 --> 00:10:49,180
有這麼一個16歲孩子在 kaggle競爭中很具競爭力

212
00:10:49,180 --> 00:10:50,990
所以這一定可行

213
00:10:50,990 --> 00:10:53,120
我們正逢其時

214
00:10:53,120 --> 00:10:54,560
如果人們想要學習

215
00:10:54,560 --> 00:10:55,940
完全正確

216
00:10:55,940 --> 00:10:57,980
我敢說您常被問到一個問題

217
00:10:57,980 --> 00:11:00,160
是如果有人想要進入AI, 機器學習跟深度學習

218
00:11:00,160 --> 00:11:06,885
他們應該攻讀博士學位或者到大公司找工作?

219
00:11:06,885 --> 00:11:12,395
我想絕大一部分取決於您可以得到多少指導

220
00:11:12,395 --> 00:11:14,780
所以，攻讀博士學位

221
00:11:14,780 --> 00:11:16,400
你被保證有這樣指導

222
00:11:16,400 --> 00:11:17,787
教授的工作

223
00:11:17,787 --> 00:11:18,830
是您的指導老師

224
00:11:18,830 --> 00:11:20,800
是來照顧您

225
00:11:20,800 --> 00:11:21,950
試著盡他們可能得來

226
00:11:21,950 --> 00:11:23,565
塑造您

227
00:11:23,565 --> 00:11:28,720
幫助您變得更強在不管您想做什麼, 例如 AI

228
00:11:28,720 --> 00:11:32,060
所以有很清楚的專人，有時候兩位指導老師

229
00:11:32,060 --> 00:11:34,955
這正是他們的工作因為他們是教授

230
00:11:34,955 --> 00:11:37,755
做一位教授最喜歡的是幫助

231
00:11:37,755 --> 00:11:41,200
學生塑造成更有能力做事

232
00:11:41,200 --> 00:11:43,250
但這也不是說在公司就沒辦法

233
00:11:43,250 --> 00:11:46,730
很多公司有真的好的導師喜歡

234
00:11:46,730 --> 00:11:51,110
幫助教育人們進入跟加強他們(這個領域)等等

235
00:11:51,110 --> 00:11:55,515
只是這並不掛保證

236
00:11:55,515 --> 00:12:00,540
相較於真的攻讀博士學位, 那真的是

237
00:12:00,540 --> 00:12:06,020
一個過程您就是要學而且有人幫助您學

238
00:12:06,020 --> 00:12:09,675
所以取決於公司跟取決於博士學位課程

239
00:12:09,675 --> 00:12:14,130
是的, 但我想重點是您可以自學很多東西

240
00:12:14,130 --> 00:12:17,910
但我想您可以學得更快如果您找到一位比較有經驗

241
00:12:17,910 --> 00:12:20,469
把這個當成是

242
00:12:20,469 --> 00:12:24,945
他們的責任花時間幫助您加速整個過程

243
00:12:24,945 --> 00:12:28,780
您是在深度強化學習最常見的領導者之一

244
00:12:28,780 --> 00:12:30,720
什麼是

245
00:12:30,720 --> 00:12:32,930
深度強化學習已經做得很好的?

246
00:12:32,930 --> 00:12:37,450
如果您看一些深度強化學習成功的例子

247
00:12:37,450 --> 00:12:39,000
是很奇妙

248
00:12:39,000 --> 00:12:42,810
舉個例子, 學習玩 Atari 遊戲從圖像素

249
00:12:42,810 --> 00:12:45,540
處理這些像素就只是一些數子

250
00:12:45,540 --> 00:12:49,150
經過處理後變成遊戲搖桿的動作

251
00:12:49,150 --> 00:12:52,605
在一個例子, 我們在柏克萊做的是

252
00:12:52,605 --> 00:12:57,105
我們有一個模擬機器人發明走路而獎勵是

253
00:12:57,105 --> 00:12:59,340
簡單的越往北走越好

254
00:12:59,340 --> 00:13:02,170
且越不影響地面越好

255
00:13:02,170 --> 00:13:06,949
而它決定發明一邊走一邊跑但

256
00:13:06,949 --> 00:13:10,095
沒有人顯示過什麼是走路什麼是跑步

257
00:13:10,095 --> 00:13:14,220
或者機器人在兒童玩具店然後學著將他們放在一起

258
00:13:14,220 --> 00:13:16,935
放一個積木在比賽開幕上等等

259
00:13:16,935 --> 00:13:20,280
我想這真的很有趣, 所有這些都能學習

260
00:13:20,280 --> 00:13:24,510
從原始感測器輸入一直到原始控制項

261
00:13:24,510 --> 00:13:27,990
舉個例子, 馬達的力矩

262
00:13:27,990 --> 00:13:29,225
但同一時間

263
00:13:29,225 --> 00:13:32,460
有趣的是您可以用一個簡單的演算法

264
00:13:32,460 --> 00:13:35,310
舉個例子, 一時脈衝的推力, 您可以學習

265
00:13:35,310 --> 00:13:36,745
可以讓機器人跑步

266
00:13:36,745 --> 00:13:38,135
可以讓機器人站起來

267
00:13:38,135 --> 00:13:40,395
可以與其用兩條腿

268
00:13:40,395 --> 00:13:42,445
換成四條腿機器人

269
00:13:42,445 --> 00:13:46,465
您跑同樣的強化演算法, 它還是會學跑步

270
00:13:46,465 --> 00:13:49,280
所以,不改變強化演算法

271
00:13:49,280 --> 00:13:51,615
是非常一般化, 同樣對於 Atari 遊戲

272
00:13:51,615 --> 00:13:54,565
DQN 是一樣的 DQN 對於每一種遊戲

273
00:13:54,565 --> 00:13:56,640
但當它真的開始碰到

274
00:13:56,640 --> 00:14:00,060
一些瓶頸現在沒辦法做的時候

275
00:14:00,060 --> 00:14:03,490
它的學習總是從頭開始

276
00:14:03,490 --> 00:14:07,405
但如果能從重新使用過去學習的經驗會更好

277
00:14:07,405 --> 00:14:09,640
在下一段學習時可以更快

278
00:14:09,640 --> 00:14:13,100
而這個是目前的瓶頸還沒辦法做到

279
00:14:13,100 --> 00:14:16,490
它永遠從頭開始

280
00:14:16,490 --> 00:14:19,390
依您看,需時多久深度

281
00:14:19,390 --> 00:14:22,420
強化學習部署在機器人上環繞我們四周

282
00:14:22,420 --> 00:14:25,935
機器人開始部署在我們的世界

283
00:14:25,935 --> 00:14:29,380
我想現實面來看可行的是

284
00:14:29,380 --> 00:14:32,770
它開始於監督式學習

285
00:14:32,770 --> 00:14:35,960
行為複製, 人類做工作

286
00:14:35,960 --> 00:14:38,530
我想很多企業會這樣做

287
00:14:38,530 --> 00:14:41,790
人們在幕後做很多的事

288
00:14:41,790 --> 00:14:44,980
想像臉書訊息助理

289
00:14:44,980 --> 00:14:47,980
助理像那樣可以用人類在

290
00:14:47,980 --> 00:14:51,310
幕後做很多事, 機器學習

291
00:14:51,310 --> 00:14:54,380
配合人們做的事開始給一些建議

292
00:14:54,380 --> 00:14:58,130
人們可以有比較少的選項他們可以點擊跟選擇

293
00:14:58,130 --> 00:14:59,640
經過一段時間

294
00:14:59,640 --> 00:15:01,130
當它變得很好時

295
00:15:01,130 --> 00:15:04,465
您開始融入一些強化學習您給它一些目標

296
00:15:04,465 --> 00:15:06,565
不只是配合幕後的人們

297
00:15:06,565 --> 00:15:09,040
但給予目標去達成像是

298
00:15:09,040 --> 00:15:14,110
或許, 這兩個人多快可以排一個會議?

299
00:15:14,110 --> 00:15:16,385
他們多快可以訂機票?

300
00:15:16,385 --> 00:15:18,340
像這樣的事, 需時多久

301
00:15:18,340 --> 00:15:20,065
他們的滿意程度?

302
00:15:20,065 --> 00:15:22,815
但這或許要開始於很多

303
00:15:22,815 --> 00:15:27,605
行為複製對於人們顯示這些如何做到 

304
00:15:27,605 --> 00:15:30,690
看來行為複製在監督式學習去

305
00:15:30,690 --> 00:15:33,580
模擬人類行為然後慢慢的

306
00:15:33,580 --> 00:15:37,434
強化學習用來讓它想長一點的時間

307
00:15:37,434 --> 00:15:38,500
這是對的總結嗎?

308
00:15:38,500 --> 00:15:39,715
我會這樣說，是的

309
00:15:39,715 --> 00:15:43,540
因為從從頭開始的強化學習是一件有趣的事來看

310
00:15:43,540 --> 00:15:46,780
那是超級有趣很少有這麼有趣的事來看

311
00:15:46,780 --> 00:15:50,440
就是強化學習機器人從零開始到發明一些東西

312
00:15:50,440 --> 00:15:54,280
但就是花時間且由時候並不安全

313
00:15:54,280 --> 00:15:56,200
非常感謝, 這真的令人著迷

314
00:15:56,200 --> 00:15:58,005
我真的很高興有這個機會聊天

315
00:15:58,005 --> 00:16:02,670
謝謝您 Andrew, 非常感激有這個機會