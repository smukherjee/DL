1
00:00:00,060 --> 00:00:04,380
上一段的影片我們描述了

2
00:00:02,250 --> 00:00:06,150
深度 l 層神經網路， 也

3
00:00:04,380 --> 00:00:08,550
談到了有關的記號我們用來

4
00:00:06,150 --> 00:00:10,650
描述這樣的網路, 在這段影片您

5
00:00:08,550 --> 00:00:13,769
會看到如何執行正向傳播

6
00:00:10,650 --> 00:00:16,440
在深度網路，像往常一樣我們先

7
00:00:13,769 --> 00:00:18,660
看看正向傳播

8
00:00:16,440 --> 00:00:21,330
在單一訓練例子 x 的樣子

9
00:00:18,660 --> 00:00:22,920
然後我們會談到

10
00:00:21,330 --> 00:00:24,810
向量化版本當您

11
00:00:22,920 --> 00:00:26,849
同時執行正向傳播在

12
00:00:24,810 --> 00:00:29,660
整個訓練集, 但

13
00:00:26,849 --> 00:00:32,579
給予一個單一訓練例子 X

14
00:00:29,660 --> 00:00:34,800
這是您如何計算

15
00:00:32,579 --> 00:00:42,329
第一層的啟動, 對於第一

16
00:00:34,800 --> 00:00:48,239
層您計算 z1 等於 w1 乘 x

17
00:00:42,329 --> 00:00:51,120
加 b1, 所以 w1 跟 b1 是

18
00:00:48,239 --> 00:00:53,879
影響第一層的參數

19
00:00:51,120 --> 00:00:56,899
這是第一層

20
00:00:53,879 --> 00:00:59,280
神經網路, 然後您計算

21
00:00:56,899 --> 00:01:04,979
那一層的啟動值等於

22
00:00:59,280 --> 00:01:06,810
g of z1, 而啟動函數

23
00:01:04,979 --> 00:01:09,090
g 取決於您在第幾層

24
00:01:06,810 --> 00:01:11,010
也許用指標來標示

25
00:01:09,090 --> 00:01:12,689
這是第一層的啟動函數, 如果您這樣做

26
00:01:11,010 --> 00:01:13,320
您就計算了

27
00:01:12,689 --> 00:01:18,360
第一層的啟動值

28
00:01:13,320 --> 00:01:24,470
第二層又是如何呢?

29
00:01:18,360 --> 00:01:32,189
您會這樣計算 z2 等於 w2 a1

30
00:01:24,470 --> 00:01:34,950
加 b2 所以啟動值在

31
00:01:32,189 --> 00:01:39,180
第二層是權值矩陣乘上

32
00:01:34,950 --> 00:01:44,270
第一層的輸出, 這個值, 加上

33
00:01:39,180 --> 00:01:49,579
第二層偏差向量然後 a2

34
00:01:44,270 --> 00:01:55,770
等於啟動函數應用到

35
00:01:49,579 --> 00:01:57,990
z2, 所以這是第二層等等

36
00:01:55,770 --> 00:02:00,299
直到您算到輸出層

37
00:01:57,990 --> 00:02:06,240
就是第四層您會

38
00:02:00,299 --> 00:02:09,959
有 z4 等於這層參數

39
00:02:06,240 --> 00:02:11,780
乘上啟動值

40
00:02:09,959 --> 00:02:14,569
從上一層來的

41
00:02:11,780 --> 00:02:23,930
加上偏差向量然後

42
00:02:14,569 --> 00:02:26,720
同樣的 a4 等於 g of z4

43
00:02:23,930 --> 00:02:29,900
這是您如何計算預估

44
00:02:26,720 --> 00:02:35,390
輸出 y-hat, 一件事情要提醒

45
00:02:29,900 --> 00:02:38,270
這裡的 x 也是 a0, 因為

46
00:02:35,390 --> 00:02:41,209
輸入特徵向量 x 也是

47
00:02:38,270 --> 00:02:44,000
第 0 層的啟動值, 所以我們挖出

48
00:02:41,209 --> 00:02:47,000
x 劃掉 x 然後放 a0

49
00:02:44,000 --> 00:02:48,709
然後您看所有這些

50
00:02:47,000 --> 00:02:53,980
方程式看起來都一樣

51
00:02:48,709 --> 00:03:02,750
一般的規則是 zl 等於

52
00:02:53,980 --> 00:03:05,750
wl 乘 l - 1 加上 bl

53
00:03:02,750 --> 00:03:10,630
然後那一層的啟動值會是

54
00:03:05,750 --> 00:03:16,850
啟動函數應用到

55
00:03:10,630 --> 00:03:20,120
z 值, 所以這是一般化正向

56
00:03:16,850 --> 00:03:23,540
傳播方程式, 所以也們做完了所有這些

57
00:03:20,120 --> 00:03:26,299
對於單一訓練例子, 如何

58
00:03:23,540 --> 00:03:29,660
做向量化

59
00:03:26,299 --> 00:03:32,720
同時作用在整個訓練集

60
00:03:29,660 --> 00:03:35,030
方程式看起來相當類似於

61
00:03:32,720 --> 00:03:40,060
之前, 對於第一層您會有

62
00:03:35,030 --> 00:03:48,410
大寫 Z1 等於 W1 乘上

63
00:03:40,060 --> 00:03:54,650
大寫 X 加 b1, 然後  A1 等於 g

64
00:03:48,410 --> 00:03:57,920
of Z1, 注意到這個 X

65
00:03:54,650 --> 00:03:59,959
是等於 A0, 這是

66
00:03:57,920 --> 00:04:01,850
將訓練例子疊在

67
00:03:59,959 --> 00:04:05,450
不同的列上, 您可以

68
00:04:01,850 --> 00:04:08,269
挖出 X, 您可以放 A0

69
00:04:05,450 --> 00:04:08,720
在這裡, 而下一層

70
00:04:08,269 --> 00:04:16,720
像是

71
00:04:08,720 --> 00:04:21,980
Z2 等於 W2 A1 加 b2, 然後 A2

72
00:04:16,720 --> 00:04:24,530
等於 g of Z2

73
00:04:21,980 --> 00:04:28,370
我們只是拿這些向量 z 或 a

74
00:04:24,530 --> 00:04:29,810
等等將它們疊起來, 所以

75
00:04:28,370 --> 00:04:34,310
這是 z 向量對於第一個訓練

76
00:04:29,810 --> 00:04:37,310
例子, z 向量對於第二個訓練

77
00:04:34,310 --> 00:04:39,830
例子等等直到第 m 個訓練

78
00:04:37,310 --> 00:04:43,700
例子然後依列疊起來

79
00:04:39,830 --> 00:04:47,390
稱之為大寫 Z

80
00:04:43,700 --> 00:04:50,000
同樣的對於大寫 A 也只是像大寫

81
00:04:47,390 --> 00:04:52,040
X 所有訓練例子是列

82
00:04:50,000 --> 00:04:53,720
向量從左疊到右, 然後

83
00:04:52,040 --> 00:04:59,450
一樣在這個程序完成時

84
00:04:53,720 --> 00:05:03,200
y-hat 等於 g of z4 

85
00:04:59,450 --> 00:05:04,670
這也是等於 A4, 這是

86
00:05:03,200 --> 00:05:08,000
對所有訓練例子的預估

87
00:05:04,670 --> 00:05:09,980
水平疊起來

88
00:05:08,000 --> 00:05:12,590
總結一下我們的符號我將

89
00:05:09,980 --> 00:05:17,720
修改一下所們的符號

90
00:05:12,590 --> 00:05:19,820
取代小寫 z 跟 a 用

91
00:05:17,720 --> 00:05:22,070
大寫的同樣字母這已經

92
00:05:19,820 --> 00:05:23,810
像是大寫 Z, 而這給

93
00:05:22,070 --> 00:05:25,790
您向量化的正向

94
00:05:23,810 --> 00:05:29,060
傳播讓您同時執行在

95
00:05:25,790 --> 00:05:32,990
整個訓練集而 A0 

96
00:05:29,060 --> 00:05:35,240
是 X, 如果您看這個

97
00:05:32,990 --> 00:05:37,670
向量化的建置它像是

98
00:05:35,240 --> 00:05:40,370
會有一個迴圈

99
00:05:37,670 --> 00:05:44,360
也就是 for l

100
00:05:40,370 --> 00:05:47,000
等於 1 到 4, l 從 1

101
00:05:44,360 --> 00:05:48,950
到大寫 L, 您需要計算

102
00:05:47,000 --> 00:05:51,860
第一層的啟動值, 然後第二層

103
00:05:48,950 --> 00:05:54,370
然後第三層, 第四層

104
00:05:51,860 --> 00:05:56,660
似乎要用一個迴圈

105
00:05:54,370 --> 00:05:58,550
我知道當建置您的

106
00:05:56,660 --> 00:06:00,770
神經網路時我們通常想去掉

107
00:05:58,550 --> 00:06:03,290
明顯迴圈，但這個地方

108
00:06:00,770 --> 00:06:05,060
我不認為有辦法

109
00:06:03,290 --> 00:06:06,590
建置這個而不用

110
00:06:05,060 --> 00:06:09,080
迴圈， 所以當我們建置正向

111
00:06:06,590 --> 00:06:10,700
傳播時是完全可以有

112
00:06:09,080 --> 00:06:12,740
迴圈當我們計算啟動值

113
00:06:10,700 --> 00:06:15,050
第一層, 第二層, 第

114
00:06:12,740 --> 00:06:17,210
三層, 第四層, 沒有人知道可不可以

115
00:06:15,050 --> 00:06:19,970
我想沒辦法

116
00:06:17,210 --> 00:06:23,060
做這些不用迴圈

117
00:06:19,970 --> 00:06:24,620
從 1 到大寫 L, 從 1 到

118
00:06:23,060 --> 00:06:27,830
您有幾層在您的神經網路

119
00:06:24,620 --> 00:06:30,980
在這裡是完全沒問題的

120
00:06:27,830 --> 00:06:32,690
使用明顯的迴圈

121
00:06:30,980 --> 00:06:35,300
這是深度神經網路的記號

122
00:06:32,690 --> 00:06:37,760
跟我們如何做正向

123
00:06:35,300 --> 00:06:39,680
傳播在這個網路, 如果

124
00:06:37,760 --> 00:06:41,900
我們看到目前的片段有一點點

125
00:06:39,680 --> 00:06:44,000
似曾相似, 那是因為

126
00:06:41,900 --> 00:06:45,830
我們看到的是拿一些片段

127
00:06:44,000 --> 00:06:47,750
類似於您在

128
00:06:45,830 --> 00:06:50,750
神經網路使用一個隱藏層

129
00:06:47,750 --> 00:06:53,420
只是重複多做幾次

130
00:06:50,750 --> 00:06:55,420
實際上當我們建置深度

131
00:06:53,420 --> 00:06:57,860
神經網路, 一種方式

132
00:06:55,420 --> 00:06:59,450
增加您的建置無臭蟲(錯誤)的機會

133
00:06:57,860 --> 00:07:01,580
是用很

134
00:06:59,450 --> 00:07:03,500
系統化的方式來想, 很小心在

135
00:07:01,580 --> 00:07:05,300
您使用矩陣的維度

136
00:07:03,500 --> 00:07:07,280
當我試著寫我的程式時, 我

137
00:07:05,300 --> 00:07:08,960
通常用一張紙

138
00:07:07,280 --> 00:07:11,480
很小心地想著

139
00:07:08,960 --> 00:07:13,940
我使用的矩陣的維度

140
00:07:11,480 --> 00:07:16,570
讓我們看看您也如何可以做到

141
00:07:13,940 --> 00:07:16,570
在下一段影片