1
00:00:00,006 --> 00:00:04,743
В останньому відео ти побачив/ла як виглядає 
нейронна мережа (НМ) з одним прихованим шаром.

2
00:00:04,743 --> 00:00:08,175
В цьому відео давай детальніше розглянемо як ця

3
00:00:08,175 --> 00:00:10,361
НМ обчислює вихідні дані.

4
00:00:10,361 --> 00:00:15,533
Ти побачиш щось дуже схоже на логістичну регресію (ЛР), 
просто повторене багато разів.

5
00:00:15,533 --> 00:00:16,423
Давайте поглянемо.

6
00:00:16,423 --> 00:00:19,364
Ось як виглядає двошарова НМ.

7
00:00:19,364 --> 00:00:23,973
Давай детальніше розглянемо що саме обчислює ця НМ.

8
00:00:23,973 --> 00:00:26,653
Тож раніше ми казали, що ЛР

9
00:00:26,653 --> 00:00:31,035
(цикл ЛР) складається з 2-ох кроків обчислень.

10
00:00:31,035 --> 00:00:34,498
1-ий обчислює z ось таким чином, а 2-ий

11
00:00:34,498 --> 00:00:37,754
обчислює активатори сигмоїди від z.

12
00:00:37,754 --> 00:00:40,536
А НМ просто робить це багато разів.

13
00:00:40,536 --> 00:00:43,953
Давай для початку сфокусуємось на одному з вузлів прихованого шару.

14
00:00:43,953 --> 00:00:46,320
Давай глянемо на перший вузол прихованого шару.

15
00:00:46,320 --> 00:00:48,079
Тож я поки приховаю інші вузли.

16
00:00:48,079 --> 00:00:50,820
Аналогічно як в ЛР зліва

17
00:00:50,820 --> 00:00:54,391
ці вузли прихованого шару мають 2 кроки обчислень.

18
00:00:54,391 --> 00:00:58,418
1-ий крок, ліва половина цього вузла,

19
00:00:58,418 --> 00:01:02,754
обчислює z=wᵀx+b. І ми повинні позначити,

20
00:01:02,754 --> 00:01:08,253
що всі ці величини пов'язані з першим прихованим шаром. 
Ось чому ми маємо

21
00:01:08,253 --> 00:01:13,458
тут багато квадратних дужок. І це - перший вузол прихованого шару.

22
00:01:13,458 --> 00:01:16,597
Ось чому ми маємо там ще й верхній індекс 1.

23
00:01:16,597 --> 00:01:18,424
Тож це 1-ий крок, а далі 2-ий крок

24
00:01:18,424 --> 00:01:24,419
обчислює a[1]₁, що = сигмоїді від z[1]₁.

25
00:01:24,419 --> 00:01:29,013
Тож для обох z та a, згідно конвенції позначень, - a[l]ᵢ -

26
00:01:29,013 --> 00:01:33,770
верхній індекс l в квадратних дужках - це номер шару (1), а

27
00:01:33,770 --> 00:01:37,720
нижній індекс i - це вузол вказаного шару.

28
00:01:37,720 --> 00:01:42,344
Тож вузол, який ми розглядаємо, 
знаходиться в першому (прихованому) шарі і є першим в ньому.

29
00:01:42,344 --> 00:01:45,878
Ось чому верхній і нижній індекси =1.

30
00:01:45,878 --> 00:01:49,965
Тож цей маленький круг (перший вузол) НМ відображає

31
00:01:49,965 --> 00:01:52,579
виконання цих 2-ох кроків обчислень.

32
00:01:52,579 --> 00:01:58,399
Тепер давай глянемо на 2-ий вузол прихованого шару НМ.

33
00:01:58,399 --> 00:02:01,482
Аналогічно як в ЛР зліва,

34
00:02:01,482 --> 00:02:04,781
маленький круг відображає 2 кроки обчислень.

35
00:02:04,781 --> 00:02:08,733
1-ий крок обчислює z (це все ще шар 1, але

36
00:02:08,733 --> 00:02:12,996
вже 2-ий вузол) =wᵀx+b[1]₂,

37
00:02:12,996 --> 00:02:17,880
а потім a[1]₂= сигмоїді від z[1]₂.

38
00:02:17,880 --> 00:02:23,071
Постав відео на паузу якщо хочеш, щоб перепровірити, що

39
00:02:23,071 --> 00:02:28,453
верхні і нижні індекси відповідають написаному фіолетовим.

40
00:02:28,453 --> 00:02:32,831
Тож ми поговорили про перші 2 приховані вузли НМ.

41
00:02:32,831 --> 00:02:36,940
Приховані вузли 3 і 4 відображають аналогічні обчислення.

42
00:02:36,940 --> 00:02:39,778
Тепер давай візьмемо цю пару рівнянь

43
00:02:39,778 --> 00:02:44,169
і цю пару рівнянь і скопіюємо їх на наступний слайд.

44
00:02:44,169 --> 00:02:48,921
Тож ось НМ і перша та друга пари рівнянь,

45
00:02:48,921 --> 00:02:54,050
які ми нещодавно вивели для 1-ого і 2-ого прихованих вузлів.

46
00:02:54,050 --> 00:02:59,022
Якщо продовжити і записати відповідні рівняння для 3-ого і

47
00:02:59,022 --> 00:03:02,093
4-ого прихованих вузлів, то отримаємо таке.

48
00:03:02,093 --> 00:03:06,550
Просто пересвідчимось, що позначення правильні. Оцей вектор w[1]₁

49
00:03:06,550 --> 00:03:09,430
транспонується і множиться на x. Так?

50
00:03:09,430 --> 00:03:13,460
Ось що позначає верхній індекс T - що вектор транспонований.

51
00:03:13,460 --> 00:03:17,585
Тепер, як ти, можливо, вже здогадався/лась, для реалізації НМ

52
00:03:17,585 --> 00:03:20,209
робити це циклом for видається неефективним.

53
00:03:20,209 --> 00:03:25,174
Тож ми візьмемо ці 4 пари рівнянь і векторизуємо їх.

54
00:03:25,174 --> 00:03:29,348
Почнемо з того, що подивимось як обчислити z як вектор.

55
00:03:29,348 --> 00:03:30,859
Виявляється, це можна зробити так.

56
00:03:30,859 --> 00:03:34,843
Давай візьмемо ці w і складемо їх в матрицю.

57
00:03:34,843 --> 00:03:38,767
Ми матимемо w[1]₁ᵀ, тож це буде вектор-рядок.

58
00:03:38,767 --> 00:03:42,231
(Транспонований вектор-стовпець дає вектор-рядок).

59
00:03:42,231 --> 00:03:48,494
Далі w[1]₂ᵀ, w[1]₃ᵀ, w[1]₄ᵀ.

60
00:03:48,494 --> 00:03:54,499
Тож, склавши ці 4 вектори w, отримуємо матрицю.

61
00:03:54,499 --> 00:03:59,204
Можна також розглядати це як 4 вузли ЛР

62
00:03:59,204 --> 00:04:03,913
і що кожен вузол ЛР має відповідний вектор параметрів w,

63
00:04:03,913 --> 00:04:06,535
а, склавши разом ці вектори,

64
00:04:06,535 --> 00:04:08,842
ми отримаємо цю матрицю 4*3.

65
00:04:08,842 --> 00:04:14,281
Якщо далі взяти цю матрицю і помножити її на вхідні ознаки

66
00:04:14,281 --> 00:04:19,806
x₁, x₂, x₃, то, згідно правил множення матриць,

67
00:04:19,806 --> 00:04:24,546
отримаємо w[1]₁ᵀx, w[1]₂ᵀx,

68
00:04:24,546 --> 00:04:30,995
w[1]₃ᵀx, w[1]₄ᵀx. І не забуваємо про b.

69
00:04:30,995 --> 00:04:35,997
Тож додаємо до цього оцей вектор b[1]₁, b[1]₂,

70
00:04:35,997 --> 00:04:40,811
b[1]₃, b[1]₄. Тобто ось це.

71
00:04:40,811 --> 00:04:45,654
Тепер тут b[1]₁, b[1]₂, b[1]₃, b[1]₄.

72
00:04:45,654 --> 00:04:50,579
І бачимо, що кожний рядок результату чітко відповідає

73
00:04:50,579 --> 00:04:55,772
кожному з цих рядків, кожному з цих рівнянь вгорі.

74
00:04:55,772 --> 00:05:00,899
Іншими словами, ми щойно показали, що ось це =

75
00:05:00,899 --> 00:05:05,303
z[1]₁, z[1]₂, z[1]₃, z[1]₄ за визначенням.

76
00:05:05,303 --> 00:05:10,289
І, можливо очевидно, ми це будемо називати вектором z[1].

77
00:05:10,289 --> 00:05:15,097
Він утворюється складанням всіх z в вектор-стовпець.

78
00:05:15,097 --> 00:05:19,524
Векторизація має одне практичне правило, 
що допомагає орієнтуватись [в позначеннях]:

79
00:05:19,524 --> 00:05:23,966
коли шар має кілька вузлів, то їх складають по вертикалі.

80
00:05:23,966 --> 00:05:27,656
Ось чому наші z[1]₁ по z[1]₄ відповідають

81
00:05:27,656 --> 00:05:31,852
4-ом вузлам прихованого шару і ось чому

82
00:05:31,852 --> 00:05:36,481
ми складаємо ці 4 величини по вертикалі - 
щоб сформувати вектор z[1].

83
00:05:36,481 --> 00:05:40,457
І ще дещо про позначення. Ось ця матриця 4*3,

84
00:05:40,457 --> 00:05:45,233
яка отримана складанням маленьких w[1]₁, w[1]₂ і т.д.,

85
00:05:45,233 --> 00:05:49,860
яку ми позначатимемо великою W[1]. І, аналогічно, цей вектор

86
00:05:49,860 --> 00:05:54,623
позначатимемо b[1]. Тож це вектор 4*1.

87
00:05:54,623 --> 00:05:59,584
Тож тепер ми обчислили z, 
використовуючи векторно-матричні позначення.

88
00:05:59,584 --> 00:06:03,535
Останнє, що потрібно зробити, це обчислити значення a.

89
00:06:03,535 --> 00:06:08,195
І навряд чи це несподівано, ми побудуємо a[1]

90
00:06:08,195 --> 00:06:13,019
складанням значень активаторів a[1]₁ по a[1]₄.

91
00:06:13,019 --> 00:06:18,202
Тобто беремо оці 4 значення і складаємо по вертикалі в вектор a[1].

92
00:06:18,202 --> 00:06:21,122
І це буде сигмоїдою від z[1].

93
00:06:21,122 --> 00:06:25,794
А це буде реалізацією сигмоїдальної функції, яка бере

94
00:06:25,794 --> 00:06:30,761
4 елементи z і застосовує до них поелементно сигмоїдальну функцію.

95
00:06:30,761 --> 00:06:36,750
Тож резюмуємо. Ми визначили, що z[1]=W[1] помножити на вектор x

96
00:06:36,750 --> 00:06:41,883
+ вектор b[1], а a[1]= сигмоїді від z[1].

97
00:06:41,883 --> 00:06:47,321
Тож давай скопіюємо це на наступний слайд і побачимо,

98
00:06:47,321 --> 00:06:52,156
що для 1-ого шару НМ з заданими вхідними x

99
00:06:52,156 --> 00:06:56,286
ми маємо z[1]=W[1]x+b[1] і

100
00:06:56,286 --> 00:07:01,526
a[1]=σ(z[1]). І розміри відповідно

101
00:07:01,526 --> 00:07:06,563
4*1=4*3 * 3*1 + 4*1.

102
00:07:06,563 --> 00:07:11,297
А це - 4*1 - такий же розмір, який ми отримуємо вкінці.

103
00:07:11,297 --> 00:07:16,793
Пам'ятаєш ми казали, що x це a[0]? Тож ŷ=a[2].

104
00:07:16,793 --> 00:07:21,560
Якщо захочеш, то можеш замінити оцей z на a[0]. Тому що a[0] -

105
00:07:21,560 --> 00:07:25,417
це всього лише псевдонім для вектора вхідних ознак x.

106
00:07:25,417 --> 00:07:30,968
А тепер, аналогічно, можемо вивести, що розрахунки

107
00:07:30,968 --> 00:07:35,972
в наступному шарі можуть бути записані подібним чином. 
Вихідний шар

108
00:07:35,972 --> 00:07:40,770
має пов'язані параметри w[2] і b[2].

109
00:07:40,770 --> 00:07:44,549
w[2] в цьому випадку буде матрицею 1*4,

110
00:07:44,549 --> 00:07:47,529
b[2] - це просто дійсне число, тобто 1*1.

111
00:07:47,529 --> 00:07:51,982
А z[2] буде дійсним числом і записується як матриця 1*1.

112
00:07:51,982 --> 00:07:57,267
Оце буде матрицею 1*4 помноженою на 4*1 плюс b 1*1.

113
00:07:57,267 --> 00:08:02,397
І в результаті отримаємо дійсне число. 
Якщо розглядати результат як останній вихідний вузол,

114
00:08:02,397 --> 00:08:07,787
аналогічно як в ЛР, де є параметри w і b,

115
00:08:07,787 --> 00:08:12,517
то w відіграватиме роль w[2] транспонованого

116
00:08:12,517 --> 00:08:16,675
(w[2]=wᵀ), а b=b[2].

117
00:08:16,675 --> 00:08:21,665
Тож якщо закрити ліву частину НМ, проігнорувати її,

118
00:08:21,665 --> 00:08:26,434
то залишиться лише останній вихідний вузол, дуже схожий на ЛР,

119
00:08:26,434 --> 00:08:30,010
який відрізняється лише тим, що замість параметрів w і b

120
00:08:30,010 --> 00:08:35,784
ми пишемо w[2] і b[2] з розмірами 4*1 і 1*1.

121
00:08:35,784 --> 00:08:39,765
Резюмуємо. Для ЛР

122
00:08:39,765 --> 00:08:44,620
щоб отримати результат або реалізувати передбачення

123
00:08:44,620 --> 00:08:51,143
потрібно обчислити z=wᵀx+b та ŷ=a=σ(z).

124
00:08:51,143 --> 00:08:55,499
А для НМ з одним прихованим шаром потрібно

125
00:08:55,499 --> 00:09:00,131
реалізувати обчислення всього лише оцих 4-ох рівнянь. І, по суті,

126
00:09:00,131 --> 00:09:04,902
це являється векторизованою реалізацією обчислень спочатку

127
00:09:04,902 --> 00:09:09,329
оцих 4-ох ЛР вузлів прихованого шару (це роблять оці рівняння),

128
00:09:09,329 --> 00:09:13,867
а потім оцей ЛР шар, вихідний шар (це роблять оці рівняння).

129
00:09:13,867 --> 00:09:18,401
Надіюсь я зрозуміло описав. 
Проте, головне запам'ятати, що щоб обчислити

130
00:09:18,401 --> 00:09:22,001
цю НМ, все, що потрібно, - це оці 4 рядки коду.

131
00:09:22,001 --> 00:09:25,706
Тож ти побачив/ла як, маючи один вектор вхідних ознак x,

132
00:09:25,706 --> 00:09:30,278
з допомогою 4-ох рядків коду можна обчислити результати цієї НМ.

133
00:09:30,278 --> 00:09:34,575
Аналогічно як для ЛР ми теж хочемо провести векторизацію

134
00:09:34,575 --> 00:09:39,002
для багатьох тренувальних зразків. І ми це побачимо коли складемо 3

135
00:09:39,002 --> 00:09:43,653
тренувальні зразки в стовпці, в матрицю і дещо модифікуємо її.

136
00:09:43,653 --> 00:09:47,396
Також, аналогічно як в ЛР,

137
00:09:47,396 --> 00:09:50,514
ти зможеш обчислити результати НМ

138
00:09:50,514 --> 00:09:55,114
не лише для 1 тренувального зразка, а для всього тренувального набору.

139
00:09:55,114 --> 00:09:57,939
Тож давай розглянемо це детальніше в наступному відео.