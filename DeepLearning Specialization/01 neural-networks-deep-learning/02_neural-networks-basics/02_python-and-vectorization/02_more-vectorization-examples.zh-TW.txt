在前一段影片您見到一些
如何向量化的例子 使用內建函數來
避免明顯的 迴圈讓您加快
您的程式 讓我們看更多的例子 重要的法則謹記在心是當 您設計您的神經網路程式
或是您的羅吉斯迴歸分析時 儘可能避免
明顯的迴圈 當然不可能完全
不使用迴圈 但當您可以使用內建函數或者 找到其他方法來計算您所需要的 通常會
比您使用明顯的迴圈更快 讓我們看另一個例子 假設您想計算一個向量
U 是矩陣 A 乘上 另一個向量，V 矩陣乘法的定義是您的 Ui 等於 總和於 j, A(i, j), Vj 好是吧。 這是 Ui 的定義 所以
非向量化建置是 設 U 等於  np.zeros 這會是 n 乘 1 然後 for i 等等 for j 等等 然後 Ui += Aij 乘上 Vj 所以這是兩個
迴圈經過 i 跟 j 這是非向量化版本 向量化建置是
 u = np.dot(Ａ,v) 這樣在右邊的向量化建置 現在消除了 兩個不同的迴圈且會快很多 讓我們看下一個例子 假設您已經有一個向量 
v 在記憶體中您想要 應用指數函數到
v 的每一個元素 您計算 U 是一個向量
即 e 的 v1次方, e 的 v2次方 等等直到 e 的 vn次方 這是一個非向量化
的建置, 就是首先 初始化 U 為零向量，然後你 然後您用一個迴圈來
計算一次一個元素 實際上 Python numpy 有
很多內建函數讓您 計算這些向量就只用
一個單一的函數呼叫 所以我會這樣建置
導入 numpy 為 np 然後您只要呼叫 U 等於
np.exp(v), 注意到前面 您用了一個明顯的迴圈
現在用一行程式 這裡 v 是一個輸入向量 u 是一個輸出向量 您消除了明顯得迴圈
而在右邊的建置 會比用明顯的迴圈快很多 實際上, numpy 函數庫有很多
向量值的函數 像 np.log(v) 會計算
逐元素的對數函數 np.abs 計算絕對值 np.maximum 計算
元素中的極大值 所以您取
每一個元素 v 跟 0 的最大值 v 星號 星號 2 v**2 算每一個元素
的平方對於每個元素 1/v 取每個元素的倒數
等等 每當您試著寫
迴圈時 先看一下，看看是否可以呼叫 numpy 內建函式
來做它而不需要用到迴圈 讓我們將所有學到的應用到 羅吉斯迴歸分析
梯度下降建置 看是否我們可以去除
至少兩個迴圈之一 這是我們的程式來計算
羅吉斯迴歸分析的導數 我們有兩個迴圈 一個是在這裡, 
第二個是在這裡 所以在我們的例子 我們有 n 或者說 nx 等於 2 但如果您有更多的特徵 比兩個多的特徵,
那您需要用一個迴圈對於 dw1 dw2, dw3 等等 假設這裡是 for j 等於 1 到 nx dwj 做更新, 是吧? 所以我們想消除這
第二個 for 迴圈 這是我們在這裡要做的 所以我們要做的方式是
與其用明顯的初始化 dw1 dw2 等等為零 我們將去掉這個,
而是將 dw 用成一個向量 我們設 dw 等於np.zeros, 然後 做一個 nx 乘 1 維度的零向量 然後這裡, 與其使用 迴圈經過每一個元素 我們只用這個向量值運算 dw += xi 乘 dZi, 最後 取代這個, 我們用 dw /= m, 現在我們將兩個
迴圈變成一個迴圈 我們還有這一個迴圈
經過每一個訓練例子 我希望這段影片給您
一些感覺有關 向量化 以及去掉一個迴圈 您的程式已經可以跑更快 但實際上我們可以做得更好 因此,在下一段影片, 我將談到如何更深入向量化
羅吉斯迴歸分析 您看到相當驚訝的結果
不使用任何迴圈 不需要一個迴圈
經過這些訓練例子 您可以用程式來處理
整個訓練集 幾乎在一個時間內 讓我們下一段影片見