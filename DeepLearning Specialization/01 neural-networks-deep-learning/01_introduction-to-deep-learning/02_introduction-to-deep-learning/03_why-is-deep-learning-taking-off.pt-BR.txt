Se as ideias técnicas básicas por trás das redes de Aprendizagem Profunda 
tem estado por ai, por décadas, 
então porque somente agora estão decolando? 
Nesse vídeo vamos ver as 
principais causas por trás do aumento do 
aprendizado profundo, porque acho que 
isso vai ajudar você a ver as melhores oportunidades 
dentro da sua própria organização pra aplicar 
essa ferramenta. Nos últimos anos, muitas pessoas tem me perguntado: Andrew 
porque o aprendizado profundo tem funcionado tão bem? E pra responder essa pergunta, essa é a figura que eu desenho. Veja essa figura que eu desenho, onde no eixo horizontal eu coloco a quantidade de dados que temos para uma tarefa. E digamos que no eixo vertical nos colocamos a performance do algorítimo de aprendizado, ou seja, a precisão de nosso classificador de spams ou predição do clique em anúncio 
ou a precisão de nossa rede neural em predizer a posição dos outros carros a partir de um carro sem motorista. Assim, se você plotar a performance de um algorítimo de aprendizado tradicional como suporte a maquina vetorizada ou regressão logística como uma função da quantidade de dados que você tem, você pode ter uma curva parecida com essa, onde a performance melhora a medida que você adiciona mais dados. Mas, depois de um tempo em que a performance esteja num platô como uma linha horizontal (não desenhei muito bem) e não se sabe o que fazer com tantos dados. E o que acontece em nossa sociedade, talvez nos últimos 20 anos é que para muitos problemas nós saímos dessa frequente pouca quantidade de dados para uma quantidade muito grande de dados. E devemos agradecer muito a digitalização de nossa sociedade onde muitas atividades humanas estão agora digitalizadas. Gastamos muito tempo em computadores, websites, app de celulares e atividades com dispositivos digitais que criam dados. E obrigado ao aumento de câmeras baratas embutidas em nosso celulares e também acelerômetros e toda sorte de sensores para Internet das Coisas. Também, nos últimos 20 anos, temos coletado cada vez mais dados para uma série de aplicações, onde apenas acumulamos cada vez mais dados, mais do que algoritmos de aprendizado tradicional são capazes de manipular com eficiência. Então, onde uma nova rede rede neural nos leva, parece ser que se você treina uma pequena onde a performance pode parecer assim. E se você treina uma grande rede neural, que podemos chamar de rede neural de tamanho médio que tem uma performance bem melhor. E se você treina uma rede neural bem grande, pode ver que a performance vai se tornando cada vez melhor. Algumas observações: se você deseja atingir um alto nível de performance, então você precisa de duas coisas: primeiro, você precisa ser capaz de conseguir treinar uma rede neural bem grande para conseguir 
a vantagem de poder usar uma grande quantidade de dados e segundo, você precisa estar nessa posição do eixo x para ter uma grande quantidade de dados. Assim, dizemos que a escala tem guiado o progresso do aprendizado profundo e, por escala eu quero dizer tanto o tamanho da rede neural, o que significa uma rede neural com uma série de unidades escondidas, uma série de parâmetros, uma série de conexões e também uma escala dos dados. De fato, atualmente um dos melhores meios de melhorar a performance em uma rede neural é treinar uma rede neural grande ou adicionar more data a rede. Mas isso só funciona ate um certo ponto já que, eventualmente, você não tem mais dados ou então sua rede está tão grande que leva muito tempo para treinar. Mas melhorando a escala, atualmente tem nos levado a um longo caminho no mundo do aprendizado. Para fazer esse diagrama um pouco mais preciso, vou apenas adicionar mais algumas poucas coisas. Eu escrevei Quantidade de dados aqui no eixo x. Tecnicamente, essa é uma quantidade de dados rotulados, onde dado rotulado significa treinar exemplos onde temos tanto a entrada X e o rótulo y. Eu vou introduzir uma notação que vamos utilizar mais tarde nesse curso. Vamos utilizar a letra m minuscula para denotar o tamanho do conjunto dos dados de treino ou o número de exemplos de treino. Isso com a letre minuscula m. Então esse é o eixo horizontal. Mais alguns detalhes sobre essa figura: nesse área de conjuntos de dados pequenos, a ordem relativa dos algorítimos não é muito bem definida. Assim, se você não tem uma grande quantidade de dados, então vai depender dos conhecimentos técnicos para manipular as características, 
que determinam a performance. Então é bem possível que se alguém treinar com SVM esteja apenas mais motivado a manipular a engenharia das características e se alguém treinar uma rede neural enorme, que talvez nessa área o SVM possa dar melhores resultados. Então, nessa região do lado esquerdo da figura, a ordem relativa entre os algoritmos não é bem definida. E a performance depende muito mais dos seus conhecimentos sobre manipular as características no sentido de diminuir os detalhes sobre algoritmos. E nessa região de de muitos dados ou conjuntos muito grandes de dados de treinamentos m, na figura a direita, onde mais consistentemente vemos grandes redes neurais dominando. Assim, se algum colega seu perguntar porque as redes neurais estão decolando, eu sugiro que você mostre essa figura. Então, eu diria que Então eu diria que atualmente o aumento do quando aprendendo foram dados escalonados e computação em escala, com habilidade de treinar redes neurais muito grandes e tanto CPUs como GPUs nos habilitam a fazer uma serie de progressos, mas incrivelmente, especialmente nos últimos anos, temos visto incríveis inovações nos algoritmos. Eu também não entendo que muitas das inovações em algoritmos em feito com que as redes neurais rodem bem mais rápido. Assim, como exemplo concreto, um dos paradigmas em redes neurais tem sido a mudança do uso da função sigmoid que se parece com isso, para a função ReLU que já comentamos antes e que se parece com isso. Não se preocupe se ainda não entende os detalhes, mas um dos problemas de usar a função sigmoid em aprendizado de máquina é que nessa região onde a inclinação da função o gradiente seria zero e assim o aprendizado se torna muito lento, porque quando você implementa o gradiente descendente e o gradiente é zero, os parâmetros mudam muito devagar, fazendo o aprendizado ser muito lento. Ao passo que, mudando o que chamamos de função de ativação da rede neural para usar essa função chamada ReLU ou função linear retificadora, o gradiente é igual a um para todos os valores positivos de entrada E assim o gradiente é muito menos provável tender para zero e o gradiente aqui, a inclinação é zero a esquerda, mas mudando de função sigmoid pra função ReLU tem feito o algoritmo chamado gradiente descendente trabalhar bem mais rápido. E nesse simples exemplo o algoritmo equivale. O impacto de inovação que esse algoritmo fez foi uma grande melhora computacional. Assim, existem vários outros exemplos como esse onde mudamos o algoritmo para permitir que o código rode bem mais rápido o que permite treinar redes neurais bem maiores ou fazer isso quando temos grandes redes neurais ou uma grande quantidade de dados. A outra razão do porque computação rápida é importante é porque o processo de treinar uma rede neural é muito iterativo. Geralmente você tem uma ideia para o seu arquiteto de redes e assim você implemente a ideia em código implementando assim, sua ideia.
Então isso permite que você execute um experimento que mostra a você o que sua rede neural faz e então você analisando você muda alguns detalhes da sua rede neural e volta para esse circulo várias vezes. E quando sua rede neural leva muito tempo para treinar, também vai levar tempo para completar um ciclo. Então, tem uma diferença muito grande em sua produtividade ao construir sua rede neural, quando você pode ter uma ideia e testá-la em 10 minutos ou ao longo do dia e ver se funciona, versus se você treina uma rede neural por um mês, o que, às vezes acontece porque você tem o resultado em 10 minutos ou talvez um dia e você pode ainda tentar várias ideias para tentar descobrir se sua rede neural da bons resultados para sua aplicação. 
Assim, a computação rápida tem realmente ajudado 
muito em termos de acelerar a taxa de retorno de resultados experimentais e isso tem realmente ajudado tanto os que trabalham com redes neurais, como também os pesquisadores de aprendizado profundo, tornando essa interação mais rápida, o que alavanca suas ideias mais rapidamente. Assim, tudo isso tem contribuído para esta explosão 
que ocorre na comunidade de pesquisas de aprendizado profundo, o que tem resultado em incríveis novos algoritmos, promovendo um contínuo progresso na área. Assim, essa são algumas das forças que reforçam o aumento do aprendizado profundo. Mas a boa notícia é que essas forças ainda estão operando fortemente para fazer o aprendizado profundo ser cada vez melhor. Dados digitais: a sociedade está cada vez mais gerando dados digitais, o que demanda computação com o aumento de hardware especializado como GPUs, redes rápidas ou diferentes tipos de hardware. Eu acredito que nossa habilidade de construir grandes redes neurais em adição aos níveis de computação, vão continuar melhorando e as comunidades que pesquisam os algoritmos vão continuar apresentando fenomenais descobertas no campo dos algoritmos. Sendo assim, acho que podemos ser otimistas. Eu sou otimista que o aprendizado profundo continuará melhorando cada vez mais nos próximos anos. Assim, vamos ao último vídeo dessa sessão onde vou falar um pouco mais sobre o que você aprendeu nesse curso. 
[Tradução: Carlos Roberto| Revisão: Carlos Lage]