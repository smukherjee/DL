1
00:00:00,000 --> 00:00:01,530
لاحظنا في الفيديو السابق،

2
00:00:01,530 --> 00:00:06,885
كيف استطعنا من خلال مقارنة نماذج
التدريب أفقيًا في المصفوفة x

3
00:00:06,885 --> 00:00:11,158
اشتقاق تطبيق موجّه للانتشار
الأمامي من خلال شبكتك العصبية.

4
00:00:11,158 --> 00:00:14,760
دعونا نتناول اليوم تفسيرات أخرى
لكتابة هذه المعادلات

5
00:00:14,760 --> 00:00:19,775
باعتبارها تطبيقًا صحيحًا للطريقة
المتجهية على عدة أمثلة.

6
00:00:19,775 --> 00:00:25,590
ولنستعرض الآن جزءًا من العملية
الحسابية للانتشار لبضعة أمثلة.

7
00:00:25,590 --> 00:00:27,645
لنفترض أنه في نموذج التدريب الأول

8
00:00:27,645 --> 00:00:29,130
ستجدون أنفسكم تقومون بحساب التالي

9
00:00:29,130 --> 00:00:38,970
x1 زائد b1، وفي نموذج التدريب الثاني

10
00:00:38,970 --> 00:00:49,310
ستقومون بحساب x2 زائد b1

11
00:00:49,310 --> 00:00:50,900
وفي نموذج التدريب الثالث

12
00:00:50,900 --> 00:00:56,064
ستقومون بحساب 3 زائد b1.

13
00:00:56,064 --> 00:01:00,930
لذا، لتبسيط الشرح الموجود في هذه الشريحة، سأتجاهل b.

14
00:01:00,930 --> 00:01:08,395
لنفترض أن b تساوي صفرًا،
حتى يكون هذا الشرح أبسط قليلاً.

15
00:01:08,395 --> 00:01:11,140
ومع ذلك، سنُجري بعض التغييرات
على الوسيطة

16
00:01:11,140 --> 00:01:14,320
التي سنعرضها حتى لو لم تكن قيمة b تساوي صفرًا.

17
00:01:14,320 --> 00:01:17,610
وما فعلناه هو لمجرد تبسيط شرح
محتوى هذه الشريحة.

18
00:01:17,610 --> 00:01:21,110
حسنًا، سنفترض أن w1
هي إحدى المصفوفات.

19
00:01:21,110 --> 00:01:25,625
وبداخل هذه المصفوفة
يوجد عدد من الصفوف.

20
00:01:25,625 --> 00:01:28,296
وبالنظر إلى هذه العملية الحسابية لـ x1

21
00:01:28,296 --> 00:01:30,070
فستجدون أن

22
00:01:30,070 --> 00:01:40,021
حاصل ضرب w1 في x1 هو متجه
عمود يجب رسمه كالتالي.

23
00:01:40,021 --> 00:01:47,420
وبالمثل، إذا نظرتم إلى المتجه x2 هذا

24
00:01:47,420 --> 00:01:54,730
وقمنا بضرب w1

25
00:01:54,730 --> 00:02:00,460
في x2 فسنحصل على متجه عمود ثانٍ، صحيح؟

26
00:02:00,460 --> 00:02:03,250
وهو يعطينا z12.

27
00:02:03,250 --> 00:02:06,730
وأخيرًا، إذا نظرنا إلى x3،

28
00:02:06,730 --> 00:02:12,315
وقمنا بضرب w1 في x3،

29
00:02:12,315 --> 00:02:19,530
فسنحصل على متجه عمود ثالث وهو
ما أطلقنا عليه z1

30
00:02:19,530 --> 00:02:25,250
والآن، إذا فكرتم في مجموعة التدريب X "كابيتال"،

31
00:02:25,250 --> 00:02:31,475
التي حصلنا عليها بتكديس
كل نماذج التدريب.

32
00:02:31,475 --> 00:02:37,010
تكّونت المصفوفة X "كابيتال" بتكديس كل من المتجه x1

33
00:02:37,010 --> 00:02:43,430
عموديًا مع المتجه x2 ثم المتجه x3.

34
00:02:43,430 --> 00:02:46,250
وذلك إذا كان عدد نماذج التدريب
هو ثلاثة فقط.

35
00:02:46,250 --> 00:02:50,371
وإذا كان العدد أكثر من ذلك، فسنستمر
في تكديسها أفقيًا على هذا النحو.

36
00:02:50,371 --> 00:02:57,790
ولكن إذا أخذنا المصفوفة x، وقمنا
بضربها في w، فسنحصل على

37
00:02:57,790 --> 00:03:00,190
إذا أخذنا كيفية عمل مضاعفة
المصفوفات بعين الاعتبار

38
00:03:00,190 --> 00:03:02,680
فسيتضمن العمود الأول

39
00:03:02,680 --> 00:03:06,313
القيم نفسها التي كتبتها هنا قبل قليل
باللون الأرجواني.

40
00:03:06,313 --> 00:03:10,930
وسيتضمن العمود الرابع هذه القيم
الموجودة هنا نفسها.

41
00:03:10,930 --> 00:03:16,612
وبالمثل سيتضمن العمود الثالث هذه القيم
الموجودة هنا باللون البرتقالي.

42
00:03:16,612 --> 00:03:19,480
هذه هي النتيجة النهائية أمامكم.

43
00:03:19,480 --> 00:03:27,740
وهي بالطبع تساوي z11
التي عبّرنا عنها

44
00:03:27,740 --> 00:03:37,185
بمتجه عمود تلاه z12 في صورة
متجه عمود تلاه z13،

45
00:03:37,185 --> 00:03:39,273
التي عبّرنا عنها أيضًا بمتجه عمود.

46
00:03:39,273 --> 00:03:41,100
وهذا في حالة وجود ثلاثة
نماذج تدريب فقط.

47
00:03:41,100 --> 00:03:44,255
فإذا كانت هناك مزيد من النماذج،
فسنحصل على مزيد من الأعمدة.

48
00:03:44,255 --> 00:03:51,220
وهذه ببساطة هي المصفوفة Z1 "كابيتال".

49
00:03:51,220 --> 00:03:55,230
وأتمنى أن تكونوا قد فهمتهم السبب وراء

50
00:03:55,230 --> 00:04:02,830
ما قمنا به مسبقًا بضرب w1 في xi
وكان الناتج

51
00:04:02,830 --> 00:04:08,310
هو Z1i، وذلك في حالة نموذج
تدريب واحد في المرة الواحدة.

52
00:04:08,310 --> 00:04:12,565
وعند أخذ نماذج التدريب
المختلفة وتكديسها في أعمدة مختلفة،

53
00:04:12,565 --> 00:04:15,250
ستكون النتيجة المقابلة
التي سنحصل عليها

54
00:04:15,250 --> 00:04:18,725
هي كل قيم Z مكدّسة في الأعمدة.

55
00:04:18,725 --> 00:04:24,565
لن أتناول هذا الجزء، ولكن يمكنكم
تجربة ذلك إن أردتم في Python broadcasting،

56
00:04:24,565 --> 00:04:26,245
وإذا قمتم بإضافة

57
00:04:26,245 --> 00:04:30,534
قيم b هذه إلى القيم المعروضة
فستظل النتيجة صحيحة.

58
00:04:30,534 --> 00:04:34,540
وما سيحدث فعليًا هو تنفيذ Python broadcasting،

59
00:04:34,540 --> 00:04:41,790
الذي يقوم بتوزيع القيمة bi على كل
عمود من أعمدة هذه المصفوفة

60
00:04:41,790 --> 00:04:48,220
حسنًا، إذًا ما قمت به في هذه الشريحة
هو أنني قدمت تفسيرًا

61
00:04:48,220 --> 00:04:51,980
للمعادلة Z1 =w1X + b1

62
00:04:51,980 --> 00:04:54,020
وهو تطبيق صحيح للطريقة المتجهية

63
00:04:54,020 --> 00:04:57,493
للخطوة الأولى من الخطوات الأربع
التي تحدثنا عنها في الشريحة السابقة

64
00:04:57,493 --> 00:04:59,990
لكننا توصلنا في الوقت نفسه إلى أن
التحليل المماثل سيوضح لنا

65
00:04:59,990 --> 00:05:02,660
أنه يمكننا تطبيق الخطوات الأخرى
بنجاح أيضًا باتّباع

66
00:05:02,660 --> 00:05:08,105
منطق مشابه حيث إنه إذا قمنا بتكديس
المدخلات في أعمدة فستكون النتيجة بعد المعادلة

67
00:05:08,105 --> 00:05:11,510
الحصول على مخرجات
مقابلة مُكدسة في أعمدة.

68
00:05:11,510 --> 00:05:14,970
وأخيرًا دعونا نلخص سريعًا ما تحدثنا
عنه في هذا الفيديو.

69
00:05:14,970 --> 00:05:16,520
إذا كانت هذه هي الشبكة العصبية
الخاصة بك،

70
00:05:16,520 --> 00:05:21,693
فلقد ذكرنا أن هذا هو ما ينبغي فعله، في حال أردت تنفيذ انتشار أمامي،

71
00:05:21,693 --> 00:05:27,693
نموذج تدريب واحد في المرة الواحدة والبدء
من i = 1 حتى m، وتناولنا بعد ذلك

72
00:05:27,693 --> 00:05:34,100
كيفية تكديس نماذج التدريب في أعمدة
مثل هذه وتوزيع قيم z1،

73
00:05:34,100 --> 00:05:38,265
a1 وz2 وa2 التي تكدست في الأعمدة
المقابلة كما هو واضح أمامكم.

74
00:05:38,265 --> 00:05:43,820
هذا نموذج للقيمة A1 "كابيتال" ولكنه صحيح
أيضًا لكل من z1،

75
00:05:43,820 --> 00:05:46,975
وa1 وz2 وa2.

76
00:05:46,975 --> 00:05:51,090
وما عرضناه على الشريحة السابقة أن

77
00:05:51,090 --> 00:05:58,785
هذا السطر يتيح لنا استخدام مُوجه لذلك
على كل نماذج m في وقت واحد.

78
00:05:58,785 --> 00:06:00,555
واتضح لنا أنه باتّباع المنطق نفسه،

79
00:06:00,555 --> 00:06:03,880
يمكننا إثبات أن كل السطور الأخرى

80
00:06:03,880 --> 00:06:08,811
تُعد طُرقًا متجهية صحيحة للسطور
الأربعة الخاصة باللغة البرمجية.

81
00:06:08,811 --> 00:06:10,675
أود أن أذكركم

82
00:06:10,675 --> 00:06:18,960
لأن x تساوي أيضًا a0، وذلك لأن كما تتذكرون

83
00:06:18,960 --> 00:06:27,980
أن متجه ميزة الإدخال x كان يساوي
a0 وبالتالي فإن xi يساوي a0i.

84
00:06:27,980 --> 00:06:30,870
وحينها سنلاحظ وجود تناظر بين

85
00:06:30,870 --> 00:06:34,110
هذه المعادلات، ويمكن كتابة المعادلة
الأولى هذه على النحو الآتي.

86
00:06:34,110 --> 00:06:41,790
z1 تساوي w1 a0 زائدb1

87
00:06:41,790 --> 00:06:45,680
وسنلاحظ أن هاتين المعادلتين

88
00:06:45,680 --> 00:06:51,805
وهاتين المعادلتين متشابهتان جدًا
ولكن كل المؤشرات تزيد بواحد فقط.

89
00:06:51,805 --> 00:06:55,880
وبالتالي يتضح لنا أن الطبقات المختلفة
من الشبكة العصبية

90
00:06:55,880 --> 00:07:00,585
تقوم بالشيء نفسه تقريبًا أو تكرر
العمليات الحسابية نفسها مرارًا وتكرارًا.

91
00:07:00,585 --> 00:07:04,220
توجد لدينا هنا شبكة عصبية
مكونة من طبقتين

92
00:07:04,220 --> 00:07:08,475
وعندما نتناول شبكات عصبية أكثر تعقيدًا
في الفيديوهات القادمة

93
00:07:08,475 --> 00:07:11,670
فستلاحظون أنه حتى الشبكات العصبية
الأكثر تعقيدًا تطبق هاتين

94
00:07:11,670 --> 00:07:16,215
الخطوتين وتكررهما مرات أكثر مقارنة
بعدد المرات التي لاحظتموها هنا.

95
00:07:16,215 --> 00:07:21,255
كانت هذه هي الطريقة التي يمكنكم اتّباعها لاستخدام
موجه لنماذج التدريب في الشبكة العصبية الخاصة بكم.

96
00:07:21,255 --> 00:07:25,590
لقد استخدمنا حتى الآن الدالات السينية
خلال الشبكات العصبية الخاصة بنا.

97
00:07:25,590 --> 00:07:27,925
وأتضح أنها ليست الخيار الأمثل.

98
00:07:27,925 --> 00:07:29,675
لذلك، دعونا في الفيديو التالي نتعمق قليلاً

99
00:07:29,675 --> 00:07:32,450
في كيفية استخدام ما يُطلق عليه

100
00:07:32,450 --> 00:07:37,190
"دالات تنشيط" مختلفة، والتي تُعتبر
الدالة السينية إحدى خياراتها المحتملة.