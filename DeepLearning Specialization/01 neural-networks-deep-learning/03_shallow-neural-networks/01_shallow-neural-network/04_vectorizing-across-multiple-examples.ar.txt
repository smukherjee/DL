في الفيديو السابق، تعلمنا كيفية
حساب التنبؤ في شبكة عصبية بإعطاء مثال تدريبي واحد. في هذا الفيديو, سنرى كيفية استخدام
متجه واحد على أكثر من مثال تدريبي. والناتج سيكون مشابهًا جدا لما
رأيناه في الانحدار اللوجستى. فبواسطة تكديس عدة أمثلة
تدريبية في أعمدة مختلفة من المصفوفة، ستكونون قادرين على أخذ
المعادلات التي كانت لديكم في الفيديو السابق. وبتعديل بسيط للغاية، تغييرها
لجعل الشبكة العصبية تقوم بحساب النتائج لكل الأمثلة في نفس الوقت تقريبًا. فلنرَ تفاصيل كيفية القيام بذلك. هذه كانت المعادلات الأربعة من الفيديو
السابق، التي توضح كيفية حساب z1 a1 وz2 وa2. وتريكم عندما يكون لديكم متجه
سمة الإدخال x، كيف يمكنكم استخدامها لتوليد a2 والتي
تساوى ŷ لمثال تدريبي واحد. والان اذا كان لديك عدد m من الأمثلة
التدريبية، فستحتاج الى تكرار هذه العملية فلنقل في المثال التدريبي الأول x أس 1 كي تحسب ŷ(1) والتي تمثل
التنبؤ في أول مثال تدريبي. ثم x(2) تستخدم لتوليد التنبؤ ŷ(2). وهلم جرا وصولاً الى
x(m) لتوليد تنبؤ ŷ(m). ولكتابة كل دوال التنشيط هذه كرموز أيضاً سأكتب هذه بصيغة (1)[a[2. وهذه (2)[a[2. و[a(2)[m، إذن هذا الرمز (a[2](i الأقواس المنحنية حول i
تشير الى المثال التدريبي رقم i والأقواس المربعة حول 
2تشير الى الطبقة 2. حسناً. هذه هي طريقة عمل معاني
الأقواس المنحنية والمربعة. ولذلك للإشارة إلى أن لديكم
تطبيقًا دون استخدام متجه واحد وتريدون احتساب التنبؤات
لكل الأمثلة التدريبية لديكم فأنتم تحتاجون إلى تنفيذ i = 1 to m. ثم بشكل أساسي تطبيق هذه المعادلات الأربعة. أنتم تحتاجون لجعل (z[1](i يساوى [W(1)x(i)+b[1 (a[1](i تساوي سينية (z[1](i)). (z[2](i تساوي (w[2]a[1](i زائد [b[2 و (a[2](i تساوى سينية (z[1](i)). إذن في الأساس، تلك المعادلات الأربعة
بالأعلى مع إضافة القوس المنحني للأس i لكل المتغيرات التي تعتمد على المثال التدريبي. وهكذا نضيف القوس المنحنى
العلوي i إلى x وz وa. إذا أردنا حساب كل النواتج
لعدد m من الأمثلة التدريبية. والذي نريد عمله هو استخدام متجه واحد لكل
 العمليات الحسابية للتخلص من معادلة for هذه. وبالمناسبة، إذا بدا وكأنني أوضح
الكثير من المبادئ الأساسية والتفاصيل للجبر الخطي، حيث يتضح أن
كونكم قادرين على تطبيق هذا بصورة صحيحة مهم في عصر التعلم العميق. وقد اخترنا الترميز بعناية
فائقة لهذه الدورة التدريبية وعملنا على جعل خطوات استخدام
موجه واحد أسهل ما يمكن. ولذلك آمل أن شرح هذه المبادئ
والحقائق الأساسية سيساعدكم على على تطبيق هذه الخوارزميات
بطريقة صحيحة بشكل أسرع. إذن دعوني انسخ هذا المقطع من
التعليمة البرمجية إلى الشريحة التالية وسنتعرف كيف يمكننا استخدام موجه واحد هنا. إذن إليكم ما لدينا من
الشريحة السابقة مع for loop على الأمثلة التدريبية m. لنتذكر أننا عرفنا المصفوفة x على أنها تساوى الأمثلة التدريبية المكدسة في
هذه الأعمدة بهذا الشكل. لذلك نأخذ الأمثلة التدريبية ونكدسها في أعمدة. لذا تصبح هذه n أو ربما مصفوفة بعدية (nx,m). سوف أشرح لكم ملخص ما يجب عليكم فعله كي تطبقوا معالجة عدة عناصر
بمتجه واحد في for loop هذه. ويتبين أن ما تحتاجون إليه هو حساب [Z[1] = W[1]X + b[1 A[1]‎ يساوي سينية Z[1]. ثم [Z[2] = w[2 A[1] + b[2]* وثم A[2]‎ يساوي سينية ‎ Z[2]. لذا إذا أردتم معرفة أوجه التشابه،
فقد انتقلنا من أحرف x الصغيرة للمتجه لمصفوفة X للحرف الكبير بتكديس
الحروف الصغيرة x في أعمده مختلفة. إذا فعلتم الشيء نفسه لحروف z مثلاً. إذا أخذتم (z[1](1 وz[1](2) وهكذا وكل هذه متجهات أعمدة
حتى z[1](m)، أليس كذلك؟ هذه هي الكمية الأولى لعدد
m بهم كلهم، ونكدسها في أعمدة. هذا يعطينا ببساطة المصفوفة [Z[1. وبالمثل إذا نظرنا إلى هذه الكمية وأخذنا (a[1](1 و(a[1](2 وهكذا حتى (a[1](m وكدسناهم جميعًا في أعمدة. فهذا، كما فعلنا بالانتقال من الحرف
 الصغير x إلى الحرف الكبير X ومن الحرف الصغير z الى الحروف الكبير Z. فهذا ينتقل من الحرف الصغير a
وهو المتجهات إلى الحرف الكبير [A[1 الموجود هنا، وبصورة مماثلة في [z[2 و[a[2. حسنًا. ويمكن الحصول عليهم
من خلال أخذ هذه المتجهات و تكديسها أفقيًا. وأخذ هذه المتجهات وتكديسها أفقيًا للحصول على الحرف الكبير [Z[2 و[A[2. إحدى خصائص هذه الرموز التي قد تساعدك في التفكير بهذا هو أن
هذه المصفوفات مثلا Z وA سوف نقوم بترميزها
أفقيًا في الأمثلة التدريبية. لهذا يتوافق الفهرس الأفقي
مع الأمثلة التدريبية المختلفة فكلما انتقلنا من اليسار الى اليمين،
فإننا نفحص الخلايا (الأمثلة) التدريبية. ورأسيًا، فإن هذا الفهرس الرأسي
يتوافق مع عقد مختلفة في في الشبكة العصبية. على سبيل المثال، هذه العقدة أو القيمة الموجودة بالأعلى في أقصى يسار من المصفوفة تتوافق مع التنشيط من الوحدة الخفية الأولى
من المثال التدريبي الأول. تتوافق قيمة واحدة أسفلها إلى
التنشيط في الوحدة الخفية الثانية في المثال التدريبي الأول ثم الوحدة الثالثة الخفية
في المثال التدريبي الأول وهكذا. لذا كلما نزلتم للأسفل، فأنت
تشيرون إلى عدد الوحدات الخفية. بينما إذا تحركنا أفقيًا،
فسننتقل من الوحدة الخفية الأولى. والمثال التدريبي الأول
الى الوحدة الخفية الأولى و المثال التدريبي الثاني،
ثم المثال التدريبي الثالث. وهلم جرا حتى نصل الى تلك
العقدة هنا التي تتوافق مع التنشيط للوحدة الخفية الأولى في المثال
التدريبي الأخير أي المثال التدريبي رقم m. حسنا. هكذا أفقيًا، تنتقل المصفوفة
 A إلى أمثلة تدريبية مختلفة. ورأسيًا، تشير الرموز المختلفة في المصفوفة إلى وحدات خفية مختلفة. ويكون نفس المفهوم صحيحًا للمصفوفة Z وأيضًا X حيث أفقيا، تتوافق مع أمثلة تدريبية مختلفة. ورأسيًا مع سمات إدخال مختلفة والتي تختلف حقاً عن تلك
في طبقة الإدخال للشبكة العصبية. حسنا، بهذه المعادلات أنتم
تعرفون الآن كيفية التطبيق بشبكتكم بالطريقة المتجهية التي تتيح
استخدام متجه واحد لعدة أمثلة. في الفيديو التالي، سوف
أشرح قليلاً لم يعد هذا التطبيق الصحيح لهذا النوع
من المعالجة بمتجه واحد. وسيتضح أن السبب مشابه
لما رأيناه في الانحدار اللوجستى. لننتقل الى الفيديو التالي.