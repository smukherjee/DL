1
00:00:00,000 --> 00:00:01,440
У попередньому відео

2
00:00:01,440 --> 00:00:05,700
ми бачили як можна використати векторизацію, 
щоб обчислити передбачення -

3
00:00:05,700 --> 00:00:11,485
малі a - для всього тренувального набору одночасно.

4
00:00:11,485 --> 00:00:15,030
В цьому відео ми розглянемо як можна використати векторизацію,

5
00:00:15,030 --> 00:00:19,205
щоб обчислити градієнти для всіх m тренувальних зразків.

6
00:00:19,205 --> 00:00:21,380
І, знову ж, одночасно.

7
00:00:21,380 --> 00:00:22,890
І потім в кінці відео

8
00:00:22,890 --> 00:00:26,175
ми об'єднаємо ці обчислення і покажемо як можна записати

9
00:00:26,175 --> 00:00:29,730
дуже ефективну реалізацію логістичної регресії (ЛР).

10
00:00:29,730 --> 00:00:32,505
Тож, ти можливо пам'ятаєш, що для обчислення градієнтів

11
00:00:32,505 --> 00:00:36,910
ми обчислювали dz⁽¹⁾ для першого зразка,

12
00:00:36,910 --> 00:00:43,870
який =a⁽¹⁾-y⁽¹⁾, потім dz⁽²⁾=

13
00:00:43,870 --> 00:00:52,134
a⁽²⁾-y⁽²⁾ і т.д.

14
00:00:52,134 --> 00:00:56,425
І т.д. для всіх m тренувальних зразків.

15
00:00:56,425 --> 00:01:01,218
Тож, давай визначимо нову змінну

16
00:01:01,218 --> 00:01:08,595
dZ, яка буде = dz⁽¹⁾, dz⁽²⁾, dz⁽ᵐ⁾.

17
00:01:08,595 --> 00:01:13,910
Знову ж, всі змінні d малі z складаємо горизонтально.

18
00:01:13,910 --> 00:01:21,200
Тож це буде матриця розміру 1*m або вектор-рядок розмірністю m.

19
00:01:21,200 --> 00:01:23,520
Тепер згадаємо з попереднього слайду.

20
00:01:23,520 --> 00:01:28,405
Ми вже знайшли як обчислити велике A, а саме: від a⁽¹⁾

21
00:01:28,405 --> 00:01:36,735
до a⁽ᵐ⁾. Ми визначили велике Y від y⁽¹⁾ до y⁽ᵐ⁾.

22
00:01:36,735 --> 00:01:39,200
Також складене горизонтально.

23
00:01:39,200 --> 00:01:42,780
Тож, базуючись на цих визначеннях,

24
00:01:42,780 --> 00:01:46,770
можливо, ти вже побачив/ла, що dZ може бути обчислене як

25
00:01:46,770 --> 00:01:52,750
A-Y. Тому що це буде a⁽¹⁾-y⁽¹⁾

26
00:01:52,750 --> 00:01:55,670
(тобто перший елемент), a⁽²⁾-y⁽²⁾

27
00:01:55,670 --> 00:01:59,980
(тобто другий елемент) і т.д.

28
00:01:59,980 --> 00:02:06,115
Тож цей перший елемент a⁽¹⁾-y⁽¹⁾ якраз буде визначенням dz⁽¹⁾,

29
00:02:06,115 --> 00:02:11,670
другий елемент - якраз визначення dz⁽²⁾ і т.д.

30
00:02:11,670 --> 00:02:13,965
Тож лише одним рядком коду

31
00:02:13,965 --> 00:02:20,095
можна обчислити все оце одночасно.

32
00:02:20,095 --> 00:02:24,010
В попередній реалізації

33
00:02:24,010 --> 00:02:27,695
ми позбулись одного циклу for, проте, все ще маємо

34
00:02:27,695 --> 00:02:31,600
оцей другий цикл for для тренувальних зразків.

35
00:02:31,600 --> 00:02:35,440
Тож ми ініціалізуємо dw в 0, у вектор нулів.

36
00:02:35,440 --> 00:02:38,905
Але все ще маємо цикл для тренувальних зразків, де в нас є

37
00:02:38,905 --> 00:02:43,015
dw+=x⁽¹⁾dz⁽¹⁾

38
00:02:43,015 --> 00:02:50,440
для першого тренувального зразка, dw+=x⁽²⁾dz⁽²⁾ і т.д.

39
00:02:50,440 --> 00:02:56,980
Тож ми робимо це m разів, а потім ділимо dw на m. І, аналогічно, для b, так?

40
00:02:56,980 --> 00:03:03,370
db ініціалізувалось в 0, db+=dz⁽¹⁾,

41
00:03:03,370 --> 00:03:09,120
db+=dz⁽²⁾ і до

42
00:03:09,120 --> 00:03:16,835
dz⁽ᵐ⁾ і db ділиться на m. Ось це ми мали в попередній реалізації.

43
00:03:16,835 --> 00:03:18,700
Ми вже позбулись одного циклу for.

44
00:03:18,700 --> 00:03:25,045
Тож, принаймі зараз, dw є вектором і ми не будемо окремо коригувати dw⁽¹⁾,

45
00:03:25,045 --> 00:03:26,850
dw⁽²⁾ і т.д.

46
00:03:26,850 --> 00:03:29,860
Тож ми вже позбулись цього, проте, все ще

47
00:03:29,860 --> 00:03:33,630
маємо цикл for для m зразків тренувального набору.

48
00:03:33,630 --> 00:03:36,290
Тож давай векторизуємо ці операції.

49
00:03:36,290 --> 00:03:38,380
Ось що ми можемо зробити.

50
00:03:38,380 --> 00:03:42,745
Для реалізації векторизації db робиться додавання

51
00:03:42,745 --> 00:03:47,940
всіх оцих dz з подальшим діленням на m. Тож,

52
00:03:47,940 --> 00:03:51,580
db, по суті, - 1/m,

53
00:03:51,580 --> 00:03:56,530
сума, по i від 1 до m, dz⁽ⁱ⁾,

54
00:03:56,530 --> 00:04:03,055
де всі dz - це ось цей вектор-рядок. Тож в Python

55
00:04:03,055 --> 00:04:04,765
реалізація виглядатиме наступним чином:

56
00:04:04,765 --> 00:04:08,155
1/m*np.

57
00:04:08,155 --> 00:04:12,210
sum(dz)

58
00:04:12,210 --> 00:04:15,115
Тож треба просто взяти цю змінну і викликати

59
00:04:15,115 --> 00:04:19,195
функцію np.sum() для неї і вона дасть нам db.

60
00:04:19,195 --> 00:04:22,330
А що з dw? Я просто запишу

61
00:04:22,330 --> 00:04:26,375
правильне рівняння, яке вказує що робити.

62
00:04:26,375 --> 00:04:28,164
dw буде 1/m помножити на

63
00:04:28,164 --> 00:04:34,485
матрицю X, помножити на dzᵀ.

64
00:04:34,485 --> 00:04:37,990
Спробуємо зрозуміти чому це так.

65
00:04:37,990 --> 00:04:41,806
це = 1/m, потім матриця X -

66
00:04:41,806 --> 00:04:48,325
стовпчики від x⁽¹⁾ до x⁽ᵐ⁾ - і dzᵀ

67
00:04:48,325 --> 00:04:56,040
буде ось таким від dz⁽¹⁾ до dz⁽ᵐ⁾.

68
00:04:56,040 --> 00:05:00,900
І, якщо вивести що буде добутком цієї матриці і цього вектора,

69
00:05:00,900 --> 00:05:05,585
то це буде 1/m помножити на [x⁽¹⁾dz⁽¹⁾

70
00:05:05,585 --> 00:05:12,523
плюс крапка-крапка-крапка плюс x⁽ᵐ⁾dz⁽ᵐ⁾].

71
00:05:12,523 --> 00:05:21,405
Тож цей вектор розміру n*1 і буде результатом

72
00:05:21,405 --> 00:05:24,725
обчислень dw, тому що dw брало оці

73
00:05:24,725 --> 00:05:27,710
x⁽ⁱ⁾dz⁽ⁱ⁾, додавало їх і саме це

74
00:05:27,710 --> 00:05:32,300
і робить оцей добуток матриці на вектор. І, знову ж,

75
00:05:32,300 --> 00:05:35,655
ми можемо обчислити dw одним рядком коду.

76
00:05:35,655 --> 00:05:40,010
Тож, ось це - векторизована реалізація обчислення похідних.

77
00:05:40,010 --> 00:05:44,540
Ми використовуємо цей рядок, щоб реалізувати db і

78
00:05:44,540 --> 00:05:50,540
оцей - щоб реалізувати dw. 
І, відміть, що без циклу for для тренувального набору

79
00:05:50,540 --> 00:05:55,265
ми тепер можемо обчислити коригування для наших параметрів.

80
00:05:55,265 --> 00:06:01,185
Тож тепер давай запишемо повністю як реалізувати ЛР.

81
00:06:01,185 --> 00:06:02,550
Ось наш первинна,

82
00:06:02,550 --> 00:06:07,866
дуже неефективна, невекторизована реалізація.

83
00:06:07,866 --> 00:06:11,775
Тож, перше, що ми зробили в попередньому відео, 
то це позбулись ось цього циклу for, так?

84
00:06:11,775 --> 00:06:14,400
Тож, замість того, щоб проходити циклом по dw₁,

85
00:06:14,400 --> 00:06:15,755
dw₂ і т.д.,

86
00:06:15,755 --> 00:06:23,595
ми підставили тут вектор dw, що =dw+=x⁽ⁱ⁾,

87
00:06:23,595 --> 00:06:28,775
яке тепер є вектором, помножити на dz⁽ⁱ⁾.

88
00:06:28,775 --> 00:06:32,000
А тепер ми побачимо, що можемо позбутись

89
00:06:32,000 --> 00:06:36,670
не лише циклу for внизу, а й ось цього циклу for.

90
00:06:36,670 --> 00:06:38,654
Тож ось як це можна зробити.

91
00:06:38,654 --> 00:06:42,925
Тож, скориставшись попереднім слайдом,

92
00:06:42,925 --> 00:06:46,085
можемо сказати, що велике Z

93
00:06:46,085 --> 00:06:57,625
=wᵀX+b, а в коді буде Z=np.

94
00:06:57,625 --> 00:07:07,315
dot(w.T, X)+b. І a=σ(Z).

95
00:07:07,315 --> 00:07:12,710
Тож тепер ми обчислили оце все і оце все для всіх значень i.

96
00:07:12,710 --> 00:07:14,715
Далі. На попередньому слайді

97
00:07:14,715 --> 00:07:21,070
ми сказали, що обчислюватимемо dZ як велике A мінус велике Y.

98
00:07:21,070 --> 00:07:24,460
Тож тепер ми обчислюємо оце все для всіх значень i.

99
00:07:24,460 --> 00:07:31,495
І, нарешті, dw=1/m*X*

100
00:07:31,495 --> 00:07:39,700
*dzᵀ, а db=1/m*

101
00:07:39,700 --> 00:07:43,328
*np.sum(dz).

102
00:07:43,328 --> 00:07:49,120
Тож ми щойно зробили пряме і зворотне поширення,

103
00:07:49,120 --> 00:07:53,030
тобто обчислили передбачення і похідні для

104
00:07:53,030 --> 00:07:57,340
всіх m тренувальних зразків без використання циклу for.

105
00:07:57,340 --> 00:08:00,835
І, отже, коригування Градієнтного спуску

106
00:08:00,835 --> 00:08:04,462
буде w=w-α*dw,

107
00:08:04,462 --> 00:08:12,020
яке ми щойно вгорі обчислили, і b=b-α*db.

108
00:08:12,020 --> 00:08:17,341
Інколи тут ставлять двокрапку, щоб позначити, що це - присвоєння,

109
00:08:17,341 --> 00:08:21,675
але я не повністю дотримувався цих позначень.

110
00:08:21,675 --> 00:08:25,450
Проте, в будь-якому випадку, ми щойно реалізували

111
00:08:25,450 --> 00:08:29,635
одну ітерацію Градієнтного спуску для ЛР.

112
00:08:29,635 --> 00:08:32,308
Тепер. Я знаю, що сказав, що нам треба позбавлятись

113
00:08:32,308 --> 00:08:35,260
явних циклів for якщо це можливо, проте, якщо ми хочемо

114
00:08:35,260 --> 00:08:38,230
реалізувати багато ітерацій

115
00:08:38,230 --> 00:08:42,880
Градієнтного спуску, 
то нам, все-таки, потрібен цикл for для кількості ітерацій.

116
00:08:42,880 --> 00:08:47,860
Тож, якщо ми хочемо виконати 1000 ітерацій Градієнтного спуску,

117
00:08:47,860 --> 00:08:53,675
то нам потрібен цикл for для цієї кількості ітерацій.

118
00:08:53,675 --> 00:08:55,870
Це - такий собі крайній цикл for.

119
00:08:55,870 --> 00:08:59,210
Я не думаю, що є спосіб позбутися цього циклу for.

120
00:08:59,210 --> 00:09:02,390
Проте, я думаю, що буде надзвичайно цікаво, 
якщо ти зможеш реалізувати

121
00:09:02,390 --> 00:09:07,117
хоча б одну ітерацію Градієнтного спуску без використання циклу for.

122
00:09:07,117 --> 00:09:09,880
Тож, це все. Тепер ти маєш високовекторизовану і

123
00:09:09,880 --> 00:09:14,745
високоефективну реалізацію Градієнтного спуску для ЛР.

124
00:09:14,745 --> 00:09:18,850
Є ще одна деталь, про яку я хотів би поговорити в наступному відео.

125
00:09:18,850 --> 00:09:24,155
Вона була в цьому відео, я коротко про неї згадав, 
вона зветься посів.

126
00:09:24,155 --> 00:09:28,240
Посів являється методикою Python і

127
00:09:28,240 --> 00:09:32,915
NumPy. 
Він дозволяє зробити окремі частини коду набагато ефективнішими.

128
00:09:32,915 --> 00:09:37,090
Тож давай детальніше розглянемо посів в наступному відео.