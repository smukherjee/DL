Sie haben von mir bereits vernommen, dass die Berechnungen eines Neuronalen Netzwerkes in der Art eines Vorwärtslaufs resp. einer Vorwärts-Ausbreitung organisiert wird, bei welcher die Ausgabe des Neuronalen Netzwerkes berechnet wird, gefolgt von einem Rückwärtslauf resp. einer Rückwärts-Ausbreitung, welcher wir nutzen um die Gradienten resp. die Ableitungen zu berechnen. Der Berechnungsgraph erklärt, weshalb das in dieser Art organisiert ist. In diesem Video wollen wir ein Beispiel betrachten. Um den Berechnungsgraphen zu illustrieren, wollen wir ein einfacheres Beispiel als die Logistische Regression oder Neuronale Netzwerke verwenden. Nehmen wir an, dass wir versuchen eine Funktion J zu berechnen, welche eine Funktion der drei Variablen a, b und c ist und die Funktion 3(a+bc) beträgt. Die Berechnung dieser Funktion hat aktuell 3 unterscheidbare Schritte: Der erste notwendige Schritt berechnet bc und - nehmen wir an - speichert das Resultat in der Variablen mit dem Namen u. Damit ist u=bc und danach kann man V=a*u berechnen. Also sagen wir dies ist V. Und schließlich ist ihre Ausgabe J = 3V. Damit ist dies ihre abschließende Funktion J, welche Sie nun versuchen automatisiert zu berechnen. Wir können diese drei Schritte nehmen und in einem Berechnungsgraphen wie folgt aufzeichnen: Nehmen wir an, ich zeichne die drei Variablen a,b und c an dieser Stelle Das erste, was wir taten, war u=bc zu berechnen. Also werde ich darum eine Rechteck zeichnen und damit ergeben sich die Eingänge dazu als b und c. Im weiteren hätten wir V=a+u mit den Eingängen u, welchen wir soeben berechnet haben, gemeinsam mit a. Und schließlich haben wir J=3V. Machen wir ein konkretes Beispiel mit a=5, b=3 und c=2 dann wäre u=bc gleich 6 und damit würde a+u gleich 5+6 also 11; womit J drei mal soviel wäre, folglich J=33. Und in der Tat können wir hoffentlich verifizieren, dass dies drei mal (fünf plus (drei mal zwei)) sind. Und, wenn wir dies alles berücksichtigen erhält man tatsächlich 33 für den Wert von J. Der Berechnungsgraph erweist sich als praktisch, wenn man ausgeprägte oder besondere Ausgangs-Variable, wie in diesem Fall J, optimieren möchte. Im Falle der Logistischen Regression ist J selbstverständlich die cos-Funktion, die wir versuchen zu minimieren. Und, was wir in diesem kleinen Beispiel gesehen haben, ist dass man durch den Pfad von links-nach-rechts den Wert von J berechnen kann. Und wie wir in den nächsten paar Folien für das Berechnen der Ableitungen sehen werden, existiert wie folgt ein Pfad von rechts-nach-links wie hier, der in die gegenseitige Richtung der blauen Pfeile führt. Somit wäre dies das Natürlichste für die Berechnung der Ableitungen. Um zu rekapitulieren, der Berechnungsgraph strukturiert eine Berechnung mit diesen blauen Pfeile von links-nach-rechts. Wir beziehen uns auf das nächste Video, das zeigt wie Sie die Ableitungen entsprechend den rückwärts gerichteten, roten Pfeile von rechts-nach-links berechnen können. Lasst uns zum nächsten Video gehen.