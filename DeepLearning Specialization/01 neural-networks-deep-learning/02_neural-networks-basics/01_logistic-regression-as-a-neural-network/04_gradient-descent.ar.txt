لقد تناولنا نموذج الانحدار اللوجستي. وتناولنا أيضًا دالة الخسارة التي
تقيس مستوى أدائك في مثال تدريب فردي. وتناولنا أيضًا دالة التكلفة التي تقيس
مستوى أداء المتغيرين w وb في مجموعة التدريب بالكامل الخاصة بكم. والآن دعونا نتحدث عن كيف يمكن
استخدام خوارزمية الانحدار التدريجي لتدريب أو تعليم المتغيرين w وb
على مجموعة التدريب الخاصة بكم. لتلخيص هذه النقطة، هذه هي خوارزمية
الانحدار اللوجستي المعروفة. ولدينا في السطر الثاني دالة التكلفة J. وهي دالة المتغيرين w وb. وهذا ما يُعرف بالمتوسط. ولذا فهي 1 مقسوم على m
مضروب في مجموع دالة الخسارة. وبالتالي تقيس دالة الخسارة مستوى صحة نتائج خوارزميات ŷ(i)‎ على كل مثال
من أمثلة التدريب ومقارنتها بالوسم الملموس ŷ(i)‎
في كل مثال من أمثلة التدريب. ونرى على اليمين المعادلة الكاملة
بعد توضيحها بالتفصيل. وبالتالي تقيس دالة التكلفة
مستوى أداء المتغيرين w وb على مجموعة التدريب. ولتعلُّم مجموعة المتغيرين w وb،
يبدو أنه من الطبيعي أن نعثر على w وb اللذين يجعلان دالة
التكلفة J(w, b)‎ صغيرة قدر الإمكان. هذه صورة توضيحية للانحدار التدريجي. في هذا المخطط، تُمثل المحاور الأفقية مساحة المتغيرين w وb. من الناحية العملية، يُمكن أن يكون المتغير w
متعدد الأبعاد، ولكن لأغراض الرسم، لنوضح w كرقم حقيقي فردي
وb كرقم حقيقي فردي. وتقع دالة التكلفة J(w, b)‎ أعلى المحورين الأفقيين w وb. يُمثل ارتفاع السطح قيمة J(w, b)‎
عند نقطة معينة. وما نُريد فعله هو أن نجد قيمة w وb التي تقابل الحد الأدنى من دالة التكلفة J. تحوّلت دالة التكلفة J إلى دالة محدبة. إنها تُشبه الوعاء الفردي الكبير،
لذلك هذه دالة محدبة وهي عكس الدالات التي تبدو بهذا الشكل فهي دالات غير مُحدبة،
وتحتوي على كثير من الأمثلية المحلية. لذا فإن حقيقة أن دالة التكلفة J(w,b)‎
هي دالة مُحدبة يُعد من أهم الأسباب التي تجعلنا نستخدم
دالة التكلفة J هذه بالتحديد للانحدار اللوجستي. ولإيجاد قيمة جيدة للمتغيرين سنقوم بتهيئة w وb إلى بعض القيمة الأولية التي نُشير إليها بهذه النقطة الحمراء الصغيرة. يصلُح تقريبًا أي أسلوب تهيئة مع
الانحدار اللوجستي. وعادةً ما نقوم بتهيئة القيمة إلى صفر. ويصلُح أيضًا أسلوب التهيئة العشوائية ولكن لا يُطبقه الناس في
حالة الانحدار اللوجستي. ولكن نظرًا لأن هذه الدالة مُحدبة،
فبغض النظر عن مكان التهيئة يلزم أولاً أن تصل إلى نفس النقطة أو
النقطة نفسها تقريبًا. ويبدأ الانحدار التدريجي عند
هذه النقطة الأولية ثم يتحرك في اتجاه نحو منطقة أشد انحدارًا. ولذلك بعد خطوة واحدة من الانحدار التدريجي
ربما ينتهي المطاف بك إلى هنا لأنه يحاول اتخاذ خطوات إلى أسفل في
الاتجاه الأكثر انحدارًا أو بسرعة نحو الأسفل قدر الأماكن. إن هذه هي إحدى تكرارات الانحدار التدريجي. وبعد تكرارين للانحدار التدريجي،
قد تصل إلى هذه النقطة وثلاثة تكرارات وما إلى ذلك. أعتقد أن هذا الجزء مخفٍ في
الجزء الخلفي من الرسم حتى تقترب إلى الأمثلية العالمية
أو الاقتراب قليلاً من الأمثل العالمي. توضح هذه الصور خوارزمية الانحدار التدريجي. دعونا نكتب تفاصيل أكثر قليلاً. ولغرض التوضيح، لنفترض أن هناك دالة J(w)‎ التي تريد تقليلها،
وربما تبدو هذه الدالة هكذا. ولتسهيل هذا الرسم، سأتجاهل قيمة المتغير b الآن كي يُصبح رسمًا أُحادي البُعد
بدلاً من رسم متعدد الأبعاد. يُمكّننا الانحدار التدريجي من تنفيذ ذلك، وسنُجري التحديث التالي بصورة متكررة. سنأخذ قيمة w ونقوم بتحديثها. وسنستخدم "= :" لتمثيل هذا التحديث. وبذلك تصبح "w : = w - α" مضروبة في المُشتقة dJ(w)/dw. سأكرر ذلك مرارًا وتكرارًا حتى
تتقارب الخوارزمية. هناك ملحوظتان هنا، رمز ألفا هو معدل التعلم ويتحكم في كبر حجم الخطوة التي نأخذها
عند كل تكرار أو انحدار تدريجي. سنتحدث لاحقًا عن بعض أساليب
اختيار معدل التعلم ألفا. وثانيًا، هذه الكمية هنا،
إنها مُشتقة. هذا هو التحديث أو التغيير الذي
يلزم تنفيذه للمتغير w. عندما نبدأ كتابة التعليمات البرمجية
لتنفيذ الانحدار التدريجي سنستخدم اسم المتغير في التعليمات البرمجية هو dw لتمثيل مصطلح المُشتقة هذا. ولذلك عند كتابة التعليمات البرمجية،
سنكتب على سبيل المثال "w : = w - α" مضروبة في dw. ونستخدم dw ليكون اسم المتغير لتمثيل
هذه المُشتقة. والآن لنتأكد من أن تحديث
الانحدار التدريجي أصبح منطقيًا. لنفترض أن المتغير w كان هنا. وبذلك أصبحت تقف عند هذه النقطة
على دالة التكلفة J(w)‎. تذكروا أن تعريف المُشتقة هو انحدار الدالة عند نقطة ما. إن انحدار الدالة هو الارتفاع
مقسوم على عرض المثلث المنخفض المُلامس لـ J(w)‎ في هذه النقطة. وتكون المُشتقة هنا إيجابية. فالتحديث الذي قمنا به هو المتغير w
مطروحًا منه معدل التعلم ومضروبًا في المُشتقة. المُشتقة هناك بقيمة موجبة،
ثم تصل إلى الطرح من w وبالتالي أخذ خطوة جهة اليسار. سيجعل الانحدار التدريجي الخوارزمية تُقلل ببطء المتغير إذا كنت قد بدأت
بقيمة w الكبيرة. ومثال آخر، إذا كان المتغير w هنا، عند هذه النقطة، سيكون الانحدار هنا
dJ/dw سالبًا وسيتم تحديث الانحدار التدريجي بطرح قيمة ألفا،
ثم إجراء عملية الضرب في الرقم السالب. وهكذا نصل إلى زيادة المتغير w ببطء، حتى تزداد قيمة w بتكرارات متتابعة للانحدار التدريجي. إذا كنت تريد التهيئة جهة اليسار أو جهة اليمين، سيتحرك الانحدار التدريجي
تجاه الحد الأدنى العالمي هنا. إذا لم تكن مُلمًا بالمشتقات
أو حساب التفاضل والتكامل وما يعنيه مُصطلح dJ(w)/dw، فلا داعي للقلق. سنتحدث بمزيد من التفصيل عن المشتقات
في الفيديو التالي. إذا كان لديك معلومات كافية عن
حساب التفاضل والتكامل، قد تكون أكثر إلمامًا بكيفية
عمل الشبكات العصبية. وإن لم تكن مُلمًا إلمامًا جيدًا
بحساب التفاضل والتكامل فسنتناول في الفيديوهات القادمة معلومات أساسية حول المُشتقات وحساب التفاضل والتكامل حتى تتمكّن
من استخدام الشبكات العصبية بكفاءة تامة. ولكننا سنكتفي الآن بإيضاح أن هذا المُصطلح يمثل انحدار الدالة ونحن نريد تحديد انحدار الدالة
في الوضع الحالي للمتغيرات حتى نتمكن من اتخاذ هذه الخطوات لأقصى
انحدار، وبالتالي نستطيع تحديد اتجاه الدخول للوصول إلى الجزء الأسفل
من دالة التكلفة J. لذا فقد كتبنا الانحدار التدريجي J(w)‎
إذا كان w هو المتغير الوحيد لديك. لاحظ أن في الانحدار اللوجستي،
دالة التكلفة تتكون من المتغيرين w وb. وفي هذه الحالة، فإن الحلقة الداخلية للانحدار
اللوجستي، وهذا هو هذا الشيء الموجود هنا يُعد شيئًا يجب تكراره على النحو الآتي. ستقوم بتحديث المتغير w بالشكل الآتي
w مطروح منها معدل التعلم، ثم إجراء عملية ضرب في مشتقة J(w,b)‎ فيما يتعلق بـ w. تقوم بعدها بتحديث b على النحو الآتي
b مطروح منها معدل التعلم، ثم إجراء عملية ضرب في مشتقة دالة التكلفة فيما يتعلق بـ b. هاتان المعادلتان في الجزء الأسفل
هما التحديث الفعلي الذي تقوم بتطبيقه. وبعيدًا عن ذلك، أود الإشارة إلى أحد الرموز
في حساب التفاضل والتكامل تُسبب الحيرة لبعض الناس. لا أعتقد أنه من المهم أن تفهم
حساب التفاضل والتكامل فهمًا تامًا ولكن في حال رأيت هذه الأشياء، أريد أن أتأكد
أنك لا تفكر كثيرا في هذا الرمز. وهو ذلك في حساب التفاضل والتكامل،
هذا الجزء المُحدد بالأزرق نكتبه بهذا الشكل أو نرسم
هذا الرمز المائل الطريف. هذا الرمز يرمز إلى حرف d ولكن مكتوب بنمط مختلف مائل،
فعندما ترى هذا التعبير فإنه يرمز إلى مشتقة الدالة J(w,b)‎ أو انحدار الدالة J(w,b)‎ في الحقيقة، ومدى انحدار الدالة في اتجاه w. وقاعدة الترميز في حساب التفاضل والتكامل،
الذي أعتقد أنه ليس منطقيًا تمامًا ولكن القاعدة في ترميز حساب التفاضل والتكامل،
والتي أعتقد أنها تجعل الأشياء أكثر تعقيدًا بكثير مما تحتاج إليه هو أنه
إذا كانت J هي دالة لمتغيرين أو أكثر، بدلاً من استخدام حرف d،
فاستخدم هذا الرمز الطريف المائل. وهذا ما يُطلق عليه "رمز مُشتقة جزئية". ولكن لا تقلق بشأنه الآن. وإذا كانت J هي دالة لمتغير واحد فقط،
عندئذٍ يمكنك استخدام حرف d. لذلك الفرق الوحيد بين استخدام
رمز المُشتقة الجزئية مائل أو استخدام حرف d كما فعلنا بالأعلى هو نوع الدالة J إذا كانت بمتغيرين أو أكثر. وفي أي من الحالتين، يمكنك استخدام هذا الرمز
أو رمز المشتقة الجزئية أو إذا كانت J هي دالة بمتغير واحد،
فاستخدم حرف d. هذه أحد القواعد اللطيفة للترميز في
حساب التفاضل والتكامل والتي أعتقد أنها تجعل الأمور أكثر تعقيدًا مما هي عليه. ولكن إذا رأيت رمز المشتقة الجزئية،
فإن كل ما يعنيه هو قياس منحدر الدالة بالنسبة إلى
واحد من المتغيرات. وعلى نحو مماثل بالالتزام بالترميز
الرياضي الصحيح سابقًا، كما تعلم في حساب التفاضل والتكامل لأن دالة J لها
مُدخلين وليس مُدخل واحد. فيلزم كتابة هذا الذي اكتبه الآن في الجزء
السُفلي باستخدام رمز المُشتقة الجزئية. ولكنه في واقع الأمر مماثل تقريبًا لما يعنيه
استخدام حرف d. وختامًا، عندما تُطبق ذلك في
التعليمات البرمجية، سنستخدم ترميز هذه الكمية
التي قمت بتحديث المتغير w بها، سنرمز إليها بالمتغير dw
في التعليمات البرمجية لديك. وهذه الكمية أيضًا، صحيح؟ الكمية التي تريد تحديث المتغير b بها سنرمز إليها بالمتغير db في
التعليمات البرمجية لديك. حسنًا، كانت هذه كيفية تطبيق الانحدار التدريجي. والآن إذا لم تكن قد درست حساب التفاضل
والتكامل لبضع سنوات، أنا أعرف أنه قد يكون هناك مشتقات أخرى في حساب التفاضل والتكامل تكون
مُعتادًا عليها أكثر حتى الآن. ولكن إذا كنت تشعر بهذا الأمر، فلا تقلق. سنستعرض في الفيديو القادم
مزيدًا من المعلومات الأساسية عن المُشتقات. وحتى بدون أن يكون لديك فهم عميق رياضي
لحساب التفاضل والتكامل، بل فقط من خلال الإلمام بأساسيات
حساب التفاضل والتكامل، ستكون قادرًا على جعل الشبكات العصبية
تعمل بفعالية. دعونا ننتقل إلى الفيديو التالي
الذي سنتحدث فيه أكثر قليلاً عن المشتقات.