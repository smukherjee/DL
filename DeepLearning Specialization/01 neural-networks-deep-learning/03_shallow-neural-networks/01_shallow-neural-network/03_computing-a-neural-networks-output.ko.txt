이전 비디오에서는 신걸 숨겨진 레이어 
신경망이 어떻게 생겼는지 보았는데요, 이번 비디오에서는 정확히 어떻게 신경망들이 결과값을 산출해내는지 한번 보도록 하겠습니다. 그 절차는 마치 로제스틱 회귀분석방식과 
비슷한데요, 반복적으로 진행이 됩니다. 한번 자세히 살펴볼까요. 이것이 two layer 신경망이 생긴 모양인데요, 어떻게 결과값을 산출하는지 
한번 자세히 살표보도록하죠. 이전에 이야기 했지만, 로지스틱 회귀분석은, 여기 이 동그란 이미지에서 2가지 절차로 이루어지는데요, 첫번째 단계로는 Z의 값을 이와 같이 구하고 두번째로는, Z의 시그모이드 함수로 activation을 산출합니다. 신경망에서는 이러한 
절차를 여러번 진행 하는 것입니다. 한번 숨겨진 레이어 에 있는 한개의 노드를 예로 시작해볼까요 그럼 숨겨진 레이어에 있는 첫번때 노드를 보겠습니다. 다른 노드들은 일단 잘 안보이게 하겠습니다. 왼쪽의 로지스틱 회귀분석과 비슷하게 여기 이 숨겨진 레이어의 노드는 
2가지의 계산 단계가 있는데요. 첫번째는, 여기 이 노드 반쪽에서 왼쪽으로 생각하십시요. 이 것은 z는 w transpose x 더하기 B이구요 표기는 여기서와 같이 첫번째 
숨겨진 레이어에서 속하는 양을 나타내는데요, 그렇기 때문에 이렇게 대괄호들이 많이 쓰였습니다. 
이것은 그리고 숨겨진 레이어의 첫번째 노드입니다. 그렇기 때문에 위첨자에 1로 표시하는 것입니다. 처음에는 이렇게 나타내고 두번째 절차는 a1 은 z1의 시그모이드 함수를 계산합니다. 그러므로 z와 a 에 대해 공식 표기는 여기서 a, l , i 위첨자 대괄호 l은 층의 번호를 나타내고 여기 i 첨자는 층에 있는노드를 표현합니다. 그럼 저희가 볼 것은 1번 층인데요, 
즉 숨겨진 레이어에서 첫번째 노드입니다. 그렇기 때문에 위첨자와 아래첨자가 모두 1이였던 것입니다. 여기 동그라미에서 첫번째 노드는 이 2가지 계산 절차를 진행하는 것임을 표현해줍니다. 자 그럼 이제 네트워크의 2번째 노드를 보겠습니다.
숨겨진 레이어에서의 2번째 노드 말이죠. 마찬가지로 로지스틱 회귀분석을 
나타내는 왼쪽의 그림과 같이, 여기 조금한 동그라미가 2가지 계싼 절차를 나타내죠. 첫번째는 z값을 계산하는건데요, 
이것은 아직 1번 층입니다. 이제 2번째 노드는 w = transpose x 더하기 v입니다. 그리고 a 1, 2 = z의 시그모이드 1, 2입니다. 
여러분이 언제든 비디오를 멈추셔서지 확인하셔도 되는데요, 
위첨자와 아래첨자 표기가 위의 보라색으로 적었던 내용과 동일한 원리라는 
것을 다시 한번 확인할 수 있습니다. 신경망에 있는 위의 2개 숨겨진 유닛에 대해 알아봤는데요, 유닛 3가 4도 마찬가지로 비슷한 계산법이 적용됩니다. 그럼 이제 여기 이 공식과 여기 이 공식을 다음 슬라이드에 복사해보겠습니다. 여기 네트워크가 보이구요, 여기는 쳣번째 
공식을 나타내고 있구요, 여기는 2번째 공식입니다. 이 2개는 저희가 첫번째와 두번째 
숨겨진 유닛에서계산했던 공식이죠. 그런 다름에 여러분이 이와 같이 
비슷하게 세번째와 네번째도 공식을 적용하면, 세번째와 네번째 숨겨진 유닛에 대해 말이죠, 
다음과 같이 말이죠. 이 표기를 확실하게 하기 위해 한번 보겠습니다. 
이것은 w11 인데요, 이것은 vector transpose 곱하기 x입니다. 여기 위첨자 t가 나타내는 것입니다.
이것은 vector transpose입니다. 여러분도 짐작하셨겠지만, 
이것을 신경망 네트워크에 도입하는 경우에, 이것을 4개의 루프로 하는 것은 
비효율적이라 생각하실 것입니다. 그렇기 때문에 이 4개의 
공식을 갖고 벡터화시킬 것입니다. 그러면 저는 먼저 z를 벡터로 
산출하는 방법을 보여드릴 것입니다. 이렇게 하실 수 있습니다. 일단 여기 W들을 가지고 매트릭스에 쌓도록 하겠습니다. 그러면 여기와 같이 w 1 1 transpose 와 같은 세로 벡터인데요 이렇게 줄의 형식 벡터로 나타낼 수 있습니다. 이어서 w 1 2 transpose , 
w 1 3 transpose w 1 4 transpose와 같습니다. 이렇게 4개의 벡터를 합쳐서 메트릭스가 나옵니다. 이것을 생각하는 방식은 보이는 것과 
같이 4개의 로지스틱 회귀분석법이 있죠. 각각의 로지스틱 회귀분석 은 
연계되는 매개변수 w가 있죠. 그리고 이런 4개의 벡터를 쌓으면서 결과적으로 4 X 3 매트릭스가 생깁니다. 그러면 이 매트릭스를 가지고 입력 특성 값인 x1, x2, x3와 곱하면, 매트릭스가 곱해지는 과정에 의해 w1 1 transpose x, w 2 1 transpose x, w 3 1 transpose x, w 4 1 transpose x 가 나옵니다. 
그러면 이제 b들을 알아보도록 하겠습니다. 그러면 여기 벡터들에 더하는데요, b11 b12 b13 in b14 그러면 이것은 이것과 같은데요, b11 b12 b13 b14 그러면 여기 보이듯이 각각의 결과값에 대한 4줄은, 여기 각각의 양과 위와 같이 똑같이 일치합니다. 다시 말해, 여기 이 것이 그러므로 z1 1, z1 2, z1 3, z 1 4와 일치하게 됩니다. 여기에서 정의된 것터럼 말이죠. 
그리고 놀라시진 않겠지만 이 전체값을 저희는 z1이라고 부르겠습니다. 
이 값은 각각의 개인 값을 세로 벡터에 쌓아서 생깁니다. 벡터화를 시키는 경우에, 
여러분께 도움이 될만한 경험에 의거한 규칙은, 이것을 제대로 접근하도록 도움을 줄만한 방법은, 
이렇게 층별로 다른 노드가 있는경우, 세로로 쌓을텐데요, 그렇기 때문에 z11에서 z14까지 있는 경우, 이렇게 다른 노드들이숨겨진 레이어에서 이 4개의 값을 세로로 쌓았습니다. 
결과적으로 벡터 z1을 구성하기 위해서 말이죠, 한가지 표기를 더 보자면, 여기 이 4 X 3 매트릭스는 소문자 w11, w12, 등등을 쌓아서 생긴 것인데요, 이 매트릭스를 대문자 W 1이라고 부를 것입니다.
 이 벡터는그리고 비슷하게 B 위첨자 대괄호 1이라고 부를 것입니다. 이제 그러면 저희는 벡터 매트릭스 
표기를 통해서 Z의 값을 계산했는데요, 저희가 마지막으로 해야하는 것은 
여기 이 a의 값을 계산하는 것입니다. 놀랍지 않게도 a1을 여기 이런 activation 값들, a11에서 a14 까지의 값들을 쌓아서 정의할 것입니다. 그러므로 여기 4개의 값을 가져서 쌓도록 합니다. a1이라는 벡터에 말이죠.
그러면 이것은 z1의 시그모이드가 될 것입니다. 이것은 이제 시그모이드 함수의 도입인데요, 이 것은 z의 4가지 요소를 갖고 
시그모이드 함수에 적용되는 것입니다. element wise가 적용되는 것이죠.
저희는 z1이 w1 곱하기
벡터 x 더하기 벡터x 더하기 벡터 b1이라는 것을 알아냈는데요.
그리고 a1은 시그모이드 곱하기 z1입니다. 이것을 다음 슬라이드에 복사하겠습니다 
입력값 x에 대해 신경망의 첫번째 층에 z1은 w1 곱하기 X 더하기 B 1인데요, a1은 z1의 시그모이드 이구요, 이것의 다이멘션은 4 x 1 = 이것은 4 x 3 매트릭스이고, 
곱하기 3 x 1벡터 더하기 4 x 1 벡터인 b가 더하잽니다. 그리고 이것은 이것과 다이멘션이 동일하게 4 x 1입니다. 
그리고 기억하시겠지만, x는 0이라고 했죠. ŷ이 a2인 것과 같이 말이죠. 그렇기 때문에 원하면 이 x값을 a0로 대입해도 됩니다. 입력특성 x 벡터에 가명이기 때문에 대입해도 됩니다. 비슷한 derivation 방법으로 다음 층의 표기도 비슷하게 나타낼 수 있는데요, 결과값이 하는 것은, w2와 b2와 연계가 될텐데요, 이런 매개 변수의 경우, 
이것은 1x 4매트릭스가 될 것입니다. 그리고 b2는 (1, 1) 실수가 됩니다 그렇기 때문에 z2 가 (1, 1) 
실수인 매트릭스가 될 것입니다. 이것은 1, 4가 될 것이고, 이것은 4, 1 이였죠. 
더하기 b2는 1, 1입니다. 그렇기 때문에 이것은 또한 실수가 됩니다. 여기 이 결과값을 로지스틱 회귀분석 방식으로 생각하면, 
w와 b의 매개 변수를 갖는 것 말이죠. W는 실제로 w[2] transpose와 유사한 역할을합니다. W는 W transpose와 같 b는 b2와 같습니다. 네트워크의 이 왼쪽에 있는 
부분을 일단 무시하겠습니다. 그러면 여기 이 마지막 결과값은 
로지스틱 회귀분석방식과 매우 유사한데요, 단지 w와 b로 매개 변수를 갖는 대신에, 변수를 w2와 b2로 쓰는 것입니다.
1 x 4 다이멘션과 1 x 1 다이멘션으로 말이죠. 로지스틱 회귀분석이 결과값을 도입하기 위해서는 또는 예측하기 위해서는 
Z를 w transpose x 더하기 b로 나타냅니다. 그리고 ŷ은 a이고, z의 시그모이드입니다. 만약 숨겨진 레이어가 1개인 
신경망의 경우, 해야하는 것은, 이런 결과값을 갖기 위해서 말이죠,
여기 이 4개의 공식을 도입합니다. 이것을 결과값을 도출하기 위한 
벡터화 도입이라고 생각하면 쉽습니다. 여기 숨겨진 레이어의 로지스틱 
회귀분석 유닛에 대해 말이죠. 이것이 하는 역할이 그렇구요, 이것은 
결과값 층의 regression인데요, 이것이 하는 것입니다. 이러한 표현이 이해가 됐었으면 
좋겠습니다. 기억하실 것은, 이런 신경망의 결과값을 계산하기 
위해서는 여기 4개 라인의 코드만 필요합니다. 1개의 입력 특성 벡터값이 주어지면, 
4개의 코드를 활용하여, 4개의 코드를 활용하여, 계산할 수 있습니다. 로지스틱 회귀분석과 비슷하게, 복수의 트레이닝 
샘플을 가지고 벡터화하고 싶을 것입니다. 가지고 벡터화하고 싶을 것입니다.
이런 경우, 트레이닝 예시들을 줄별로 트레이닝 시킴으로써 매트릭스를 
이용해서 말이죠, 아니면 약간의 변형을 주어, 로지스틱 회귀분석에서 본 것과 같이, 신경망의 결과값을 예시 별로 계산하는 것이 아니라 전체 트레이닝 세트에서 결과값을 찾을 수 있습니다. 이 내용은 다음 비디오에서 다루겠습니다.