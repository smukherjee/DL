إذا كانت الأفكار التقنية الأساسية التي
يقوم عليها التعلم العميق والتي تقوم عليها الشبكات العصبية
الجديدة موجودة منذ عقود لماذا لم تأخذ في الانتشار بهذه
الطريقة إلا الآن؟ في هذا الفيديو سوف نقوم بتوضيح بعض الأسباب الرئيسية لازدياد الاهتمام بالتعلم
العميق حيث أظن أن ذلك سوف يساعدك على اقتناص أفضل الفرص في المؤسسة التي تعمل بها
لتطبيق هذه المفاهيم عليها. خلال السنوات القليلة الأخيرة سألني العديد من الأشخاص
السؤال التالي "أندرو، لماذا يعمل التعليم العميق
بهذا الشكل الجيد للغاية؟" وعندما كان يُطرح ذلك السؤال
عليّ، غالبًا كنت قوم برسم
الصورة التالية لهم. لنفترض أننّا رسمنا الشكل
 البياني حيث المحور الأفقي يمثل مقدار البيانات
التي لدينا لمهمة معينة. لنفترض أننا نستخدم المحور الرأسي ونرسم أداء خوارزمية التعلم الخاصة بنا مثل دقة مُصنف البريد
الإلكتروني المزعج لدينا أو برنامج التنبؤ بالنقرات الخاص بنا أو دقة شبكتنا العصبية لاستكشاف مواقع
 السيارات الأخرى النسبة لسيارتنا
ذاتية القيادة. يتضح أنه عندما تقوم برسم منحنى
الأداء خوارزمية تعلم تقليدية مثل ماكينة متجه الدعم أو التراجع اللوجيستي كدالة لمقدار
البيانات لمتاحة لدينا فقد تحصل على منحنى قوسي مثل هذا حيث يتحسن الأداء لمدة معينة
 كلما قمت إضافة المزيد
من البيانات، ولكن بعد فترة معينة يحافظ منحني الأداء على
نفس القيمة تقريبًا. هذا الجزء من المفترض أن يكون
 عبارة عن خطوط أفقية
ولكني رسمته بشكل غير متقن. يمكن تفسير ذلك كأنهم لم يكونوا قادرين
 على التعامل مع كل هذا القدر
الضخم من البيانات. والذي حدث في مجتمعنا على مدار العشرين عامًا الماضية تقريبًا أنه
فيما يخص العديد من المشكلات انتقلنا من مرحلة كنا نملك فيها كمية
ضئيلة نسبيًا من البيانات إلى مرحلة نملك فيها
كمية هائلة من البيانات ومعظم ذلك ناجم عن رقمنة المجتمع حيث تتم إدارة الكثير من
 الأنشطة البشرية
حاليًا عبر المنصات الإلكترونية. فنحن نمضي الكثير من الوقت أمام
أجهزة الكمبيوتر وعلى مواقع الويب وعلى تطبيقات الهاتف المحمول
 والأنشطة التي نستخدم فيها
أجهزة رقمية وتقوم بخلق بيانات. وبفضل انتشار الكاميرات رخيصة الثمن والموجودة في الهواتف الجوالة وكذلك مقاييس السرعة و كل أنواع المستشعرات التي تستخدم في إنترنت الأشياء بدأنا كذلك في جمع المزيد والمزيد من البيانات. لذلك، خلال العشرين عامًا الماضية
بالنسبة للعديد من التطبيقات قمنا بحفظ وتجميع المزيد من المعلومات أكثر من القدر الذي كانت خوارزميات التعلم التقليدية
تستطيع الاستفادة منه بشكل فعال. ومع الشبكات العصبية، تبين أنه إذا قمت بتدريب شبكة عصبية صغيرة، فإن الأداء سوف يكون شيئًا
مشابهًا لما يحدث عند تدريب شبكة عصبية أكبر إلى حد ما والتي تُدعى شبكة عصبية متوسطة الحجم حيث يكون الأداء أفضل دائمًا. وإذا قمت بتدريب
شبكة عصبية كبيرة للغاية فسوف يستمر أداء الشبكة في التحسن أكثر وأكثر. ونتيجة لذلك، هناك ملاحظتان تظهران، الأولى أنه إذا أردت أن تصل لهذا الأداء المرتفع للغاية فسوف تحتاج إلى شيئين اثنين. الشيء الأول أنك في الغالب يجب أن تكون
قادرًا على تدريب شبكة عصبية كبيرة بشكل كافٍ لكي تستطيع الاستفادة من القدر الكبير من البيانات التي لديك
والشيء الثاني أنك يجب أن تكون هنا على محور x وتحتاج إلى الكثير من البيانات. لذا، دائمًا ما نقول إن النطاق كان يدفع
التعلم العميق نحو التقدم، وما أعنيه بالنطاق هو حجم الشبكة العصبية أي تلك الشبكة العصبية التي تحتوي على الكثير
من الوحدات المخفية والكثير من المعلمات والكثير من الصلات وكذلك نطاق البيانات. في الواقع، في الغالب يكون من بين الطرق ذات
أفضل درجات الموثوقية للحصول على الأداء الجيد في الشبكات العصبية تدريب شبكة أكبر أو توفير
المزيد من البيانات لها، وهذا يجدي حتى نقطة معينة فقط لأنه في نهاية المطاف سوف تقوم بتشغيل كل البيانات أو
في نهاية المطاف تكون الشبكة العصبية ضخمة للغاية بحيث تستغرق وقتًا طويلاً للغاية
لتدريبها، إلا أن مجرد تحسين النطاق قد دفعنا للأمام كثيرًا في الواقع
في عالم التعلم العميق. ولجعل هذا الرسم البياني أكثر دقة من الناحية الفنية دعوني أضيف بعض الأشياء الأخرى. لقد كتبت مقدار البيانات على المحور "x". من الناحية الفنية، هذا مقدار البيانات المصنفة حيث ما أعنيه بالبيانات المصنفة أمثلة التدريب، لدينا
المدخلات "x" والتصنيف "y". لإعطاء المزيد من الرموز التي سوف نستخدمها
في وقت لاحق في هذه الدورة التدريبية سوف نستخدم الحرف "m" اللاتيني الصغير للإشارة إلى
حجم مجموعة التدريب الخاصة بي. لذا، يشير الحرف اللاتيني "m" الصغير إلى عدد أمثلة التدريب.
ويكون هذا هو المحور الأفقي. هنا تفصيلان آخران في هذا الشكل في هذا النظام الخاص بمجموعات التدريب الصغيرة لا يكون الترتيب النسبي للخوارزميات معرفًا
بشكل جيد في الواقع. لذا، يعتمد ما إذا لم يكن لديك الكثير من بيانات التدريب على مهارتك في سمات الهندسة اليدوية والتي تحدد الأداء. وبالتالي، يكون من الممكن إلى حد كبير أن يكون الشخص
الذي يقوم بالتدريب في SDM أكثر تحفزًا فيما يخص سمات الهندسة اليدوية عن شخص
يقوم بالتدريب على شبكة عصبية أكبر وربما في أنظمة مجموعات التدريب الصغيرة يمكن أن يكون SDM أفضل. لذا، في هذه المنطقة إلى يسار الشكل لا يكون الترتيب النسبي بين الخوارزميات معرفًا جيدًا، ويعتمد الأداء بشكل أكبر على مهارتك في سمات التعليق وغير ذلك من تفاصيل الخوارزميات البسيطة، وفي نظام البيانات الضخم هذا فقط ومجموعات التدريب الضخمة للغاية وأنظمة "m" الضخمة للغاية في اليمين، نرى بشكل أكثر اتساقًا الشبكات العصبية الضخمة وهي تسود
على المنهجيات الأخرى. لذا، إذا سألك أحد أصدقائك عن سبب انتشار الشبكات العصبية فإني أشجعك على رسم هذه الصورة له كذلك. ويمكن أن أقول أنه في الأيام الأولى للتعلم العميق وفي بداية نشأته المعاصرة كان الأمر يتعلق بنطاق البيانات ونطاق العمليات الحسابية. إن قدرتنا على تدريب الشبكات العصبية الضخمة للغاية سواء في وحدات المعالجة المركزية أو وحدات معالجة الرسومات هي ما ساعدتنا على تحقيق الكثير من التقدم. لكن، بشكل متزايد، على وجه الخصوص في
السنوات العديدة الأخيرة شهدنا ابتكارًا ضخمًا في مجال الخوارزميات كذلك. لذا، فأنا أيضًا لا أريد أن أتفهم هذا الأمر. ومن المثير للاهتمام أن الكثير من الابتكارات في
مجال الخوارزميات نجم عن محاولة دفع الشبكات العصبية نحو التقدم بسرعة أكبر. ومن بين الأمثلة الراسخة على ذلك أن واحدة من الطفرات الضخمة للغاية في الشبكات العصبية كانت تتمثل في التحول من استخدام دالة Sigmoid التي تبدو مثل ذلك إلى دالة ReLU التي تحدثنا عنها باختصار في فيديو سابق والتي تبدو مثل ذلك. إذا لم تكن تفهم تفاصيل ما أتحدث عنه
فلا تقلق بشأن ذلك. لكن، اتضح أن إحدى المشكلات الناجمة عن
استخدام دوال Sigmoid في تعليم الماكينات كانت وجود
تلك المناطق هنا في ميل الدالة حيث يكون التدرج قريبًا من الصفر وبالتالي يصبح التعلم بطيئًا للغاية لأنك عندما تقوم بتنفيذ انحدار تدريجي ويكون التدرج صفرًا تتغير المعلمات ببطء شديد، وبالتالي يصبح التعليم بطيئًا للغاية. في حين أنه من خلال تغيير دالة التنشيط في الشبكة العصبية لاستخدام هذه الدالة التي يطلق عليها دالة القيمة أو
وحدة التصحيح الخطية REOU، يساوي التدرج "واحد" لكل
قيم المدخلات الإيجابية حسنًا؟ وبالتالي، تكون احتمالية تقليص التدرج إلى الصفر أقل بكثير. والتدرج هنا، ميل هذا الخط صفر في اليسار، إلا أنه يتضح أنه من خلال الانتقال من دالة Sigmoid إلى دالة القيمة جعل ذلك خوارزمية اسمها الانحدار
التدريجي تعمل بشكل أسرع. لذا، ربما يكون ذلك مثالاً على الابتكار البسيط
نسبيًا في مجال الخوارزميات إلا أن تأثير هذا الابتكار في مجال الخوارزميات كان في
مساعدته في العمليات الحسابية بشدة. وفي الواقع، هناك الكثير من الأمثلة المشابهة لذلك حيث قمنا بتغيير الخوارزمية لأن ذلك يؤدي إلى تشغيل التعليمات البرمجية بسرعة أكبر، كما أن ذلك يساعدنا على تدريب شبكات
عصبية أكبر أو استنتاج ذلك بحيث يكون مقدار التعليمات البرمجية معقولاً حتى عندما يكون
لدينا شبكة ضخمة أو الكثير من البيانات. السبب الآخر الذي يجعل العمليات الحسابية السريعة أمرًا مهمًا هو أنه اتضح أن عملية تدريب الشبكة الخاصة بك أمر يتكرر للغاية. في الغالب، تكون لديك فكرة لبنية الشبكة العصبية لديك، وبالتالي تقوم بتنفيذ الفكرة
في شكل تعليمات برمجية. وبالتالي، يساعدك تنفيذ الفكرة في إجراء تجربة تخبرك بمدى جودة عمل الشبكة
العصبية، ومن خلال النظر في ذلك يمكنك العودة لتغيير تفاصيل الشبكة العصبية الخاصة بك، وبعد ذلك تمر
في هذه الدائرة مرارًا وتكرارًا. وعندما تحتاج الشبكة العصبية
الخاصة بك إلى وقت كبير لتدريبها يتطلب الأمر الكثير من الوقت لكي تمر بهذه الدورة ويظهر فرق ضخم في إنتاجيتك في بناء الشبكات العصبية عندما تكون لديك فكرة وتجربها وتراها وهي تعمل خلال 10 دقائق أو حتى خلال جزء كبير من اليوم في مقابل تدريب
الشبكة العصبية الخاصة بك لمدة شهر. حسنًا، في بعض الأحيان يحدث ذلك، لأنك عندما تحصل على نتيجة خلال 10 دقائق أو حتى خلال يوم يمكن أن تقوم بتجريب المزيد من الأفكار وتزداد احتمالية اكتشاف شبكة عصبية تعمل بشكل جيد للتطبيق الخاص بك. لذا، فقد ساعد تسريع العمليات الحسابية بشدة فيما يتعلق بتسريع معدل الحصول على نتائج التجريب، وقد ساعد ذلك بشدة ممارسي الشبكات العصبية وكذلك الباحثين الذين يعملون في مجال التعلم العميق على التكرار بشكل أسرع كثيرًا وتحسين الأفكار بشكل أسرع. لذا، فقد كان ذلك كله بمثابة التطور الضخم في مجتمع أبحاث التعلم العميق برمته
وهو تطور مذهل في رأيي فيما يتعلق بابتكار خوارزميات جديدة وتحقيق
تقدم مستمر على تلك الجبهة. فهذه بعض القوى التي تعيق تطور التعلم
العميق إلا أن الخبر السار هنا أن هذه القوى ما زالت تعمل بكل قوة
لجعل التعلم العميق أقوى بالنسبة للبيانات. إن المجتمع ما زال ينتج المزيد من البيانات الرقمية أو يعتمد على العمليات الحسابية مع انتشار الأجهزة المتخصصة
مثل وحدات معالجة الرسومات والشبكات الأسرع والعديد من أنواع البرامج. أنا واثق للغاية في أن قدرتنا على بناء
شبكات عصبية ضخمة للغاية من وجهة نظر العمليات الحسابية سوف تستمر في التحسن
وتعتمد على الخوارزميات في حين أن مجتمعات أبحاث التعلم العميق برمتها سوف تستمر في أن تكون استثنائية فيما يتعلق
بالابتكار على جبهة الخوارزميات. لذا، لهذا السبب أعتقد أننا يمكن أن نشعر بالتفاؤل. أنا متفائل بالقطع حيال أن التعلم العميق سوف يستمر في التحسن لعدة سنوات قادمة. وبناءً على ذلك، دعونا ننتقل
إلى آخر فيديو في هذا القسم حيث سنتحدث بشكل أكبر على
ما تعلمناه في هذه الدورة التدريبية.