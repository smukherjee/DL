您看過我畫一些
神經網路的圖 在這段影片中, 我們將談談
這些圖的意義 換句話說, 我們畫過的這些神經網路圖
真正代表什麼意思 我們先把焦點放在
一種神經網路 稱為單一隱藏層 這是神經網路的圖 讓我們賦予這些圖形
不同部分的名稱 我們有輸入特徵, x1,
x2,x3 垂直疊起來 這是所謂神經網路的
輸入層 或許並不意外,這包含了神經網路的輸入 然後有另一層小圓圈 而這是稱為神經網路的
隱藏層 我回頭再來解釋為什麼
稱為隱藏 最後這一層, 
在這個例子, 只有一個節點 而這個單一節點層稱為
輸出層, 負責 產生估計值 y-hat 在神經網路
使用監督式學習訓練 訓練集包含了
輸入 x 跟目標輸出 y 所以這個名詞'隱藏層'指的是
在訓練集裡 這些在中間節點的值
並不被觀察到. 也就是說您在訓練集裡
看不到他們應該是什麼值 您看到了輸入 您看到輸出應該是多少 但在隱藏層的值
並沒有在訓練集裡 這樣解釋了 隱藏層 的名字
就因為您 並沒看到它們在訓練集 讓我們介紹一下更多的符號。 以前,我們使用
向量  X  表示輸入特徵和 另一種記號 輸入特徵的值
是 A 上標方括號 0 這個專有名詞 A 代表
啟動而 它指的是不同層的值 在神經網路傳遞到
下一層 所以輸入層傳遞
x的值到隱藏層 我們將之稱為
輸入層A上標0的啟動 下一層,隱藏層,將
持續來產生一些啟動值 我將它寫成
A 上標方括號 1 特別來說,
第一單元或者說第一個節點 我們產生A上標
方括號1下標1 第二個節點,我們產生一個值。 我們用下標 2, 等等.. 所以,一個上標 方括弧1, 這是一個 4 維向量
要用在Python中 因為這是 4x1 矩陣,或
4列 向量,像這樣。 它是 4 維, 因為
這個例子裡以們有四個節點 四個單元, 或者說
四個隱藏單元在隱藏層 最後
輸出層產生 A2值 就只是一個實數 所以
y-hat 就用A2的值 因此,這類似于
羅吉斯迴歸分析那樣,我們有 y-hat 等於 a 在羅吉斯迴歸分析,我們
只有一個輸出層, 所以我們並不使用上標
方括號 但是有了我們的神經網路
我們現在要使用上標方括號 方括號來明顯表示
它是從哪一層來的 一件關於符號有趣的事
在神經網路 是您看到的這個網路
稱為兩層神經網路 而原因是當我們
數神經網路幾層時 我們不算輸入層 所以隱藏層是第一層
輸出層是第二層 用我們的符號約定我們
稱輸入層是第零層 技術上而言在這個神經網路
應該是三層 因為有輸入層, 隱藏層, 和 輸出層。 但常規的說法是, 如果您
讀研究論文跟其他時候在 這個課程裡, 您看到人們提及
這特定的神經網路是兩層 神經網路, 因為我們不當
輸入層是正式的一層 最後, 一些會進入
隱藏層跟 輸出層的會是
伴其相關的參數 隱藏層會有
相關的參數 w 跟 b 我將寫成上標
方括號 1 來表明這些 參數相關於
第一層也就是隱藏層 我們以後會
看到 w 會是一個 4 乘 3 矩陣 b 會是 4 乘 1 向量在這個例子 而第一個維度 4 
來自於我們有 四個節點在我們的
隱藏層的事實，而 3 來自於
我們有三個輸入特徵的事實 我們會在以後談論
這些矩陣的維度 也許屆時會比較有感覺 但在一些輸出層有
也有與之關聯的參數 w 上標方括號 2 跟
b 上標方括號 2 而這些的維度是
1 乘 4 跟 1 乘 1 而這個 1 乘 4 因為隱藏
層有四個單元 輸出層只有一個單元 但我們會在以後影片中談到這些
矩陣跟向量的維度 您剛剛看到一個兩
層神經網路的樣子 也就是
使用一個隱藏層的神經網路 在下一個影片中 讓我們更進一步看
這個神經網路怎麼做計算 也就是這個神經
網路如何從輸入 x 一直到
計算它的輸出 y-hat