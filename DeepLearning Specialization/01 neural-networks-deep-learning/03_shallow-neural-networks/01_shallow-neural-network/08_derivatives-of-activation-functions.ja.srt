1
00:00:00,302 --> 00:00:04,340
誤差逆伝播法を実装するためには、

2
00:00:04,340 --> 00:00:07,813
活性化関数の導関数の傾きを
計算できなくてはなりません。

3
00:00:07,813 --> 00:00:11,333
活性化関数の選択肢を見て、

4
00:00:11,333 --> 00:00:14,025
それらの傾きを計算する方法を学びましょう。

5
00:00:14,025 --> 00:00:17,239
これが、見慣れたシグモイド活性化関数です。

6
00:00:17,239 --> 00:00:22,252
与えられたzにおいて、

7
00:00:22,252 --> 00:00:27,184
この関数はそこに対応した傾き、
つまり導関数を持っています。

8
00:00:27,184 --> 00:00:32,389
この小さい三角形の横幅に対する高さですね。

9
00:00:32,389 --> 00:00:39,823
g(z)がシグモイド関数のとき、
その傾きはd/dz g(z)です。

10
00:00:39,823 --> 00:00:47,034
微積分学から、
これがg(x)のzにおける傾きだとわかります。

11
00:00:47,034 --> 00:00:52,513
もしあなたが微積分学を知っていて、
微分の方法がわかるなら、

12
00:00:52,513 --> 00:00:56,074
シグモイド関数を微分したとき、

13
00:00:56,074 --> 00:01:00,300
それがこの式と等しくなると
わかります。

14
00:01:00,300 --> 00:01:02,380
繰り返しますが、ここでは微分の方法を
一つ一つやることはありません。

15
00:01:02,380 --> 00:01:04,839
しかし、もし微積分学に詳しいなら

16
00:01:04,839 --> 00:01:08,465
ぜひ動画を止めて自分で証明してみてください。

17
00:01:08,465 --> 00:01:16,583
これはg(z)×(1-g(z))と等しくなります。

18
00:01:16,583 --> 00:01:20,923
では、この式が本当に意味を成すかどうか
確認してみましょう。

19
00:01:20,923 --> 00:01:26,343
まず、zがとても大きい数字、
例えば10だとしましょう。

20
00:01:26,343 --> 00:01:30,315
するとg(z)は1に近くなり、

21
00:01:30,315 --> 00:01:38,758
この左の式から、d/dz g(z)は

22
00:01:38,758 --> 00:01:42,979
1×(1-1)で、

23
00:01:42,979 --> 00:01:46,851
とても0に近い数字となることがわかります。

24
00:01:46,851 --> 00:01:51,267
実際これは正しいですね。
zが大きいとき、傾きは0に近くなりますから。

25
00:01:51,267 --> 00:01:58,885
逆に、もしzが-10のとき、この辺りで、
g(z)は0に近いです。

26
00:01:58,885 --> 00:02:01,765
左の式によると、

27
00:02:01,765 --> 00:02:07,333
d/dz g(z)は0×(1-0)に近い値となります。

28
00:02:07,333 --> 00:02:10,005
なので、これもとても0に近くなり、
正しい答えとなります。

29
00:02:10,005 --> 00:02:16,889
最後に、zが0のとき、g(z)は1/2です。

30
00:02:16,889 --> 00:02:18,983
シグモイド関数のこの部分ですね。

31
00:02:18,983 --> 00:02:24,040
このとき、導関数は

32
00:02:24,040 --> 00:02:28,459
1/2×(1-1/2)で、1/4となります。

33
00:02:28,459 --> 00:02:33,135
それは実際、z=0のときの導関数、
つまりこの関数の傾きとして

34
00:02:33,135 --> 00:02:35,831
正しい値なのです。

35
00:02:35,831 --> 00:02:38,839
最後に、もう少し表記法を
紹介します。

36
00:02:38,839 --> 00:02:42,321
たまに、これを書く代わりに、

37
00:02:42,321 --> 00:02:46,087
導関数を簡略化したg'(z)という書き方を
使います。

38
00:02:46,087 --> 00:02:52,167
この上にあるダッシュはプライムと呼ばれます。

39
00:02:52,167 --> 00:02:55,283
微積分学におけるg'(z)とは、

40
00:02:55,283 --> 00:03:00,455
入力変数zについての関数gの導関数を
簡略化した書き方です。

41
00:03:00,455 --> 00:03:07,513
ニューラルネットワークでは、a=g(z)で、

42
00:03:07,513 --> 00:03:11,351
それはこれと等しくなります。

43
00:03:11,351 --> 00:03:17,145
すると、これはa×(1-a)と書くことができます。

44
00:03:17,145 --> 00:03:20,109
たまに実装するとき、

45
00:03:20,109 --> 00:03:25,256
g'(z)=a(1-a)というような書き方を
目にすることがあるでしょう。

46
00:03:25,256 --> 00:03:29,040
それは、導関数を意味するg'が

47
00:03:29,040 --> 00:03:33,428
これと等しいということを
示しているだけです。

48
00:03:33,428 --> 00:03:38,397
この公式の利点は、aの値を計算してあれば、

49
00:03:38,397 --> 00:03:43,078
この式を使って、傾き、つまりg'の値も

50
00:03:43,078 --> 00:03:45,038
すぐに計算できるということです。

51
00:03:45,038 --> 00:03:47,632
ここまでが、シグモイド活性化関数でした。

52
00:03:47,632 --> 00:03:51,172
次はtanh活性化関数を見てみましょう。

53
00:03:51,172 --> 00:03:56,311
前と同じような感じで、d/dz g(z)の定義は

54
00:03:56,311 --> 00:04:01,155
あるzにおけるg(z)の傾きです。

55
00:04:01,155 --> 00:04:07,747
そして、双曲線のタンジェント関数を見れば、

56
00:04:07,747 --> 00:04:13,066
そしてもし微積分を知っていれば、

57
00:04:13,066 --> 00:04:17,359
微分がこのシンプルな式で表せると
わかるでしょう。

58
00:04:20,813 --> 00:04:23,997
前と同じように簡略化した書き方を使えば、

59
00:04:23,997 --> 00:04:27,019
これはg'(z)と表せます。

60
00:04:27,019 --> 00:04:30,941
やりたければ、この式が意味を成すかどうか
確認できます。

61
00:04:30,941 --> 00:04:37,005
例えばz=10のとき、tanh(z)は1に近くなります。

62
00:04:37,005 --> 00:04:41,309
これは+1から-1になります。

63
00:04:41,309 --> 00:04:45,183
そしてg'(z)は、この式によれば、

64
00:04:45,183 --> 00:04:48,148
1-1^1、すなわち0になります。

65
00:04:48,148 --> 00:04:53,930
つまり、zがとても大きければ傾きは0に近くなる
ということです。

66
00:04:53,930 --> 00:04:58,760
逆に、zが小さい数字、例えば-10だとしたら、

67
00:04:58,760 --> 00:05:02,440
tanh(z)は-1に近くなります。

68
00:05:02,440 --> 00:05:07,871
するとg'(z)は1-(-1)^2となるので、

69
00:05:07,871 --> 00:05:12,792
1-1と近くなり、こちらも0に近くなります。

70
00:05:12,792 --> 00:05:18,421
最後に、z=0なら、tanh(z)=0となり、

71
00:05:18,421 --> 00:05:22,165
傾きは1となります。

72
00:05:22,165 --> 00:05:26,433
実際z=0のときの傾きは1となっています。

73
00:05:26,433 --> 00:05:33,001
要約すると、
a=g(z)つまりaがtanh(z)と等しいとき、

74
00:05:33,001 --> 00:05:38,300
微分したg'(z)は1-a^2となります。

75
00:05:38,300 --> 00:05:42,000
繰り返しますが、
もしaの値を前もって計算してあれば、

76
00:05:42,000 --> 00:05:46,522
この公式を使って
微分も素早く計算できるのです。

77
00:05:46,522 --> 00:05:49,618
最後に、ReLUとLeaky ReLU活性化関数の

78
00:05:49,618 --> 00:05:51,338
微分を計算する方法です。

79
00:05:51,338 --> 00:05:57,866
ReLUでは、g(z)=max(0,z)です。

80
00:05:57,866 --> 00:06:03,330
なので、zが0より小さい場合、
微分は0となります。

81
00:06:03,330 --> 00:06:09,066
zが0より大きい場合は1となります。

82
00:06:09,066 --> 00:06:15,498
実は、zが0ちょうどの場合は
微分は定義できません。

83
00:06:15,498 --> 00:06:18,339
しかし、ソフトウェアでこれを実装するとき、

84
00:06:18,339 --> 00:06:21,398
数学的に完璧ではないかもしれません。

85
00:06:21,398 --> 00:06:25,571
しかし、zが0ちょうどのとき

86
00:06:25,571 --> 00:06:30,501
微分を1か0に設定しても問題はないでしょう。

87
00:06:30,501 --> 00:06:31,781
気にする必要はありません。

88
00:06:31,781 --> 00:06:33,578
最適化するときに、

89
00:06:33,578 --> 00:06:37,109
g'(z)は実際は
g(z)の劣勾配と呼ばれるものになって、

90
00:06:37,109 --> 00:06:41,360
そのため最急降下法がちゃんと働きます。

91
00:06:41,360 --> 00:06:47,327
しかし、zがぴったり0.00000...になる可能性は
とても小さいので、

92
00:06:47,327 --> 00:06:52,805
z=0のときの微分を何に定義しても

93
00:06:52,805 --> 00:06:54,303
あまり問題はありません。

94
00:06:54,303 --> 00:06:59,155
これが、実際に微分を実装する方法です。

95
00:06:59,155 --> 00:07:03,712
最後に、Leaky ReLU活性化関数で

96
00:07:03,712 --> 00:07:06,882
ニューラルネットワークを訓練するとき

97
00:07:06,882 --> 00:07:12,244
g(z)は0.01zとzの大きい方を取ります。

98
00:07:12,244 --> 00:07:15,247
なので、zが0より小さいとき
g'(z)は0.01となり、

99
00:07:15,247 --> 00:07:19,074
zが0より大きいとき、1になります。

100
00:07:19,074 --> 00:07:20,477
もう一度言いますが、

101
00:07:20,477 --> 00:07:26,403
zがちょうど0のとき、
厳密に言うと勾配は定義されません。

102
00:07:26,403 --> 00:07:31,479
しかし実装する際には、z=0のとき

103
00:07:31,479 --> 00:07:38,353
g'(z)を0.01か1のどちらに設定しても
問題ありません。

104
00:07:38,353 --> 00:07:41,499
どちらでもコードはちゃんと動きます。

105
00:07:41,499 --> 00:07:45,594
これらの公式を使って、
活性化関数の勾配、つまり微分を

106
00:07:45,594 --> 00:07:48,400
計算できるようになりました。

107
00:07:48,400 --> 00:07:50,553
ピースが揃ったところで、

108
00:07:50,553 --> 00:07:54,502
ニューラルネットワークの最急降下法を
実装する方法を学びましょう。

109
00:07:54,502 --> 00:07:57,309
では、次の動画に進みましょう。