1
00:00:00,860 --> 00:00:05,760
我們已經談過向量化讓您明顯的加快您程式的速度

2
00:00:05,760 --> 00:00:08,160
在這段影片中, 我們將談您如何可以向量化

3
00:00:08,160 --> 00:00:10,545
羅吉斯迴歸分析的建置

4
00:00:10,545 --> 00:00:12,960
所以用他們來處理整個訓練集

5
00:00:12,960 --> 00:00:15,930
也就是建置一個單一循環的梯度下降對於

6
00:00:15,930 --> 00:00:22,330
整個訓練集甚至不需要一個迴圈

7
00:00:22,330 --> 00:00:24,039
我對這項技術非常興奮

8
00:00:24,039 --> 00:00:26,670
當我們以後談論到有關於神經網路甚至

9
00:00:26,670 --> 00:00:30,050
不用ㄧ個迴圈

10
00:00:30,050 --> 00:00:35,965
讓我們開始吧, 首先先檢驗羅吉斯迴歸分析的正向傳播步驟

11
00:00:35,965 --> 00:00:37,860
如果您有 m 個訓練例子

12
00:00:37,860 --> 00:00:40,605
為了要預測的第一個例子

13
00:00:40,605 --> 00:00:42,105
您需要計算

14
00:00:42,105 --> 00:00:45,480
計算 z 我用這個熟悉的方法

15
00:00:45,480 --> 00:00:47,370
計算這個啟動的

16
00:00:47,370 --> 00:00:49,485
您計算 y-hat 在第一個例子

17
00:00:49,485 --> 00:00:52,705
然後做第二個訓練例子地預測

18
00:00:52,705 --> 00:00:54,405
您需要計算這個

19
00:00:54,405 --> 00:00:57,085
然後做第三個例子的預測

20
00:00:57,085 --> 00:00:59,045
您需要計算這個, 等等

21
00:00:59,045 --> 00:01:01,020
而您也許需要這樣做 m 次

22
00:01:01,020 --> 00:01:03,855
如果您有 m 個例子

23
00:01:03,855 --> 00:01:08,250
實際上為了做正向傳播步驟

24
00:01:08,250 --> 00:01:13,435
也就是計算這些 m 訓練例子的預測

25
00:01:13,435 --> 00:01:14,865
有一種方式

26
00:01:14,865 --> 00:01:17,925
不需要明顯的迴圈

27
00:01:17,925 --> 00:01:20,450
我們來看怎麼做

28
00:01:20,450 --> 00:01:26,455
首先, 記得我們定義矩陣大寫 X 為訓練輸入

29
00:01:26,455 --> 00:01:30,895
不同的欄疊在一起像這樣

30
00:01:30,895 --> 00:01:33,810
所以這是一個矩陣

31
00:01:33,810 --> 00:01:38,425
是一個 nx 乘 m 矩陣

32
00:01:38,425 --> 00:01:41,885
我這樣寫成 Python numpy shpae 的格式

33
00:01:41,885 --> 00:01:50,350
這只是說 X 是 nx 乘 m 維矩陣

34
00:01:50,350 --> 00:01:54,670
現在第一件事是我想展示您如何計算z1, z2,

35
00:01:54,670 --> 00:01:56,512
z3等等

36
00:01:56,512 --> 00:01:58,665
所有在一個步驟中

37
00:01:58,665 --> 00:02:01,195
實際上只用一行程式

38
00:02:01,195 --> 00:02:06,930
我將建立一個 1

39
00:02:06,930 --> 00:02:13,100
乘 m 矩陣實際是一個行向量我將計算z1

40
00:02:13,100 --> 00:02:15,405
z2 ...等等

41
00:02:15,405 --> 00:02:18,480
一直到zm, 一次解決

42
00:02:18,480 --> 00:02:22,175
實際上這個可以表示成

43
00:02:22,175 --> 00:02:29,225
W轉置 大寫矩陣X 加這個向量 B

44
00:02:29,225 --> 00:02:31,040
B, ... 等等

45
00:02:31,040 --> 00:02:33,315
而這個

46
00:02:33,315 --> 00:02:34,480
B, B. B, B

47
00:02:34,480 --> 00:02:38,980
東西是一個 1乘m 向量或者說

48
00:02:38,980 --> 00:02:46,725
1乘m 矩陣有 m 維度行向量

49
00:02:46,725 --> 00:02:50,495
依照您對於矩陣乘法的熟悉程度

50
00:02:50,495 --> 00:02:56,300
您也許把 W 轉置 X1,

51
00:02:56,300 --> 00:02:58,760
X2,... 到 Xm

52
00:02:58,760 --> 00:03:05,755
W轉置當作一個行向量

53
00:03:05,755 --> 00:03:10,655
這個W轉置會是一個行向量像這樣

54
00:03:10,655 --> 00:03:18,614
第一個項目會是計算W轉置X1,

55
00:03:18,614 --> 00:03:22,970
W轉置X2等等...

56
00:03:22,970 --> 00:03:29,840
W轉置Xm, 然後加第二項 B

57
00:03:29,840 --> 00:03:30,960
B, B, ..等等

58
00:03:30,960 --> 00:03:33,565
您在每個項目最後加上B

59
00:03:33,565 --> 00:03:37,650
您最終得到另一個 1 乘m 向量

60
00:03:37,650 --> 00:03:38,955
而第一個項目

61
00:03:38,955 --> 00:03:40,590
第二個項目等等

62
00:03:40,590 --> 00:03:42,810
總共 m 個元素

63
00:03:42,810 --> 00:03:45,605
而如果您對應上面的定義

64
00:03:45,605 --> 00:03:51,250
第一個元素剛好是 z1

65
00:03:51,250 --> 00:03:57,305
第二個元素剛好是 z2 等等

66
00:03:57,305 --> 00:04:00,035
就像我們得到大寫X

67
00:04:00,035 --> 00:04:02,870
您拿您的訓練例子

68
00:04:02,870 --> 00:04:07,400
將他們一個疊一個, 水平疊起來一樣

69
00:04:07,400 --> 00:04:11,069
我將定義大寫Z 像

70
00:04:11,069 --> 00:04:16,385
您用這個小寫 z 將它們水平疊在一起

71
00:04:16,385 --> 00:04:21,080
就像您水平疊這些小寫 x 相對應到每個不同的訓練例子

72
00:04:21,080 --> 00:04:24,350
您得到大寫 X

73
00:04:24,350 --> 00:04:27,420
一樣的方式當您拿這些小寫 z

74
00:04:27,420 --> 00:04:28,805
水平疊在一起

75
00:04:28,805 --> 00:04:34,050
您得到這個變數大寫 Z

76
00:04:34,050 --> 00:04:37,400
而實際上, 為了建置這個

77
00:04:37,400 --> 00:04:45,773
numpy 的指令是大寫 Z 等於 np.dot(W.T, X) + B

78
00:04:45,773 --> 00:04:51,095
就是 W 轉置X 加 B

79
00:04:51,095 --> 00:04:53,645
Python 有一個微妙的地方

80
00:04:53,645 --> 00:04:59,405
也就是 b 是一個實數或者您可以說 1乘1矩陣

81
00:04:59,405 --> 00:05:01,330
就是一個平常的實數

82
00:05:01,330 --> 00:05:06,230
但, 當您加這個向量跟這個實數

83
00:05:06,230 --> 00:05:13,235
Python 自動拿這個實數 b 展成一個 1乘m 行向量

84
00:05:13,235 --> 00:05:16,490
如果這個運算看起來有點奧妙

85
00:05:16,490 --> 00:05:20,120
這是稱為 Python 廣播 (broadcasting)

86
00:05:20,120 --> 00:05:22,210
您現在先不用擔心

87
00:05:22,210 --> 00:05:25,760
我們會在下ㄧ段影片談到

88
00:05:25,760 --> 00:05:29,180
但請記住只用一行程式, 就是這一行程式

89
00:05:29,180 --> 00:05:33,290
您可以計算大寫 Z 而大寫 Z

90
00:05:33,290 --> 00:05:37,698
將是一個 1乘m 的矩陣包含所有的小寫 z

91
00:05:37,698 --> 00:05:41,200
小寫 z1 直到小寫 zm

92
00:05:41,200 --> 00:05:46,255
所以這是 Z, 那 A 呢?

93
00:05:46,255 --> 00:05:48,260
我們接著想要做的是

94
00:05:48,260 --> 00:05:52,685
找一個方式來計算 A1

95
00:05:52,685 --> 00:05:57,220
A2...到 Am

96
00:05:57,220 --> 00:05:58,700
在同一時間

97
00:05:58,700 --> 00:06:03,350
就像堆疊小寫 x 成為

98
00:06:03,350 --> 00:06:08,870
大寫 X, 堆疊小寫 z 成為大寫 Z 一樣

99
00:06:08,870 --> 00:06:10,810
堆疊小寫 a

100
00:06:10,810 --> 00:06:12,470
將會造成新的變數

101
00:06:12,470 --> 00:06:15,200
我們將其定義為大寫A

102
00:06:15,200 --> 00:06:18,075
而在程式作業中

103
00:06:18,075 --> 00:06:22,790
您會看到如何建立一個向量值S型函數

104
00:06:22,790 --> 00:06:24,480
所以用S型函數

105
00:06:24,480 --> 00:06:32,380
輸入這個大寫 Z 為變數會非常有效率輸出大寫 A

106
00:06:32,380 --> 00:06:36,620
您會在程式作業中看到所有細節

107
00:06:36,620 --> 00:06:38,110
總結一下

108
00:06:38,110 --> 00:06:42,655
我們在這張投影片看到的是與其使用迴圈來經過

109
00:06:42,655 --> 00:06:47,515
m 個訓練例子計算小寫 z 跟小寫 a

110
00:06:47,515 --> 00:06:52,090
一次一個, 您可以使用這一行程式

111
00:06:52,090 --> 00:06:54,290
來同時計算所有這些 z

112
00:06:54,290 --> 00:06:57,100
而用這一行程式

113
00:06:57,100 --> 00:06:59,260
使用適當的建置

114
00:06:59,260 --> 00:07:04,115
小寫 Sigma 來同時計算所有小寫 a

115
00:07:04,115 --> 00:07:05,965
所以這是您如何同時來建立

116
00:07:05,965 --> 00:07:07,948
向量化建置的

117
00:07:07,948 --> 00:07:11,560
正向傳播於所有 m 個訓練例子

118
00:07:11,560 --> 00:07:13,985
總結一下, 您剛看過您如何使用

119
00:07:13,985 --> 00:07:18,100
很有效的向量化來計算所有的啟動

120
00:07:18,100 --> 00:07:21,700
同時計算小寫 a

121
00:07:21,700 --> 00:07:24,860
接下來, 您也可以很有效率使用向量化

122
00:07:24,860 --> 00:07:27,910
來計算反向傳播

123
00:07:27,910 --> 00:07:29,650
跟計算導數

124
00:07:29,650 --> 00:07:32,000
我們在下一段影片看如何做到